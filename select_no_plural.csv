submission_id;locale;setting_value
21;en_US;"Scientific experiment usually demand high performance computing (HPC) and involve the execution of a flow of activity, so they can be modeled as scientific workflows. ScientificWorkflow Management system (SWfMS) provide ways of defining and executing these experiment in HPC environments and they produce detailed information about the workflow composition and execution. However, analyzing this information is not always trivial. This paper presents a profiling framework called HPSW-Prof1 that aims to provide the user with a set of feature for the statistical treatment and manipulation of provenance information obtained from scientific experiment executed with SWfMS Swift. Through the HPSW-Prof, data analysis can become a transparent process since it also offers a visualization layer that supports user for better accessing and manipulating their result."
22;en_US;"Spatial indices like the R-tree and the R*-tree are widely employed in spatial databases to improve the spatial query processing, such as point query and spatial range query. Different parameters are conceivable for spatial indices, which directly impact in their performance. Despite there are many evaluations of spatial indices in the literature, the reproducibility of these evaluations requires much implementation efforts. In this paper, we propose FESTIval, a PostgreSQL extension that provides a unique environment to evaluate different spatial indices with different parameters. As a result, FESTIval automatically collects statistical data of performed operations and allows the performance comparison of spatial indices by using different metrics."
25;en_US;"<p>The analysis of complex network, represented by graph, finds application in several area of knowledge. In this paper, we analyze the performance of graph processing platforms, which represent different approaches to the problem. In our evaluation, we also consider analysis algorithm that are<br>of great interest of the community (connectivity, centrality, and path), as well as a set of real and synthetic network with diverse topological characteristics and dimensions. The obtained experimental result contribute with guidelines for those interest to better select the most efficient graph processing platform to their analytics interests.</p>"
26;en_US;"<p>The development of the Internet of Things (IoT) has led to a considerable increase in the number and variety of device connected to the Internet. sensor have become a regular part of our environment, installed incars and buildings, as well as smart phones and other device that continuously collect data about our lives even without our intervention. With such connected device, a broad range of application has been developed and deployed, including those dealing with massive volumes of data. In this paper,<br>we propose a data management approach within an IoT environment, thus contributing with the specification of functionalities and the conception of technique for collecting, filtering and storing data conveniently and efficiently. Our main goal is to enable multiple and distinct middleware to work together in a non-intrusive manner. The corresponding developed prototype is used for the validation of our proposal in a case study regarding<br>a Smart Home System scenario.</p>"
27;en_US;"<p>Stance detection aims to automatically identify if the text author is in favor or against a subject or target. This work describes a semi-supervised method for stance detection. The core is a set of rule to identify stance based on positive or negative opinions of targets directly or indirectly related. Tweets<br>automatically labeled using the rule compose a training corpus for a supervised approach. The resulting predictive model allows to predict the stance of unlabeled tweets. This paper presents the method and analyzes the obtained result when applied to different data domains like political candidatures, climate<br>change and legalization of abortion.</p>"
28;en_US;"<p>Nowadays, a massive volume of data has been produced by a variety of data source. The easy access to these data presents new opportunities. In this sense, choosing the most suitable data source for a specific use has become a challenge. The literature contains many work that perform quality<br>assessment in data source as a mean of solving this issue. However, only few work take into account the dynamicity of source. In this work, we address the problem of performing data quality assessment in dynamic data source. Furthermore, we propose the establishment of a Quality Profile, which consists<br>in a set of metadata that provides information about the quality of a data source. The experiment performed on real-world scenarios have demonstrated that our strategy produces satisfactory result.</p>"
29;en_US;"<p>Set similarity join is a core operation for text data integration, cleaning, and mining. Previous research work on improving the performance of set similarity joins mostly focused on sequential, CPU-based algorithm. Main optimizations of such algorithm exploit high threshold values and the underlying data characteristics to derive efficient filters. In this paper, we investigate strategies to accelerate set similarity join using Graphic Processing Units (GPUs). Our approach exploits massive parallelism instead of filtering and, as a result, exhibits much better robustness to variations of threshold values and data distributions. Experimental evaluation shows that we are able to obtain up to 57x speedups over highly optimized CPU-based algorithm.</p>"
30;en_US;"<p>Contradiction Analysis is a relatively new multidisciplinary and complex area with the main goal of identifying contradictory pieces of text. It can be addressed from the perspectives of different research area such as Natural Language Processing, Opinion Mining, Information Retrieval, and Information Extraction. This paper focuses on the problem of detecting sentiment-based contradictions which occur in the sentences of a given review text. Unlike other types of contradictions, the detection of sentiment-based contradictions can be tackled as a post-processing step in the traditional sentiment analysis task. In this context, we adapted and extended an existing contradiction analysis framework by filtering its result to remove the review that are erroneously labeled as contradictory. The filtering method is based on two simple term similarity algorithm. An experimental evaluation on real product review has shown proportional improvements of up to 30% in classification accuracy and 26% in the precision of contradiction detection.</p>"
31;en_US;"<p>The ever increasing volume of data produced nowadays presents challenges for storing and processing this data. Traditional database solutions are not efficient to face these challenges, especially with respect to scalability. One approach to provide scalability is the adoption of a layered architecture which<br>combines a distributed storage system with a simple access interface. This paper presents ALOCS, a distributed repository which adopts the key-value model, allowing the user application to control the allocation of data into servers. The goal is to allow the application to co-allocate data that are frequently used to gether. Our experimental study shows that ALOCS improves query response times by reducing the amount of remote data accesses.</p>"
34;en_US;"It is well-known that fine tuning in database physical design is an important strategy for speeding up data access. In this paper, we introduce a new approach, denoted HypoPlans, to make relational database system able to execute self-tuning actions, based on the notion of Hypothetical Query Execution Plans. HypoPlans is non-intrusive and completely autonomous. In this sense, it is DBMS-independent and does not require any DBA intervention. Our approach is based on heuristics that run continuously. Thus, HypoPlans is able to guide decisions on the current physical database configuration in order to dynamically react to workload changes. More specifically, we present in this paper the software architecture of a framework, which implements HypoPlans. In order to evaluate the viability of our approach, we have instantiated this framework for the database physical design concerning index (self)tuning. Our experiment show that HypoPlans is quite effective and efficient, also presenting low resource consumption."
43;en_US;"The Relational Algebra is composed of several operators to assist query and data manipulation on Relational Databases. The Relational Division operator, particularly, allows simple representations of several query involving the concept of “for all”, however, the SQL does not have an explicit implementation for it. In this paper, we compare the performance of the best implementation known for the division operator in SQL, considering different cases of use. We also present a new algorithm for the division, which we implemented through stored procedures. We performed a case study using the relational division to select genetic data. The result showed that our implementation for the relational division is potentially faster than the best implementation in SQL."
44;en_US;"Diversity has been promoted in image retrieval result using clustering algorithm to tackle query, which refer to multiple information needs, e.g., due to ambiguity. Despite the effective result of diversity-aware method, the image wealth of large collections and the subjectivity of human perception bring the semantic gap problem. This paper presents multimodal fusion approaches aimed at reducing the diversity gap with ensemble clustering and dimensionality reduction. The applied method were evaluated by quantifying the clustering effectiveness in comparison to human decisions. The experimental result demonstrate the potential of these approaches to boost diversity-oriented engines and that they could improve state-of-the-art system. "
46;en_US;"A new era of computer with solid state memory (SSDs) chips providing petabytes of storage area is coming. Nonetheless database system (DBSs) were designed presupposing that databases are persisted in hard disk drives (HDDs) for storing databases. Over the years, DBS components have been optimized based on performance characteristics of HDDs. Simply replacing HDDs by faster SSDs may not fully exploit the capabilities of SSDs. In this paper, we present and defend the idea of hardware-aware database system in order to make database system able to fully exploit the advantages provided by new hardware, such as solid state memories."
49;en_US;"Issues in the area of geographic databases, caused by the lack of a standard geographic conceptual data model, can be classified as interoperability problem. This paper proposes a method to reach horizontal interoperability, i.e., a schema can be transformed in another schema designed using a different model. UML infrastructure and the Enterprise Architect CASE tool are used in the process. To reduce the number of transformations between all schemas, a UML Profile called GeoProfile is used as a base model. OCL expressions are used to enforce spatial constraints."
51;en_US;"This work presents, for the first time in literature, a low-cost framework to mine data obtained from passengers smart cards, buses GPS and bus stops geolocation using Lambda Architecture approach. Operators, company, government and passengers will use this knowledge for improving usability, comfort, and quality of transportation service. This analysis gives greater insight into the volume and flow of passengers and the real existing demand for bus service, facilitating its control and management, allowing decision-making. As result, bus stops and city area are classified according to buses demand."
55;en_US;"A myriad of application from different domains collects time serie data for further analysis. In many of them, such as seismic dataset, the observed data is also associated to a space dimension, which corresponds, in fact, to spatial-time serie. The analysis of these dataset is difficult due to both the continuous nature of the observed data and the relationship between spatial and time dimensions. Meanwhile, sequential pattern mining technique have been successfully used in large volume of transactional databases to obtain insights from data. In this work, we start exploring the discovery of frequent sequential pattern in seismic dataset. For that, we discretize continuous values into symbols and adapt well known sequential algorithm to mine spatial-time dataset. To better understand the quality of the identified pattern, we visualize them over the original seismic traces image. Our preliminary result indicate that the study of sequence mining in seismic dataset is promising."
56;en_US;"Social coding is an approach of software development that enables cooperation among developers. Specially, GitHub can be modeled as a social coding network and its study allows the discovery of relevant pattern, e.g., the collaborations strength. Finding such pattern may help to improve the recommendation of developers and the evaluation of team formation. Here, our goal is to analyze the correlation between network properties and such strength."
59;en_US;"The search for educational content in courseware repositories is laborious and time consuming. There is an abundance of such repositories, and research efforts to facilitate search, but access is guided by keyword and/or terms selected by courseware authors, thus lacking flexibility. The goal of this project is to design and develop a suite of tool to assist user to find, analyze and select pieces of educational content that are relevant to their learning goals. Contributions will be both at the algorithm and software design level, and at the user (application) level."
83;en_US;"Dengue fever is a mosquito-borne disease present in all Brazilian territory. Brazilian government, however, lacks an accurate early warning system to quickly predict future dengue outbreaks. Such system would help health authorities to plan their actions and to reduce the impact of the disease in the country. However, most attempts to model dengue fever use parametric model which enforce a specific expected behaviour and fail to capture the inherent complexity of dengue dynamics. Therefore, we propose a new Bayesian non-parametric model based on Gaussian process to design an accurate and flexible model that outperforms previous/standard technique and can be incorporated into an early warning system, specially at city from Southeast and Center-West regions. The model also helps understanding dengue dynamics in Brazil through the analysis of the covariance functions generated."
84;en_US;"The classification task, when performed by machine learning algorithm, requires previous training on labeled instances. In many application, the data labeling process is expensive and can affect the predictive performance of classification model. A current solution has been the use of active learning, which investigates strategies for data labeling. Its main goal is to decide which instances should be labeled and added to the training set, reducing the overall labeling costs. However, the strategy normally depends on a learning algorithm, which should be chosen by a machine learning specialist - usually based on a cross-validation procedure. Consequently, there is a deadlock: without the complete training set, the algorithm that will present the best learning curve cannot be known in advance. Ideally, some type of automatic selection should be employed to solve this deadlock. This study investigates the use of meta-learning for automatic algorithm selection in active learning tasks. Experimental result show that meta-learning is able to find correspondences between algorithm and dataset feature in order to help active learning to reduce the risks of incurring in unexpected labeling costs."
85;en_US;"Supervised classification is the most studied task in Machine Learning. Among the many algorithm used in such task, Decision Tree algorithm are a popular choice, since they are robust and efficient to construct. Moreover, they have the advantage of producing comprehensible model and satisfactory accuracy levels in several application domains. Like most of the Machine Leaning method, these algorithm have some hyperparameters whose values directly affect the performance of the induced model. Due to the high number of possibilities for these hyper-parameter values, several studies use optimization technique to find a good set of solutions in order to produce classifier with good predictive performance. This study investigates how sensitive decision trees are to a hyper-parameter optimization process. Four different tuning technique were explored to adjust J48 Decision Tree algorithm hyper-parameters. In total, experiment using 102 heterogeneous dataset analyzed the tuning effect on the induced model. The experimental result show that even presenting a low average improvement over all dataset, in most of the cases the improvement is statistically significant."
86;en_US;"The Goal-Directed Risk-Sensitive Markov Decision Process allows arbitrary risk attitudes for the probabilistic planning problem to reach a goal state. In this problem, the risk attitude is modeled by an expected exponential utility and a risk factor λ. However, the problem is not well defined for every λ, posing the problem of defining the maximum (extreme) value for this factor. In this paper, we propose an algorithm to find this  -extreme risk factor and the corresponding optimal policy."
87;en_US;"In this paper we study the application of a domaindependent heuristic to airport ground traffic control. We consider two variants of the problem. In the first, proposed for the International Planning Competition in 2004, the in-bound and out-bound airplanes have fixed parking and take-off positions. In the second, more realistic variant a controller can assign dynamically for each airplane the runway for take-off or the parking position, such that the total movement of planes at the airport is minimized. We are particularly interested in the second variant, which has an implicitly defined goal state where multiple states could satisfy the goal condition, and the impact of this fact on domain-independent and domain-dependent heuristics. We compare domain-independent heuristics in the Fast Downward planner on this domain to a domain-dependent heuristic."
88;en_US;"In this paper we study the application of pattern databases (PDBs) to optimally solving Atomix. Atomix is a puzzle, where one has to assemble a molecule from atoms by sliding moves. It is particularly challenging, because the slides makes it hard to create admissible heuristics, and state-of-theart heuristics are rather uninformed. A pattern database (PDB) stores solutions to an abstract version of a state space problem. An admissible lower bound for a given state is obtained by decomposing it into abstract states and combining their precomputed solutions. Different from other puzzles a pattern in Atomix cannot be simply obtained by omitting pieces from the puzzle. We also study the search algorithm Partial Expansion A∗’s application to Atomix, as a reduced-memory alternative to A∗. experiment show our method solves more instances and significantly improves current lower bounds, running times and node expansions compared to the best solution in the literature."
89;en_US;"Planning with partial observation, an area called contingent planning, is a complex and challenging problem since it requires to keep track of belief states to search for a contingent plan of actions. Recent approaches considers the agent’s knowledge about the world to compile a contingent planning problem into a full observable planning problem, described in an epistemic logic language, and then use an efficcient full observable planner to solve the translated problem. In this paper we use the concept of relevance and causality to propose a new translation based in a structure called Causal Graph that can improve the belief tracking task of contingent Planning problem described in a more general planning language, in particular problem envolving actions with uncertainty on its conditional effects."
90;en_US;"The imbalance problem is receiving an increasing attention in the literature. Studies in binary cases are recurrent, however there still are several real world problem with more than two classes. The known solutions for binary dataset may not be applicable in this case. Some efforts are being applied in decomposition technique which transforms a multiclass problem into some binary problem. However it is also possible to face a multiclass problem with an ad hoc approach, i.e., a classifier able to handle all classes at once. In this work a method able to handle several classes is proposed. This new method is based on the Voronoi diagram. We try to dynamically divide the feature space into several regions, each one assigned to a different class. It is expected for the method to be able to construct a complex classification model. However, as it is in its beginning, some tests need to be performed in order to evaluate its feasibility. experiment with some classical classifier confirm its feasibility, and comparisons with ad hoc method found in literature show its potentiality."
91;en_US;"Semi-supervised learning is a challenging topic in machine learning that has attracted much attention in recent years. The availability of huge volumes of data and the work necessary to label all these data are two of the reasons that can explain this interest. Among the various method for semisupervised learning, the co-training framework has become popular due to its simple formulation and promising result. In this work, we propose Co-MLM, a semi-supervised learning algorithm based on a recently supervised method named Minimal Learning Machine (MLM), built upon co-training framework. experiment on UCI data sets showed that Co-MLM has promising performance in compared to other co-training style algorithm."
92;en_US;"An usual strategy to solve multiclass classification problem in Machine Learning is to decompose them into multiple binary sub-problem. The final multiclass prediction is obtained by a proper combination of the outputs of the binary classifier induced in their solution. Decision directed acyclic graph (DDAG) can be used to organize and to aggregate the outputs of the pairwise classifier from the one-versus-one (OVO) decomposition. Nonetheless, there are various possible DDAG structures for problem with many classes. In this paper evolutionary algorithm are employed to heuristically find the positions of the OVO binary classifier in a DDAG. The objective is to place easier sub-problem at higher levels of the DDAG hierarchical structure, in order to minimize the occurrence of cumulative errors. For estimating the complexity of the binary sub-problem, we employ two indexes which measure the separability of the classes. The proposed approach presented sound result in a set of experiment on benchmark dataset, although random DDAGs also performed quite well."
93;en_US;"Many weightless neural network, such as WiSARD, are RAM-based classifier that receive binary data as input. In order to convert raw data into binary input, several technique are applicable. This work evaluates the impact of some of these binarization technique on the accuracy of two types of classifier: WiSARD model and WiSARD with bleaching mechanism. The binary encoding technique explored were: (i) thermometer, (ii) threshold, (iii) local threshold, (iv) Marr-Hildreth filter, and (v) Laplacian filter. The MNIST digit dataset was used to compare the accuracy obtained by each encoding technique. result showed a difference of more than 20% in the accuracy due to the choice of encoding approach."
94;en_US;"The existence of missing data is a common fact in real application which can significantly affect the data analysis process. In order to overcome this problem, many method have been proposed in the literature. Extreme Learning Machine (ELM) has become a very popular research topic in machine learning and artificial intelligence area due to its characteristics such as fast training procedure, good generalization and universal approximation capability. Although ELM has been successfully applied in different domains, its basic formulation cannot handle dataset with missing values properly. This paper presents a variant of the Extreme Learning Machine (ELM) for dataset with missing values. In the proposed method, probability distributions for the missing values are estimated using the expectation maximization (EM) algorithm, assuming that data is normally distributed. The Unscented Transform (UT) is used to estimate the values of the hidden layer outputs, and the weights of the output layer are assigned using the Moore-Penrose Pseudoinverse. Numerical experiment are carried out in order to evaluate the performance of the proposed method in four real world and two synthetic regression dataset. The result show that the proposed method presented a good performance in terms of Average RootMean-Squared Error (ARMSE)."
95;en_US;"Driven by recent developments in the area of Artificial Intelligence research, a promising new technology for building intelligent agent has evolved. The technology is termed Deep Reinforcement Learning (DRL) and combines the classic field of Reinforcement Learning (RL) with the representational power of modern Deep Learning approaches. DRL enables solutions for difficult and high dimensional tasks, such as Atari game playing, for which previously proposed RL method wereinadequate. However, these new  olution approaches still take a long time to learn how to actuate in such domains and so farare mainly researched for single task cenarios. The ability to generalize gathered knowledge and transfer it to another task has been researched for classical RL, but remains an open problem for the DRL domain. Consequently, in this article we evaluate under which conditions the application of Transfer Learning (TL) to the DRL domain improves the learning of a new task. Our result indicate that TL can greatly accelerate DRL when transferring knowledge from similar tasks, and that the similarity between tasks plays a key role in the success or failure of knowledge transfer."
97;en_US;"In this paper, we present a novel supervised learning algorithm for object recognition from sets of image, where the sets describe most of the variation in an object’s appearance caused by lighting, pose and view angle. In this scenario, generalized mutual subspace method (gMSM) has attracted attention for image-set matching due to its advantages in accuracy and robustness. However, gMSM employs PCA, which has high computational cost contrasting to state-of-art appearancebased method. To create a faster method, we replace the traditional PCA by 2D-PCA and variants on gMSM framework. In general, 2D-PCA and variants require less memory resource than conventional PCA since its covariance matrix is calculated directly from two-dimensional matrices. The introduced method has the advantage of representing the subspaces in a more compact manner, providing reasonably competitive recognition rate comparing to the traditional MSM, confirming the suitability of employing 2D-PCA and variants on gMSM framework. These result have been revealed through experimentation conducted on five widely used dataset."
100;en_US;"In this paper, we propose a new no-reference quality assessment ethod which uses a machine learning technique based on texture analysis. The proposed method compares test image with texture image of a public database. Local Binary pattern (LBPs) are used as local texture feature descriptors. With a Csiszar-Morimoto divergence measure, the histograms of ´ the LBPs of the test image are compared with the histograms of the LBPs of the database texture image, generating a set of difference measures. These difference measures are used to blindly predict the quality of an image. Experimental result show that the proposed method is fast and has a good quality prediction power, outperforming other no-reference image quality assessment method."
101;en_US;"Twitter is one of the most used social media with user generating about 1 million message per day. As a result of the expansion of this microblog, there is a diversity of language used by user and many studies aimed at identifying the language of tweets. The third most used language on Twitter is Portuguese, a pluricentric language with two national standard varieties: Brazilian Portuguese and European Portuguese. Identifying a language variety may positively impact various Natural Language Processing tasks, but accomplishing this task is still regarded as one of the bottlenecks in this area, especially when combined with another bottleneck, language identification applied to short text. Thus, given these challenges, this paper provides a current view on the automatic discrimination of the two main Portuguese language varieties on Twitter text by using an acknowledged approach with different technique and feature in order to get an optimum configuration to fit our problem. result reached 0.9271 for accuracy using an ensemble method, which combines character 6- grams and word unigrams and bigrams."
102;en_US;"Unsupervised feature such as word representations mostly given by word embeddings have been shown significantly improve semi supervised Named Entity Recognition (NER) for English language. In this work we investigate whether unsupervised feature can boost (semi) supervised NER in Spanish. To do so, we use word representations and collocations as additional feature in a linear chain Conditional Random Field (CRF) classifier. Experimental result (82.44% F-score on the CoNLL- 2002 corpus and 65.72% F-score on Ancora Corpus) show that our approach is comparable to some state-of-art Deep Learning approaches for Spanish, in particular when using cross-lingual Word Representations."
103;en_US;"Social query is the practice of sharing questions through collaborative environments. In order to receive help, askers usually broadcast their requests to the entire community. However, the prerequisite to receive help is to have the problem noticed by someone who is able and available to answer. Previous work have identified a correlation between the characteristics of the questions and the outcome of receiving or not an answer. These findings suggest that there are some characteristics that are more likely to attract the helpers´ attention. Our proposal is to analyze the CQA history to identify how these so-called “good” characteristics affect the performance of shared questions. Our result suggest that: (1) answered questions present more of these “good” characteristics than unanswered ones; (2) the more “good” characteristics are present in a question, the more people it attracts; (3) the more people are attracted by a question, the faster it will be answered and more responses will be received; (4) answered questions attract more people than unanswered ones; (5) difficulty does not play a role in attracting people."
104;en_US;"Short text are everywhere on the Web, including message in social media, status message, etc, and extracting semantically meaningful topic from these collections is an important and difficult task. Topic modeling method, such as Latent Dirichlet Allocation, were designed for this purpose. However, discovering high quality topic in short text collections is a challenging task. This is because most topic modeling method rely on information coming from the word co-occurrence distribution in the collection to extract topic. As in short text this information is scarce, topic modeling method have difficulties in this scenario, and different strategies to tackle this problem have been proposed in the literature. In this direction, this paper introduces a method for topic modeling of short text that creates pseudo-document representations from the original document. The method is simple, effective, and considers word co-occurrence to expand document, which can be given as input to any topic modeling algorithm. experiment were run in four dataset and compared against state-of-the-art method for extracting topic from short text. result of coherence, NPMI and clustering metrics showed to be statistically significantly better than the baselines in the majority of cases."
105;en_US;"Particle Swarm Optimization algorithm (PSO) has been largely studied over the years due to its flexibility and competitive result in different application. Nevertheless, its performance depends on different aspects of design (e.g., inertia factor, velocity equation, topology). The task of deciding which is the best algorithm design to solve a particular problem is challenging due to the great number of possible variations and parameters to take into account. This work proposes a novel context-free grammar for Grammar-Guided Genetic Programming (GGGP) algorithm to guide the construction of Particle Swarm Optimizers. The proposed grammar addresses four aspects of the PSO algorithm that may strongly influence on its convergence: swarm initialization, neighborhood topology, velocity update equation and mutation operator. To evaluate this approach, a GGGP algorithm was set with the proposed grammar and applied to optimize the PSO algorithm in 32 unconstrained continuous optimization problem. In the experiment, we compared the designs generated considering the proposed grammar with the designs produced by other grammars proposed in the literature to automate PSO designs. The result obtained by the proposed grammar were better than the counterparts. Besides, we also compared the generated algorithm to stateof-art algorithm. The result have shown that the algorithm produced from the grammar achieved competitive result."
107;en_US;"Supervised machine learning (ML) and lexiconbased are the most frequent approaches for opinion mining (OM), but they require considerable effort for preparing the training data and to build the opinion lexicon, respectively. This paper presents two unsupervised approaches for OM based on Particle Swarm Optimization (PSO). The PSO-based approaches were evaluated by eighteen experiment with different corpora types, domains, language, class balancing and pre-processing technique. The proposed approaches achieved better accuracy on twelve experiment. Best result were obtained on corpora with a reduced number of dimensions and for specific domains. Best accuracy (0.79) was obtained by Discrete IDPSO on the OBCC corpus, outperforming supervised ML and lexicon-based approaches for this corpus."
108;en_US;"Data clustering is an important tool for statistical data analysis and exploration, and it has been successfully applied in many fields like image understanding, bioinformatics, big data mining, and so on. From the past few decades, Evolutionary algorithm (EAs) have been introduced to deal with clustering task, given their global search capabilities and their mechanism to escape from local minima points. EAs execution is driven in an attempt to optimize a criterion function, also known as fitness function. In this work, we evaluate the influence of the fitness function on Group Search Optimization (GSO) meta-heuristic when applied to data clustering. Three different fitness function are proposed to GSO. experiment are performed on twelve benchmark data sets obtained from UCI Machine Learning Repository to evaluate the performance of all alternative GSO model in comparison to other well-known partitional clustering method from literature."
109;en_US;"One-class classification (OCC) is an important problem with application in several different area such as outlier detection and machine monitoring. Since in OCC there are no examples of the novelty class, the description generated may be a tight or a bulky description. Both cases are undesirable. In order to create a proper description, the presence of examples of the novelty class is very important. However, such examples may be rare or absent during the modeling phase. In these cases, the artificial generation of novelty sample may overcome this limitation. In this work it is proposed a two steps approach for generating artificial novelty examples in order to guide the parameter optimization process. The result show that the adopted approach has shown to be competitive with the result achieved when using real (genuine) novelty sample."
110;en_US;"Given an edge-weighted simple graph G, the minimum quadratic spanning tree problem consists in finding a spanning tree of G such that the sum of the weights of its edges plus the sum of the product of the weights of pairs of edges is minimum over all spanning trees of G. When the product of the weights of pairs of edges is calculated only for adjacent edges, the problem is called adjacent-only minimum quadratic spanning tree. This problem belongs to NP-hard. In this study we investigate the performance of a tabu search algorithm with ejection chain for the bi-objective version of this problem. An experiment with 168 instances is reported."
111;en_US;"Transcription is the process of making an RNA copy of a gene sequence. Next, this copy (mRNA) is then translated into proteins. Proteins dictates the expected behavior inside the cells and are required for the structure, function, and regulation of the body’s tissues and organs. Together, transcription and translation are known as gene expression. Transcriptograms are basically defined as “image” of gene expression data of genomes, by generating expression profiles for transcriptomes. They allow to assess cell metabolism, being capable of discriminating the stage the cell is going through at a given instant, as well as pointing metabolic changes in altered cellular states as compared to a control state, independently of the transcriptome profilling protocol. Though, they cannot highlight differential expression profiles. We present a new possibility of RNA-Seq data analysis using Transcriptograms for discovering module-based differential expression profiles. We demonstrate its practical application while obtaining more specific gene signatures as well as functional annotations, closely related to biomedical context. Moreover, these signatures are also enriched by survival cancer analysis."
112;en_US;"Property Crime has been highlighted as one of the major criminal offenses within the Brazilian Legal System. Moreover, it is common that there is some misunderstanding amongst the subtypes of this crime, such as Theft, Robbery, Misappropriation, and Extortion. We still emphasize the very nuance of legal literature that makes this domain as hostile as challenging: a weakly formalized knowledge, the presence of conflicts and ambiguities between norms, the heterogeneity of legal literature, as well as the diversity in reasoning model. Therefore, this article presents, inspired by UFO-B foundational ontology, a conceptual model for the representation of crime against property in the Brazilian Criminal Code, in order to support some decision-making process, as the agent behavior classification and the inference of punishments. Thus, we present throughout this article, an ontological formalization for the Theory of Crime from Brazilian Penal Code, as well as for Property crime application."
113;en_US;"The exponentially grow of Web and data availability, the semantic web area has expanded and each day more data is expressed as knowledge bases. Knowledge bases (KB) used in most project are represented in an ontology-based fashion, so the data can be better organized and easily accessible. It is common to map these KBs into a graph when trying to induce inference rule from the KB, thus it is possible to apply graph-mining technique to extract implicit knowledge. One common graph-based task is link prediction, which can be used to predict edges (new facts for the KB) that will appear in a near future. In this paper, we present Graph Rule Learner (GRL), a method designed to extract inference rule from ontological knowledge bases mapped to graph. GRL is based on graph-mining technique, and explores the combination of link prediction metrics. Empirical analysis reveled GRL can successfully be applied to NELL(Never-Ending Language Learner)1 helping the system to infer new KB beliefs from existing beliefs (a crucial task for a never-ending learning system)."
114;en_US;"Probabilistic logic programming combines logic and probability, so as to obtain a rich modeling language. In this work, we extend PROBLOG, a popular probabilistic logic programming language, with new constructs that allow the representation of (infinite-horizon) Markov decision process. This new language can represent relational statements, including symmetric and transitive definitions, an advantage over other planning domain language such as RDDL. We show how to exploit the logic structure in the language to perform Value Iteration. Preliminary experiment demonstrate the effectiveness of our framework."
115;en_US;"Group profiling method aim to construct a descriptive profile for communities in complex network. The application of such method in the analysis of co-authorship network enables us to move forward in understanding the scientific communities, leading to new approaches to strengthen and expand scientific collaboration network. This task is similar to the document cluster labeling task, which encourages the adaptation of cluster labeling method for group profiling problem. In this work, we present a comparative study of group profiling and cluster labeling algorithm in a co-authorship network. A qualitative survey was conducted to evaluate the generated profiles, as well as the pros and cons of different profiling strategies, were analyzed with concrete examples. The result demonstrated a similar performance of both group profiling and cluster labeling method."
116;en_US;"Imbalanced data sets originating from real world problem, such as medical diagnosis, can be found pervasive. Learning from imbalanced data sets poses its own challenges, as common classifier assume a balanced distribution of examples’ classes in the data. Sampling technique overcome the imbalance in the data by modifying the examples’ classes distribution. Unfortunately, selecting a sampling technique together with its parameters is still an open problem. Current solutions include the brute-force approach (try as many technique as possible), and the random search approach (choose the most appropriate from a random subset of technique). In this work, we propose a new method to select sampling technique for imbalanced data sets. It uses Meta-Learning and work by recommending a technique for an imbalanced data set based on solutions to previous problem. Our experimentation compared the proposed method against the brute-force approach, all technique with their default parameters, and the random search approach. The result of our experimentation show that the proposed method is comparable to the brute-force approach, outperforms the technique with their default parameters most of the time, and always surpasses the random search approach."
117;en_US;"In this paper, we use the concept of extended Choquet integral generalized by a copula function, as proposed by Lucca et al.. More precisely, the copula considered in their study uses a variable α, with different fixed values for testing its behavior. In this contribution we propose a modification of this method assigning a value to this α parameter using a genetic algorithm in order to find the value that best fits it for each class. Specifically, this new proposal is applied in the Fuzzy Reasoning Method (FRM) of Fuzzy Rule-Based Classification system (FRBCSs). Finally, we compare the result provided by our new approach against the best solution proposed by Lucca et al. (that uses an fixed value for the variable α). From the obtained result it can be concluded that the genetic learning of the α parameter is statistically superior than the fixed one. Therefore, we demonstrate that our genetic method can be used as an alternative for this function."
118;en_US;"Concepts and method of complex network can be used to analyse text at their different complexity levels. Examples of natural language processing (NLP) tasks studied via topological analysis of network are keyword identification, automatic extractive summarization and authorship attribution. Even though a myriad of network measurements have been applied to study the authorship attribution problem, the use of motifs for text analysis has been restricted to a few work. The goal of this paper is to apply the concept of motifs, recurrent interconnection pattern, in the authorship attribution task. The absolute frequencies of all thirteen directed motifs with three node were extracted from the co-occurrence network and used as classification feature. The effectiveness of these feature was verified with four machine learning method. The result show that motifs are able to distinguish the writing style of different authors. In our best scenario, 57.5% of the books were correctly classified. The chance baseline for this problem is 12.5%. In addition, we have found that function word play an important role in these recurrent pattern. Taken together, our findings suggest that motifs should be further explored in other related linguistic tasks."
119;en_US;"The large amount of data produced by application in recent years needs to be analyzed in order to extract valuable underlying information from them. Machine learning algorithm are useful tool to perform this task, but usually it is necessary to reduce complexity of data using feature selection algorithm. As usual, many algorithm were proposed to reduce dimension of data, each one with its own advantages and drawbacks. The variety of algorithm leads to either choose one algorithm or to combine several method. The last option usually brings better performance. Based on this, this paper proposes an analysis of two distinct approaches of combining feature selection algorithm (decision and data fusion). This analysis was made in supervised classification context using real and synthetic dataset. result showed that one proposed approach (decision fusion) has achieved the best result for the majority of dataset"
120;en_US;"It is a great challenge to company, governments and researcher to extract knowledge in high dimensional databases. Discriminative pattern (DPs) is an area of data mining that aims to extract relevant and readable information in databases with target attribute. Among the algorithm developed for search DPs, it has highlighted the use of evolutionary computing. However, the evolutionary approaches typically (1) are not adapted for high dimensional problem and (2) have many nontrivial parameters. This paper presents SSDP (Simple Search Discriminative pattern), an evolutionary approach to search the top-k DPs adapted to high dimensional databases that use only two easily adjustable external parameters."
121;en_US;"Learning content from video is not an easy task and traditional machine learning approaches for computer vision have difficulties in doing it satisfactorily. However, in the past couple of years the machine learning community has seen the rise of deep learning method that significantly improve the accuracy of several computer vision application, e.g., Convolutional Neural network (ConvNets). In this paper, we explore the suitability of ConvNets for the movie trailers genre classifi- cation problem. Assigning genres to movies is particularly challenging because genre is an immaterial feature that is not physically present in a movie frame, so off-the-shelf image detection model cannot be directly applied to this context. Hence, we propose a novel classification method that encapsulates multiple distinct ConvNets to perform genre classification, namely CoNNECT, where each ConvNet learns feature that capture distinct aspects from the movie frames. We compare our novel approach with the current state-of-the-art technique for movie classification, which make use of well-known image descriptors and lowlevel handcrafted feature. result show that CoNNECT significantly outperforms the state-of-the-art approaches in this task, moving towards effectively solving the genre classification problem."
122;en_US;"Recent advances on multi-objective evolutionary algorithm (MOEAs) have acknowledged the important role played by selection, replacement, and archiving strategies in the behavior of these algorithm. However, the influence of these method has been scarcely investigated for the particular class of MOEAs that use probabilistic modeling of the solutions. In this paper we fill this void by proposing an analysis of the role of the aforementioned strategies on an extensive set of bi-objective functions. We focus on the class of algorithm that use Gaussian univariate marginal model, and study how typical selection and replacement strategies used together with this probabilistic model impact the behavior of the search. Our analysis is particularized for a set of bi-objective functions that exhibit a representative set of characteristics (e.g. decomposable, ill-conditioned, non-linear, etc.). The experimental result shows that MOEAs that use simple probabilistic modeling outperform traditional MOEAs based on crossover operators."
123;en_US;"Argumentation in multi-agent system provides both a mechanism for agent reasoning under uncertainty and conflicting information as well as for communication in a more elaborate way, allowing agent to understand each other through the exchange of additional information when compared to other forms of agent communication. Even though argumentation technique can play an important role in multi-agent system, little research has been carried out on the issues in integrating argumentation technique and agent-oriented programming language, which would allow the development of practical application taking advantage of such combined technique. In this work, we present an argumentation framework developed on the basis of an agentoriented programming language. We cover mainly the practical aspects of such integration, focusing on the knowledge representation expressivity resulting from it. Our approach allows the development of multi-agent application where agent are able to use arguments in their decision-making process as well as for communication. The framework has been successfully used as part of the development of a healthcare multi-agent prototype application."
124;en_US;"Although Reinforcement Learning method have successfully been applied to increasingly large problem, scalability remains a central issue. While Object-Oriented Markov Decision process (OO-MDP) are used to exploit regularities in a domain, Multiagent System (MAS) method are used to divide workload amongst multiple agent. In this work we propose a novel combination of OO-MDP and MAS, called Multiagent Object-Oriented Markov Decision Process (MOO-MDP), so as to accrue the benefits of both strategies and be able to better address scalability issues. We present an algorithm to solve deterministic cooperative MOO-MDPs, and prove that it learns optimal policies while reducing the learning space by exploiting state abstractions. We experimentally compare our result with earlier approaches and show advantages with regard to discounted cumulative reward, number of steps to fulfill the task, and Q-table size."
125;en_US;"Particle Swarm Optimization (PSO) is largely used to solve optimization problem effectively. Nonetheless, the PSO performance depends on the fine tuning of different parameters. To make the algorithm design process more independent from human intervention, some researcher have treated this task as an optimization problem. Grammar-guided Genetic Programming algorithm (GGGP), in special, have been widely studied and applied in the context of algorithm optimization. GGGP algorithm produce customized designs based on a set of production rule defined in the grammar; differently from method that simply select designs in a pre-defined limited search space. In this work, we proposed a tree-based GGGP technique for the generation of PSO algorithm. This paper intends to investigate whether this approach can improve the production of PSO algorithm when compared to other GGGP technique already used to solve the current problem. In the experiment, a comparison between the tree-based and the commonly used linearized GGGP approach for the generation of PSO algorithm was performed. The result showed that the tree-based GGGP produced better algorithm than the counterparts. We also compared the algorithm generated by the tree-based technique to state-of-art optimization algorithm, and the result showed that the algorithm produced by the tree-based GGGP achieved competitive result."
126;en_US;"Argumentation-based reasoning plays an important role in agent reasoning and communication, yet little research has been carried out on the issues in integrating argumentation technique into practical multi-agent platforms and the various source of information in such system. In this work, we extend an argumentation-based reasoning mechanism to take into account preferences over arguments supporting contrary conclusions, which in practice means the agent will be able to act more informedly, being able to decide on beliefs about which it would be otherwise ambivalent. Such preferences come from elements that are present or can be more easily obtained in the context of practical multi-agent programming platforms, such as multiple source from which the information (used to construct the arguments) was acquired, as well as varying degrees of trust on them. Further, we introduce different agent profiles by varying the way certain operators are applied over the various information source leading to the preferences over competing arguments in our approach. Unlike previous approaches, our approach accounts for multiple source for a single piece of information and is based on an argumentation-based reasoning mechanism implemented on a multi-agent platform so arguably more computationally grounded than those approaches."
132;en_US;"In this paper we study the facility leasing problem with penalties. We present a 3-approximation primal-dual algorithm, based on the algorithm by Nagarajan and Williamson for the facility leasing problem and by Charikar,
Khuller, Mount and Narasimhan for the facility location problem with penalties."
134;en_US;"In this paper we study the problem of coloring the edges of a graph for any k-list assignment such that there is no maximal monochromatic biclique, in other word, the k-biclique edge-choosability problem. We prove that the K3- free graph that are not odd cycles are 2-star edge-choosable, chordal bipartite graph are 2-biclique edge-choosable and we present a lower bound for the biclique choice index of power of cycles and power of paths. We also provide polynomial algorithm to compute a 2-biclique (star) edge-coloring for K3-free and chordal bipartite graph for any given 2-list assignment to edges."
135;en_US;"Given graph G and H, we denote the following property by G rbÝÑp H: for every proper edge-colouring of G (with an arbitrary number of colours) there is a rainbow copy of H in G, i.e., a copy of H with no two edges of the
same colour. It is known that, for every graph H, the threshold function p rb H “ p rb H pnq of this property for the binomial random graph Gpn, pq is asymptotically at most n ´1{mp2q pHq , where mp2q pHq denotes the so-called maximum 2-density of H. In this work we discuss this and some recent result in the study of antiRamsey properties in random graph, and we prove that if H “ C4 or H “ K4 then p rb H ă n ´1{mp2q pHq , which is in contrast with the known facts that p rb Ck “ n ´1{mp2q pCkq for k ě 7, and p rb K` “ n´1{mp2qpK`qfor k ě 19.
"
136;en_US;"Let G be a connected graph and P be a set of pairwise vertex-disjoint paths in G. We say that P is a path cover if every vertex of G belongs to a path in P. The minimum path cover problem asks for a path cover of minimum
cardinality. In this problem, known to be NP-hard, the set P may contain trivial (single-vertex) paths. We study a variant of this problem in which the objective is to find a path cover without trivial paths. Using the well-known EdmondsGallai decomposition, we show that deciding whether a graph contains such kind of path cover can be reduced to a matching problem on a bipartite graph. We also show hardness and inapproximability result for both problem."
140;en_US;"A deadlock occurs in a distributed computing when a group of process wait indefinitely for resource from each other. Such a property is stable, that is, once occurs into a global state it also will exist in any subsequent global state. Distributed computation are usually represented by wait-for graph, where the behavior of process is determined by a deadlock model. In this paper we consider the scenario where deadlock was detected in a system and then some deadlock-breaking set must be found and removed. Hence, given a
“snapshot” G of a deadlocked distributed computation which operates according to a deadlock model M, we investigate the complexity of vertex deletion and arc deletion problem whose goal is to obtain the minimum number of removals in order to turn G free of graph structures that characterize deadlocks. The complexity of such problem depends on the deadlock model which governs the computation as well as the type of structure to be removed. The result of this paper are NP-completeness proofs and polynomial algorithm for general and
particular graph classes. In special, we show that the arc deletion problem on the OR Model can be solved in polynomial time, and the vertex deletion problem on the OR Model remains NP-Complete even on graph with  (G) = 4, but it is solvable in polynomial time on graph with  (G)   3."
141;en_US;"This paper introduces the concept of probabilistic implicit graph representations, extending the definition from [Spinrad 2003] by allowing the adjacency test to have a constant probability of false positives or false negatives.
It also discusses two novel representations based on well-known probabilistic data structures: one that uses Bloom filters and can represent general graph with the same space complexity as the adjacency matrix (but outperforms it for sparse graph), and other that uses MinHash and can represent trees with lower space complexity than any deterministic implicit representation."
142;en_US;"In this work, we extend multi-agent epistemic logic for reasoning about properties in protocol. It is based on Dolev-Yao model and uses structured propositions, a new technique to deal with message, keys and properties
in security protocol in an uniform manner, keeping the logic propositional. In order to illustrate the applicability of this new logic, an example is presented."
143;en_US;"The problem of determining the chromatic index of a graph, even when triangle-free, is NP-hard. However, the Overfull Conjecture implies that this problem can be solved in polynomial time for graph with large maximum
degree. In order to prove the conjecture, it is sufficient to show that all nonsubgraph-overfull graph with   > n/3 are Class 1. A special case of non-subgraph-overfull graph are the graph with no proper majors. We show that
all triangle-free graph with no proper majors, regardless of maximum degree, are Class 1. We also provide a polynomial-time algorithm to colour such graph."
144;en_US;"Given a graph G and a pair s,t in V(G), where each edge e has a weight t(e) and each vertex v has a value p(v) such that t(e) represent a transportation time and p(v) a prize collecting. Prize Collecting Path (PCP) consists
of finding a (s,t)-path that minimizes the total transportation time minus the total prize of node in such path. PCP is at core of numerous relevant application in several fields like telecommunications, transportation and logistics. In this paper, the complexity behavior of the problem is analyzed. For some cases we prove that PCP is NP-complete, these result lead to the generation of new sets of benchmark instances that are computationally hard according to natural characteristics of the problem. In addition, polynomial time algorithm are described
for other cases and a mathematical formulation is introduced to solve general instances of PCP."
147;en_US;"Let lct(G) be the minimum size of a set of vertices that contains at least one vertex in every longest cycle of a graph G. We show that lct(G) = 1 if G is a 3-tree, and that lct(G) ≤ 2 if G is a 2-connected partial 3-tree."
149;en_US;"A labelling of a graph G is a mapping π : S → L, where L ⊂ R and S = E(G) or S = V (G) ∪ E(G). If S = E(G), π is an L-edge-labelling and, if S = V (G) ∪ E(G), π is an L-total-labelling. For each v ∈ V (G), the colour of v under π is defined as cπ(v) = P uv∈E(G) π(uv) if π is an L-edgelabelling; and cπ(v) = π(v) + P uv∈E(G) π(uv) if π is an L-total-labelling. The pair (π, cπ) is a neighbour-distinguishing-L-edge (total)-labelling if π : S → L is an edge (total)-labelling and cπ(u) 6= cπ(v), for every edge uv ∈ E(G). The 1,2,3-Conjecture states that every simple graph with no isolated edge has a neighbour-distinguishing-L-edge-labelling with L = {1, 2, 3}. In this work, we verify the 1,2,3-Conjecture for powers of paths and powers of cycles and we also show that powers of cycles have a neighbour-distinguishing-{a, b}-totallabelling, a, b ∈ R, a 6= b."
151;en_US;"We introduce the Least-Dependency Constrained Spanning Tree Problem, which consists of finding a spanning tree where each edge has at least one edge of its dependency set, if non-empty, also in the tree. The dependencies
on the input graph G are described by a digraph D where the vertices are the edges of G, and the in-neighbors of a vertex are its dependency set. We show that the optimization problem is NP-hard even if G is a chordal cactus with maximum degree 3 or diameter at most 2, and D is a disjoint union of arborescences of height 2. The same complexity is proved when G is planar bipartite, and each component of D is an oriented cycle or an anti-arborescence of height 1. We also report two polynomial cases."
152;en_US;"A path (resp. cycle) decomposition of a graph G is a set of edgedisjoint paths (resp. cycles) of G that covers the edge-set of G. Gallai (1966) conjectured that every graph on n vertices admits a path decomposition of size
at most b(n + 1)/2c, and Hajós (1968) conjectured that every Eulerian graph on n vertices admits a cycle decomposition of size at most b(n − 1)/2c. In this paper, we verify Gallai’s Conjecture for serie–parallel graph, and for graph with maximum degree 4. Moreover, we show that the only graph in these classes that do not admit a path decomposition of size at most bn/2c are isomorphic to K3, K5 or K5 − e. The technique developed here is further used to present a new proof of a result of Granville and Moisiadis (1987) that states that Eulerian
graph with maximum degree 4 satisfy Hajós’ Conjecture."
155;en_US;"An ordered pair (π, cπ) is said to be a gap-[k]-edge-labelling (gap-[k]- vertex-labelling) if π is an edge-labelling (vertex-labelling) on the set {1, . . . , k}, and cπ is a proper vertex-colouring induced by a gap-function based on π. Gap-[k]- edge-labellings and gap-[k]-vertex-labellings were first introduced by M. Tahraoui et al. [7] and A. Dehghan et al. [2], respectively. The edge-gap number (vertex-gap number) is the least k for which there exists a gap-[k]-edge-labelling (gap-[k]-vertexlabelling) of a graph. In this work, we study the edge-gap number, χ g E , and the vertexgap number, χ g V, of cycles, crowns and wheels. "
162;en_US;"Let (G, w, t) denote a triplet consisting of a connected graph G = (V, E) with a nonnegative weight function w defined on E, and a real number t > 1. A tree t-spanner of G is a spanning tree H of G such that for each pair of
vertices u, v, the distance between u and v in H is at most t times the distance between u and v in G. We address the Minimum Weight Tree Spanner Problem (MWTS), defined as follows. Given a triplet (G, w, t), find a tree t-spanner in G that has the smallest possible weight. It is known that MWTS is NP-hard for every fixed t ≥ 4. We propose two ILP formulations for MWTS, based on arborescences, of polynomial size, and present some preliminary result on the computational experiment with these formulations."
163;en_US;"We deal with the cumulative vehicle routing problem (VRP), a generalization of the capacitated VRP, which objective is to minimize the fuel consumption. Gaur et al. in 2013 gave a 4-approximation based on a well-known
partition heuristic to the traveling salesperson problem (TSP). We present a tighter analysis obtaining a
(4 −4/3s³Q²) -approximation, where Q is the capacity of the vehicle and s is a scaling factor. To the best of our knowledge, this is the best proved approximation for the cumulative VRP so far."
235;en_US;"The stream processing domain is present in several real-world application that are running on multi-core system. In this paper, we focus on data compression application that are an important sub-set of this domain. Our main goal is to assess the programmability and efficiency of domain-specific language called SPar. It was specially designed for expressing stream parallelism and it promises higher-level parallelism abstractions without significant performance losses. Therefore, we parallelized Lzip and Bzip2 compressors with SPar and compared with state-of-the-art framework. The result revealed that SPar is able to efficiently exploit stream parallelism as well as provide suitable abstractions with less code intrusion and code refactoring."
243;en_US;"Given the pervasiveness of multi-core processors in system from various domains, the need for efficient parallelization tool has only increased during the last decade. Among the paradigms built to answer this demand, Task Parallelism stands out as a highly productive tool for leveraging data parallelism with minimum code altering. Nonetheless, its current supporting runtimes cannot efficiently execute workloads involving tasks in the fine 1-100us range, limiting its applicability. That said, by performing a thorough Petri-Net-based analysis of task parallel system with several degrees of HW-assistance, we show that the development of Native CPU support for Task Parallelism is the key for efficiently serving these challenging workloads."
245;en_US;"GPUs have established a new baseline for power efficiency and computing power, delivering larger bandwidth and more computing units in each new generation. Modern GPUs support the concurrent execution of kernels to maximize resource utilization, allowing other kernels to better exploit idle resource. However, the decision on the simultaneous execution of different kernels is made by the hardware, and sometimes GPUs do not allow the execution of blocks from other kernels, even with the availability of resource. In this work, we present an in-depth study on the simultaneous execution of kernels on the GPU. We present the necessary conditions for executing kernels simultaneously, we define the factors that influence competition, and describe a model that can determine performance degradation. Finally, we validate the model using synthetic and real-world kernels with different computation and memory requirement."
246;en_US;"As computational science simulation produce ever increasing volumes of data, executing part or even the entire visualization pipeline in the supercomputer side becomes more a requirement than an option. Given the uniqueness of the high performance K computer architecture, the HIVE visualization framework was developed, focusing on meeting visualization and data analysis demands of scientists and engineers. In this paper, we present an analysis on the input/output (I/O) performance of post-hoc visualization. The contribution of this research work is characterized by an analysis of a set of empirical study cases considering huge simulation dataset using HIVE on the K computer. result from the experimental effort, using a dataset produced by a real-world global climate simulation, provide a differentiated knowledge on the impact of dataset partitioning parameters in the I/O performance of large-scale visualization system, and highlight challenges and opportunities for performance optimizations."
247;en_US;"QcBits is a state-of-the-art constant-time implementation of a code-based encryption scheme for post-quantum public key cryptography. This paper presents an optimized version of its decoding process, which is used for message decryption. Our implementation leverages SSE and AVX instructions extensions and performs 3.6 to 4.8 times faster than the original version, while preserving the 80-bit security level and constant time execution. We also provide experimental data that indicates a further 1.4-factor speedup supposing the existence of instructions for vectorial conditional moves and 256-bit register shifts. Finally, we implemented countermeasures for side-channel security and showed that they do not affect the overall performance."
250;en_US;"We present a hybrid exact algorithm for the Hitting Set Problem (HSP) for highly heterogeneous CPU-GPU-MIC platforms. With several technique that permit an efficient exploitation of each architecture, low communication cost and effective load balancing, we were able to solve large HSP instances in reasonable time, achieving good performance and scalability. We obtained speedups of up to 25.32 in comparison with using two six-core CPUs and exact HSP solutions for instances with tens of thousands of variables in less than 5 hours. These result reinforce the statement that heterogeneous cluster of CPUs, GPUs and MICs can be used efficiently for high-performance computing."
251;en_US;"Workload-aware loop schedulers were introduced to deliver better performance than classical strategies, but they present limitations on workload estimation, chunk scheduling and integrability with application. Targeting these challenges, in this work we propose a novel workload-aware loop scheduler that is called BinLPT and it is based on three feature. First, it relies on some user-supplied estimation of the workload of the target parallel loop. Second, BinLPT uses a greedy bin packing heuristic to adaptively partition the iteration space in several chunks. The maximum number of chunks to be produced is a parameter that may be fine-tuned. Third, it schedules chunks of iterations using a hybrid scheme based on the LPT rule and on-demand scheduling. We integrated BinLPT in OpenMP, and we evaluated its performance in a large-scale NUMA machine using a synthetic kernel and 3D N-Body simulation. Our result revealed that BinLPT improves performance over OpenMP’s strategies by up to 45.13% and 37.15% in the synthetic and application kernels, respectively."
252;en_US;"Multi-tier is one of the most used architectures to create application and easily deploy them to the cloud. In the literature, there are a great number of research work focusing on the placement of these application. While some of these work take into consideration performance, most of them are concerned about reducing infrastructure costs. Besides, none of them take into consideration the interference and network affinity characteristics. Therefore, in this work, we create placement policies that aim to improve the performance of multi-tier application by analyzing the interference and network affinity characteristics of each tier. These characteristics work as a force pushing tiers closer or farther depending on the interference and affinity levels. Moreover, by using these placement policies, we show that multi-tier application can better utilize the infrastructure, using the same infrastructure but with an improved performance."
253;en_US;"Processor-in-Memory (PIM) architectures, such as the Hybrid Memory Cube (HMC), are emerging nowadays as a solution for processing large amount of data directly inside the memory. In this area, several researcher are proposing and evaluating new instructions and new PIM architectures. For such evaluations, trace-driven simulators, as the Simulator of Non-Uniform Cache Architectures (SiNUCA), are commonly used in order to model these new proposed system. Such simulators provide fast prototyping of new architectures, while it requires the researcher to write simulation traces manually when evaluating new Instruction Set Architecture (ISA) proposals, which is an time consuming and error prone task. In this work, we propose a methodology for fast generation of simulation traces focused on HMC architecture, which consists on a high-level Intrinsics-HMC library and a modification inside the trace-generator tool from SiNUCA. Our proposal enables the researcher to write high level code in C/C++ language using our library, which mimics the behavior of HMC instructions. These codes can be compiled and executed in traditional x86 architectures for verification. After ensure the code is correct and working, the user can use our modified version of SiNUCA-Tracer to translate HMC functions into HMC instructions know by the simulator, providing a convenient solution to generate traces and fast simulation of new PIM architectures. result using the proposed technique applied on database application kernels show the correct translation and simulation of new HMC instructions using SiNUCA."
256;en_US;"When applied to signed network, the Correlation Clustering (CC) problem consists of an important tool to study how balanced a social group behaves and if this group might evolve to a possible balanced state. Solving such combinatorial optimization problem is a challenging task, which heavily relies on heuristic procedures, one of the few solution method capable of analyzing large network instances. In this work, we present a novel approach to solve the CC problem on large-scale signed network. A distributed GPU-powered version of the ILS metaheuristic, which benefits from data parallelism, has been developed. This technique provides good quality clustering result when compared to non-distributed method. experiment were conducted on both synthetic and real dataset. The proposed algorithm achieved improved solution values when compared to the existing parallel solution method. In particular, one of the largest graph we have considered in our experiment contains 1 million node and 8 million edges – such graph can be clustered in two hours using our algorithm. The new method can process network for which there is no efficient solution using the existing algorithm found in the literature."
259;en_US;"AA well-known challenge with long running time query in database environments is how much time a query will take to execute. This prediction is relevant for several reasons. For instance, by knowing that a query will take longer to execute than desired, one resource reservation mechanism can be performed, which means reserving more resource in order to execute this query in a shorter time in a future request. In this research work, it is presented a proposal in which the use of an advance reservation mechanism in a cloud database environment, considering machine learning technique, provides resource recommendation. The proposed model is presented, in addition to some experiment that evaluate benefits and the efficiency of this enhanced proposal."
313;en_US;"A well-known challenge with long running time query in database environments is how much time a query will take to execute. This prediction is relevant for several reasons. For instance, by knowing that a query will take longer to execute than desired, one resource reservation mechanism can be performed, which means reserving more resource in order to execute this query in a shorter time in a future request. In this research work, it is presented a proposal in which the use of an advance reservation mechanism in a cloud database environment, considering machine learning technique, provides resource recommendation. The proposed model is presented, in addition to some experiment that evaluate benefits and the efficiency of this enhanced proposal."
360;en_US;"Given the pervasiveness of multi-core processors in system from various domains, the need for efficient parallelization tool has only increased during the last decade. Among the paradigms built to answer this demand, Task Parallelism stands out as a highly productive tool for leveraging data parallelism with minimum code altering. Nonetheless, its current supporting runtimes cannot efficiently execute workloads involving tasks in the fine 1-100us range, limiting its applicability. That said, by performing a thorough Petri-Netbased analysis of task parallel system with several degrees of HW-assistance, we show that the development of Native CPU support for Task Parallelism is the key for efficiently serving these challenging workloads."
364;en_US;"QcBits is a state-of-the-art constant-time implementation of a codebased encryption scheme for post-quantum public key cryptography. This paper presents an optimized version of its decoding process, which is used for message decryption. Our implementation leverages SSE and AVX instructions extensions and performs 3.6 to 4.8 times faster than the original version, while preserving the 80-bit security level and constant time execution. We also provide experimental data that indicates a further 1.4-factor speedup supposing the existence of instructions for vectorial conditional moves and 256-bit register shifts. Finally, we implemented countermeasures for side-channel security and showed that they do not affect the overall performance."
369;en_US;"Workload-aware loop schedulers were introduced to deliver better performance than classical strategies, but they present limitations on workload estimation, chunk scheduling and integrability with application. Targeting these challenges, in this work we propose a novel workload-aware loop scheduler that is called BinLPT and it is based on three feature. First, it relies on some user-supplied estimation of the workload of the target parallel loop. Second, BinLPT uses a greedy bin packing heuristic to adaptively partition the iteration space in several chunks. The maximum number of chunks to be produced is a parameter that may be fine-tuned. Third, it schedules chunks of iterations using a hybrid scheme based on the LPT rule and on-demand scheduling. We integrated BinLPT in OpenMP, and we evaluated its performance in a large-scale NUMA machine using a synthetic kernel and 3D N-Body simulation. Our result revealed that BinLPT improves performance over OpenMPs strategies by up to 45.13% and 37.15% in the synthetic and application kernels, respectively."
370;en_US;"The stream processing domain is present in several real-world application that are running on multi-core system. In this paper, we focus on data compression application that are an important sub-set of this domain. Our main goal is to assess the programmability and efficiency of domain-specific language called SPar. It was specially designed for expressing stream parallelism and it promises higher-level parallelism abstractions without significant performance losses. Therefore, we parallelized Lzip and Bzip2 compressors with SPar and compared with state-of-the-art framework. The result revealed that SPar is able to efficiently exploit stream parallelism as well as provide suitable abstractions with less code intrusion and code re-factoring."
375;en_US;"When applied to signed network, the Correlation Clustering (CC) problem consists of an important tool to study how balanced a social group behaves and if this group might evolve to a possible balanced state. Solving such combinatorial optimization problem is a challenging task, which heavily relies on heuristic procedures, one of the few solution method capable of analyzing large network instances. In this work, we present a novel approach to solve the CC problem on large-scale signed network. A distributed GPU-powered version of the ILS metaheuristic, which benefits from data parallelism, has been developed. This technique provides good quality clustering result when compared to non-distributed method. experiment were conducted on both synthetic and real dataset. The proposed algorithm achieved improved solution values when compared to the existing parallel solution method. In particular, one of the largest graph we have considered in our experiment contains 1 million node and 8 million edges - such graph can be clustered in two hours using our algorithm. The new method can process network for which there is no efficient solution using the existing algorithm found in the literature."
484;en_US;"Crime prevention requires the effective use of police resource, which demands the access of criminal information for planning security actions. The number of crime occurrence is higher than the official reported numbers. Many victims do not report crime directly to the security agencies. Instead, they prefer to anonymously report using different channels, such as the Web. In this article, we introduce our approach to characterize crime reported in the Web. Particularly, we collect criminal data from popular websites that store crime occurrence, and we use clustering analysis to discover crime pattern on the collected data. Applying our approach to a popular Brazilian crime report website, we observe that more than 41% of the crime were not reported to the security agencies, and most of them are thefts and robberies occurring at night and dawn. In addition, minor offenses present different pattern of serious crime. Moreover, crime pattern are different in rich and poor neighborhood."
486;en_US;"The study of Lattes platform allows addressing and analyzing Brazil researcher network which could be useful for defining politics to improve science, technology, and innovation. This work evaluated Lattes Platform coauthorship network. This network evolves over time, which means that new coauthorships will arise in future. Therefore, using link prediction method in this network would help to identify growing knowledge area in Brazil. The used technics were Spectral Evolution, wich is new in this context, Common Neighbors, Adamic-Adar and Jaccard. The main goal was to evaluate the link prediction accuracy with different method at the coauthorship network of Lattes Platform. The Spectral Evolution was worse than the others. Adamic-Adar method presented the best result - 817 times better than the random link prediction."
493;en_US;"The study of social ties has lead to building rigorous model that reveal the evolution of social network and their dynamism. In this context, a central aspect is the strength of ties, which allows the study of the roles of relationships. Here, besides analyzing the strength of co-authorship ties, we also present a set of metrics and algorithm to measure such strength. Initial studies of social network have emphasized the importance of properly measuring the strength of social ties to understand social behaviors [Granovetter 1973, Newman 2001]. Also, the study of social ties is fundamental for building rigorous model that reveal the evolution of social network (SN) and the dynamics of social exchange [Aiello et al. 2014]. More recently, analyzing tie strength has allowed to investigate the roles of relationships including ranking for influence detection [Freire and Figueiredo 2011], as well as its influence in communication pattern [Wiese et al. 2015] and team formation [Castilho et al. 2017]."
494;en_US;"This paper aims to discuss social capital inequalities between postgraduate student enrolled in a social sciences program in a Brazilian university. I analyze data from 47 postgraduate student using linear model, stochastic blockmodelling and the Social Selection Model (SSM). The analysis shows that social formations occur mainly from participation in research groups and from methodological perceived habilities."
495;en_US;"Brazilian Web user are among the most active in social network and very keen on interacting with others. Offensive comment, known as hate speech, have been plaguing online media and originating a number of lawsuits against company which publish Web content. Given the massive number of user generated text published on a daily basis, manually filtering offensive comment becomes infeasible. The identification of offensive comment can be treated as a supervised classification task. In order to obtain a model to classify comment, an annotated dataset containing positive and negative examples is necessary. The lack of such a dataset in Portuguese, limits the development of detection approaches for this language. In this paper, we describe how we created annotated dataset of offensive comment for Portuguese by collecting news comment on the Brazilian Web. In addition, we provide classification result achieved by standard classification algorithm on these dataset which can serve as baseline for future work on this topic."
525;en_US;"<p>The study of social ties has lead to building rigorous model that reveal the evolution of social network and their dynamism. In this context, a central aspect is the strength of ties, which allows the study of the roles of relationships. Here, besides analyzing the strength of co-authorship ties, we also present a set of metrics and algorithm to measure such strength. Initial studies of social network have emphasized the importance of properly measuring the strength of social ties to understand social behaviors [Granovetter 1973, Newman 2001]. Also, the study of social ties is fundamental for building rigorous model that reveal the evolution of social network (SN) and the dynamics of social exchange [Aiello et al. 2014]. More recently, analyzing tie strength has allowed to investigate the roles of relationships including ranking for influence detection [Freire and Figueiredo 2011], as well as its influence in communication pattern [Wiese et al. 2015] and team formation [Castilho et al. 2017].</p>"
533;en_US;"-Studies with ensemble system have gained attention recently and, most of them, propose new method for the design (generation) of different components in these system. In parallel, new contributions of meta-learning have been presented as an efficient alternative to automatic recommendation of algorithm. In this paper, we apply meta-learning in the process of recommendation of important parameters of ensemble system, which are: architecture and individual classifier. The main goal is to provide an efficient way to design ensemble system. In order to validate the proposed approach, an empirical investigation is conducted, recommending three possible types of ensemble architectures (Bagging, Boosting and Multi-Boosting) and five possible types of learning algorithm to compose the ensemble system (individual classifier or components). An initial analysis of the result confirms that meta-learning can be a promising tool to be used in the automatic choice of important parameters in ensemble system."
534;en_US;"-Knowledge about algorithm similarity is an important aspect of meta-learning, where the information gathered from previous learning tasks can be used to guide the selection of algorithm for new dataset. Usually this task is done by comparing global performance measures across different dataset or alternatively, comparing the performance of algorithm at the instance-level. In both cases, the previous similarity measures do not consider misclassification costs, and hence they neglect an important information that can be exploited in different learning context. In this paper we present algorithm similarity measures that deals with cost proportions and different threshold choice method for building crisp classifier from learned model. experiment were performed in a meta-learning study with 50 different learning tasks. The similarity measures were adopted to cluster algorithm according to their aggregated performance on the learning tasks. The clustering process revealed similarity between algorithm under different perspectives."
535;en_US;"- This paper evaluates some strategies to approximate the performance of dynamic ensembles based on NN-rule to the oracle performance. For this purpose, we use a multi-objective optimization algorithm, based on Differential Evolution, to generate automatically a pool of accurate and diverse classifier in the form of Extreme Learning machine. However, the rule defined for selecting the classifier depends on the quality of the information obtained from regions of competence. Thus, we also improve the regions of competence in order to avoid noise and create smoother class boundaries. Finally, we employ a dynamic ensemble selection method. The performance of the proposed method was experimentally investigated using 12 benchmark dataset and result of comparative analysis are presented."
539;en_US;"-In multi-label dataset, the number of labels associated with each instance is an important feature to be observed. Two relevant characteristics related to dataset number of labels are cardinality and density. In this work, we use artificial dataset generated through a framework named Mldatagem, freelyavailable in the internet. This framework enables configuring some other characteristics of the generated dataset. In this paper we present a study that analyze how and when distinct characteristics of the dataset influence the performance of multilabel learning method."
540;en_US;"-Part-of-Speech Tagging is a fundamental task on many Natural Language Processing system. This task consists in identifying the syntactic category, i.e. the part of speech, of each word in a sentence. Despite the fact that the current state-of-theart accuracy for this task is around 97%, any improvement has an immediate impact on more complex tasks, like Parsing, Semantic Role Labeling and Information Extraction. Thus, it is still relevant to explore this task. In this paper, we introduce a part-ofspeech tagger based on the Structure Learning framework that reduces the smallest known error on the Portuguese Mac-Morpho corpus by 7.8%. We also apply our tagger to a recently revised version of Mac-Morpho. Our system accuracy on this latter version is competitive with a semi-supervised Neural Network trained on Mac-Morpho plus a very large non-annotated corpus. Additionally, our system is simpler than previous system and uses a very limited feature set. Our system employs a Large Margin training criteria to derive a structure predictor that is more robust on unseen data."
541;en_US;"-The rapid change of trading values from tangible assets to Intelectual Property has put both businesses and academia in a race to acquire and protect the rights to exploit such property. This is mainly accomplished in the form of patent issuing by the governments, being time consuming and complicated due to the vast amount of document that need to be analyzed in order to assert the novelty or validity of a patent application. Patent information retrieval research is thus growing quickly to support document analysis across multiple domains and information system. One of the big challenges in patent analysis is the identification of the elements of innovation (concepts, process, materials) and the relations between them, in the patent text. This paper presents a method for extracting semantic information from patent claims by using semantic annotations on phrasal structures, abstracting domain ontology information and outputting ontology-friendly structures to achieve generalization. An extraction system built upon the method is briefly evaluated on a document sample from INPI, the Brazilian patent office, a challenging information source."
575;en_US;"-We propose polarity detection from colloquial expressions distinctive of a bilingual population. The hybrid language we address its called “Jopara”, composed by Spanish and Guaraní, spoken in Paraguay, similar to the “Louisianas Creole” in the United States. We categorize polarity in three classes (positive, negative and neutral) and address this problem by applying both lexicon-based and machine-learning approaches. In this document its shown the application scenario, the building process of the bilingual lexicon and the attributes preprocessing to create the classifier input. The input data is retrieved from Twitter so the expressions are similar to natural language. Finally, result are displayed to compare performance of these technique when applied on this kind of language. Its shown that classical classifier have very good performances, with correction rates of over 80% even with small training sets, if their parameters are properly adjusted along with an adequate selection of attributes."
576;en_US;"⎯ Local Coherence is a very important aspect in multidocument summarization, since good summaries not only condense the most relevant information, but also present it in a well-organized structure. One of the most investigated model for local coherence is the Entity-based model, which has been successfully used, once it facilitates the computational approach for coherence measurement. Particularly, this model was used for the evaluation of local coherence in multi-document summaries, achieving promising result. In order to improve the potential of the Entity-based model, we propose the creation of a language model for multi-document summaries that integrates the Entity-based model with discourse knowledge, mainly from Cross-document Structure Theory. Our result show that this type of information enriches the Entity-based Model by capturing other phenomena that are inherent to multi-document summaries, such as redundancy and complementarity, which improves the performance of the original model."
577;en_US;"-This work describes an opinion mining application over a dataset extracted from the web and composed of review with several Internet slangs, abbreviations and typo errors. Opinion mining is a study field that tries to identify and classify subjectivity, such as opinions, emotions or sentiments in natural language. In this research, 759.176 Portuguese review were extracted from the app store Google Play. Due to the large amount of review, large-scale processing technique were needed, involving powerful framework such as Hadoop and Mahout. Based on tests conducted it was concluded that pre-processing has an insignificant role in opinion mining task for the specific domain of review of mobile apps. The work also contributed to the creation of a corpus consisting of 759 thousand review and a dictionary of slangs and abbreviations commonly used in the Internet."
578;en_US;"-This paper proposes a study and comparison of the combination of multiple metadata types to improve the recommendation of movie item according to user preferences. We used four algorithm available in the literature to analyze the descriptions, and compared each other using all the possible combinations of the metadata extracted from two dataset, namely MovieLens and IMDB. As a result of our evaluation, we found out that combining metadata generates better predictions for the considered content-based recommenders."
579;en_US;"-Recommender system are designed to assist individuals to identify item of interest in a set of options. A context-aware recommender system makes recommendation by incorporating available contextual information into the recommendation process. One of the major challenges in context-aware recommender system research is the lack of automatic method to obtain contextual information for these system. Considering this scenario, in this paper, we propose to use contextual information from topic hierarchies to improve the performance of context-aware recommender system. Three different types of topic hierarchies are constructed by using the LUPI-based Incremental Hierarchical Clustering method: a topic hierarchy using only a traditional bag-of-word, a second topic hierarchy using a bag-of-word of named entities and a third topic hierarchy using both information. We evaluate the contextual information in four context-aware recommender system. The empirical result demonstrate that by using topic hierarchies we can provide better recommendation."
580;en_US;"-In this paper, we present a technique that uses multimodal interaction of user to generate a more accurate list of recommendation optimized for the user. Our approach is a response to the actual scenario on the Web which allows user to interact with the content in different ways, and thus, more information about his preferences can be obtained to improve recommendation. The proposal consists of an ensemble technique that combines rankings generated by unimodal recommenders based on particular interaction types. By using a combination of implicit and explicit feedback from user, we are able to provide better recommendation, as shown by our experimental evaluation presented in this paper."
582;en_US;"-Multi-Objective Optimization problem (MOPS) present several challenges. In particular, when the number of objectives is greater than three, they are actually called ManyObjective Optimization problem (MaOPs). To overcome this limitation, researches are investigating multi-swarm approaches. Multi-swarm is a very interesting approach that allows the decomposition of different aspects of the problem and each swarm could specialize on a dedicate part of the problem. This study explores this idea to create a novel multi-swarm algorithm, called A-Multi, which tackles the main challenge of MaOPs: to convergence towards the true Pareto front and to diversify the obtained solutions covering the entire Pareto front. A-Multi project is based on different swarms use different archiving method, ones specialized on diversity and others specialized on convergence. The algorithm is evaluated with several MaOPs in terms of both convergence and diversity and the result shows the validity of archive based multi-swarm approach."
583;en_US;"- In the context of multi-objective optimization, where there may be many optimal incomparable solutions, most of the optimizers maintain a limited repository, to keep the objective vectors of the solutions found during the execution. There are several method to decide which vectors remain in that limited size archive, and these different technique may have properties that guarantee the diversity and quality of their outcomes. This paper examines some of those strategies, analyzing their properties, and comparing empirically their outputs based on two quality indicators, additive epsilon and hypervolume. Most of the archiving technique studied in this work cannot ensure that at the end of the process their vectors are all optimal. Due to this fact, a new approach is presented, based on a second archive to store the points which would be discarded. The main idea is verify how much the recycled vectors could improve the generated set. In the realized tests, the method had not a significant time cost regardless the adopted archiving technique."
584;en_US;"-Ensemble of classifier, or simply ensemble system, have been proved to be efficient for pattern recognition tasks. However, its design can become a difficult task. For instance, the choice of its individual classifier and the use of feature selection method are very difficult to define in the design of these system. In order to smooth out this problem, we will apply meta-learning and multi-objective optimization in the choice of important parameters of ensemble system. Therefore, this work applies meta-learning technique to define an initial configuration of an multi-objective optimization algorithm, more specifically NSGA II. The meta-learner is used to recommend the proportion of each type of base classifier to compose the ensemble system. The NSGA II is used to generate heterogeneous ensembles selecting attributes, types and parameters of base classifier optimizing the classification error and the bad diversity. The result are analysed using error rate and multi-objective metrics in order to verify whether to use of meta-learning generates more accurate ensemble system."
585;en_US;"-In this paper, we introduce a kind of Hopfield network that can be used for the storage and recall of vectors whose entries are unit quaternions. We show that the novel model, referred to as continuous-valued quaternionic Hopfield neural network (CV-QHNN), produces a sequence that under mild conditions converges to a fixed point for any initial state. Furthermore, computational experiment reveal that a CV-QHNN, synthesized using the projection rule, exhibit optimal absolute storage capacity and some noise tolerance as an associative memory model."
586;en_US;"-The elevated plus-maze is widely used as a tool for neurobiological studies of anxiety and defense in rodents. In a previous work, an artificial neural network (ANN) with weights adjusted by a genetic algorithm (GA) was used to investigate the behavior of rats in an elevated plus-maze. The study of the ANNs architecture, which was fixed in the previous work, can provide insights about the role of sensory inputs and memory in model employed to investigate the behavior of rats. In this paper, we propose an evolving ANN for this problem. The architecture of the recurrent ANN is evolved by the GA together with its weights. The experiment indicate that the evolving ANN produces better result than the fixed architecture previously investigated. Besides, the experiment indicate that only three of the six sensory units and only two of the four hidden units are used in the evolved ANN. This result is useful to understand how the rat uses the sensory information and memory while navigating in the elevated plus-maze."
605;en_US;"- Efficient automatic system which continuously learn over long periods of time, and manage to evolve its knowledge, by discarding obsolete parts of it and acquiring new ones to reflect recent data, are difficult to be constructed. This paper addresses neural network (NN) learning in non-stationary environments related to financial markets, aiming at forecasting stock closing price. To face up this dynamic scenario, an efficient NN model is required. Therefore, Constructive Neural network (CoNN) were employed due to its self-adaptation capability, in contrast to regular NN which demands parameter adjustment. This paper investigates a possible ensemble organization, composed by NNs trained with the Cascade Correlation CoNN algorithm. An ensemble is an effective approach to nonstationary learning because it provides pre-defined rule that enable new learners - with new knowledge - to take part of the ensemble along data stream processing. result obtained with data stream related with four different stocks are then analysed and favorably compared with those obtained with the traditional MLP NNs, trained with Backpropagation."
606;en_US;"-A common solution for activation function design in HNN is the LUT representation that has acceptable area constraints and usually achieves acceptable execution time. tool and technique for automatic generation of LUTs have been developed but have some problem as high complexity, high dependency of external tool or language and the optimization technique that are not efficient enough for critical application. In order to solve some of the presented problem this paper describes a method for automatic LUT generation that overcomes some deficiencies of existing method using a simple approach. This method was evaluated considering two different robotic system that hereafter will be implemented in hardware and whose network have a different behavior using different domains of the same activation function. Proposed method achieved good result that are directly related to how network define the activation function domain."
607;en_US;"ions are built from the observation of microscopic interaction in order to provide a global understanding of the system trajectory. The scaling issue is then handled by observational device that directly compute such macroscopic descriptions without collecting any microscopic data. This macroscopic observation process is evaluated on a classic ant colony model."
608;en_US;"-Bounded-parameter Markov decision process (BMDP) can be used to model sequential decision problem, where the transitions probabilities are not completely know and are given by interval. One of the criteria used to solve that kind of problem is the maximin, i.e., the best action on the worst scenario. The algorithm to solve BMDPs that use this approach include interval value iteration and an extension of real time dynamic programming (Robust-LRTDP). In this paper, we introduce a new algorithm, named B2RTDP, also based on real time dynamic programming that makes a different choice of the next state to be visited using upper and lower bounds of the optimal value function. The empirical evaluation of the algorithm shows that it converges faster than the state-of-the-art algorithm that solve BMDPs."
609;en_US;"application of automated planning under uncertainty are often modelled as a discrete and continuous state Markov Decision Process (DC-MDP). Symbolic Dynamic Programming is the existent exact solution for DC-MDPs that uses the eXtended Algebraic Decision Diagrams (XADDs) to symbolically represent the state value function and that computes a complete state-space policy (which is very costly and limits solutions to problem with small size and depth). RealTime Dynamic Programming (RTDP) is an efficient solution method for discrete state MDPs that provides a partial solution for a known initial state. In this paper we combine the RTDP solution with XADD symbolic representation and computation of the value function to propose the Continuous Real Time Dynamic Programming (CRTDP) algorithm. This novel planner uses heuristic search and symbolic generalisation to efficiently update the value function by regions. We show that using the initial state information greatly reduces the number of regions in the value function, therefore allowing CRTDP to solve DC-MDPs more efficiently than standard symbolic dynamic programming both in time and space required for the solution."
610;en_US;"ion. The validation is done through the analysis of scenarios that can happen in a production system, and with the use of the proposal of prediction is verified that in these scenarios is possible to extract important information."
611;en_US;"-In this paper, we investigate some variants of a basic linear genetic programming (LGP) algorithm in the problem of symbolic regression. We explore the effects of using technique to control bloat and to privilege a greater percentage of effective code in the population, individually, and examine its possibility of producing better solutions. We also test the effects and performance of an operator that considers two successful individuals as subfunctions and join them into a new individual. We conduct experiment and discuss what effects each variant introduces to the evolution and its chance of producing better solutions."
612;en_US;"-We propose the Quantum-Inspired Multi-Gene Linear Genetic Programming (QIMuLGP), which is a generalization of Quantum-Inspired Linear Genetic Programming (QILGP) model for symbolic regression. QIMuLGP allows us to explore a different genotypic representation (i.e. linear), and to use more than one genotype per individual, combining their outputs using least squares method (multi-gene approach). We used 11 benchmark problem to experimentally compare QIMuLGP with: canonical tree Genetic Programming; Multi-Gene treebased GP (MGGP); and QILGP. QIMuLGP obtained better result than QILGP in almost all experiment performed. When compared to MGGP, QIMuLGP achieved equivalent errors for some experiment with its runtime always shorter (up to 20 times and 8 times on average), which is an important advantage in high dimensional-scalable problem."
614;en_US;"-This paper presents a case study of machine learning applied to measure the risk of corruption of civil servants using political party affiliation data. Initially, a statistical hypothesis test verified the dependency between corruption and political party affiliation. Then, we constructed dataset with standardization and three different discretization technique. Using Weka environment, this work shows the application and statistical evaluation of four classification algorithm to build model for predicting risk of corruption: Bayesian network, Support Vector machine, Random Forest, and Artificial Neural network with backpropagation. To evaluate the model we used data mining metrics such as precision, recall, kappa statistic and percent correct. Lastly, the case study compares the learned model with the best performance to the experts model. The comparison not only confirms previous experts affirmations, but also provides new assertions on the affiliation-corruptibility relation. Index Terms-Corruption; Civil Servant; Political Affiliation; Machine Learning; Random Forest."
615;en_US;"-Knowledge formalization and reasoning automation are central within Artificial Intelligence. Classical logic has been traditionally used for such purposes. However, it is better suited to deal with complete knowledge in ideal circumstances. In real situations, in which the knowledge is partial, classical logic is not sufficient since it is monotonic. Nonmonotonic logics have been proposed to better cope with practical reasoning. A successful formalization of nonmonotonic reasoning is Reiters default logic which extends classical logic with default rule. Unfortunately, default logic is undecidable. One reason for that is the use of classical logic as its monotonic basis. In this work, we change the default logic monotonic basis and propose a new default logic based on the description logic ALC . This new default logic is decidable and useful to formalize practical reasoning on hierarchical ontology with exceptions, specially the ones that deals with legal knowledge and reasoning. On the default counterpart, we add some restrictions to the application of defaults in order to obtain nice properties such as coherence and elimination of anomalous extensions. We present the main algorithm used to build the extensions for this logic with its complexity analysis."
616;en_US;"Description Logics based language have emerged as the standard knowledge representation scheme for ontology. Typically, an ontology formalizes a number of dependent and related concepts in a domain, encompassed as a terminology. Usually, such terminologies are manually defined, which may yield unnecessarily large and complex terminologies, with a number of redundant group of literals among concepts. Simplicity has always been seen as a hallmark of good model, as they lead to faster inference and easier maintenance, compared to complex model. However, it is a hard task to manually convert a large and complex terminology, sometimes with about a hundred concepts definitions, to a simpler one. In this paper, we present an automatic refinement method to compress terminologies. The method relies on ideas of subtree isomorphism to convert a terminology into a simpler one without changing its semantics. Experimental result show that the proposed method successfully returns more compact terminologies while still maintaining the same set of individuals associated to a concept."
617;en_US;"-Hidden Markov model (HMMs) are widely used model for sequential data. As with other probabilistic model, they require the specification of local conditional probability distributions, which can be too difficult and error-prone, especially when data are scarce or costly to acquire. The imprecise HMM (iHMM) generalizes HMMs by allowing the quantification to be done by sets of, instead of single, probability distributions. iHMMs have the ability to suspend judgment when there is not enough statistical evidence, and can serve as a sensitivity analysis tool for standard non-stationary HMMs. In this paper, we formalize iHMMs and develop efficient inference algorithm to address standard HMM usage such as the computation of likelihoods and most probable explanations. experiment with real data show that iHMMs produce more reliable inferences without compromising efficiency."
618;en_US;"-In this paper we present some SAT and MaxSAT codifications for trees in graph. We review two known encodings and suggest four new ones. We categorize the encodings into three categories: Absolute encodings state that each vertex must be in a fixed position in some structure; Relative encodings state the relative positions between the vertices in some structure; Counting-based encodings use theoretical graph properties to hardcode the degree of each vertex in a tree. We use these encodings to reduce the Steiner Tree Problem in graph to (Partial Weighted) MaxSAT and compare their efficiency to solve random instances and ones from the SteinLib benchmark. The experiment strongly suggest that relative encodings are more efficient than absolute ones, but there is not an overall best encoding between relative and counting-based ones."
619;en_US;"-Several practical application require joining various rankings into a consensus ranking. These application include gathering the result of multiple query in information retrieval, deciding the result of a poll involving multiple judges and joining the outputs from ranking classification algorithm. Finding the ranking that best represents a set of rankings is a NP-hard problem, but a good solution can be found by using metaheuristics. In this paper, we investigate the use of Clustering Search (CS) algorithm allied to Simulated Annealing (SA) for solving the rank aggregation problem. CS will cluster the solutions found by SA in order to find promising regions in the search space, that can be further exploited by a local search. Experimental result on benchmark data sets show the potential of this approach to find a consensus ranking, achieving similar or better solutions than those found by other popular rank aggregation strategies."
620;en_US;"-This paper proposes a collaborative filtering approach that uses user review to produce item descriptions that represent a consensus of user regarding item feature. While earlier work focused on using structured metadata to represent item, recent approaches study how to use user-provided text, such as review, to produce better insights about the semantics in the content. Some involved problem, such as noise, personal opinions and false information are reduced by an algorithm based on sentiment analysis and natural language processing. We provide an evaluation using the MovieLens dataset, and the result are promising when compared to recommenders based only on structured metadata."
621;en_US;"-The goal of sentiment analysis is to determine opinions, emotions, and attitudes presented in source material. In tweet sentiment analysis, opinions in message can be typically categorized as positive or negative. To classify them, researcher have been using traditional classifier like Naive Bayes, Maximum Entropy, and Support Vector machine (SVM). In this paper, we show that a SVM classifier combined with a cluster ensemble can offer better classification accuracies than a stand-alone SVM. In our study, we employed an algorithm, named C3E-SL, capable to combine classifier and cluster ensembles. This algorithm can refine tweet classifications from additional information provided by clusterers, assuming that similar instances from the same cluster are more likely to share the same class label. The resulting classifier has shown to be competitive with the best result found so far in the literature, thereby suggesting that the studied approach is promising for tweet sentiment classification."
622;en_US;"-Short-text classification is a challenging natural language processing problem. Beyond classification accuracy, another issue refers to the dimensionality of the feature vectors used for classification. This is especially important for embedded application with hard constraints of computational power and memory. To deal with such problem, many technique of dimensionality reduction have been developed over the last years. The Supervised Distance Preserving Projections (SDPP) has shown promising result. This work proposes a modified version of the SDPP method, called Regularized SDPP, which relies on the regularization theory. On the basis of experimental evaluation, the proposed approach has achieved good result in comparison to the state-of-the-art method in nonlinear dimensionality reduction."
659;en_US;"-The recognition of emotions from others face is an universal and fundamental skill for social interaction. Many researcher argue that there is a set of basic emotions which were preserved during evolutive process because they allow the adaption of the organisms behavior to distinct daily situations. This paper is about emotion analysis and the identification of facial elements relevant for this task. The proposed approach is based on psychological research. Different facial representations are proposed to represent the geometrical characteristics of the human face and their performance is evaluated using Machine Learning technique. Also, an investigation of the facial elements related to the identification of the six basic emotions plus the neutral state is presented."
660;en_US;"-This work proposes a new method, KernelCanvas, that is adequate to the Weightless Neural Model known as WiSARD for generating a fixed length binary input from spatiotemporal pattern. The method, based on kernel distances, is simple to implement and scales linearly to the number of kernels. Five different dataset were used to evaluate its performance in comparison with more widely employed approaches. One dataset was related to human movements, two to handwriteen characters, one to speaker recognition and the last one to speech recognition. The KernelCanvas combined with WiSARD classifier approach frequently achieved the highest scores, sometimes losing only for the much slower K-Nearest Neighbors approach. In comparison with other result in the literature, our model has performed better or very close to them in all dataset."
661;en_US;"-In this paper, a new visual selection model is proposed, which combines both early visual feature and objectbased visual selection modulations. This model integrates three main mechanism. The first is responsible for the segmentation of the scene allowing the identification of objects. In the second one, the average of saliency of each object is calculated for each feature considered in this work, which provides the modulation of the visual attention for one or more feature. Finally, the third mechanism is responsible for building the object-saliency map, which highlights the salient objects in the scene. It will be shown that top-down modulation can overcome bottom-up saliency by selecting a known object instead of the most salient (bottom-up) and is even clear in the absence of any bottom-up clue. Several experiment with synthetic and real image are conducted and the obtained result demonstrate the effectiveness of the proposed approach for visual attention."
662;en_US;"-Image representation is an essential issue regarding the problem related to image processing and understanding. In the last years, the sparse representation modeling for signals has been receiving a lot of attention due to its state-of-theart performance in different computer vision tasks. One of the important factors to its success is the ability to promote representations well adapted to the data which rised with the dictionary learning algorithm. The most well known of theses algorithm is the K-SVD. In this work we proposed the αK-SVD algorithm, which tries to explore the search space of possible dictionaries better than the K-SVD. Our approach is evaluated on two public face recognition databases. The result showed that our approach achieved better result than the K-SVD and LC-KSVD when the sparsity level is low."
663;en_US;"-Multi-label learning handles dataset where each instance is associated with multiple labels, which are often correlated. As other machine learning tasks, multi-label learning also suffers from the curse of dimensionality, which can be mitigated by dimensionality reduction tasks, such as feature selection. The standard approach for multi-label feature selection transforms the multi-label dataset into single-label dataset before using traditional feature selection algorithm. However, this approach often ignores label dependence. This work proposes an alternative method, LCFS, which constructs new labels based on relations between the original labels to augment the label set of the original dataset. Afterwards, the augmented dataset is submitted to the standard multi-label feature selection approach. experiment using Information Gain as a measure to evaluate feature were carried out in 10 multi-label benchmark dataset. For each dataset, the quality of the feature selected was assessed by the quality of the classifier built using the feature selected by the standard approach in the original dataset, as well as in the dataset constructed by four LCFS settings. The result show that setting LCFS with simple strategies using pairs of labels gives rise to better classifier than the ones built using the standard approach in the original dataset. Moreover, these good result are accomplished when a small number of feature are selected."
664;en_US;"-In transportation system, drivers usually choose their routes based on their own knowledge about the network. Such a knowledge is obtained from drivers previous trips. When drivers are faced with jams they may change their routes to take a faster path. But this re-routing may not be a good choice because other drivers can proceed in the same way. Furthermore, such behavior can create jams in other links. On the other hand, if drivers build their routes aiming at maximizing the overall travel time (system utility), rather than their individual travel time (agent utility), the whole system may benefit. This work presents two reinforcement learning algorithm for solving the route choice problem in road network. The IQ-learning uses an individual reward function, which aims at finding a policy that maximizes the agent utility. On the other hand, DQ-learning algorithm shapes the agent reward based on difference rewards function, and aims at finding a route that maximizes the system utility. Through experiment we show that DQ-learning is able to reduce the overall travel time when compared to other method."
665;en_US;"-Given the huge size of music collections available on the Web, automatic genre classification is crucial for the organization, search, retrieval and recommendation of music. Different kinds of feature have been employed as input to classification model which have been shown to achieve high accuracy in classification scenarios under controlled environments. In this work, we investigate two components of the music genre classification process: a novel feature vector obtained directly from a description of the musical structure described in MIDI files (named as structural feature), and the performance of relational classifier compared to the traditional ones. Neither structural feature nor relational classifier have been previously applied to the music genre classification problem. Our hyphoteses are: (i) the structural feature provide a more effective description than those currently employed in automatic music genre classification tasks, and (ii) relational classifier can outperform traditional algorithm, as they operate on graph model of the data that embed information on the similarity between music tracks. result from experiment carried out on a music dataset with unbalanced distribution of genres indicate these hypotheses are promising and deserve further investigation."
666;en_US;"-The methodology of multi-label classification is experimentally evaluated in the context of a chemical process where the occurrence of multiple faults is a plausible scenario. As a benchmark, the Tennessee Eastman simulator is used. Modifications to the source code of this system were made in order to permit the simultaneous existence of different faulty machine states. In this work, the method of dependent binary relevance is compared to the binary relevance in terms of the subset accuracy performance criterion, since in a complexly coupled chemical process the dependence of certain fault classes should reveal."
667;en_US;"-Extracting topic from posts in social network is a challenging and relevant computational task. Traditionally, topic are extracted by analyzing syntactic properties in the message, assuming a high correlation between syntax and semantics. This work proposes SToC, a new method for generating more cohesive and meaningful semantic topic within a context. SToC postprocess the output of a Non-Negative Matrix Factorization (NMF) method in order to determine which latent factors should be further merged to improve cohesion. Based on NMFs output, SToC defines a topic transition graph and uses Markovian theory to merge pairs of topic mutually reachable in this graph. experiment on two real data sample from Twitter demonstrate that SToC is statistically better than fair baselines in supervised scenarios and able to determine cohesive and semantically valid topic in unsupervised scenarios."
668;en_US;"-This paper presents some result on lexicon-based classification of sentiment polarity in web review of products written in Brazilian Portuguese. They represent a first step towards a robust opinion miner from review of technology products. The evaluation shows the performance of 3 different sentiment lexicons combined with simple strategies. It is also discussed the risk of considering the rating provided by the writers for the purpose of evaluating the algorithm. The result show that the better combination is the version of the algorithm that deals also with negation and intensification and uses the sentiment lexicon Sentilex. The average F-measure achieved 0.73."
669;en_US;"-This paper aims to propose a mathematical model that evaluates the distribution of the vocabulary frequency terms in proportion to a probabilistic ideal. Once we are able to evaluate it, the main objective of this work is to use it in order to examine text denoising. We propose this new metric based on the classic Zipfs law statistic method. The experimental set to test the classic Zipfs law and our developed model is based on some books of the classic literature and some tweets sets of Twitter. Thus, our main result is that the model proposed in this work is more sensitive to the presence of text noises than Zipfs law and is asymptotically quicker, suitable to corpus of social media network."
670;en_US;"-Given the amount of information stored in textual data and the fact that it is unstructured, algorithm able to process and transform it to a format useful to solve real world problem are desirable. Tasks like organization and exploration of large document collections can benefit from the design of such method. This work proposes an incremental, online and probabilistic clustering algorithm for textual data, based on a mixture of Multinomial distributions. The main advantage of the model is that only a single step over the training data is necessary to learn from it. As more text are processed, the model improves its structure to better represent the data stream."
743;en_US;"-Web service monitoring is important for consumers and provider. For the consumer, it is important to know if the provider is respecting the established electronic contract. provider must satisfy functional and non-functional feature as required by consumers. This paper proposes a selfadaptive architecture for web service monitoring which tries to predict when the provider may not respond in time because of its load. It focuses initially on one non-functional feature, the response time. The goal is to decrease the average response time of requests made to the provider. To improve the response time, the proposed architecture uses a fuzzy method to increase the priority of service whose contract may be violated. Changing priorities gives to the provider an adaptive behavior to avoid contract violations. result show that a decrease in the average response time implies a decrease in the number of contract violations."
744;en_US;"-The multi-objective Quadratic Assignment Problem (mQAP) is a hard optimization problem with many real-world application, such as in hospital layouts. The main purposes of this paper are: (1) the investigation of hybrid algorithm combining Transgenetic algorithm and Evolutionary Multiobjective Optimization (EMO) framework to deal with mQAP and (2) to compare the ability of EMO algorithm based on Pareto dominance with those based on decomposition to deal with the mQAP. Transgenetic algorithm (TAs) are evolutionary algorithm based on cooperation as the main evolutionary strategy. Two hybrid algorithm are proposed to deal with the mQAP: NSTA (TA + NSGA-II) and MOTA/D (TA + MOEA/D). To analyze the performance of the proposed algorithm, nonparametric statistical tests and multi-objective quality indicators are used. The proposed algorithm are compared with NSGAII and MOEA/D in 126 instances of the mQAP. The result demonstrate the superiority of decomposition and transgenetic based algorithm, particularly in MOTA/D."
745;en_US;"-Several Ant Colony Optimization (ACO) algorithm have been proposed to solve multiobjective problem. MOEA/DACO is a multiobjective algorithm based on ACO and the decomposition approach and presents best result when compared with MOEA/D and BiCriterion on discrete optimization problem. This paper proposes a new parallel implementation of MOEA/DACO for execution on the Graphics Processing Unit (GPU) using NVIDIA CUDA in order to improve the efficiency, reaching high quality result in a reasonable execution time. Based on recent researches, both the solution construction and pheromone update phases are implemented using a data parallel approach. We use the multiobjective Traveling Salesman Problem (MTSP) as application. We report speedups of up to 11x from the sequential implementation. Moreover, the result point out that: the number of objectives and the number of subproblem affect directly the speedup."
746;en_US;"-The detection of concept drift allows to point out when a data stream changes its behavior over time, what supports further analysis to understand why the phenomenon represented by such data has changed. Nowadays, researcher have been approaching concept drift using unsupervised learning strategies, due to data streams are open-ended sequences of data which are extremely hard to label. Those approaches usually compute divergences of consecutive model obtained over time. However, those strategies tend to be imprecise as model are obtained by clustering algorithm that do not hold any stability property. By holding a stability property, clustering algorithm would guarantee that a change in clustering model correpond to actual changes in input data. This drawback motivated this work which proposes a new approach to model data streams by using a stable hierarchical clustering algorithm. Our approach also considers a data stream composed of a mixture of time-dependent and independent observations. experiment were conducted using synthetic data streams under different behaviors. result confirm this new approach is capable of detecting concept drift in data streams."
747;en_US;"-Nowadays, many service are available from mobile device, like smartphone. A growing number of people are using these device to access bank accounts, social network and to store personal information. However, common authentication mechanism already present in these device may not provide enough security. Recently, a new authentication method, named accelerometer biometrics, has been proposed. This method allows the identification of user using accelerometer data. Accelerometers, usually present in modern smartphone, are device that measure acceleration forces. In accelerometer biometrics, a model is induced for the user of the smartphone. However, as a behavioral biometric technology, user model may became outdated over time. This paper investigates the use of adaptation mechanism to update biometric user model induced by accelerometer data along the time. The paper also proposes and evaluates a new adaptation mechanism with promising experimental result."
748;en_US;"-Clustering analysis aims to distribute a dataset in groups in such a way that individuals from the same group have a high degree of similarity among each other, while individuals from different groups have a high degree of dissimilarity among each other. Clustering analysis has become an important mechanism for data exploration and understanding. Evolutionary algorithm (EAs) have been widely applied for clustering analysis, given their flexibility and capabilities to deal with difficult environments. In this context, Group Search Optimizer (GSO) is a natureinspired algorithm based on animal searching behavior and group living theory to solve continuous optimization problem. This paper presents a new evolutionary algorithm for data clustering, named KGSO, which uses a Group Search Optimizer and KMeans approach to perform the clustering task. experiment were performed on seven benchmark dataset obtained from UCI Machine Learning Repository and seven synthetic dataset to evaluate the performance of proposed algorithm in comparison to other well-known clustering method from literature."
749;en_US;"-This paper puts forward a proposal for a new type of Self-Organizing Map which makes fast computation, has topology and number of node variable. The map follows a set of 3 basic rule to create groups with receptive fields of approximately the same size regardless of the density of sample. Comparisons of performance with other types of maps were made which used MSE as the metric error and the run time. Two time-serie were used as benchmarks. Possible application of this model include clustering, time-serie forecasting and Vector Quantization."
750;en_US;"-A ring of phase oscillators has been proved to be useful for pattern recognition. It has at least three nontrivial advantages over the traditional dynamical neural network, such as Hopfield Model: First, each input pattern can be encoded in a vector instead of a matrix; second, the connection weights can be determined analytically; third, due to its dynamical nature, it has the ability to capture temporal pattern. In the previous studies of this topic, all pattern are encoded as stable periodic solutions of the oscillator network. In this paper, we continue to explore the oscillator ring for pattern recognition. Specifically, we propose algorithm, which use the chaotic dynamics of the closed loops of Stuart-Landau Oscillators as artificial neurons, to recognize randomly generated fractal pattern. It is worth to note that fractal pattern recognition is a challenge problem due to their discontinuity nature and their complex form."
751;en_US;"-Clustering is one of the most used data mining technique, while computational topology is a very recent field bridging abstract mathematics with concrete computational technique. In this paper, we explore the hypothesis that topologically-similar cluster may indicate meaningful relationships. Our approach has an efficient implementation based on computing Minimum Spanning Trees to obtain topological information of each cluster. We then compute a discreteness and a disconnectedness index, used to characterize each cluster, thus allowing the retrieval of equivalence classes. We show that for a real-world highdimensional network intrusion data set, the topologically-similar cluster retrieved by our approach do indeed correspond to meaningful equivalence classes present in the data set."
752;en_US;"-Description Logics are the basis for the OWL language, which is the standard to represent ontology on the web. As knowledge is usually not static, it is important to be able to revise and repair knowledge bases described in Description Logics. Belief Revision deals with the problem of revising a knowledge base by incoming information. In this paper we propose algorithm for operations that accept as incoming information a set of sentences, instead of the usual single sentence and we present an implementation as a plug-in for Protégé, the most widely used ontology editor nowadays."
753;en_US;"-Recently, prediction of new links between two individuals in social network has gained a lot of attention. However, to fully understand and predict how the network evolves through time, ending relationships also need to be predicted. Although most approaches use graph-based method for link prediction, these may not be suited for the unlink prediction task. In this paper, we propose an approach for unlink prediction that uses information about the domain of discourse through a probabilistic ontology, specified in the probabilistic description logic CRALC. We empirically evaluated our approach comparing it with standard graph-based and some state of the art unlink method. The result shows significant improvement on detecting unlinks when considering our proposal."
754;en_US;"-Recent work have proposed to model social conceptions of rationality (in contraposition to individual rationality) by means of a logic of community. In [11], the authors have defined a logic of friendship to model social relationship as those contained in social network. In fact, they have focused on the definition of a Facebook feature named Inbox message. Following this track, we will extend such a work by introducing in this paper the Private Dynamic Epistemic Friendship Logic (PDEFL) to represent public and private communications among agent, in which the privacy can be established in two ways: either it is defined by the sender of the message or it is defined by the receiver of the message. Furthermore, inspired by the way Facebook user can deal with the privacy of their posted message in what is known as wall, in PDEFL every agent can delimitate his/her privacy level and determine who can see it: everyone (public), only him/her, only friends and only friends of friends."
755;en_US;"-In this paper we focus on lifted inference for statistical relational model; that is, inference that avoids complete grounding, in model that combine logical and probabilistic assertions. We focus on relational Bayesian network that can be represented through parfactors and aggregation parfactors. We present a new elimination rule for lifted variable elimination, and show how to use firstorder d-separation to extend the reach of existing elimination rule."
756;en_US;"-Many real world complex network have an a overlapping community structure, in which a vertex belongs to one or more communities. Numerous approaches for crisp overlapping community detection were proposed in the literature, most of them have a good accuracy but their computational costs are considerably high and infeasible for large-scale network. Since the multilevel approach has not been previously applied to deal with overlapping communities detection problem, in this paper we propose an adaptation of this approach to tackle the detection problem to overlapping communities case. The goal is to analyze the time impact and the quality of solution of our multilevel strategy regarding to traditional algorithm. Our experiment show that our proposal consistently produces good performance compared to single-level algorithm and in less time."
757;en_US;"-In this paper, we study musical knowledge extraction and discrimination. Specifically, we propose a method for automatic extraction of drums rhythmic pattern of music and the rhythmic summarization of a set of songs from the same artist. A musical piece is generally formed of one or more predefined rhythmic pattern and such pattern are composed of rhythmic cells (RC), which are groups of rhythmic figures derived from  -th division of a larger rhythmic figure. At the pre-processing and encoding phase, the RCs of drums percussion lines are represented in duration-weighted notation (DWN). Then, the vector of DWM is encoded to be free of the dimensional dependence on the number of figures in the RC. After that, a network is constructed from the encoded DWM using the method proposed in this paper. We find that the rhythmic pattern of the musical work are related to the formation of communities in the network. In this work, two community detection algorithm are used: Louvain algorithm for the disjoint community detection and Bayesian Nonnegative Matrix Factorization algorithm (BNMF) for detecting overlapping communities. Moreover, a new measure for quantifying the relevance of communities to differentiate types of rhythmic pattern is introduced. The proposed technique has been applied to automatic extraction of drums rhythmic pattern of the song “Drive my car” by The Beatles. Experimental result show good performance of the proposed method."
758;en_US;"-Complex network are a unified form of representing complex system. Through this representation is possible to study dynamical system and make time serie analysis using network technique. One common characteristic of many real world time serie is the periodicity. Detecting these periods is interesting because it permits to forecast the serie behavior. Some technique have been proposed to search for these periods but many of them fail to deal with noisy data. In this paper, we present an algorithm for periodicity detection in noisy data based on community detection. First, the method transforms a time serie by dividing it into interval that are represented by vertices. Then, we apply community detection in order to cluster highly connected ranges. These cluster of vertices represent periodic changes in the serie and can be used to detect periodicity. The efficiency of the proposed method is illustrated in a meteorological case study where we detected periodicity in a noisy temperature data."
759;en_US;"-Complex network became a very important tool in machine learning field, helping researcher to investigate and mine data. They can model real dynamic network, aiding to unveil informations about the system they model. Communities are notable groups that may exist in a complex network and the community detection problem is the focus of attention of many researcher. The igraph library implements a good set of community detection algorithm, allowing researcher to easily apply them to data mining tasks. But each algorithm uses a different approach, leading to different performances. In this paper, the community detection algorithm implemented in the igraph library are investigated and ranked according to their performances in a set of different scenarios. result show walktrap and multi-level got the highest scores while leading eigenvector and spinglass got the lowest ones. These findings are an important contribution for aiding researcher to select or discard algorithm in their own experiment using igraph library."
760;en_US;"-During the software testing process a variety of test suites can be generated in order to evaluate and assure the quality of the products. However, in some context the execution of all suites does not fit the available resource (time, people, etc). In such cases, the suites could be automatically reduced based on some selection criterion. Automatic Test Case (TC) selection could be used to reduce the suites based on some selection criterion. This process can be treated as an optimization problem, aiming to find a subset of TCs which optimizes one or more objective functions (i.e., selection criteria). In this light, we developed two new mechanism for TC selection which consider two objectives simultaneously: maximize branch coverage while minimizing execution cost (time). These mechanism were implemented using multi-objective technique based on Particle Swarm Optimization (PSO). Additionally, we create hybrid multi-objective selection algorithm in order to improve the result. The experiment were performed on the space program from the SIR repository, attesting the feasibility of the proposed hybrid strategies."
761;en_US;"-Evolutionary Computing (EC) approaches have been widely applied on optimization problem, given their flexibility and capabilities to deal with difficult environments. In this context, Group Search Optimizer (GSO) was proposed as a nature-inspired algorithm based on animal searching behavior and group living theory to solve continuous optimization problem. Cooperation has been applied successfully to improve the performance of population-based method, such as Genetic Algorithm (GA) and Particle Swarm Optimization (PSO). In this paper, two new cooperative group search optimization model are presented, based on multiple GSO groups, employing divideand-conquer strategies. experiment were performed on 14 benchmark functions to evaluate the performance of the proposed algorithm in comparison to other well-known EC method from literature. Experimental result showed that the proposed approaches are able to achieve better result than standard GSO in most of the test functions."
762;en_US;"-Many-objective optimization problem (MaOPs) are a class of multi-objective problem that presents more than three functions to be optimized. As most Pareto based algorithm scale poorly according to the number of objectives, researcher are working on alternatives to overcome these limitations. An algorithm that has shown good result in solving MaOPs is the Iterated Multi-swarm (I-Multi) which presents a clever multi-swarm strategy to spread the solutions across different area of the objective space while keeping a good convergence. As the I-Multi is a very recent algorithm, alternative approaches are yet to be explored. Here we investigate the use of an Estimation of Distribution Algorithm (EDA) in the multiswarm stage of I-Multi. EDAs create a model based on the best solutions found and sample new solutions based in this model. An EDA that presents good performance is the rBOA which is a real-valued version of the Bayesian optimization algorithm. This work presents an algorithm called C-Multi consisting of a hybrid between the I-Multi and the rBOA with the aim to join the diversity strength of I-Multi and the convergence characteristic of rBOA. An experimental study is conducted using the seven well-known DTLZ test functions with 3, 5, 10, 15 and 20 objectives to evaluate the performance of the algorithm as the number of objectives scales up. The result point that the new algorithm presents superior convergence and diversity on hard problem."
763;en_US;"-Dealing with big amounts of data is one of the challenges for clustering, which causes the need for distribution and management of huge data sets in separate repositories. New distributed system have been designed to scale up from a single server to thousands of machine. The MapReduce framework allows to divide a job and combine the result seamlessly. The k-means is one of the few clustering algorithm that satisfies the MapReduce constrains, but it requires the previous specification of the number of cluster and is sensitive to their initialization. In this work, we propose a MapReduce clustering algorithm to execute multiple parallel runs of k-means with different initializations and number of cluster. Additionally, a MapReduce version of a cluster relative validity index is implemented and used to find the best result. The proposed algorithm is experimentally compared with the Apache Mahout project MapReduce implementation of k-means. Statistical tests applied on the result indicate that the proposed algorithm can outperform the Mahouts implementation when multiple k-means partitions are required."
764;en_US;"IEEE Computer Society Publications The world-renowned IEEE Computer Society publishes, promotes, and distributes a wide variety of authoritative computer science and engineering text. These books are available from most retail outlets. Visit the CS Store at http://www.computer.org/portal/site/store/index.jsp for a list of products. IEEE Computer Society Conference Publishing service (CPS) The IEEE Computer Society produces conference publications for more than 300 acclaimed international conferences each year in a variety of formats, including books, CD-ROMs, USB Drives, and on-line publications. For information about the IEEE Computer Societys Conference Publishing service (CPS), please e-mail: cps@computer.org or telephone +1-714-821-8380. Fax +1-714-761-1784. Additional information about Conference Publishing service (CPS) can be accessed from our web site at: http://www.computer.org/cps CPS Online is our innovative online collaborative conference publishing system designed to speed the delivery of price quotations and provide conferences with real-time access to all of a project publication materials during production, including the final paper. The CPS Online workpace gives a conference the opportunity to upload files through any Web browser, check status and scheduling on their project, make changes to the Table of Contents and Front Matter, approve editorial changes and proofs, and communicate with their CPS editor through discussion forums, chat tool, commenting tool and e-mail."
2146;en_US;"Network Functions Virtualization is a paradigm in which network service are virtualized over generic hardware. In this approach, one of the key challenges is the performance when compared to dedicated solutions. This work evaluates the performance of an HTTP proxy in two virtualization solutions, KVM and Docker. result show that Docker performs better than KVM, presenting proxy processing times close to those of a non-virtualized solution. However, when more isolation is required, KVM is more suitable. In this line, this work shows that the para-virtualization of KVM significantly improves performance, but not enough to overcome Docker."
2147;en_US;"Cloud computing has emerged as a cost-effective paradigm for hosting and delivering service. Cloud provider adopt server consolidation strategies to achieve efficient management of resource. A drawback is that application running on the same host compete for physical resource. Such interference can affect the performance of application. Performance monitors are useful tool to detect or even predict performance degradation. However, the monitoring itself can be a source of contention. In this paper, we analyze the influence of performance monitoring overhead in virtualized environments. Furthermore, as a mean to reduce contention for shared resource, we propose an approach to reduce the dimensionality of the performance feature space."
2149;en_US;"Interactive and real-time application, such as online game, often have strict latency requirement. More specifically, they may require user to have similar latency values; otherwise there may be unfairness between them. This work proposes an application for software defined network that ensures that the latencies between each user and the server are as close as possible. This application periodically solves an optimization problem that takes latency of the links into account and chooses the paths of the flows in the network. From the experiment carried out with emulation, it can be noticed that the proposed network application achieves a level of fairness greater than that of a traditional network."
2154;en_US;"Detection and classification of Internet interruptions is a widely studied topic. However, although there are several technique and studies for detecting interruptions, this is not done with a focus on the interruptions to the end user. This paper presents a systematic evaluation of Internet interruptions from historical data of an Internet monitoring system, called RIPE Atlas. The result show that the geoeconomic parameters used in this research have little correlation with the amount of interruptions in the Internet. However, we observe that there are differences in the duration and frequency of interruptions with the location of the device. We show that a simple interruption model can be used to identify network problem, as in the case of Hurricane Harvey. We identified a 10% increase in the number of interruptions and 44% in interruption time in Houston (Texas) during the hurricane. The result can be used in the future as a substrate for the development of new interrupt predictors."
2155;en_US;"This paper document our efforts towards understanding which factors are more relevant in human mobility prediction. Our work is divided into two phases. First, we characterize a dataset consisting of more than 200,000 user check-ins in the Foursquare social network, inferring important pattern in human mobility. Second, we use factorial design to quantify the importance of several types of contextual information in human mobility prediction. Our result show that the proximity of the user possible next check-in to his or her home and work location are the most important factors (among the ones we analyzed) to be used by mobility prediction model."
2162;en_US;"The threat posed by botnets of infecting a large number of device and using them together to perform several malicious actions has become a growing issue to the Internet security. One way to deal with it is to have method able to correctly identify those botnets and then run necessary countermeasures. Many approaches using machine learning (ML) have been proposed over the years to cope with botnet detection. Nonetheless, the algorithm commonly employed cannot adapt to new data without significant effort. In this sense, a ML research topic referred to as stream mining may be a solution. Stream mining algorithm are specially tailored to learn incrementally with new instances, without consuming significant memory or time. This work proposes an approach using the Very Fast Decision Tree, a classification algorithm used on stream mining that can learn incrementally when needed, to identify botnets by observing network flows. When evaluating the approach on multiple scenarios with different botnets, we were able to achieve high performance metrics on the majority of scenarios, while using a significantly low number of labelled instances."
2163;en_US;"Several factors may influence the number of spam received by email user, from user profile information such as age or nationality to the way the email account is exposed on the Web. We propose a replication study of an experiment conducted more than a decade ago to understand the changes in the dynamics of the business of spam. To that end, using real email addresses created and managed only for the experiment, we simulate four different behavior profiles: i) interaction on social network, ii) purchase in e-commerce sites, iii) interaction on forums and message boards and iv) use of file sharing tool, and analyze the amount of spam received on those accounts. The result indicate that linking an email account to a social network is the most significant influence on the spam rate."
2166;en_US;"Nowadays, time serie data underlies countless research activity. Despite the wide range of technique to capture and process all this information, issues such as analyzing large amounts of data and detecting unusual behaviors on them still pose a great challenge. In this context, this paper suggests SHESD+, a statistical technique that combines the Extreme Studentized Deviate (ESD) test and a decomposition procedure based on Loess to detect anomalies on time serie data. The proposed technique employs robust metrics to identify anomalies in a more proper and accurate manner, even in the presence of trend and seasonal spikes. Simulation studies are carried out to evaluate the effectiveness of the SH-ESD+ using the published Numenta Anomaly Benchmark (NAB) collection. Computational result show that the SH-ESD+ performs consistently when compared against state-of-the-art and classic detection technique."
2168;en_US;"Experiment reproducibility, essential for the verification of effectiveness/efficiency of scientific contributions, is particularly challenging in the context of large-scale distributed system. Non-programmed failures (either at node that compose the system, or in the communication between them) may make it difficult for one to achieve statistical significance in the result, or to verify their validity. To address this problem, we propose EASYEXP, a fault-tolerant architecture to ensure the reproducibility of experiment in non-reliable distributed testbeds. In EASYEXP, node in the experiment environment “interpret” workers and execute actions that are expected for them, following a predefined schedule. In the event of failure of a node, it is replaced by another functional one, keeping the execution context of the worker interpreted by it. result obtained show that EASYEXP is able to maintain a lower variation (standard deviation of 1.6 %) and higher precision (95.7 %) among multiple runs of the same experiment, when compared to those performed in a traditional way (25% deviation and 72% accuracy only)."
2171;en_US;"In recent years, the use of the fog computing paradigm is increasingly present in studies and service offered by a smart city, as the intelligent home system which are one of the service to be highlighted. However, such paradigm brings two major challenges within the context of intelligent homes: how to extract the data that will be used in the decision-making process efficiently, and how to enable interoperability among the device. Thus, this work proposes ImPeRIum, an intelligent decision system which forms a fog computational environment to manage the application of the residence. ImPeRIum was evaluated in both the simulated environment and the real environment. When compared with other work in literature, ImPeRIum showed an advance in the state of the art and It obtained three promising result: (i) high hit rate with a low delay in the decision-making process; (ii) efficient in the information dissemination with a low overhead in infrastructure; and (iii) robustness in processing with a low energy consumption."
2174;en_US;"Sentiment Analysis in social network has been explored in different types of research, and its main intention is to extract user opinion on a wide range of subjects, making possible to obtain significant information. For Portuguese, Sentiment Analysis research is still being established. In this context, this work proposes a method to estimate sentiment in social network for the Portuguese language, focusing on Twitter. For such purpose, we used a Committee, which is implemented through a set of machine learning algorithm for classification. The evaluation of the proposed method was performed using statistical and performance tests. The result indicate that the Committee had better accuracy when compared to other machine learning algorithm for the performance tests. Nevertheless, there was no proven statistical difference between the Committees algorithm and some of the algorithm, indicating that these method could achieve equivalent accuracy to the Committee in some specific situations, such as a larger database."
2177;en_US;"The employment of IEEE 802.11p compliant device in the automotive environment is considered a crucial factor to leverage traffic safety and efficiency, which makes it critical to evaluate this standard before it is fully integrated with real system. However, due to the high cost and the low supply of commercial device, most of the work involving VANETs (Vehicular Ad-hoc network) is still carried out only with simulation. In order to investigate possible equivalences, this work investigates the result of real measurements involving V2I (Vehicle-to-Infrastructure) and V2V (Vehicle-to-Vehicle) scenarios. For this, result obtained using OBUs (On-Board Units) and RSUs (Road-Side Units) were compared with those obtained by the NS-3 simulator. Three metrics were evaluated: the maximum reach, the packet delivery rate and the packet inter-reception time. The influence of different types of modulation allowed in the IEEE 802.11p standard and of several mobility pattern were also analyzed. This work represents a reference for the complete integration of this standard, and contributes to the validation and evolution of the current simulation model."
2178;en_US;"The accurate detection of people in indoor environments requires high-cost device, while low-cost device, in addition to low accuracy, offers little information about the monitored events. The perturbations that can affect the electromagnetic signals used by 802.11 interface make this type of device a low-cost sensor, widely available, and enoughly accurate for several application. In this work, we propose the WiDMove, a proposal to detect the entry and exit of people indoors using channel quality measurements (known as Channel State Information - CSI) offered by the IEEE 802.11n standard. Our proposal is based on signal processing and machine learning technique, which allow us to extract and classify event signatures using the CSI. In lab tests with off-the-shelf 802.11 interface, we collected CSI sample that were affected by 8 different people. From this collected data we extracted the signature of the entry and exit events using some technique such as Principal Component Analysis (PCA) and Short-Time Fourier Transform (STFT). We trained a Support Vector Machine (SVM) classifier and validated it with cross-validation, using the K-Fold and Leave-One-Out technique. WiDMove presented that can reach an average accuracy above 85%."
2179;en_US;"There are great expectations on technologies such as network functions virtualization (NFV) and centralized or cloud radio access network (CRAN) and how they can accelerate deployment of new network service and at the same time decrease some costs of the network operators. In this context, there is a relevant problem that involves three main concerns: 1) which cell sites to be updated; 2) how to update the selected cell sites, i.e., change to fully virtual or not; and 3) where to serve the visualized cell sites. Those issues are influenced by the centralization level employed on a certain radio access network (RAN). We propose an optimization model that allows the decision maker to define the weight (or reward) of the centralization level and evaluate the impact on metrics such as the necessary investment and the achieved level of centralization. The model shows how the investment should be allocated depending on the level of centralization and the relative cost among the different resource. Our heuristic presents performance similar to the deterministic approach but it is able to obtain solutions much faster and to deal with large network (i.e., city and metropolitan regions)."
2182;en_US;"Shared computing system are composed by different resource types, such as CPU and memory, and hold user with different resource constraints. While some user execute short workloads in which fast allocation is essential, others execute long workloads that require more resource. Among the different proposals to allocate resource in this scenario, Dominant Resource Fairness (DRF) is notable for satisfying some desirable properties, such as truthfulness and Pareto efficiency. However, these proposals focus only on instantaneous fairness, ignoring user heterogeneity. This paper proposes DRF with state (SDRF). SDRF satisfies the fundamental properties of DRF, besides enforcing a new notion of fairness that look at past resource allocations. We verify SDRF with both theoretical analysis and simulation using Google cluster traces. result show that SDRF reduces user average waiting time and improves fairness by increasing the number of completed tasks for user with lower demand with low impact on high-demand user."
2183;en_US;"Blockchain is a distributed database that maintains a list of transactions in a data structure called block, which connected to the previous one, builds a chain of blocks. It was designed with the purpose of providing secure, public and auditable financial transactions. Nevertheless, it can be deployed in many area and it is prone to attacks. One of the most well-known attack is the Selfish Mining, which under certain conditions, can result in a disproportionate share of rewards to attackers straying from the honest behavior. This paper introduces and analyses the Stalker, a strategy used by a Selfish Miner to prevent a specific block or transaction from being published. result show that the efficacy of this strategy is directly proportional to the computational power relation between the attacker and the target. result show that the Stalker can block up to 40% of target blocks and has a collateral damage of dropping blocks from other node."
2185;en_US;"Network virtualization has gained visibility by enabling the development of new functionalities and application for the internet. With virtualization, a logical view of the hardware is created so that multiple virtual network can coexist on the same physical network substrate. The virtual network embedding problem belongs to the NP-hard class not allowing the use of exact approaches. In this work, the application of a fast heuristic approach in a multidomain, decentralized and online environment is proposed, through an orchestrators control. A comparative study regarding the implementation of three different orchestration model is presented: total knowledge, partial and without knowledge of the internal physical network infrastructure of the domains. Experimental result show the performance of the orchestrator along with the heuristic, reporting energy consumption, profit generation and message exchange metrics for the different approaches."
2188;en_US;"The community has discussed the potential of processing and wireless communication of vehicles in a transportation system. In this sense, VANETs aim to exploit the communication and sensing capabilities of vehicles to feed data into application and service. VANETs also contribute to the emergence of ADAS and ITS, which seek to provide service to user as safety and less tiring trips. Many of these system need to authenticate their user, but they do so in a way that an attacking driver can use them. This work explores the driver identification as an extra authentication factor to local service and vehicular network. Then, a virtual sensor was developed to determine the driver identity, with precision above 98%, using embedded sensor data. This sensor was also used to identify driver suspects. Besides, based on the suspects identification, we discuss the impacts of these drivers in the data dissemination in a vehicular network."
2190;en_US;"The large amount of data generated by the advances of mobile technology makes the service provider get more and more interested in collecting and analyzing it. In this study, we investigate for the first time a real and largescale dataset related to the use of mobile application to identify pattern of access, data traffic, period of use, and transition among service. The characterization result reveal that different service are consumed differently by their user. In addition to the characterization, the contributions of this work are two-fold. First, we propose and validate a synthetic data generator that can be used by other researcher. Also, we evaluate which metrics affect the prediction of the next application to be launched, reducing then the user waiting time."
2191;en_US;"In 5G network, the traffic demands are expected to increase significantly. To deal with this problem, many research efforts focus on TWDMPON for the fronthaul. However, TWDM-PON suffers from the issue of wasted bandwidth when a demand is smaller than the channel. In order to avoid this inefficiency, we propose an OFDM-PON supported architecture for the Cloud Radio Access Network (C-RAN) topology to implement the technology of elastic optical network into C-RAN. experiment show that OFDM-PON allows for improved usage of the bandwidth (between 145% and 218% improvement), similar average wait time for requests (average difference below 7%), and similar request loss (average difference below 2%) in comparison to TWDM."
2193;en_US;"Smart city emerge as a topic that applies information and communication technology in urban centers to monitor their dynamics and allow the improvement of service for their citizens. This monitoring occurs, for example, when analyzing data produced by citizens in their daily lives. A significant amount of this data has spatio-temporal annotations, which may be used to analyze the city dynamics, such as the mobility flow. Due to these characteristics and also the possibilities brought by their use and analyses, this work presents a novel approach to use social media data to enhance the positioning of taxis within the city. The result show that data from location-based social network may be used as peoples concentration virtual sensor, which can be used by the urban transportation system. The present shows how different urban data source can be related using spatio-temporal correlation of three different source was verified. The proposal was validated using data from the taxi system of New York City and also data from the Twitter platform. The analysis was handled using the SMAFramework, a framework to perform analysis in urban mobility data."
2194;en_US;"The cloud computing paradigm consolidated the on-demand provisioning of virtual resource. However, the diversity of service, prices, Data Centers (DCs), and geographical footprints, have turned the clouds into a complex and heterogeneous environment. There are several Infrastructure-as-aService(IaaS) provider differentiated by the provisioning costs, and service capabilities. Due to management complexity, the survivability and reliability aspects are often disregarded by tenants, eventually resulting on heavy losses due to unavailability of service hosted by Virtual Infrastructures (VIs). We present an alternative to improve VIs survivability and reliability, taking into account the use of replicas and the spreading of virtual resource atop provider, regions, and zones. Replicas are used to achieve an user-defined reliability level while the controlled spreading of VI components decrease the probability of full outages. In addition, the proposal performs a cost-effective provisioning. We formulate the VI allocation, survivability, and reliability requirement as a Mixed Integer Program (MIP). Simulation result using different target reliability levels shows an increase on survivability without inflating costs."
2202;en_US;"Nowadays, the Internet is part of our lives, being an essential way of communication. However, it suffers from limitations that prevent guarantees of Quality of Service (QoS) to the user. Thus, Internet Service provider (ISPs) need to evolve, adding new technologies and management strategies, such as Network Virtualization (NV), Software Defined Network (SDN) and Network Function Virtualization (NFV), resulting in the Future Internet Service provider (FISPs). Therefore, FISPs slice their network resource among clients and delivered service, where an algorithm to define the structure of the slice is crucial . Additionally, FISPs should consider the elastic resource utilization of the clients within periods of time through the day. In this context, this paper presents the Per Time Calculation (PETIC) algorithm to define slices based on the daytime bandwidth requirement of the clients. Numerical result suggest that the proposed algorithm defines more suitable slices than the existing approaches."
2218;en_US;"device of Internet of Things suffer from severe processing and power constraints, which hinders offering complex network service, other than simple data transmission. In smart city scenarios, the lack of these service, such as security and quality of service, might lead to low performance that can result in disasters in urban centers. In this paper, we propose an agile and effective network function virtualization infrastructure of isolated domains of connected device, which outsource network tasks from the device to the networking cloud. The domain isolation is achieved by virtualizing the gateway access node to which IoT device connect. We have deployed a prototype to provide security and quality of service to IoT application. Preliminary result show that the gateway virtualization does not impact the performance of virtual network functions. Additionally, our proposal provides security for connected device, identifying the mallicious traffic with 99.8% accuracy, avoiding denial of essential service, and ensuring quality of service."
2223;en_US;"The use of botnets, network composed of malware-infected device, for malicious activity, such as denial-of-service attacks and spam/phishing distribution, causes billion-dollar losses every year. The growth of the Internet of Things, combined with the low security of its device, has provided invaders with a rich environment for the creation of botnets. To combat such network, it is essential to understand their behavior. In this work we monitor widespread IoT-based Bashlite botnets using a network of low-interactivity honeypots. We analyzed both the scanning and infection of vulnerable device as well as the command flow sent to infected device by their controllers. Our result suggest that botnets rely on infrastructure provider, that most of the infections use unmodified publicly-available source code, and that there is a concentration of attacks on specific targets."
2225;en_US;"This work presents a circuit reallocation strategy aware of the physical layer effects. The main objective of the strategy is to reduce blockages related to transmission quality of the circuits. It is worth mentioning that the reallocation of elastic optical circuits has already been the focus of other studies, but only aimed at the defragmentation of the network. The proposed strategy is applied to two physical layer-aware RMLSA algorithm: K-Shortest Path Computation (KS-PC) and K-Shortest Path with Reduction of QoTO (KSP-RQoTO). The performance of each of the algorithm is evaluated with and without the use of the proposed strategy. The result were obtained through computational simulation for NSFNet and EON network topologies. In terms of probability of blocking circuits, the KS-PC and KSP-RQoTO algorithm presented respectively reductions of up to 29.75% and 44.06% for the NSFNet topology. These reductions were obtained by reallocating only 12.01% of the active circuits for the KS-PC and 16.47% for the KSP-RQoTO. In the EON topology, there was an approximate gain of up to 49.42% for KS-PC and 31.91% for KSP-RQoTO. The percentage of reallocated circuits for the EON topology was up to 13.34% and 11.50% for the KS-PC and KSP-RQoTO algorithm, respectively."
2232;en_US;"Caching is a fundamental element of networking system since the early days of the Internet. By filtering requests towards custodians, caches reduce the bandwidth required by the latter and the delay experienced by clients. The requests which are not served by a cache, in turn, comprise its miss stream, which is a smoothed version of the stream of request arrivals. In this paper, we propose novel mechanism to leverage hysteresis (i.e., smoothing) on cache evictions and insertions. The proposed solutions extend TTL-like mechanism, and rely on two knobs to tune the time between insertions and evictions given a target hit rate. We show the particular improvement of the two thresholds strategy in reducing download times, making the system more predictable and accounting for different costs associated with object retrieval."
2236;en_US;"In recent years wireless network have been used more widely and their monitoring reveals that there are still key weaknesses in implementing the 802.11 protocol that can be changed to improve efficiency and end-to-end performance. In these network, where the medium is shared, management traffic is an essential element that among other functions allows to maintain connectivity and promote service quality. However, in the case where the network have low mobility, the frequent transmissions of beacon frames by the access points causes overhead in the channels which can be characterized as unnecessary traffic, which increases linearly at each additional access point. In this work, we present a proposal to modify the 802.11 protocol to support the dynamic adjustment of the transmission interval between beacon frames in order to increase the efficiency of the network. The proposal is based on the observation of certain geographic movement pattern of stations that share the same channel, pattern that are not common on low mobility network and may indicate if stations are going to associate or dissociate from an access point in the near future. The simulation result show that dynamic tuning can be effective and increase throughput in network with low mobility stations."
2247;en_US;"Billions of device connected to the Internet generate a large amount of data every day, which they serve as the basis for application on a global scale. The increasing demand for these application creates some challenges in the Internet of Things ecosystem, e.g. data integration and device heterogeneity. Solutions on cloud-based platforms have been increasingly used to address such issues. However, a robust infrastructure for storing and processing large amounts of run-time data is required. This work presents a cloud IoT platform capable of handling with the integration of a large amounts of data and heterogeneity of device based on Apache Kafka. The main contributions of this work are: i) the specification, implementation and validation of an IoT platform in the cloud and; ii) design and development of a generic interface based on webservice for abstraction of details regarding the platform with the device. With integration of the platform and the interface developed, it was possible to obtain satisfactory result in the standardization of the communication and in the flow and storage of reliable data, offering rates of fast transfers in Mb/s."
2249;en_US;"Software Defined network (SDN) isolate the control plane from the data plane, allowing a global view of the network and providing a high level programmable network. This can be very useful for managing network access control by associating device flows to user profiles. This paper proposes a tool for managing user profiles by authorizing device flows using software-defined network. This tool has been implemented on the OpenFlow controller POX. In this paper we describe the experiment performed and the result obtained, which show the efficacy and the ease of use of the mechanism."
2250;en_US;"Recommender system are increasingly present in Internet user routine. Therefore, platforms like Youtube and Netflix seek to improve their recommendation system, to provide a better experience for their user. The experience of user, however, depends on a multitude of factors. In particular, caching system have an important influence in the quality of experience (QoE), since they impact quality of service (QoS) metrics (such as the delay and the throughput) experienced by user. In this paper, our goal is to devise a QoE-friendly recommender system. To this aim, we conduct an experiment with real user, having different profiles. Each user is requested to evaluate different movies, which vary in their contents and in the corresponding QoE. Our result provide a novel perspective on the relationships between recommender system and caching system. With decision trees, we propose a recommender system which accounts for QoE and content nature simultaneously. The proposed system reached a precision of 83% using our preliminary dataset which counts with hundreds of user ratings."
2258;en_US;"We live today in a highly competitive world in many area, including the business world. Thus, strategic business partnerships are important for a business to succeed, especially for those exposed to a dynamic and uncertain market. Therefore, this study aims to identify expressive virtual relationships between company that are generated spontaneously by user in social media. To this end, a business similarity model based on common spontaneous reactions of user in social media, particularly Facebook, is proposed, as well as a new algorithm for detecting business communities within the proposed model. To demonstrate the proposed methodology, the study uses more than 280 million user reactions on Facebook about company in Curitiba, Brazil. Exploring these data and the proposed methodology, this study shows the possibility to identify non-trivial relations between company, which may enable the development of new mechanism for recommending strategic business partnerships for entrepreneurs and business owners."
2261;en_US;"Crime data refers to crime events reported in natural language to the emergency response center of the police forces. Furthermore, it comprehends the textual description of the event and may be utilized to understand what characterizes crime situations, considering weapon of crime, objects stolen, criminal activity and more. In this work its applied data pre-processing, transformation and mining technique to discover hidden crime details in the dataset relating similar records. Consequently, the crime records are classified into 3 groups considering the sophistication of the criminal action, being: A (low sophistication), B (medium sophistication), or C (high sophistication). To find out the impact of absence and usage of pre-processing technique and which data mining technique achieves the best result, two experiment were performed and had their mean accuracy compared. The usage of pre-processing and Random Forest algorithm achieved better result and also the capability of understanding a high dimensional and dynamic data. Consequently, the joint of these technique can provide better information to police forces."
2265;en_US;"Vehicle network have become a frequently studied topic of the Internet of Things. It allows communication between vehicles and access points along the streets, making the route safer for people. From studies of this network, it is possible to better understand peoples behavior in big city, including their routines, most frequented places for each weekday and mobility model. With the result, it can be created several application for human benefit and improve network communication protocol. In this work, we analyze taxicabs traces regarding encounters throughout the day in the city of San Francisco, USA. The goal is to show that there are standards in the number of times these vehicles meet, mainly by comparing weekends with weekdays. For the development, it was used temporal graph, calibrated traces of the citys táxis and three metrics that are related to the number of encounters. The metrics explored were: repeated encounters throughout the day, repeated encounters throughout the day in the same place, and the ratio of the number of repeated encounters over the total number of encounters for each vehicle. As a result, we find some pattern in the vehicle routines."
2267;en_US;"With the increase of vehicles in the big urban centers we can observe an increase in the number of congestion and accidents in the public ways caused not only by the lack of attention of the driver but also by the lack of a traffic infrastructure that assists the driver in the decision making before a event or condition of the route. One of the service provided to the driver is the monitoring of the roads to detect the flow of vehicles that are traveling in a road. In order to increase the efficiency of the traffic flow and optimize the process of propagating this information to the user, we propose an architecture in which to detect and classify the flow of vehicles on the highway. For this, the proposed architecture has a mechanism in which the concepts of computational vision are used to extract the maximum information from the roads in order to inform drivers about the traffic conditions of vehicles on Brazilian highways. The efficiency of the proposed method was evaluated. The result showed that the developed method obtained a lower false positive around 3%, a lower false negative (9%), consequently a better classification of vehicles. In addition, the proposed solution obtained a flow classification score around 90"
2269;en_US;"In the last years, WSNs are being implemented in different types of application in the urban scenario, being one of the approaches, the monitoring of natural disasters, for example floods. Typically, application to detect natural disasters are installed in inhospitable locations and rely on multihop communication for the data to reach a sink sink. In this scenario, one of the main challenges of these system is to issue warnings in a timely manner to avoid major disasters. The issue of risk and disaster management and mitigation has been discussed by several countries at the conventions on climate change and sustainable development. However, correlating WSN disseminated data to achieve this goal is not a trivial task. For these reasons, this paper proposes a prediction model based on data mining and machine learning, in order to correlate different databases to achieve a higher quality of information. The algorithm Random Forest stood out among others, reaching 97% accuracy, and outperformed them in the rigorous t-test test of the weka tool. In addition, the forecast model has shown that it can better manage the resource of an RSSF."
2277;en_US;"The Impact failure detector (FD), introduced in [Rossetto et al. 2015a] outputs a trust level value which expresses the degree of confidence in the system. An impact factor is assigned to each process and the trust level is equal to the sum of the impact factors of the process not suspected of failure. Moreover, an input threshold parameter defines a lower bound value for the trust level, over which the confidence in the system is ensured. However, in the definition of the impact factor, every node has an impact factor value which does not change during execution. In this article, we propose a message-pattern implementation of the Impact FD (query-response) in which the concept of impact factor is extended to become dynamic. Its value is periodically re-evaluated based on the history of false suspicions of the node. Performance result of experiment conducted with real PlanetLab traces confirm that the dynamic impact factor increases significantly the confidence in the system, when compared to the original static impact factor."
2281;en_US;"A big challenge when designing and operating a federation of cloud computing provider is the implementation of a suitable business model that enables the federation to function appropriately. Barter-based business model were proposed as a cheap and efficient way to mediate transactions between the provider that form the federation. In this work, we discuss the challenges related to the implementation of a barter mechanism in a federation of cloud computing provider, proposed by us previously. The performance of the mechanism is evaluated through controlled experiment. The result obtained corroborate previous result obtained with simplified simulation model. In particular, the mechanism in place is able to ensure fairness in the use of resource while maintaining the satisfaction of collaborative members at sufficiently high levels."
2285;en_US;"The fog computing concept aims at taking cloud service closer to the clients to optimize resource and increase network performance, since the current centralized model might not be able to handle the demands typical from the Internet of Things. In this paper, we present a generic model for the deployment of fog computing, which can be used as reference for real use cases. We have set up a testbed to demonstrate the feasibility of our model and present result from a performance analysis study that highlights when the use fog computing is viable, based on factors and peculiarities of each use case."
2286;en_US;"The deployment of Internet of Things (IoT) based application for Smart city emphasize the need for solutions that can automatically detect events of interest in these system. Some scenarios, such as smart public lighting and user monitoring in the so-called digital squares, are examples that generate a massive amount of data. In these scenarios, anomalies need to be identified as fast as possible, since corresponding actions should be executed in a timely manner. An atypical event can have huge impacts on the nearby population. A fog computing based architecture has been proposed to make real-time anomaly detection feasible. The model was evaluated with real data from digital squares from the city of São Paulo and with data from synthetically generated sensor, obtaining satisfactory result in both cases."
2293;en_US;"Heterogeneous network offer a wide range of multimedia service ranging from safety and traffic warnings to entertainment and advertising video. In this context, user can access content through the communication between their device with different wireless network, such as, LTE and Wi-Fi. However, real-time video streaming at a heterogeneous network with Quality of Experience (QoE) is a challenging task, due to the great diversity of both mobile node and radio base stations of a heterogeneous network. To mitigate such factors, this paper presents a handover algorithm that considers QoE, Quality of Service (QoS) and channel quality in heterogeneous network, known as handover aware of Quality of Service, Experience and Radio (SER). The proposed algorithm considers the Analytic Hierarchy Process (AHP) to adjust the degree of importance of each criteria in choosing the appropriate radio base station that the mobile node must connect to, allowing a more efficient handover decision for video transmission with QoE support. Simulation result show that SER handover delivered video with QoE 15 % better compared to the algorithm found in the literature."
2297;en_US;"Software-defined networking has been providing more control to network operators, but generating several OpenFlow rule simultaneously is yet a tough job. There are already research project that generate a set of rule for basic network operations, as well as tool with their own grammars which parse high level network policy descriptions and translate them to rule. It was observed that a combination of these solutions can generate a new resource capable of giving to network administrators a friendly configuration language to help them define how data traffic should be forwarded. This work presents Havox, a service meant to help with traffic orchestration through a simple, high level configuration language based on OpenFlow fields. experiment show a considerable reduction of network programming effort in a scalable way, reducing both the number of parameters and the number of lines of code."
2298;en_US;"The specification of quality of service (QoS) requirement such as delay, jitter and throughput in traditional data network is limited by the high administrative cost of these environments. On the other hand, the softwaredefined network (SDN) paradigm, with its global vision and its higher level of programmability, simplifies the management of the whole infrastructure of the data network. In this sense, SDN can provide simple and effective QoS provisioning mechanism in these network in order to meet the needed requirement. Thus, in this paper, we propose a QoS provision architecture exploiting the capabilities of the SDN model. The approach consists in providing software components that allow the specification of classes of service, in addition to negotiating the QoS requirement between application and the network controller. In this platform, the SDN controller monitors the environment and adjusts the network through resource reservation and traffic prioritization. A proof-of-concept has been deployed and our result show that the additional routines present low overhead, whereas a reduction of up to 47% in transfer times is observed."
2300;en_US;"Internet of Things (IoT) supports many user and service controlling heterogeneous device, implementing context aware application. Thus, new access control model must be created in order to support more responsive, scalable, secure and autonomous management. This paper presents an attribute-based access control model, which applies conflict resolution and access delegation in a multi-user environment. With scalability in mind, we propose the caching of access permissions, as well as a policy model in which the device with enough computational power perform part of the processing. The proposed model was implemented as part of the ManIoT architecture and evaluated by experiment on a testbed to demonstrate its efficiency. result show that our model accelerates the access management, supporting environments where multiple user and application seek to access device concurrently."
2303;en_US;"The elephant flows typically are primarily responsible for network congestion, causing impacts on application that are intolerant to delays. Although there are several work in the literature that analyze this type of traffic, none of them consider the impact of elephant flow size when perfoming the rerouting of them, influencing the Flow Completion Time (FCT) and throughput. In this way, this article presents EFM (Elephant Flow Manager) as a complete solution for monitoring and re-routing elephant flows in DCNs (Data Center network). The tests performed show that the size of the elephant flows influences the throughput and the FCT of the application and, therefore, deserves to be observed. The evaluation of the solution was performed comparing the joint use of EFM with ECMP. In all tests, our re-routing solution was better when compared to pure routing with only ECMP. Then, this work presents three main contributions: (1) proposes and implements an architecture for the detection and treatment of elephant flows in DCNs (2) highlights the importance of the size of elephant flows in the re-routing of these in DCNs (3) the EFM in conjunction with the ECMP reduces the energy consumption in the DCNs, since the FCT of the flows is decreased."
2309;en_US;"Network Function Virtualization (NFV) technology provides a flexible and low-cost network model that replaces proprietary hardware network functions with software-based virtualized network functions which run on general-purpose machine. Virtual functions are orchestrated in a distributed multi-tenant trustless environment and are, thus, susceptible to security threats. This article proposes SINFONIA, a blockchain-based system that provides security to virtualized network, ensuring auditability, non-repudiation, and integrity of orchestration operations. SINFONIA provides a modular architecture which allows the orchestration of network functions in a simple and agile way. A prototype for the Open Platform for Network Function Virtualization (OPNFV) was developed with the implementation of a specific blockchain and a collusion-resistant consensus protocol. The result show that SINFONIA provides security with low overhead to the cloud orchestrator with stable performance as the number of consensus participant increases."
2311;en_US;"The purpose of this paper is to to investigate the potential use of the blockchain technology combined with active distributed repositories to create a platform, scalable and agnostic1, specialized in the authentication and preservation of digital document. As a proof of concept of the proposed platform, was performed the construction of a public service for digital registration and verification of the authenticity of academic document. The prototype of the service offers an interface for educational institutions to register official document, such as diplomas and certificates, using blockchain and an interface so that user can verify the authenticity of a document through its registration number in a DLT. The document registered in the service are automatically inserted in the long-term digital preservation repository."
2312;en_US;"Data privacy refers to ensuring that user keep control over access to information, whereas data accessibility refers to ensuring that information access is unconstrained. Conflicts between privacy and accessibility of data are natural to occur, and healthcare is a domain in which they are particularly relevant. In the present article, we discuss how blockchain technology, and smart contracts, could help in some typical scenarios related to data access, data management and data interoperability for the specific healthcare domain. We then propose the implementation of a large-scale information architecture to access Electronic Health Records (EHRs) based on Smart Contracts as information mediators. Our main contribution is the framing of data privacy and accessibility issues in healthcare and the proposal of an integrated blockchain based architecture."
2323;en_US;"Name-based forwarding/routing (NBFR) is an emerging approach to provide location-independent delivery in Future Internet (FI). It provides identifier-based communication independently of location. Even tough many FI proposals support NBRF for specific ingredients (e.g. contents or hosts), therefore a generic approach is missing. Also, current proposals, like CCN, XIA and NetInf do not employ self-verifying names (SVNes) alternatively as identifiers and/or locators (making dual use of SVNes, saving storage resource). Another novelty is to employ the same BNFR structure not only horizontally (among node), but also inside node vertically (among operating system, process and its components). This paper provides a proof-of-concept of NovaGenesis Forwarding/Routing with Dual Names (FRDN). FRDN enables unlimited name-based data plane with SVNes. Future work includes performance evaluation in a large experimental setup, for instance employing Brazilian FIBRE research network in the context of future Internet interconnection point (FIXP) project."
2327;en_US;"The Internet-of-things attracts the attention of many researcher in computer network with the challenge of providing connectivity to a huge quantity of device. This reality can be further complicated once again with the recent proposed Internet-of-bionano-things. Nanomachine, natural or synthetic, will be able to communicate to each other and to the Internet through the means of communication system that are being developed at the nano-scale with the goal of cooperatively executing complex tasks. This technology requires a complete revision of the TCP/IP architecture to accommodate the requirement and demands of the nanonetwork. This chapter aims at introducing this research field to the computer network community, presenting the different types of communicating network, an initial reformulation of the TCP/IP architecture, research challenges and the application for the nanonetwork. This technology enables a revolution in the society and affects directly area, such as medicine, agriculture, pollution and even industry."
2329;en_US;"The goal of this short course is to present the main concepts related to network programmability, description of the data plane and packet forwarding to network device using P4 language. This short course approaches this topic in a theoretical and practical way, presenting in the first part the PISA (Protocol-Independent Switch Architecture) model under which the P4 language work. The P4 language components used to process packets are also presented. Before the second part of this course, it presents a description of the compiler and the sofware switch native of P4, named bmv2. With all these concepts presented, the second part consists of practical exercises, which allow a better understanding of the concepts and elements initially presented. Finally, this short course also aims to show some of the most relevant project that make use of P4 and in this way, perceive possible application and motivate research topic in this area."
2330;en_US;"Blockchain introduces a new on-demand consensus paradigm where the set of P2P network node confirm the order in which the transaction blocks are aggregated into the chain of blocks, providing a reliable, secure, scalable, and immutable distributed environment for the transactions execution on the Internet. The blockchain eliminates the need for a trusted third party and digitally creates a decentralized trust entity. The disruptive character of the technology is vast and application are emerging in several area: finance, health, arts, government, etc., beyond computing itself. A number of challenges exist and involve security, privacy, storage, availability, performance improvement, scalability, sustainability, etc.. This chapter presents the blockchain, its main elements, properties, model, algorithm and challenges. Special emphasis will be given to distributed consensus protocol for the maintenance of the replicated state machine, as well as the use of the technology in the context of computer network, fog computing and IoT."
2394;en_US;"The Internet contains vast amounts of data; consequently, hindering information retrieval. resource, such as the National Vulnerability Database (NVD), have emerged to remedy this situation. organization largely depend on the NVD in order to disclose vulnerabilities and collaborate towards a solution. However, there has been evidence that other source are disclosing vulnerabilities more efficiently and rapidly. The objective of this paper is to evaluate vulnerability disclosure delays from the NVD in order to state its efficiency. Among several findings, we observed that the majority of vulnerabilities are delayed within 1-7 days. Based on these result, we provide recommendation for those who currently rely only on NVD, such as IoT manufacturers and developers."
2398;en_US;"The Border Gateway Protocol (BGP) is the routing protocol responsible for connecting the entire Internet and attacks on BGP system have potential to cause major financial impact or even jeopardize the sovereignty of a country. Despite their relevance, it is not common environments that support in-depth studies of BGP. In this line, this work presents the MiniSecBGP, a testbed that supports the emulation of part of the internet topology in a realistic mode, by interacting with widely adopted BGP implementations. MiniSecBGP has modular architecture, making it flexible and expandable. Preliminary tests indicated good scalability and accuracy of the proposed solution."
2524;en_US;"Breast cancer is a disease that has been affecting thousands of women around the world. Detection of this disease in the initial stage is very important, since a treatment is initiated thus increasing the survival rate. In this paper we discuss the elaboration of an application using a machine learning model trained using the Google Prediction API. This application is able to predict if the tumor of a given patient is classified as benign or malignant."
2526;en_US;"This paper presents an exploratory research about the construction of computational application in health. The goal is evaluate studies in this field from the perspective of the Design Science Research, an approach that involves design and development of artifacts in scientific process. The study considers publications of the 17th workhop of Medical Informatics (2017), analyzing elements presented from the perspective of the mentioned method. The result indicate that the approach can contribute to increase the consistency and accuracy of the computational work applied to health."
2530;en_US;"This article describes the virtual walking simulator for heart rate analysis. The system was developed in the UNREAL ENGINE 4 environment and consists of heart rate sensor and Mini stepper. The system is connected to the computer and viewed through the monitor. The interface was made using the Arduino Atmega 2560 kit and RS232 serial communication. The simulator and heart rate sensor presented values for different environments."
2542;en_US;"Several work have addressed the development of mechanism for elastic allocation of memory, creating a need for a precise way to evaluate such solutions. Analyzing the technical literature, we found a gap in the state of the art in the evaluation of vertical elasticity, since the proposals of metrics and methodologies focus on the evaluation of horizontal elasticity. In this sense, this work contributes with the development of the EMA-Bench, a benchmark for evaluating elastic memory allocation mechanism. The benchmark enables to analyse a mecanism in terms of accuracy and time proportions spent in overprovisioning and overprovisioning states, as well as the financial costs involved. The result show that the proposed tool is able to assist the user to define the best mechanism to be adopted, ensuring cost reduction and the maintenance of quality of service. In addition, the EMA-Bench can be used by other researcher in the comparison and refinement of experiment and elastic solutions."
2550;en_US;"The elastic provisioning of virtual infrastructures (IVs) enable a dynamic management of cloud resource. Based on elasticity, virtual computing, storage, and communication the resource are adjusted to fit on hosted application requirement. In order to accomplish elasticity requests, provider rely on reallocation mechanism and policies. The concern, regarding sustentability and operational costs, turns the data center power consumption a recurring theme in provider policies. Moreover, power-aware provisioning is beneficial for both tenants and provider. Thus, we propose an algorithm considering the proportional sharing of CPU usage of data center servers in order to calculate individual costs, disable idle equipments, and reallocate virtualized resource. The experimental analysis indicates a reduction of energy consumption near to 50% without impacting the acceptance ratio of new requests."
2552;en_US;"Fog computing is an emergent paradigm that integrates cloud computing service into the network on a widely distributed level. It extends cloud capabilities near data source to overcome limitations of cloud-based IoT platforms such as mobility, location awareness and low latency. In spite of its increasing importance, there exist no readily available fog computing platforms which can help researcher to design and test real world fog application. To this purpose, simulators and testbeds are adapted to enable the investigation of fog solutions. This paper presents a framework architecture to create fog virtualized environments. Its design meets the requirement of low cost, flexible setup and compatibility with real world technologies. Unlike current approaches, the proposed architecture allows for the testing of fog components with third-party system through standard interface. A scheme to observe the behavior of the environment by monitoring network flow is provided. In addition, future developments and research directions are discussed."
2553;en_US;"Considering the great adoption of cloud computing as operational platform by e-commerce retailers and its dynamical environment setup, workload on this system is basically time-varying. Caused by user bahavioral pattern, as well as flash crowds and virals, the system trespass differents operational regions leading to transients. In a scenario where transients is commonplace, the proper study of this phenomenon is important. Although, in spite of many benchmarks whose purpose is load system with synthetic work, it is not usual to find an interface to express how workload must change on the fly during an experimental execution, as a matter of concern. Thus, this paper presents the implementation of a time-varying workload generator as an extension of the Bench4Q tool. The result point towards the importance of applying such kind of performance tests by allowing the apprisal of system transients when using IBM DB2 and PostgreSQL, revealing the dynamic behavior of the performance metric response time."
2554;en_US;"The popularization of smart device with sensing capabilities has led to a huge volume
of spatiotemporal data, obtained from different entities, such as people, vehicles, and
objects with computing capabilities. The extraction of knowledge from such data offers
unprecedented opportunities for decision making process in several area. In the mobile
networking domain, communication protocol, infrastructure planning and service delivery
are examples of application that can benefit from mining and analysis of data that is
collected from smart device. For instance, user’s historic data contain feature that are
important for detecting pattern and predicting both mobility and data traffic, in time
and spatial domains. The goal of this chapter is to present and discuss the potential of
big data analytics in the design of mobile network. In particular, we aim at showing
how 5G cellular network, vehicular network, and internet of mobile things (IoMT) can
take advantage of the knowledge extracted from their entities’ characteristics (e.g., user’s
mobility). In summary, this chapter presents: (i) the peculiarities and technique of data
analysis for the design of mobile network; (ii) an overview of the recent contributions in
the area; (iii) a framework that covers different aspects, ranging from handling the data
to employing the knowledge obtained from such data; and (iv) research challenges and
opportunities within the area.
"
2555;en_US;"Urban mobility is a current problem of modern society and large urban centers, which leads to economic and time losses, higher fuel consumption and higher CO2 emissions. In the literature, its possible to find work that point to Intelligent Transportation system (ITS) as a solution to this problem, and this research topic has received the vast attention of many researcher nowadays. In this context, vehicular network emerge as a component of the ITS, providing cooperative communication between vehicles and infrastructure and cooperating to improve the flow of vehicles in big city. In this mini-course, the objective is to discuss ITS, presenting an overview of the area, its challenges, and opportunities. In this way, this mini-course will introduce the main concepts involved in the ITS architecture, its implementation and integration with other computer network, and how to evaluate its performance. We will also show the main application in the literature that cooperate for the existence of ITS. In the end, we will discuss the challenges and opportunities found in the area of interest of the SBRC symposium, among which we highlight: data collection and fusion, characterization, prediction, security and privacy."
2556;en_US;"Thanks to the popularization of software-defined radios (SDR), it is possible today to perform high-quality research in wireless protocol in real deployments. Although this technology is still a bit expensive, there are a number of initiatives that provide free access to SDR for research. Further, the number of free software libraries available for SDR has reduced the amount of effort required to conduct research using SDR. This short course will show by examples how to perform experimental research in wireless networking using software-defined radios that are available for free on open testbeds being developed on FUTEBOL, a joint Brazil-European Union project. We will adopt a hands-on approach, in which the student will perform many small assignments on real hardware. Those assignments will demonstrate the maturity of SDR for research in wireless networking, and introduce the user to the many software tool and open source implementations of a variety of wireless standards."
2557;en_US;"Network Neutrality (NN) is becoming increasingly important as the global debate intensifies and governments worldwide implement regulations. According to NN, all types of traffic must be processed without discrimination, regardless of origin, destiny and/or content. The discrimination between different types of traffic compromises innovation, fair competition and the freedom of choice of consumers. However, ensuring that ISPs are not employing discriminating practices is still a challenge. This tutorial presents an overview of several existing solutions to detect “traffic differentiation”. These solutions differ mainly on the monitoring topology, metrics and statistical method employed. An introduction to the global debate around NN is also presented, as well as an overview of different regulations defined in Brazil and other countries around the world."
2558;en_US;"The use of public and private cloud computing solutions has been growing in the last years. Several organization identify in private clouds a way to consolidate the computational resource scattered around their infrastructure. Albeit promising, this consolidation implies on managing the (potentially large) set of user and service that need to access these clouds. In this scenario, it is highly advisable to employ authentication and authorization mechanism that allow several system to connect, reducing management efforts. The goal of this work is to identify and analyze the main cloud computing authentication model, focusing on single sign-on authentication mechanism, to propose a consolidated taxonomy. As a case study, we explain the integration of OpenID Connect with OpenStack to provide authentication and authorization service using the Google Identity Provider."
2564;en_US;"Although there are several Single-Event Upset (SEU) mitigation technique for SRAM-based Field Programmable Gate Arrays (FPGAs), comparisons are still necessary regarding dependability analyzes of these technique. Most of these assessments analyze the technique after design and implementation in FPGA which may be too costly. Stochastic/Probabilistic analysis allow to obtain result in the early stages of design. In this paper, we compare three of these strategies, Scrubbing, Triple Modular Redundancy (TMR), and Hamming code, via Probabilistic Model Checking. result show that TMR allows upsets to accumulate and must be combined with Error Correction Codes (ECCs), such as Hamming, and that the Scrubbing interval directly affects reliability while safety is more related to the coverage rate."
2570;en_US;"In healthcare, uncertainty moments are frequent, especially when they come from disease with similar signals and symptoms. This work proposes a mobile health application based on predictive classifier as inference mechanism capable to support health professionals in the identification of disease transmitted by the Aedes Aegypti mosquito. The proposed system identifies the most probable disease in the case of dengue and chikungunya, given a set of symptoms presented by a patient. This work evaluates the experiment by crossvalidation using real data, and the result show that decision tree perform well for the proposed solution."
2571;en_US;"Although the infant mortality index has been reduced in recent years, this issue is still considered a serious problem in Brazilian health system indicators. In this context, the GISSA Framework (Intelligent Governance Framework for Brazilian Health System) emerges as a framework for the Federal Government program, called “Rede Cegonha”. The main objective is to improve the health care for pregnant woman as well as the newborn. This framework aims to generate alerts focusing on the health status verification of newborns and pregnant woman in order to help healthy decision-makers in preventive actions that may mitigate the problem. Therefore, this paper presents the LAIS, an Intelligent Health System Analyzer based on data mining classifier, which the objective is to generate alerts. Finally, we present the proposal result of an application that provides the death probability of a newborn, based on the analysis of his attributes and his mother."
2572;en_US;"The growth of the population in need of health care and reduced mobility in many countries highlights the need to develop assistive technologies appropriate to this public. To this end, interactive application on mobile device are usually integrated into intelligent environments. This article proposes the INCA (IN-home healthCAre), a flexible system that combines the fog computing and publish/subscribe paradigm to individually monitor and manage individuals with reduced mobility. INCA allows you to connect new device and application in a scalable way to your infrastructure in real time, as well as a better use of the resource of the device through the fog. Two interactive application of individualized monitoring were evaluated: i) recognition of people by the image and; ii) detection of fall by means of the sensor (accelerometer and gyroscope) of a smartwatch. In addition, an evaluation of the performance of the infrastructure based on data offloading was carried out and showed promising result, being notable: i) high accuracy to identify the individuals as well as to detect their mobility; and ii) efficiency when deployed in device with scarce resource."
2574;en_US;"The significant increase of the power consumption in the last years has attracted the attention of the researches, governments and organization. The residential sector has contributed significantly to this increase. The Home Automation System, allied with the Internet of Things, is a promising solution to solve the problem of energy efficiency. In this context, it is possible to use Computational intelligence to helps carry out the decision-making process and fog computing paradigm on to manage and processing of the actions in the residence in real-time. Therefore, this work proposes a solution for collecting, disseminating and controlling through wireless sensor and actuators the decision-making in a residential environment, which is based on fog computing and computational intelligence. As proof of concept, a prototype was developed with the purpose to demonstrate the feasibility and efficiency of the proposed solution. The real result show that the proposed solution has a high hit rate with a low delay in the decision-making process, while maintaining an efficient dissemination of information with low energy consumption. Thus, the proposed system is feasible and applicable."
2577;en_US;"Conventional planning of city is usually based on surveys and other hard evidence collected and organized by the city officials and research institutions. The data is usually collected in certain time interval and it provides a limited overview to the use of urban space. Social media, including online social network, make available vast amounts of data which nowadays is easily obtained for various types of analyses. city have a chance to explore social media data as a new source to study urban dynamics and complement traditional data used for urban planning. Perhaps the new data source could also be used to overcome limitations in traditional data used in planning. In this paper, we investigated data available in Untappd, a mobile phone application for sharing beer drinking experiences, in the context of planning and place branding in Curitiba. Curitiba recently announced the creation of a Craft Beer Street, to promote local beers. By using this as a real case study we investigate a new approach that could help creating this kind of attractions, considering the aspects related to place branding as well."
2586;en_US;"In this paper, we evaluate the performance of a TCP client/server application from simulation of Drive-Thru Internet opportunistic access in public WiFi hotspots deployed on an urban environment. We observed that the use of Quality of Service (QoS) metrics for evaluating these distributed application, when generalizing result, it leads to limited analysis of the quality of Vehicleto-Infrastructure (V2I) transmissions. To overcome such a limitation, we apply new metrics of evaluation such as connection interval, disconnection interval, connectivity rate, and connectivity intermittency rate, which are mapped into the well-known metrics of Dependable Computing such as MTTF, MTTR, Availability, and MTBF, respectively. When looking at the transmissions under the time and space of the vehicles displacements, we verified that the metrics of dependability can complement and better justify the evaluation from traditional metrics of QoS and, therefore, provide a wider and deeper performance analysis about the quality of V2I transmissions."
2591;en_US;"An increasing number of user have been adopting route recommendation system, many of them motivated by the convenience that these system bring to their traffic experiences. These system observe the current traffic conditions in order to evaluate the fastest path. However, contextual information, such as pollution levels, weather conditions and security of the route, might not be taken into account in the recommendation process. With this in mind, we propose a framework to support contextaware route recommendation system. Furthermore, we present possible approaches for development of two key components of this framework: (1) identification of contextual area based on different urban data source; and (2) identification of typical routes. The proposed framework might improve existing recommendation algorithm, or also enable the proposal of new ones. To validate this hypothesis, we used a set of routes suggested by Google Maps in the city of Curitiba to identify frequent pattern on these routes. Afterwards, some insecure zones were identified in Curitiba using data provided by the government of the city and also data generated by the citizens via their mobile device. The obtained result showed the existence of an opportunity for route planners to provide differential service to user who desire it, which is an important step towards the development of context-aware vehicular network."
2595;en_US;"Advances in Internet of Things and smart city approaches are resulting in an unprecedented number of device requiring connectivity. Due to the ubiquitous presence of Wi-Fi network, connectivity solutions obtained from residential WLAN-sharing are becoming increasingly popular, although they are still very restricted in scope, and offer a general connectivity service for user seeking to surf the Internet. We argue that with a proper network control plane and orchestration mechanism like those provided by SDN, ISPs would be able to leverage the available Wi-Fi infrastructure so that it can offer network service that are tailored to the specific needs of mobile node and user. In this paper a general framework is set up to achieve this goal. As our approach explores low-cost commodity Wi-Fi access points and switches, we also include a study of the effects of SDN on a local network built on this class of equipment."
2596;en_US;"Broadband Internet access security lies in the implementation of perimeter policies and in the adoption of access control lists. These measures are precarious because they are based on common and poorly updated profiles, lacking residential user threat information. This article analyzes and characterizes residential user traffic from fixed broadband Internet access network of a large communications operator, for a period of one week, and obtains the profile of the security alarms generated by an intrusion detection system on this traffic. The result show that the proposed characterization allows classification of the flows, with an alert sensitivity of 93% in the differentiation of the legitimate flows and the alarm generating flows, thus, validating the collected dataset, and allows a 73% reduction for the traffic directed to the traffic analyzer, enabling more dynamic and efficient access network security."
2598;en_US;"Intrusion Prevention system (IPSs) are expensive and inefficient when blocking all traffic from a source address. Therefore, the ability to apply countermeasures only to malicious traffic becomes an important security challenge. This article proposes a Network Function Virtualization (NFV) architecture to provide automatic, and efficient protection against attacks. Malicious flows are dynamically diverted through a Virtual Network Functions (VNFs) chain containing an application firewall and an IDS. A prototype was built using the Open Platform for NFV (OPNFV). The architecture is capable of blocking 99.12% of the attacks without affecting 93.6% of the benign traffic."
2601;en_US;"The FIBRE testbed is a large-scale research facility for experimentation on Future Internet technologies. To address specific requirement of the Brazilian federation, it was decided to commence a new development phase in which FIBRE would have its architecture completely revised. This paper presents an overview of the next generation of the software architecture envisioned for the FIBRE testbed."
2603;en_US;"Future Internet architectures is a response from the research community to the challenges that Internet architecture faces today, such as mobility. One major issue in this area is the deployment and test of them over large scale production network. This work scales up the deployment of the clean-slate Entity Title Architecture (ETArch) on a production network of a telecom operator. Using Virtual Tunnel (VTun) as an overlay is was possible to connect different user in different city at Minas Gerais state in Brazil. ETArch Pilot shows the feasibility to move toward future Internet deployment in order to bring new service and application to user."
2606;en_US;"The SDN paradigm enables network operators to host multiple control planes in parallel, being an approach to support multiple network service. Supporting multiple control planes over production network exposes the production environment to potential risks and increases operational complexity. To understand and mitigate these risks, we implemented procedures and tool that resulted in a more reliable network. This paper describes our experience and findings with the support of multiple control planes in a wide-area production network."
2607;en_US;"In the last decade, many approaches appeared to revolutionize Internet architecture from scratch. They are collectively called Future Internet Architectures. In this paper, we address the challenge of experimenting with Internet of things in this context. Using open-source tool, we developed a standard scenario capable to evaluate proposals in a small scale first (locally, in laboratory), and latter in large scale cloud-based testing platform. As a use case of the proposal, we discuss its application to the eXpressive Internet Architecture."
2608;en_US;"Despite of evolutions, the current Internet can not adequately handle requirement such as multihoming, QoS, mobility, multicast and security. Several research groups around the world are involved in creating, experimentally and incrementally, the next generation of Internet architecture. A Brazilian initiative in this area is the Entity Title Architecture (ETArch) whose prototype is based on the concept of Software Defined Networking and uses the OpenFlow protocol. This work presents two contributions implemented in ETArch, being an authentication mechanism and an access control, whose trade-off is presented in this work."
2609;en_US;"Cloud Computing is an efficient model for processing and storing large amounts of data. The cloud is composed by heterogeneous resource and has a variable workload. Cloud object storage system arise as an efficient manager for data using heterogeneous device, regarding storage capacity and performance. In the cloud, since workload changes dynamically, the dynamic reconfiguration is needed to improve resource utilization. Thus, load balancing technique are crucial to redistribute workload among the processing node to avoid underloading or overloading. Conventional load balancing strategies are only aware of storage device capacity, resulting in system performance degradation. To address these limitations, this paper presents a non-intrusive approach to load balancing in the cloud which considers storage device with heterogeneous performance. Experimental result confirm that our approach improves performance in terms of response time and throughput when compared to the strategy employed by Openstack Swift object storage."
2610;en_US;"The wide range of Vehicular Ad-hoc network (VANETs) application, e.g., real-time video dissemination, have made VANETs an interesting field of mobile wireless communication. Vehicle-to-Vehicle (V2V) communication enables user to distribute significant amount of real-time video traffic over VANETs and to alleviate congestion over LTE network. However, the video delivery process considering an adequate Quality of Experience (QoE) in VANETs is a critical issue in both academic and industrial communities due to dynamic network topology, importance of video QoE, and broadcast nature of VANETs. This paper presents a Qoe-Aware Reinforcement approach to disseminate warning video on LTE-VANETs, called QAR. It enables an enhancement for routing protocol in LTE-VANETs that takes advantage of a centralized architecture around the base station to improve the route management, and to provide video dissemination with QoE support. We analyze the performance of QAR by using NS-2 simulation and a realistic urban mobility model. result show gains of QAR in comparison to existing proposals, where it achieves video dissemination with QoE support, less routing overhead, and robustness in LTE-VANETs."
2617;en_US;"The IP lookup phase is the core operation in packet forwarding, which is implemented via a Longest Prefix Matching (LPM) to find the next hop for every input address. In this work, we evaluate the use of parallel technique to develop a highly optimized IP lookup algorithm that employs Bloom filters and hash tables. More specifically, we investigate the implementation of our algorithm on multi-core CPUs and on the Intel R Xeon PhiTM (Intel Phi) many-core coprocessor. Our analysis includes the efficient parallelization of our Bloom filters algorithm on both device, and the experimental result show that we were able to attain high performance with this solution (over 88 million lookups per second on a single Intel Phi for IPv6). We also compared the Bloom filters optimized solution to an efficient approach based on the Multi-Index Hybrid Trie (MIHT). This comparison shows that the most efficient sequential algorithm may not be the best option in a parallel setting. Instead, it is necessary to evaluate the processors characteristics, algorithm compute/data demands and data structures employed to analyze how the algorithm will benefit from the target computing device. These findings are also important to new efforts in algorithmic developments in the topic, which have been highly focused on sequential solutions."
2618;en_US;"In D2D opportunistic network, node act as relays for transmitting message to other node according to an opportunistic routing algorithm. In this scenario, each node uses a buffer with limited capacity to store these message temporarily until they are propagated to a neighbor node according to an opportunistic routing protocol. However, when multiple message are forwarded in the network, the number of incoming message may exceed the node capacity, causing a buffer overflow. Therefore, message dropping policies are very important to this problem, because when a message is dropped, there is a chance that other copies of this message still exist in the network. This work proposes a new buffer management algorithm for opportunistic routing in D2D network named ST-Drop (Space-Time-Drop). We evaluate our solution in three different types of opportunistic routing algorithm: epidemic-based, probabilistic, and social-aware. We conduct simulation using two different publicly available data source and consider different network traffic loads. Compared to other message drop policies, ST-Drop obtained the highest message delivery ratio in all considered scenarios and the lowest overhead when applied to the state-of-art social-aware and probabilistic routing algorithm, namely, Bubble Rap and Prophet."
2624;en_US;"Routing protocol for Delay and Disruption Tolerant network frequently use message replication in order to increase the network resilience and the message delivery rate. However, uncontrolled replication may lead to network congestion, negatively impacting network performance. This paper proposes a simple and efficient hybrid network congestion control mechanism that aims at avoiding unwanted message replication and to reduce network congestion. The proposal is based on the fact that the removal of message from node buffers must be persistent, i.e. a node must not receive message that have already been removed from its buffer again. The analysis consider four real mobility traces and three well-known routing protocol. result show the proposed mechanism reduces transmission overhead in up to 98.5% in addition to increasing delivery rate and decrease delivery latency."
2626;en_US;"Although load balancing is a fundamental and well-studied problem in resource allocation, the ever changing scenarios and technologies in distributed system demand new approaches and algorithm. In this context, we consider a real world scenario where servers are heterogeneous and have dynamic background loads not controlled by the load balancer. In such scenarios, classic round robin policy or novel joint the shortest queue policy are not effective. We propose a load balancing algorithm that dispatches requests to a set of heterogeneous servers according to their CPU availability using a feedback control loop to prevent overloading. We implement this policy and evaluate its performance in real and controlled scenarios. Our evaluation indicates the proposed algorithm is more effective in distributing load than other classic policies, in particular when background load is dynamic."
2627;en_US;"MapReduce is a parallel computing model where a large dataset is split into smaller parts and executed on multiple machine. When data are not uniformly distributed, we have the so called partitioning skew, where the allocation of tasks to machine becomes unbalanced, either by the distribution function splitting the dataset unevenly or because a part of the data is more complex and requires greater computing effort. To solve this problem, we propose a function based on Simulated Annealing metaheuristic which finds a partitioning that result in a better load balancing."
2631;en_US;"In this work we report the experience of adding a high availability solution to an IaaS (Infrastructure as a Service) cloud platform called Aurora. The proposed solution is based on the multi-master replication of the cloud manager, replicas form a cluster of cloud managers running on multiple datacenters. The implementation also includes a monitoring service for the replicas. The high availability solution is fully integrated to the cloud platform so that activation is done directly by pushing a button of the Graphical User Interface. The performance and robustness of the proposed solution were evaluated experimentally. The time to (1) incorporate a new manager instance to a cluster; (2) recover an instance after a failure and (3) replicate data in different scenarios were measured and are reported in this paper. The impact of the proposed solution cost is evaluated by measuring CPU and network usage. A stress test in which the link delay between two datacenters grows up to the operating limit of the replication solution is also reported. Finally, we present a table for the system availability as a function of the MTBF (Mean Time Between Failures)."
2634;en_US;"The cloud computing paradigm have been modified. One of the most impacting changes is the usage of system level virtualization, for a better infrastructure management. The creation of Kubernetes, a containers management system, by the Cloud Native Computing Foundation (CNCF) express the efforts to guide the changes in a standard manner. Kubernetes can replicate containers, but not the state of the application hosted in the containers. This paper presents an architecture for replicating state in containers providing coordination as a service, with a light and simple coupling to the application. Some experiment analyse the behavior of application which observe eventual and strong consistency when reading data. The result shown that the proposal is feasible."
2635;en_US;"Collaborative clouds bring the elasticity advantages from traditional clouds to user with few resource, as long as they contribute with their idle resource. Nevertheless, when demand for resource exceeds supply, conflicts arise and each user allocation must be defined. In this work, we propose an allocation mechanism that guarantees resource utilization efficiency while encouraging collaboration. Using game theory, we demonstrate the mechanism properties by defining a model based on a Bayesian setting. In such setting, user constantly decide the amount of resource to either contribute, or request, from the collaborative cloud. Moreover, we use simulation with the Google cloud dataset to verify the mechanism. The result show an increase in the number of served requests up to approximately three times compared to not using the mechanism."
2638;en_US;"For some time the vihicles adopted distributed electronic system as a way to bring more comfort, active ande passive safety to the occupants. With the increase of technological demond and innovations in connectivity, vehicles became attractive to hackers. Regardless of goals of hacking, the future of automobile goes through a wide range of related work evaluating the impacts of malicious people that take control of the vehicle”s system. In this article we evaluate the vulnerabilities of a vehicular data bus, CAN and CAN-FD. It is possible for an intruder to interfere with instrument panel display system by sending forged message to the driver and even compromise sustems related to safety such as steering and brakes. Among the various types of possible attacks on the CAN bus, the D.o.S. (Denial of service) lacks of a deeper discussion in the literature. This article proposes a mechanism to protect the bus from this type of attack. A filter is designed to avoid that the bus be overloaded with false requests, providing access to authentic message exchanging"
2639;en_US;"A Pochet Switched Network (PSN) is formed by user carrying portablehandheld device such as smartphone and tablets, which store message, carry them from one point to another via physical movement, and forwards them when a communication opportunity arises. The success of the network thereby depends on the willingness of user to participate. PSN protocol tend to subject most of the routing burden on only a smaller set ofpopular node. This result in drastic resource consumption on popular node, and may eventually lead to user dissatisfaction, withdrawal, and performance degradation of the network. The key to ensuring fairness in PSN routing lies in the ability to estimate the burden on node, utilize this knowledge to provide an acceptably fair utilization of node resource, and evaluate the level of fairness achieved. This paper is concerned with measuring: (i) the burden routing impacts on node; and (ii) the fairness of routing algorithm based on the distribution of this burden. First, we propose a Global Relative Burden Detection (GReBurD) mechanism to estimate the burden on node. Simulation experiment show that GReBurD is non-scenario specific and better infers the actual burden on node as compared with existing approaches. Next, we propose a new metric for evaluating the fairness of PSN forwarding algorithm tha gives a better interpretation of the level of fairness implied."
2642;en_US;"New policies are constantly installed on the network. In Software Defined network, the various distributed controllers have to install the new policies consistently for assuring that there is no risks of network experiences transient and unexpected configuration states, which compromise the safety and the operation. In this paper, we propose a consistency protocol for serializing policy updates and for composing policies, avoiding conflicts. The main contributions are three-fold: (i) a consistency protocol for serializing policy updates; (ii) a consensus interface for enabling controllers to agree on the latest version of the network configuration; and (iii) an algorithm to verify that the new policy is an update, a refinement, or if it conflicts with other policies that have already been installed. Through formal verification, we show that the proposed consistency protocol ensures global order for all policy updates and that the proposed algorithm correctly composes all policies. The simulation of the proposal in a real network topology shows that the distributed policy update is per-consistent packet and it has a low overhead of control message."
2643;en_US;"A cloud storage service implements security mechanism to protect user data. Moreover, due to the loss of control over the cloud infrastructure, auditing and monitoring mechanism are used to detect violations of security properties, increasing the trust and transparency in cloud service. However, there are flaws in existing solutions to ensure integrity, freshness and write-serializability properties. Then, we propose a monitoring and auditing mechanism to verify these properties, allowing to detect violations that are not identified by other solutions. Colored Petri Nets (CPNs) are used to model and validate the proposed mechanism. As result, the provider cannot deny the detected violations, and attacks are detected in real-time, except collusion attacks, identified only in our auditing phase."
2645;en_US;"The peculiar characteristics of wireless sensor network (WSNs) make them vulnerable to physical attacks. Once a sensor node is physically captured by an adversary, it can be modified not only to perform malicious activity to disrupt network operation but also to propagate malicious worms to infect other node. In the face of such a threatening scenario, the system administrator needs to be aware of which node may have been compromised, so that appropriate countermeasures can be taken in a timely fashion. This paper presents the Sensor Security Status (S3), a security metric model for estimating in an online manner the probability that a sensor node has been infected, based on both the interaction among node and the alerts from the intrusion detection system (IDS). Simulation result show that S3 can accurately estimate node security level with low performance overhead and power consumption."
2648;en_US;"Software Defined Wireless Mesh network (SDWMN) enable more intelligent and programmable wireless network. SDWMN with in-band control plane can optimize resource utilization when compared to out-of-band network architectures, because in-band can exempt the need of additional physical or virtual interface and legacy protocol to coordinate the control plane traffic. This traffic can also be engineered by SDN and make use of its possible benefits. However, there are many challenges to be dealt with SDWMN in-band, such as network auto-configuration during start-up, scalability and control plane overhead over the data plane. To overcome these limitations, we propose in this paper a multi controllers architecture with adaptive monitoring in SDWMN in-band which objective is to reduce control plane overhead and delay while improving network scalability. The work is implemented as a proof-of-concept in the OpenWiMesh framework. result show it effectively reduce switch-controller latency and control plane overhead, as well as enabling higher scalability. We also show our monitoring solution enables better wireless network view and uses at least near half the bandwidth compared to a SNMP solution."
2655;en_US;"In P2P network peers share content in a topological overlay above the physical network. This is fundamental to network performance. However, the simultaneous arrival of many peers, known as flash crowd, can affect network topology and disrupt content transmission. Current studies frequently separate flash crowd from topology arrangement technique. In this work, we set topological partnership restrictions to preserve the existing mesh during a flash crowd. Using a parallel network technique, incoming peers are isolated in sub channels to avoid new relationship interference between newcomers and existing peers. This is particularly important because incoming free riders may affect existing cooperative peers significantly. In our experiment, we show that this restriction has allowed the transmission to remain unaffected in the presence of a flash crowd six times greater than would have been possible without the proposed technique."
2656;en_US;"In this paper, FuzSy, or Fuzzy Scheduler, is presented. It is a cellular network packet scheduler. It is based on quality of service and fuzzy logic. Classic solutions utilize static packet scheduling, following a prearranged priority order. Static scheduling can be unfair, or waste network resource, trying to allocate resource. FuzSy utilizes metadata from the network and, from choices made by the fuzzy logic mechanism, which seeks to prioritize classes that have a higher risk of not reaching its QoS requirement, sets a dynamic packet priority. This priority is said to be dynamic because, is one class is in a QoS position that is not favorable, the scheduler set this class priority to be higher, regardless of any previous set priority. Fourth generation, 4G, network simulation were conducted. The result show that FuzSy was able to keep all QoS within 3GPP stipulated values and was able to achieve higher fairness, not benefiting any class at others cost. One of FuzSys advantages, in relation to the other schedulers, cited in this paper, is that parameters can be added to or deleted from the fuzzy mechanism. With that, on specific situations such as places hosting large scale events the scheduler can be altered and utilize different parameters and rule to better serve the user."
2660;en_US;"Dynamic Cloud Radio Access Network (Dynamic C-RAN) is an architecture wireless that aims benefits such as flexibility and agility to new five generation (5G) network. In Dynamic C-RAN, the radio functions processing is distributed along of a hierarchical of clouds. Network Functions Virtualization has been investigated the facilities to employ this wireless functions. NFV offers orchestration of split of radio functions into Virtualized Network Functions (VNF). The orchestrator needs to consider strict requirement of C-RAN between distributed components of VNF to get real earnings. In this work, we propose a detailed evaluation of Maestro - an NFV orchestrator for wireless environments aware VNF composition. We evaluate Maestro through of linear model programming, considering the effectiveness and orchestration overhead for deciding the best place to VNF components. In addition, we evaluate the trade-off between network data rate and time to generate the placement of components."
2661;en_US;"The design of flexible and efficient mechanism for proper placement and chaining of virtual network functions (VNFs) is key for the success of Network Function Virtualization (NFV). State-of-the-art solutions, however, consider fixed (and immutable) flow processing and bandwidth requirement when placing VNFs in the Network Points of Presence (N-PoPs). This limitation becomes critical in NFV-enabled network having highly dynamic flow behavior, and in which flow processing requirement and available N-PoP resource change constantly. To bridge this gap, we present NFV-PEAR, a framework for adaptive VNF placement and chaining. In NFV-PEAR, one may periodically (re)arrange previously determined placement and chaining of VNFs, with the goal of maintaining acceptable end-to-end flow performance despite fluctuations of flow processing costs and requirement. In parallel, NFV-PEAR seeks to minimize network changes (e.g., reallocation of VNFs or network flows) done to fulfill this goal. The result obtained from an experimental evaluation provide evidence that NFV-PEAR has potential to significantly reduce the number of network changes required to ensure end-to-end flow performance, thus ensuring stable operation of network service."
2665;en_US;"Elastic Optical Network is a promising technology to compose the Internet infrastructure. For this network it is necessary to provide mechanism that guarantee its availability even after the occurrence of a failure. It is also important to provide quality of the optical signal, which tends to degrade by the effect of the physical layer impairments. This paper proposes three algorithm that use the dedicated path protection strategy: DP-SNR, DP-BSNR and DP-RQoTO. These algorithm take into account the effects of physical layer impairments in their choices of routes. An evaluation was made with dynamic traffic and requisitions with variable band demands. The three algorithm presented in this paper were compared with other literature proposals, obtaining a reduction in the blocking probability in the order of 90%. Among the proposed algorithm, the DP-RQoTO obtained a decrease in the blocking probability of at least 36% in relation to the DP-SNR and 34% in the DP-BSNR in the EON topology. In the USA topology, the minimum gain of DP-RQoTO was 22% in relation to DP-SNR and 20% in relation to DP-BSNR."
2672;en_US;"The virtualization of data centers combined with the SDN paradigm lead to the provisioning of new cloud service. Among the management challenges faced by a SDN-based cloud provider, this work improves the virtual infrastructure allocation problem with QoS requirement. First, the problem is modeled as a mixed integer programing. Thus, integer constraints are relaxed and rounding heuristics are discussed. Besides guaranteeing the QoS requirement, the result indicate a reduction on virtual network communication latency."
2673;en_US;"Software-Defined network (SDN) based on Openflow protocol perform data forwarding through flow tables using match/action mechanism. These tables have limited rule storage capacity, restricting network scalability and performance. Considering these restrictions, the main strategies for managing spatial domain rule, i.e., flow agregation and multiple flow tables, are promising to use the available storage space of the tables. These strategies impact packet processing in different ways, influencing the performance of the forwarding device and the network. In spite of the impact, the comparison between flow aggregation and multiple flow tables is poorly exploited, leaving open the definition of which strategy is more appropriate for a network considering its topology and workload. In this article a quantitative characterization is proposed, defining the gains brought by these spatial domain strategies for forwarding device and in different topologies."
2676;en_US;"Modern enterprise servers provide several feature to manage the power consumption of their subsystem. In environments with high computational demand, these feature can significantly reduce energy consumption. However, in order to make proper use of such resource, we need to understand how the application that run in these servers consume the computational resource and the implications of such usage for the overall power and energy consumption. In this work, we propose an energy model to characterize the energy consumption of enterprise servers that host Web system. Unlike other work in the literature, our model captures the consumption pattern of these application at the level of transactions and for each tier of the system. In addition, our model depends solely on the CPU utilization and on server architectural parameters, which can be easily obtained in current production environments. We demonstrate the effectiveness of our model in a real experimental environment, based on the TPC-W benchmark. result show that our model is able to estimate the energy consumption of Web application with errors in the same order of magnitude as those presented by previous work."
2678;en_US;"Even after nearly two decades of the creation of the first botnet, the detection and mitigation of their attacks remain one of the biggest challenges faced by researcher and cyber-security professionals. Although there are numerous studies related to botnet detection, estimating how much one method is better than another is still an open problem, mainly because of the difficulty in comparing and reproducing such method. This work proposes an architecture, implemented with Spark as a high-performance data processing solution, together with VisTrails as a workflow management and data provenance solution, to address this comparability and reproducibility problem in a large-scale environment, as well as a tool, ProvTracker, to analyze and compare the method result. Another contribution is on the way to couple these two technologies so that intermediary data is maintained available during several partial (re)executions of the experiment involved in each method, minimizing the impact on the analysis of the large amount of data involved."
2685;en_US;"In asynchronous distributed system it is very hard to assess if one of the process taking part in a computation is operating correctly or has failed. To overcome this problem, distributed algorithm are created using unreliable failure detectors that capture in an abstract way timing assumptions necessary to assess the operating status of a process. One particular type of failure detector is a leader election, that indicates a single process that has not failed. The unreliability of these failure detectors means that they can make mistakes, however if they are to be used in practice there must be limits to the eventual behavior of these detectors. These limits are defined as the quality of service (QoS) provided by the detector. Many work have tackled the problem of creating failure detectors with predictable QoS, but only for crash-stop process and synchronous system. This paper presents and analyzes the behavior of a new leader election algorithm named NFD-L for the asynchronous crash-recovery failure model that is efficient in terms of its use of stable memory and message exchanges."
2829;en_US;"In the context of information retrieval, similarity search for range query is the problem of finding word whose edit distance to a query are smaller than a determined distance. BK-trees is a pivot based indexing mechanism that achieves good result for this kind of query. experiment show that, despite its simplicity, the efficiency is superior to other approaches when it comes to text searching. However, no information is provided concerning the underlying structure of the tree. In this paper, we analyze different ways of implementing this indexing structure. Our experiment compare the investigated variations in terms of space cost, indexing time and search time."
2837;en_US;"This paper describes the development of a Web solution that allows the dynamic visualization of academic collaboration network. The application uses data from the Lattes platform to identify and display the relationship between sets of researcher."
2922;en_US;"Deep learning is giving machine near human levels of visual recognition capabilities and disrupting many application by replacing hand-coded software with predictive model learned directly from data. This lab introduces the machine learning workflow and provides hands-on experience with using deep neural network (DNN) to solve a real-world image classification problem. You will walk through the process of data preparation, model definition, model training and troubleshooting, validation testing and strategies for improving model performance. You will also see the benefits of GPU acceleration in the model training process. On completion of this lab you will have the knowledge to use NVIDIA DIGITS to train a DNN on your own image classification dataset."
2926;en_US;"Learn how to accelerate your C/C++ or Fortran application using OpenACC to harness the massively parallel power of NVIDIA GPUs. OpenACC is a directive based approach to computing where you provide compiler hints to accelerate your code, instead of writing the accelerator code yourself. In 90 minutes, you will experience a four-step process for accelerating application using OpenACC: (1) Characterize and profile your application; (2) Add compute directives; (3) Add directives to optimize data movement; and (4) Optimize your application using kernel scheduling."
2936;en_US;"Water has become a concern throughout the planet because it has become a scarce resource in recent years, due to several factors, especially the disrespect of human being for sustainable development. Nowadays, it is imperative to create public policies, legislation and the proposal of new methodologies, process and products that can help in the fight against pollution, waste and rational use of water resource. Particularly, the use of information technology provides a modern, agile and efficient management of water resource. One of the important actions in this sense is the water use surveillance. In this article, we discuss the surveillance process, we approach a surveillance methodology used in the Water Management Agency, and we present a Web-based information system architecture and a mobile platform to provide a management of the surveillance in an efficient and effective way. The proposed system is already online at agency and some partial result, especially regarding the denunciations, notifications and proceedings are discussed."
2941;en_US;"The study presents the importance of the information system to manage irrigation in plantations through an application and aims to automate and control the agricultural production process, minimizing waste of water. The system will be managed via web and mobile interface, through an application called Irrisusten. The physical part will consist of Arduino Uno components, ground sensor module, 5v relay module, 12v battery, led, resistors, solenoid valve, bluetooth HC-05 or HC-06 module, protoboard, jumps and USB cable."
3058;en_US;"As city are becoming green and smart, transportation system are being revamped to adopt digital technologies. Open transportation data might include GIS maps for bus routes and bus stops. Such data provide a number of opportunities to analyze a segment of the current state of the transportation system of a city. In this paper, we address and discuss some of the urban mobility open data available and their characterization from the perspectives of two metropolitan city: Curitiba (Brazil) and New York City (USA). Finally, we present challenges regarding their use."
3085;en_US;"As there are several approaches to define structural testing criteria for concurrent programs, it is necessary to describe the state of knowledge in this topic in order to identify the gaps that require to be addressed. Thus, it is fundamental to learn about who is investigating, which approaches and what purposes are there in current research, to evaluate which is the most effective path to follow to fill in divergences. Therefore, the goal of this systematic mapping is to find studies related to the testing of concurrent programs, that allows evaluating what is the best option to guide a research in the improvement of concurrent software quality through structural criteria. The result of the systematic mapping showed that there is indeed a gap in the definition of criteria for concurrent programs considering dynamic aspects."
3090;en_US;"The economic development of a nation with justice and social equity presupposes the strengthening, expansion, consolidation and integration of the whole chain that composes the national system of Science, Technology and Innovation - ST I. Currently, there is a distance from public managers, in order to obtain answers to the questions about the main aspects of research and innovation project, such as investments, researcher, institutions and area of knowledge. The primary source of this information are stored in different institutions, at different times, in heterogeneous system and formats and, therefore, such data are scattered and inaccessible. Although different data source are maintained independently, valuable information can be extracted when collections of data obtained from different source are analyzed in an integrated and collective manner. However, integrated analysis of data from different source triggers a wide variety of interoperability and heterogeneity problem. The objective is to construct a database schema in which information from different source is consumed, consolidated, standardized, published and disseminated, thus providing a view of the information of scientific project for managers."
3095;en_US;"Brazilian councils for the management of public policies are spaces for the exercise of citizenship, which requires preparation. This paper presents the result of the union between different public government institutions to offer an online course on Citizenship and Social Control. This initiative of education for transparency was intended to integrate the government and the civil society, as well as to foster transparency and enable society to perform the social control. The scientific publicization of the lessons learned in this initiative, which reached about 700 citizens by means of a Learning Management System, can spur new actions and reflections in this area."
3124;en_US;"Nowadays, diverse project in Smart city are implemented in city. However, few city explicitly assess its population opinion to verify actions that should be executed. The purpose of this work is to present a case study, conducted in Rio das Ostra/RJ, to assess population opinion related to actions to be executed in its Smart City project context."
3138;en_US;"We apply the t-linearization to the straightforward 0 1 quadratic model for the maximum diversity problem. We computationally compare the obtained model with two other linear formulations from the literature. Computational experiment show that the t-linearization generates, on average, fewer constraints than the formulations, in addition to achieving a tighter upper bound in all used instances. On the other hand, one of the formulations can be slightly faster in obtaining the bounds."
3141;en_US;"Tuza (1981) conjectured that the size τ (G) of a minimum set of edges that meets every triangle of a graph G is at most twice the size ν(G) of a maximum set of edge-disjoint triangles of G. In this paper we verify this conjecture for graph with treewidth at most 6. In this paper, all graph considered are simple and the notation and terminology are standard. A triangle transversal of a graph G is a set of edges of G whose deletion result in a triangle-free graph; and a triangle packing of G is a set of edge-disjoint triangles of G. We denote by τ (G) (resp. ν(G)) the size of a minimum triangle transversal (resp. triangle packing) of G. In [Tuza 1981] the following conjecture was posed: Conjecture (Tuza, 1981). For every graph G, we have τ (G) ≤ 2ν(G)."
3144;en_US;"The worst-case time complexity of the ShellSort algorithm is known only for some specific sequences (a sequence is a parameter of the algorithm). Relating the algorithm to the Frobenius number concept, we present an algorithm for determining the maximum number of comparisons for any sequence and array to be ordered. We apply this method together with the empirical determination of complexity to analyze several sequences whose worst case complexity are known. We show that the empirical approach succeeded in determining the same complexities which are analytically known and presented its result for sequences with unknown worst-case time complexity."
3145;en_US;"The `0-sampling problem plays an important role in streaming graph algorithm. In this paper, we revisit a near-optimal `0-sampling algorithm, proposing a variant that allows proving a tighter upper bound for the probability of failure. We compare experimental result of both variants, providing empirical evidence of their applicability in real-case scenarios. The `0-sampling problem consists in sampling a nonzero coordinate from a dynamic vector a = (a1, . . . , an) with uniform probability. This vector is defined in a turnstile model, which consists of a stream of updates S = hs1, s2, . . . , sti on a (initially 0), where si = (ui, i) 2 { 1, . . . , n} ⇥ R for all 1  i  t, meaning an increment of i units to aui . It is desirable that such sample be produced in a single pass through the stream with sublinear space complexity. The challenge arises from the fact that, since i can be negative and hence some updates in the stream may cancel others, directly sampling the stream may lead to incorrect result."
3147;en_US;"We propose a method for computing centralities based on shortest paths in time-varying, multilayer, and time-varying multilayer network using MultiAspect graph (MAG). Thanks to the MAG abstraction, these high order network are represented in a way that is isomorphic to a directed graph. We then show that well-known centrality algorithm can be adapted to the MAG environment in a straightforward manner. Moreover, we show that, by using this representation, pitfalls usually associated with spurious paths resulting from aggregation in time-varying and multilayer network can be avoided."
3149;en_US;"We study emergent information in populations of randomly generated networked computable system that follow a Susceptible-Infected-Susceptible contagion (or infection) model of imitation of the fittest neighbor. These network have a scale-free degree distribution in the form of a power-law following the Barabási-Albert model. We show that there is a lower bound for the stationary prevalence (or average density of infected node) that triggers an unlimited increase of the expected emergent algorithmic complexity (or information) of a node as the population size grows."
3152;en_US;"We present a theoretical investigation of the emergence of complexity or irreducible information in networked computable system when the network topology may change over time. For this purpose, we build a network model in which node are randomly generated Turing machine that obey a communication protocol of imitation of the fittest neighbor. Then, we show that there are topological conditions that trigger a phase transition in which eventually these networked computable system begin to produce an unlimited amount of bits of expected emergent algorithmic complexity, creativity and integration as the network size goes to infinity."
3153;en_US;"Deciding if a graph is ∆ -edge-colourable (resp. (∆ + 1) -total colourable), although it is an NP-complete problem for graph in general, is polynomially solvable for interval graph of odd (resp. even) maximum degree ∆ . An interesting superclass of the proper interval graph are the proper circular-arc graph, for which we suspect that ∆ -edge-colourability is linear-time decidable. This work presents sufficient conditions for ∆ -edge-colourability, (∆ + 1) -total colourability, and (∆+2) -total colourability of proper circular-arc graph. Our proofs are constructive and yield polynomial-time algorithm."
3158;en_US;"In the Online Circle Packing in Squares, circles arrive one at a time and we need to pack them into the minimum number of unit square bins. We improve the previous best-known competitive ratio for the bounded space version from 2.439 to 2.3536 and we also give an unbounded space algorithm. Our algorithm also apply to the Online Circle Packing in Isosceles Right Triangles and Online Sphere Packing in Cubes, for which no previous result were known."
3160;en_US;"In this paper we review and enhance the Hidden Binary Search Tree (HBST) presented in [Queiroz 2017]. The HBST idea builds on the assumption an n-node self-balanced tree (e.g. AVL) requires to assure O(log2 n) worst-case search, namely, comparison between keys takes constant time. Therefore the size of each key in bits is fixed to B = O(log2 n) once n is determined, otherwise the O(1)-time comparison assumption does not hold. HBST generalizes the searchtree property such that the position of a node in the tree result from comparing its key against 'ideal' reference values associated to its ancestors. The first ideal values comes from the mid-point of the interval 0..2B. The strategy follows recursively such that the HBST height is bounded by O(B) regardless the input sequence of keys nor self-balancing procedures. In this paper we enhance the HBST to enable keys with arbitrary number of bits."
3164;en_US;"This paper approaches the problem of finding the system of representatives of a family of disjoint sets. To solve this problem, three method were used: integer programming, branch-and-bound, and the BRKGA metaheuristic. We observed that, in randomly generated instances, the branch-and-bound algorithm was the best exact method but it was surpassed by BRKGA for large instances."
3165;en_US;"Both graph classes of k-thin and proper k-thin graph have recently been introduced generalizing interval and unit interval graph, respectively. The complexity of the recognition of k-thin and proper k-thin are open, even for fixed k 2. In this work, we introduce a subclass of the proper 2-thin graph, called proper 2-thin of precedence. For this class, we present a characterization and an efficient recognition algorithm."
3166;en_US;"The complementary prism GG¯ arises from the disjoint union of the graph G and its complement G¯ by adding the edges of a perfect matching joining pairs of corresponding vertices of G and G¯. The classical problem of graph theory, clique and independent set were proved NP-complete when the input graph is a complemantary prism. In this work, we study the complexity of both problem in complementary prisms graph from the parameterized complexity point of view. First, we prove that these problem have a kernel and therefore are Fixed-Parameter Tractable (FPT). Then, we show that both problem do not admit polynomial kernel."
3169;en_US;"This work addresses the minimum subgraph diameter problem (MSDP) by answering an open question with respect to its approximability. Given a graph with lengths and costs associated to its edges, the MSDP consists in finding a spanning subgraph with total cost limited by a given budget, such that its diameter is minimum. We prove that there is no -approximation algorithm for the MSDP, for any constant , unless P = NP. Our proof is grounded on the non-approximability of the minimum spanning tree diameter problem, proven by Bálint in 2013."
3172;en_US;"The Ramsey number R(H) of a graph H is the minimum number n such that there exists a graph G on n vertices with the property that every two-coloring of its edges contains a monochromatic copy of H. In this work we study a variant of this notion, called the oriented Ramsey problem, for an acyclic oriented graph H~ , in which we require that every orientation G~ of the graph G contains a copy of H~ . We also study the threshold function for this problem in random graph. Finally, we consider the isometric case, in which we require the copy to be isometric, by which we mean that, for every two vertices x, y 2 V (H~ ) and their respective copies x0, y0 in G~ , the distance between x and y is equal to the distance between x0 and y0."
3173;en_US;"Let D be a digraph. A path partition P of D is a collection of paths such that {V (P ) : P 2 P } is a partition of V (D). We say D is ↵ -diperfect if for every maximum stable set S of D there exists a path partition P of D such that |S  V (P )| = 1 for all P 2 P and this property holds for every induced subdigraph of D. A digraph C is an anti-directed odd cycle if (i) the underlying graph of C is a cycle x1x2 · · · x2k+1x1, where k 2, (ii) the longest path in C has length 2, and (iii) each of the vertices x1, x2, x3, x4, x6, x8, . . . , x2k is either a source or a sink. Berge (1982) conjectured that a digraph D is ↵ -diperfect if, and only if, D contains no induced anti-directed odd cycle. In this work, we verify this conjecture for digraph whose underlying graph is serie-parallel and for in-semicomplete digraph."
3174;en_US;"Let D be a digraph and k be a positive integer. Linial (1981) conjectured that the k-norm of a k-minimum path partition of a digraph D is at most max{PC2 C |C| : C is a partial k-coloring of D}. Berge (1982) conjectured that every k-minimum path partition contains a partial k-coloring orthogonal to it. It is well known that Berges Conjecture implies Linials Conjecture. In this work, we verify Berges Conjecture, and consequently Linials Conjecture, for locally in-semicomplete digraph and k-minimum path partitions containing only two paths. Moreover, we verify a conjecture related to Berges and Linials Conjectures for locally in-semicomplete digraph."
3178;en_US;"A deadlock occurs in a distributed computing when a group of process wait indefinitely for resource from each other. Such a property is stable, that is, once occurs into a global state it also will exist in any subsequent global state. Distributed computation are usually represented by wait-for graph, where the behavior of process is determined by a deadlock model. In this paper we consider the scenario where deadlock was detected in a system and then some deadlock-breaking set must be found and removed. Hence, given a “snapshot” G of a deadlocked distributed computation which operates according to a deadlock model M, we investigate the complexity of vertex deletion and arc deletion problem whose goal is to obtain the minimum number of removals in order to turn G free of graph structures that characterize deadlocks. The complexity of such problem depends on the deadlock model which governs the computation as well as the type of structure to be removed. The result of this paper are NP-completeness proofs and polynomial algorithm for general and particular graph classes. In special, we show that the arc deletion problem on the OR Model can be solved in polynomial time, and the vertex deletion problem on the OR Model remains NP-Complete even on graph with (G) = 4, but it is solvable in polynomial time on graph with (G) 3."
3179;en_US;"This paper introduces the concept of probabilistic implicit graph representations, extending the definition from [Spinrad 2003] by allowing the adjacency test to have a constant probability of false positives or false negatives. It also discusses two novel representations based on well-known probabilistic data structures: one that uses Bloom filters and can represent general graph with the same space complexity as the adjacency matrix (but outperforms it for sparse graph), and other that uses MinHash and can represent trees with lower space complexity than any deterministic implicit representation."
3180;en_US;"In this work, we extend multi-agent epistemic logic for reasoning about properties in protocol. It is based on Dolev-Yao model and uses structured propositions, a new technique to deal with message, keys and properties in security protocol in an uniform manner, keeping the logic propositional. In order to illustrate the applicability of this new logic, an example is presented. There are many approaches to formally verify authenticity and secrecy in communication protocol. In this work we are most interested in logical approaches to deal with that kind of system, in particular based on [Dolev and Yao 1983]."
3181;en_US;"The problem of determining the chromatic index of a graph, even when triangle-free, is NP-hard. However, the Overfull Conjecture implies that this problem can be solved in polynomial time for graph with large maximum degree. In order to prove the conjecture, it is sufficient to show that all nonsubgraph-overfull graph with Δ > n/3 are Class 1. A special case of nonsubgraph-overfull graph are the graph with no proper majors. We show that all triangle-free graph with no proper majors, regardless of maximum degree, are Class 1. We also provide a polynomial-time algorithm to colour such graph."
3182;en_US;"Given a graph G and a pair s,t in V(G), where each edge e has a weight t(e) and each vertex v has a value p(v) such that t(e) represent a transportation time and p(v) a prize collecting. Prize Collecting Path (PCP) consists of finding a (s,t)-path that minimizes the total transportation time minus the total prize of node in such path. PCP is at core of numerous relevant application in several fields like telecommunications, transportation and logistics. In this paper, the complexity behavior of the problem is analyzed. For some cases we prove that PCP is NP-complete, these result lead to the generation of new sets of benchmark instances that are computationally hard according to natural characteristics of the problem. In addition, polynomial time algorithm are described for other cases and a mathematical formulation is introduced to solve general instances of PCP."
3185;en_US;"Let lct(G) be the minimum size of a set of vertices that contains at least one vertex in every longest cycle of a graph G. We show that lct(G) = 1 if G is a 3-tree, and that lct(G) 2 if G is a 2-connected partial 3-tree. It is known that, in every 2-connected graph, every pair of longest cycles intersect each other in at least two vertices. A natural question asks whether all longest cycles have a vertex in common in 2-connected graph. (If the graph is not 2-connected, two longest cycles can be disjoint.) This has in general a negative answer, as the Petersens graph shows. However, there are some graph classes for which this question has a positive answer, such as classes containing only Hamiltonian graph [Thomas and Yu 1994, Tutte 1956], and dually chordal graph [Jobson et al. 2016]. In this paper we show that the class of 3-trees also has a positive answer to this question. Observe that 3-trees are not dually chordal graph, as they are not clique-Helly graph, so they are not included in the class addressed by Jobson et al. [Jobson et al. 2016]."
3187;en_US;"A labelling of a graph G is a mapping : S ! L, where L R and S = E(G) or S = V (G) [ E(G). If S = E(G), is an L-edge-labelling and, if S = V (G) [ E(G), is an L-total-labelling. For each v 2 V (G), the colour of v under is defined as c (v) = Puv2E(G) (uv) if is an L-edgelabelling; and c (v) = (v) + Puv2E(G) (uv) if is an L-total-labelling. The pair ( ; c ) is a neighbour-distinguishing-L-edge (total)-labelling if : S ! L is an edge (total)-labelling and c (u) 6= c (v), for every edge uv 2 E(G). The 1,2,3-Conjecture states that every simple graph with no isolated edge has a neighbour-distinguishing-L-edge-labelling with L = f1; 2; 3g. In this work, we verify the 1,2,3-Conjecture for powers of paths and powers of cycles and we also show that powers of cycles have a neighbour-distinguishing-fa; bg-totallabelling, a; b 2 R, a 6= b."
3188;en_US;"In this paper we study the facility leasing problem with penalties. We present a 3-approximation primal-dual algorithm, based on the algorithm by Nagarajan and Williamson for the facility leasing problem and by Charikar, Khuller, Mount and Narasimhan for the facility location problem with penalties. In the facility location problem, it is given a metric space (V, d), a set F ⊆ V of facilities, an opening cost for each facility, and a set D ⊆ V of clients. The goal is to choose a subset of facilities to open and an assignment between clients and facilities which minimize the cost of opening the facilities plus the sum of the distances from each client to its corresponding facility. This problem does not admit a polynomial-time algorithm with approximation factor smaller than 1.463 unless P = NP [Sviridenko 2002]. Currently the best approximation factor is 1.488 [Li 2013]."
3190;en_US;"We introduce the Least-Dependency Constrained Spanning Tree Problem, which consists of finding a spanning tree where each edge has at least one edge of its dependency set, if non-empty, also in the tree. The dependencies on the input graph G are described by a digraph D where the vertices are the edges of G, and the in-neighbors of a vertex are its dependency set. We show that the optimization problem is NP-hard even if G is a chordal cactus with maximum degree 3 or diameter at most 2, and D is a disjoint union of arborescences of height 2. The same complexity is proved when G is planar bipartite, and each component of D is an oriented cycle or an anti-arborescence of height 1. We also report two polynomial cases."
3194;en_US;"An ordered pair (π, cπ) is said to be a gap-[k]-edge-labelling (gap-[k]vertex-labelling) if π is an edge-labelling (vertex-labelling) on the set {1, . . . , k}, and cπ is a proper vertex-colouring induced by a gap-function based on π. Gap-[k]edge-labellings and gap-[k]-vertex-labellings were first introduced by M. Tahraoui et al. [7] and A. Dehghan et al. [2], respectively. The edge-gap number (vertex-gap number) is the least k for which there exists a gap-[k]-edge-labelling (gap-[k]-vertexlabelling) of a graph. In this work, we study the edge-gap number, χgE , and the vertexgap number, χgV , of cycles, crowns and wheels."
3202;en_US;"We deal with the cumulative vehicle routing problem (VRP), a generalization of the capacitated VRP, which objective is to minimize the fuel consumption. Gaur et al. in 2013 gave a 4-approximation based on a well-known partition heuristic to the traveling salesperson problem (TSP). We present a tighter analysis obtaining a 4 3s34Q2 -approximation, where Q is the capacity of the vehicle and s is a scaling factor. To the best of our knowledge, this is the best proved approximation for the cumulative VRP so far."
3203;en_US;"In this paper we study the problem of coloring the edges of a graph for any k-list assignment such that there is no maximal monochromatic biclique, in other word, the k-biclique edge-choosability problem. We prove that the K3free graph that are not odd cycles are 2-star edge-choosable, chordal bipartite graph are 2-biclique edge-choosable and we present a lower bound for the biclique choice index of power of cycles and power of paths. We also provide polynomial algorithm to compute a 2-biclique (star) edge-coloring for K3-free and chordal bipartite graph for any given 2-list assignment to edges."
3213;en_US;"Data center infrastructures need to provide high availability of their service. Unexpected spikes of downtime in data centers lead to financial losses. Besides, there are intangible costs such as damaged reputation, low employee satisfaction, and reduced customer retention. In this context, Network Function Virtualization (NFV) emerged as a paradigm that assists data centers in becoming more dynamic and flexible. This paper presents an availability evaluation and importance analysis under the redundancy of NFV in data centers. The NFV data center component importance is represented by using Reliability Block Diagrams (RBD). The proposed model have identified the availability importance and critical device in an NFV data center. This research also suggests alternatives for device redundancy to reach higher availability and proposes a new importance measure for analyzing the impact of NFV factors on data center availability. The measure can evaluate the degree of the impact of a failure on the data center, therefore, help to identify the factors with a substantial impact on data center availability."
3214;en_US;"Evolving 5G network scenarios will have to deal with new multiple administrative domain (aka multi-domain) orchestration model. Based on a new broker-plane approach on top of per-domain management and orchestration functions, we present a Multi-domain orchestration prototype capable to coordinate the delivery of a multi-operator End-to-End Network Service (E2ENS) that combines per-domain paths and network functions for a given service request. Our prototype implementation retrieves local information about topology and resource from each Multi-domain Orchestrator (MdO) to offer after inter-domain added value service in the form of abstract Map service. These map abstractions are easily consumable through developer-friendly REST APIs based on the Application-Layer Traffic Optimization (ALTO) standard protocol."
3217;en_US;"The IETF has been acting as one of the main actors when discussing standardization of protocol and good practices on the Internet. Collaborating with the IETF community can be complex and distant for many researcher and industry members because of the financial aspect to travel to the meeting. However, it notes the collaboration between industry and academia is actively and progressively developing and refining standards within the IETF. One of the incentives for the increased participation in IETF meetings is because it is being transmitted in real time since 2015, allowing for voice and chat interaction of remote participant. Thus, in this paper, we have as objectives to give a brief vision about how to collaborate with the IETF and to analyze the importance of this new form of participation of the face-to-face meetings that has been growing in recent years."
3218;en_US;"Dynamic analyses are technique used to observe the behavior of programs during their execution. tool that implement such technique include not only the well known profilers, such as gprof and Shark, but also dynamic binary instrumentation framework, the focus of this course. Dynamic Binary Instrumentation (DBI) adds code to a programs execution flow in order to study the events that occur during its execution. Analysis code is executed as if it were part of the programs normal execution flow, without affecting it, and performing extra tasks - like measuring performance or identifying errors - in a transparent manner. Since they work with the actual input data of programs, dynamic analyses are capable of assessing, in an exact way, conditions that cannot be defined statically. Due to this advantage and the maturity achieved by DBI tool, this technique has been widely used in multiple scenarios, notably the system security area. This mini course presents the fundamentals about DBI and discusses real examples in security of application. Hence, it enables professionals and researcher to benefit from the many possibilities offered by DBI, besides allowing the attendants to get acquainted with some concepts related to software security."
3219;en_US;"The world has been producing a large amount of data currently. With the Internet of Things, we have a network of device capable of collecting, transmitting and processing data and with this large amount of data, storing and processing these is the new challenge. Relational databases are being used by large corporations, however, the high data production implies relational databases, difficulties in scalability and performance, considering the respect of ACID properties and normal forms. We are currently working with data, often without a fixed structure, which culminates in the use of non-relational database management system (DBMS), also known as NoSQL DBs. To better understand this paradigm change, it is necessary to characterize this data, extracting the main characteristics and defining when to use a relational DBMS or a NoSQL. This paper aims to explain the main characteristics of the NoSQL databases and to mix, theory and practice, to create a CRUD application using the Java programming language, which uses MongoDB, one of the main NoSQL DBMSs on the market. Also the new profiles of software engineers and data will be addressed, and what the Big Data is breaking, opposite paradigms already established."
3225;en_US;"The socio-spatial dynamics of a city undergoes constant changes over time. Consequently, the road network and the public transport system need continuous optimization to meet citizen demands. An alternative to reduce costs and impacts on evaluation of solutions is the use of simulators and model consistent with reality. Considering that, we processed vehicle tracking data and bus system planning information of São Paulo to improve the bus movement model used by InterSCSimulator, a highly scalable simulator for smart city. In this paper, we present a mobility model based on real data from the São Paulo bus service to make the simulator more effective when recreating urban mobility scenarios."
3226;en_US;"Making city smarter can help improve city service, optimize resource and infrastructure utilization and increase quality of life. Smart city connect citizens in novel ways by leveraging the latest advances in information and communication technologies (ICT). The integration of rich sensing capabilities in todays mobile device allows their user to actively participate in sensing the environment. In Mobile CrowdSensing (MCS) citizens of a Smart City collect, share and jointly use service based on sensed data. The main challenges for smart city regarding MCS is the heterogeneity of device and the dynamism of the environment. To overcome these challenges, this paper presents an architecture based on model at runtime (M@rt) to support dynamic MCS query in Smart city. The architecture is proposed as an extension of the InterSCity platform, leveraging on its existing service and on its capability to integrate city infrastructure resource."
3228;en_US;"Amidst the problem of public safety in Brazil, this paper presents a developement and deployment history of the ROTA Platform, a smart city solution created to address problem, besides discussing its application and the purpose of each one. The result obtained from the introduction of the solution are shown and explained, thereby exposing advances caused by the platform. The paper also presents new challenges to be handled by ROTA for achieving its ideal behavior."
3230;en_US;"This paper deals with needs related to safety in the Federal University of Rio Grande do Norte (UFRN), in Natal, and proposes SIGOc - Integrated System for Occurrence Management, a platform that aims to optimize the current operation mode to manage occurrence in the UFRN campuses. SIGOc consists of two mobile application and a Web system, enabling the university community to report occurrence while supporting the work of campus safety staff for fast occurrence handling. Moreover, the proposed solution seeks to address challenges found in this context on three main fronts, namely managerial, informational, and communicational."
3231;en_US;"A notable characteristic of smart city is the increase in the amount of available data generated by several device and computational system, thus augmenting the challenges related to the development of software that involves the integration of larges volumes of data. In this context, this paper presents a literature review aimed to identify the main strategies used in the development of solutions for data integration, relationship, and representation in smart city. This study systematically selected and analyzed eleven studies published from 2015 to 2017. The achieved result reveal gaps regarding solutions for the continuous integration of heterogeneous data source towards supporting application development and decision-making."
3233;en_US;"<p>Automated planning is an important general problem solving technique in Artificial Intelligence. Given an initial state, a goal and a set of operators, we want to find a sequence of operators leading us to the goal. What makes planning interesting is that it can model different domains into planning tasks and solve them using a single method. In this work, we approach two different topic in planning. First, we study heuristics for the airport ground traffic problem and propose new heuristics that are better than any other known method. In the second part, we study tie-breakers for the A∗ search algorithm. We propose a new tie-breaking method that is proved to be the best possible and also show that our method solve more instances than previous method in literature.</p>"
3238;en_US;"Despite the consistent development of visual feature, effectively measuring the similarity among image remains a challenging problem in Contentbased Image Retrieval (CBIR) system. In this scenario, similarity learning approaches capable of improving the effectiveness of retrieval in an unsupervised way are indispensable. This undergraduate research work presents a method called Cartesian Product of Ranking References (CPRR) which was developed with this objective. An extensive experimental evaluation was conducted considering various aspects, four public image dataset, and several feature. Besides effectiveness, experiment were also conducted to assess the efficiency, considering parallel and heterogeneous computing on CPU and GPU device. The method has achieved significant effectiveness gains, including competitive state-of-the-art result on popular benchmarks."
3239;en_US;"The growing importance of smart device calls for effective user authentication mechanism. In this paper, we argue that state-of-the-art authentication mechanism are either vulnerable to known attacks or do not fully meet usability needs. To address this problem we design NomadiKey, a user-to-device authentication mechanism based on nomadic keyboard keys. NomadiKey increases security level by placing keys at different screen coordinates each time it is activated. Besides, NomadiKey preserves usability by maintaining the traditional relative position of keys. To increase security even further, we also design an extension to NomadiKey, called NomadiKey++, that employs out-of-band channels to protect the user from shoulder-surfing attacks."
3268;en_US;"The computational needs of scientific experiment often require powerful computer. One alternative way to obtain this processing power is taking advantage of the idle processing of personal computer as volunteers. This technique is known as volunteer computing and has great potential in helping scientists. However, there are several issues which can reduce the efficiency of this approach when applied to complex scientific experiment, such as, the ones with long processing time, very large input or output data, etc. In order to face these challenges, we designed a volunteer computing system based on peer-to-peer communication. When compared with the local execution of activity and traditional volunteer computing, the execution time was improved and, in some cases, there was also a reduction of the server upload bandwidth use."
3270;en_US;"One of the most important tasks in geomechanical research is executing analytical and numerical simulation to understand geomechanical phenomena. In order to attain this objective, researcher have to prepare data to perform the simulation, build the model that define the appropriate physical representation and the mathematical modeling of the problem, run a computer system capable of simulating the phenomenon, and visualize and interpret the result. This paper presents the main functional requirement to support the development of solutions that encompass the simulation of geomechanical problem, taking into account a collaborative environment with access to an efficient computer infrastructure. The paper also describes ERAS, a portal developed according to these requirement, highlighting the advantages it brings to researcher in this area."
3273;en_US;"Soils Security is a critical and growing global concern. The OpenSoils´ objective is to host, connect and share large amounts of curated soil data and knowledge at the Brazilian and South America level. The e-infrastructure consists of several layers of service, a database of soil profiles, a cloud-based computational framework to compute and share soil data integrated with a map visualization tool. OpenSoils is open, elastic, provenance-oriented and lightweight computational e-infrastructure that collects, stores, describes, curates, harmonizes and directs to various soil resource types: large dataset of soils profiles, service/application, document, project and external links. OpenSoils is the first open science-based computational framework of soils security in the literature."
3275;en_US;"Open scientific data is fundamental to support better quality and higher impact reproducible science. The creation of open scientific databases involves a number of challenges, such as the creation of standardized representations of data and metadata from different domains of knowledge, as well as the development of computational resource to assist scientists in collecting and maintaining high-quality data. This paper presents a free software computational platform for the management and sharing of data from Neuroscience experiment. This platform allows to register data and metadata of experiment in a safe and user-friendly way, integrating data records of different types, such as clinical, electrophysiological and behavioral."
3276;en_US;"High Performance Computing (HPC) has always been a fundamental component to conduct scientific experiment. Model calibrations/simulation often require several executions of scientific application by changing their input parameters. This process is a common practice in research even though it represents a tedious and error-prone task. In this paper we propose Copper framework which employs a black-box strategy and contains a set of plugins to accelerate user experiment for exploring search spaces in HPC parametric application. Copper has been used to conduct scientific experiment in different area including, agriculture, oil   gas, flood simulation, and bioinformatics."
3277;en_US;"Executing scientific workflows in high-performance cloud computing platforms requires the use of scheduling algorithm that allow workflows execution as fast as possible, while minimizing the monetary cost of such executions. In this work we study how the use of supporting information can offer guidance to scheduling algorithm, helping them to devise more efficient execution plans in terms of the total execution time (makespan) and the total monetary cost. Using two large-scale scientific workflows, our experiment showed that simple modifications on a classical scheduling algorithm (HEFT), in conjunction with the appropriate supporting information, could reduce the monetary cost of an execution in up to 59% and reduce the makespan in up to 8.6%."
3278;en_US;"Bioinformatics, especially the area of phylogeny and evolution of organisms, requires high performance computing (HPC) environments. The present work presents a behavioral analysis of the RAxML phylogeny tool in HPC environments. RAxML implements parallelism and task distribution by using threads and MPI libraries. Executions were performed in the Santos Dumont (SDumont) supercomputer. Efficiency result show the impact is generated by the variation in configuration, coupling and use of RAxML and SDumont. This information will allow a better understanding and efficient use of these specialized environments."
3281;en_US;"The muon is an elementary particle with a negative charge, and is the most abundant charged component of cosmic radiation that penetrates deep into the Earths soil. Analyzing the flow of muons that reaches our planet is important to identify solar eruptions that can cause harm to the population. This paper presents an approach based on sequence mining algorithm to automate the process of identifying frequent pattern in the captured muon stream. experiment carried out show that the approach is capable of identifying eruptions by means of the identified frequent pattern."
3292;en_US;"Heart arrhythmia, also known as irregular heartbeat, affects millions of people around the world. One of the ways to detect this cardiac dysrhythmia is by performing an electrocardiogram (ECG) exam which records the electrical activity of the heart. However, this type of exam is always interpreted by a doctor. In order to provide an alternative in heart arrhythmia diagnosis, this paper aims at developing a platform based on Internet of Things infrastructure capable of automatically monitoring and identifying cardiac arrhythmia based on feature selection and classification method."
3311;en_US;"Context-Aware Management system have been proposed in the last years to perform automatic decision making for the Internet of Things. Although scalability is an indispensable feature for those system, there are no comprehensive result reporting their performance. This paper shows result of a performance analysis study of different context-aware architectures and introduces the SenSE platform for generating sensor synthetic data. result show that different architectural choices impact system scalability and that automatic real time decision-making is feasible in an environment composed of dozens of thousands of sensor that continuously transmit data."
3316;en_US;"Precision agriculture is a concept regarding the use of technology to increase production yield while preserving and optimizing resource. One of the means to achieve that goal is to use sensor to monitor crops and adjust the cultivation according to its needs. This paper compares different technique for sensor data fusion and detection and removal of outliers from gathered data to improve sensor accuracy and to identify possible sensor malfunction. As a case study, we monitored an experimental crop of precocious dwarf cashew using soil moisture sensor. Combining generalized ESD method and a weighted outlierrobust Kalman filter generated the best result, leading to more accurate data."
3317;en_US;"With the rising number of Internet of Things device and context provider, the need for sorting and selecting them according to user requirement and to the quality of sensed information becomes prevalent. Thus, this paper presents the Rhadamanthys architecture, designed to fulfill this requirement using Quality of Context information for both ranking and selection. Individual Quality of Context criteria as defined in the literature are evaluated for each available provider and used in formulae to obtain a single score that enables ranking and allows selection."
3319;en_US;"New trends in dataplane programmability inside Software Defined Networking (SDN) paradigm are in an effort to bring multi-platform support with a high-level definition of the dataplane pipeline functions. The MultiArchitecture Compiler System for Abstract Dataplanes (MACSAD) can integrate the Protocol-Independent Packet Processors (P4) domain-specific language and the OpenDataPlane Project (ODP) APIs, to define a programmable dataplane across multiple targets in a unified compiler system. In this paper, we present and evaluate the IPv4/IPv6 Longest Prefix Match (LPM) support in MACSAD. We develop a new ODP Helper library implementing the IPv6 lookup mechanism based on the current IPv4 solution and evaluate its performance and scalability for diverse workloads and target platform configurations."
3322;en_US;"This paper compares the runtime of three distinct parallel algorithm for the evaluation of an ab initio and full-atom approach based on GA and celllist technique, in order to minimize the van der Waals energy. The three parallel algorithm are developed in C and use one of these programming model: MPI, OpenMP or hybrid (MPI+OpenMP). Our preliminary result show that van der Waals Energy are executed faster and with better speedups when using hybrid and more flexible parallel algorithm to predict the structure of larger proteins. We also show that for small proteins the communication of MPI imposes a high overhead for the parallel execution and, thus the OpenMP presents a better relation cost x benefit in such cases."
3324;en_US;"Influence is a concept found in nature and society and is related to the interdependency among a set of objects. In the context of a stock market, the variation in price of shares can influence the variation in price of other shares, leading to influential and influenced shares. In this work we leverage the notion of transfer entropy to build a network of shares and pairwise directed influence that is used to rank the most influential and influenced shares. Classical network centrality metrics such as PageRank and HITS are leveraged to rank the node. We apply our methodology to the shares in the greater stock market in Brazil, we rank node to find source and destination of influence in that market, while also comparing the different rankings and their correlation with traded volume."
3326;en_US;"Managing wireless network is challenging due to the requirement of ensuring good performance while coexisting with other network. This paper analyses a production wireless network that is also used for research. The wireless network at Universidade Federal Fluminense uses home grown technology which was funded by RNP in the SCIFI work group, which is composed of a software controller and low cost access points compatible with OpenWRT. The analysis of the wireless network is performed modeling the network as a directed graph, in which node are the access points and edges represent vicinity. algorithm for choosing the wireless channel in order to maximize performance by minimizing interference both by access points which are controlled or not by the system. The characteristics of associations of user device to the wireless network are shown. The result of the analysis show that, after the installation of new channel, up to 75% of unmanaged network in the vicinity of an access point switch their channel to adapt to the new wireless configuration."
3331;en_US;"Virtual Memory was devised in a time of scarce resource. In the coming decade we expect to see physical memory system populated with 264 bytes of RAM, a fraction of which may be non-volatile. Demand paging is inefficient in such large memories because space (Page Tables) and time (Page Table walks) overheads are too high. We collected execution traces from six application and characterized their virtual memory behavior with respect to miss rates in references to Translation Buffers (TLBs) and Segment Buffers (SBs). Our measurements indicate that the miss rates for SBs are 2-3 orders of magnitude smaller than for TLBs. In light of these result, we discuss some of the design implications of segmented system and of SBs."
3333;en_US;"A short-term solution for the depletion of Internet Protocol (IP) addresses and scaling problem in network routing is the reuse of IP address by placing Network Address Translators (NAT) at the borders of stub domains. In this article, we propose an implementation of NAT using Programming ProtocolIndependent Packet Processors (P4) language, taking advantage of its feature such as target-agnostic dataplane programmability. Through the MACSAD framework, we generate a software switch that achieves high performance with the support of different hardware (H/W) and Software (S/W) platforms. The main contributions of this paper relate to the performance evaluation result of the NAT implementation using P4 language with MACSAD compiler."
3338;en_US;"Massive data processing (big-data) related fields and cloud computing have been growing conjointly. Thus, data processing is among the largest resource consumers in datacenters, consuming around 2% of global energy. Comprehension of how elements such as virtualized environments and application parallelization degree affect such consumption is therefore an urgent need. This article relies on a monitoring solution that provides performance metrics, data mining application logs, and data produced in distributed environments to assess how power consumption of virtualized big-data application varies on allocated resource."
3346;en_US;"Performance and energy consumption are fundamental requirement in computer system. A very frequent challenge is to combine both aspects, searching to keep the high performance computing while consuming less energy. There are a lot of technique to reduce energy consumption, but in general, they use modern processors resource or they require specific knowledge about application and platform used. In this paper, we propose a library that dynamically changes the processor frequency according to the application computing behavior, using a previous analysis of its Memory-Bound regions. The result show a reduction of 1,89% in energy consumption for Lulesh application with an increase of 0,09% in runtime when we compare our approach against the governor Ondemand of the Linux Operating System."
3348;en_US;"Energy and performance of parallel system are an increasing concern for new large-scale system. Research has been developed in response to this challenge aiming the manufacture of more energy efficient system. In this context, we improved the performance and achieved energy efficiency by the development of three different strategies which use the GPU memory subsystem (global-, shared-, and read-only- memory). We also develop two optimizations to use data locality and use of registers of GPU architecture. Our developed optimizations were applied to GPU algorithm for stencil application achieve a performance improvement of up to 201:5% in K80 and 264:6% in P 100 when used shared memory and read-only cache respectively over the naive version. The computational result have shown that the combination of use read-only memory, the Z-axis internalization of stencil application and reuse of specific architecture registers allow increasing the energy efficiency of up to 255:6% in K80 and 314:8% in P 100."
3354;en_US;"Internet of Things (IoT) aims to connect multiple device and enable communication on a global scale. In this context, wearable computing turns into one of the most imperative technologies for data capture and transfer. Even though many solutions exist for fast development of wearable application, it is difficult to know which one is the best for each situation. In this paper, we evaluated the performance of three wearable computing framework: SPINE, BNSM and IBM Bluemix. We used performance metrics such as data accuracy, memory footprint and energy consumption in a movement recognition scenario. result have shown that, among the analyzed framework, (i) BNSM is the best one concerning energy-efficiency; (ii) IBM Bluemix is the best one for data accuracy. Both framework presented interesting result in terms of memory footprint."
3360;en_US;"GPUs has been widely used in scientific computing, as by offering exceptional performance as by power-efficient hardware. Its position established in high-performance and scientific computing communities has increased the urgency of understanding the power cost of GPU usage in accurate measurements. For this, the use of internal sensor are extremely important. In this work, we employ the GPU sensor to obtain high-resolution power profiles of real and benchmark application. We wrote our own tool to query the sensor of two NVIDIA GPUs from different generations and compare the accuracy of them. Also, we compare the power profile of GPU with CPU using IPMItool."
3365;en_US;"This paper proposes a new methodology for a multi parameter approach using the p-median. The optimized solution must fulfill the following criteria: It must minimize distances between city without a university to a city that has a university; It must prioritize city with a higher population; It must prioritize city with a lower United Nation Human Development Index. The use of a multiparametric approach was only possible by introducing the concept of a generalized distance. The result compare the existing distribution of campuses of the Federal system with the best location resulting from the multi parameter method proposed here. Locations for expansion of the current established university in Amazonas State, Brazil, are proposed."
3366;en_US;"This paper proposes a hybrid approach to solve the capacitated vehicle routing problem with time window constraints (CVRPTW). In order to evaluate such approach, we propose a case study with the primary goal of defining the delivery routes of school meals in the public school system of Manaus city (Amazonas - Brazil). The optimized solution minimizes the traveled distance of the delivery vehicle and takes into account the capacity and time window time constrains. The approach present in this paper is classified as global-local. On one hand, the metaheuristic simulated annealing, usingthe swap operator, is applied in the global search. On the other hand, A* search algorithm is applied in the local search, in order to refine all solutions presented by the global search. Importantly, the main difference between such approach and the remaining ones present in the literature is that all solutions from the global search are optimized in the local search. The experimental evaluation compares the result with another approach, which will be presented throughout the paper, by means of computation time and total traveled distance."
3368;en_US;"The study of large amounts of data is a current challenge and we must be prepared to treat and analyze them. In this task, pre-processing is essential for verifying data, identifying inconsistencies, possible errors and incompleteness. In this work, two dataset with more than thirty million records of the movement of taxis in the city of San Francisco and Rome were analyzed. We propose an algorithm to treat anomalous speeds identified in the preprocessing step of these dataset. We present the analysis of the dataset before and after the application of the algorithm, showing its relevance and pertinence. The result show specific characteristics of the taxi service in the two metropolises."
3369;en_US;"Mobile device are getting much more relevance during the user day, in a way that they are paying to increase device security and durability though external cases or insurance plans. However, these approaches are useless if the individuals does not properly take care of their device. This paper describes an approach to monitor and classifies a surface where a smartphone falls, making possible to categorize this crash into a range of dangerousness. The authors collected empirical data from device falls to make possible the development of an optimal classifier. Our result reached up to 88% recognition rate of surfaces considering a specific feature subset, letting us conclude that it is possible to infer user care level through the analysis of how a device is being treated."
3370;en_US;"There are several ways to make computing accessible to everyone, such as providing teaching material in text and video formats. In particular, the recording lectures and talks with the aim of making the corresponding content available (as a video or multimedia document), is a common activity in many locations world-wide. Two common approaches used to recording such events are using a studio or instrumenting a conventional classroom with cameras and microphones so as to record the activity in-place. In this paper we study the influence that the use of these two environments may have in the recording process. We report on a case study with 27 participant which recorded short academic talks in the two scenarios and also discuss how the environment affected their behavior. Understanding such influences may inform the design of infrastructures aimed at supporting the authoring of interactive multimedia document from live experiences."
3371;en_US;"The paper examines a professional choice of young high school student, that are finishing this stage, in Paranhana/RS region. A survey with 1,328 student of both genders, aged between 15 and 20 years old, was applied, of which 734 (55%) were girls. The answers indicate that these women mostly desire to attend Higher Education and that is really important the profession and the degree course, as well, in their personal achievement. However, careers and training related to technology presented a concern low demand."
3384;en_US;"This paper describes result of a research carried out with student and alumni of undergraduate course from the technological area of different universities. It aimed to raise perceptions related to the issue of the low number of women in these course, mainly in the course related to the computing area and in the labor market."
3403;en_US;"The low participation of women in the computer fields is a disturbing fact since diversity in any environment is vital to a good development, especially in technology where the role of end user is changing and they have gone from consumers to producers. This paper describes our project activity at our university with the newly enrolled student in the Computer Science course in the last 3 semesters. Our goal is to analyze the interaction among student, especially girls, in the first days of school and promote a discussion about the low number of girls in the course, giving the opportunity for them to share their experiences."
3416;en_US;"The objective of the present work is to analyze the result of the public reaction to situations of gender-related prejudice and exemplified in small dramatizations developed by the Revanche Drama Company in the event of International Womens Day organized by the Emíli@s extension project. The result reveal that the malés and femalés perception is strongly divergent."
3429;en_US;"Tiny computer called System-on-a-Chip like Raspberry Pi have revolutionized the development of application for Smart Home and Smart City. Some Machine Learning algorithm have been used to process a large amount of data produced by these Internet of Things (IoT) device. An important issue in the context of processing IoT data is the decision on where the machine learning algorithm will run. To support this decision, it is necessary to classify the IoT device according to their capabilities to run these algorithm, in terms of CPU performance, required memory, and energy demand. The aim of this paper is to classify IoT device according to their capabilities to run machine learning algorithm, and reporting real experiment that validate the proposed classification."
3436;en_US;"The culture has been, recently, recognized as a new pillar to achieve sustainability. Culture is built through generations, as an heritage. Autobiographical memories records, such as photograph, are important elements to pass down this heritage. Preserving these records, however, can present a range of challenges. In this work we address the issue of the use of photograph as records of memories (photo-memories), in the context of cultural sustainability. We present a set of challenges related to the theme, identified from a literature review, and, associated to them, we describe research opportunities for different area of Computing."
3438;en_US;"We present a multilayer image segmenter adapted to be used for Precision Agriculture (PA). PA depends strongly on the application of information technologies to divide and group geographic area based on land use, soil data, metrological data and agricultural resource for planning and implementation of activity to increase output by using optimal strategies for each segment. We implemented a modified Baatz algorithm in the statistical language R and speed sensitive code was implemented in C++. The code will be made publicly available under the GNU Lesser Public License. We show the merit of our approach at the hand of a landscape and discuss the obtained segments generated by our tool."
3451;en_US;"Decision trees are a central structure in computer science, having application in many area. This thesis contributes to the understanding of this important structure by proving by proving theoretical bounds on its behavior and also providing algorithm to construct decision trees with much stronger guarantee and that can cope with more general situations than the solutions available in the literature."
3452;en_US;"Biometric system can provide safer authentication. However, biometric feature may change over time, impacting the recognition performance due to outdated biometric references. It raises the need to automatically adapt the references over time, by using adaptive biometric system. This thesis studied several aspects of adaptive biometric system in a data stream context. Based on this investigation, it was observed that the best choice for each aspect can be user dependent. This motivated the proposal of a modular adaptive biometric system, which can select a different configuration for each user. It also generalizes several baselines and proposals into a single modular framework, while opening numerous opportunities for future work."
3454;en_US;"We study the Decomposition Conjecture posed by Barát and Thomassen (2006), which states that, for each tree T , there exists a natural number kT such that, if G is a kT -edge-connected graph and jE(T )j divides jE(G)j, then G admits a partition of its edge set into copies of T . In a serie of paper, Thomassen has verified this conjecture for stars, some bistars, paths of length 3, and paths whose length is a power of 2. In this paper we prove this conjecture for paths of any given length. Our technique is then used to prove weakenings of a conjecture of Kouider and Lonc (1999), and a conjecture of Favaron, Genest and Kouider (2010), both for path decomposition of regular graph."
3455;en_US;"To protect against brute force attacks, modern password-based authentication system usually employ mechanism known as Password Hashing Schemes (PHS). Basically, a PHS is a cryptographic algorithm that generates a sequence of pseudorandom bits from a user-defined password, allowing the user to configure the computational costs involved in the process aiming to raise the costs of attackers testing multiple password trying to guess the correct one. In this context, the goal of this research effort is to propose a novel and superior PHS alternative. Specifically, the objective is to improve the Lyra algorithm, a PHS built upon cryptographic sponges whose project counted with the authors participation. The resulting solution, called Lyra2, preserves the efficiency and flexibility of Lyra, and it brings important improvements when compared to its predecessor: (1) it allows a higher security level against attack venues involving time-memory trade-offs; (2) it includes tweaks for increasing the costs involved in the construction of dedicated hardware to attack; (3) it balances resistance against side-channel threats and attacks relying on cheaper (and, hence, slower) storage device. Besides describing the algorithm design rationale in detail, the thesis also includes a detailed analysis of its security and performance."
3457;en_US;"Texture is one of the primary visual feature used to computationally describe the pattern found in nature. Existing computational method, however, do not successfully discriminate the complexity of texture pattern. Such method disregard the possibility of describing image by benefiting from the complex system properties that are characteristic to textures. To do so, we created approaches based on the Bouligand-Minkowski fractal dimension, swarm-system Artificial Crawlers, and non-linear diffusion of Perona-Malik, technique that led to methodologies with efficacy and efficiency comparable to the state-ofthe-art. The result achieved in the four methodologies described in this work demonstrated the validity and the potential of our hypothesis in tasks of pattern recognition. The contributions of our methodologies shall support advances in materials engineering, computer vision, and agriculture."
3459;en_US;"This work deals with the problem of image restoration of monocular image acquired in participating media, i.e. media that interfere with light propagation. Specifically, the proposed work focus on the automatic restoration of image acquired in underwater and foggy/hazy scenes. The proposed restoration process requires at least a pair of image as input and produces image in which the medium effects are attenuated and the visibility improved. Differently from previous work, our method does not need additional equipment or information. We proposed a new model-based approach by estimating the depth map and the attenuation coefficient. We performed experimental evaluation in real and simulated environments with significant improvement in the quality of the image."
3460;en_US;"The current pace of innovation in computing makes it difficult to assume a fixed set of requirement for the whole life span of a system. Aggressive technology scaling also imposes additional constraints to modern hardware platforms. Field-Programmable Gate Array (FPGA) reconfiguration can help system cope with dynamic requirement such as performance and power, hardware defects due to Negative-Bias Temperature Instability (NBTI) and Process, Voltage and Temperature (PVT) variations, or application requirement unforeseen at design time. This work proposes a framework for reconfigurable components whereby the reconfiguration of a component implementation is performed transparently without user intervention. The reconfiguration process is confined in system idle time without interfering with or being interfered by other activity occurring in the system or even peripherals performing I/O. A telecommunications switch was used as a case study for the deployment of reconfigurable components as well as the impact I/O interference has in the process and to explore non-functional trade-offs between implementations."
3463;en_US;"Most data classification technique rely only on the physical feature of the data (e.g., similarity, distance or distribution), which makes them difficult to detect intrinsic and semantic relations among data item, such as the pattern formation, for instance. In this thesis, it is proposed classification method based on complex network in order to consider not only physical feature but also capture structural and dynamical properties of the data through the network representation. The proposed method comprise concepts of pattern conformation, data importance and network structural optimization, which are related to complex network theory, learning system, and bioinspired optimization. Extensive experiment demonstrate the good performance of our method when compared against representative state-of-the-art method over a wide range of artificial and real data sets, including application in domains such as heart disease diagnosis and semantic role labeling."
3464;en_US;"Moving-blocks problem are extremely hard to solve and a representative abstraction of many application. Despite their importance, the known computational complexity result are limited to few versions of these problem. In addition, there are no effective method to optimally solve them. We address both of these issues. This thesis proves the PSPACE-completeness of many versions of moving-blocks problem. Moreover, we propose new method to optimally solve these problem based on heuristic search with admissible heuristic functions and tie-breaking strategies. Our method advance the state of the art, create new lines of research and improve the result of application."
3465;en_US;"The evolution of CMOS technology made possible integrated circuits with billions of transistors assembled into a single silicon chip, giving rise to the jargon Very-Large-Scale Integration (VLSI). VLSI circuits span a wide range class of application, including Application Specific Circuits and system-On-Chip. The latter are responsible for fueling the consumer electronics market, especially in the segment of smartphone and tablets, which are responsible for pushing hardware performance requirement every new generation. The required clock frequency affects the performance of a VLSI circuit and induces timing constraints that must be properly handled by synthesis tool. This thesis focuses on technique for timing closure of cellbased VLSI circuits, i.e. technique able to iteratively reduce the number of timing violations until the synthesis of the synchronous digital system reaches the specified target frequency."
3466;en_US;"Sensitive video that may be inadequate to some audiences (e.g., pornography and violence, towards underages) are constantly being shared over the Internet. Employing humans for filtering them is daunting. The huge amount of data and the tediousness of the task ask for computer-aided sensitive videoanalysis, which we tackle in two ways. In the first one (sensitive-video classification), we explore efficient method to decide whether or not a video contains sensitive material. In the second one (sensitive-content localization), we explore manners to find the moments a video starts and ceases to display sensitive content. Hypotheses are stated and validated, leading to contributions (paper, dataset, and patents) in the fields of Digital Forensics and Computer Vision."
3468;en_US;"In AI, inconsistency measures have been proposed as a way to manage inconsistent knowledge bases. This work investigates inconsistency measuring in probabilistic logic. We show that previously existing rationality postulates for inconsistency measures in probabilistic knowledge bases are themselves incompatible and introduce a new way of localising inconsistency to reconcile these postulates. We then show the equivalence between distance-based inconsistency measures, from the AI community, and incoherence measures, from philosophy, that are based on the disadvantageous gambling behaviour entailed by incoherent probabilistic beliefs (via Dutch books). This provides a meaningful interpretation to the former and efficient method to compute the latter."
3469;en_US;"Large volumes of data have been produced in many application domains. Nonetheless, when data quality is low, the performance of Machine Learning technique is harmed. Real data are frequently affected by the presence of noise, which, when used in the training of Machine Learning technique for predictive tasks, can result in complex model, with high induction time and low predictive performance. Identification and removal of noise can improve data quality and, as a result, the induced model. This thesis proposes new technique for noise detection and the development of a recommendation system based on meta-learning to recommend the most suitable filter for new tasks. experiment using artificial and real dataset show the relevance of this research."
3470;en_US;"With the exponential growth in the scientific interest on assessing the blind user experience in the web environment, it is essential to develop studies that correlate usability feature lined up to the accessibility feature. At the same time, with technological resource advances and access to information through different device, there is a gap in the UX investigation in mobile device, specifically, in the blind user experience. Therefore, this work proposes a systematic literature revision, identifying the main blind user experience method applied in the mobile device interaction. Thus, 805 scientific articles were identified through the literature, which approached subjects like usability, blind user experience and mobile device. Through result extraction, sixteen different applied method were identified in the blind user experience on mobile device interaction. It is pointed out the applicability of method supported by expert reviewer, the observation technique, trial studies, validation and conformity verification with the Web Content Accessibility Guidelines."
3471;en_US;"​ Computer simulation of social phenomena are used in academic and non-academic context as tool for decision-aiding. By combining social scientific knowledge, computational power, and large data sets, those system may be involved in decisions that affect people who are not even aware of the existence of a simulation. This paper review topic from the philosophy of technology and computer ethics literatures in order to identify salient ethical issues related to computer simulation and the steps on the software design cycle on which they can be addressed, offering a checklist that can guide how the ethical concerns of stakeholders are listened to and incorporated into the proposed simulation system."
3473;en_US;"Software economics, acquisition, and pricing are important concerns, in particular for system-of-system (SoS). SoS are alliances of independent software-intensive system combined to offer holistic functionalities as a result of the constituents interoperability. SoS engineering involves separately acquiring constituents and combining them to form the SoS. Despite the existence of cost prediction technique at system Engineering practice, predicting SoS acquisition costs at design-time should include: 1) an analysis of the minimum set of constituents that offer a 'good enough' result, and 2) an analysis of the compatibility between the constituents to deliver the expected result. The main contribution of this paper is proposing a novel simulation-based method for cost prediction in constituents acquisition process, while considering the effectiveness of constituents combination to offer the intended functionalities, and predicting the lowest configuration, at design-time. We adopt a simulation model to predict, at design-time, the result that shall be yielded by the constituents during SoS operation. Preliminary result point out the success of our method to predict such costs while still supporting a selection of the best architectural configurations."
3474;en_US;"Despite the abundance of analysis technique to discover antipattern in BPEL, there is hardly any support for authorization constraint errors in web service orchestrated by BPEL4People. Most technique simply abstract from people (human user interaction), while people dependencies can be the source of all kinds of errors. This paper focuses on the discovery authorization constraint anti-pattern in web service orchestrated by BPEL4People. We present an analysis approach that is expressed in terms of rule card, the wellknown, stable, adaptable, and effective model-checking technique can be used to discover authorization constraint errors. Moreover, our approach enables a seamless integration of control-flow and authorization constraint verification."
3476;en_US;"This paper presents an initial theoretical essay aiming to generate reflections on the challenges related to the studies on social and human aspects in Software Engineering (SE). The focus of the discussion is based on the limitations that the SE community has in working on the frontier of knowledge with other area and how it affects the generation of scientific knowledge. Hence, an epistemological, methodological and theoretical competency model was proposed as a possible solution."
3478;en_US;"Hunger is currently a global problem, reaching 805 million people around the world and 3.4 million brazilians. This is a complex problem that will be eradicated with a better distribution of food and actions of governments and society. The FreeRice web game aims to combat hunger by converting virtual foods into real ones. This article proposes to implement the idea of FreeRice in a 3D virtual platform to help reduce hunger in Brazil."
3483;en_US;"The research project called Logicamente was created with the aim of teaching contents of computation focused on the guidelines of computational thinking for children and adolescents of basic education. Among the planned activity, it was idealized the realization of play workhops with the purpose of fixing contents work during the meetings. In this context, came the game CriptoLab that explores encryption in a disrupted computing environment. The present article consists in reporting the experiences about the application of the game in question that has as objective the crossing of a labyrinth whose course will be realized by means of assembly of logical sequences based on the commands of the application of MIT - Scratch."
3484;en_US;"The scientific logical reasoning became an important skill in the student cognitive development in algorithm teaching-learning process, stimulating their reasoning and creativity. From this perspective, gamification has been adopted as a mediating tool in this process. Studies report that the inclusion of gamification in algorithm teaching-learning process stimulates the student to develop new skills, making the knowledge more efficient. Therefore, this paper purpose is to measure and understand the cognitive development and the experiences lived by student at the addition of gamification in algorithm teaching, evaluating the scientific logical knowledge acquired by them. Consequently, 44 computer higher education student were selected. They were divided into two groups: student that used the Gamification-Mediated Algorithm Teaching Method and those who participated in the traditional teaching method. To evaluate the cognitive development between these two groups, the Scientific Logical Reasoning Test was applied. The result showed that a significant number of student that used the Gamification-Mediated Algorithm Teaching Method reached the transitory intermediary and transitory scientific knowledge levels, with greater right answer rates. We also noticed that both genders gave more right answers using the gamification-mediated algorithm teaching method."
3497;en_US;"This work presents the report of an interdisciplinary approach for teaching Software Engineering that involves four related disciplines: Software Engineering II, Software Architecture, Database system, and Object-Oriented Programming. The approach was conducted through an specific methodology in which student were grouped together and had to assume roles and responsibilities in the scope of each discipline. In addition, computational tool were used to support collaborative tasks and evaluation and monitoring mechanism were also included. This interdisciplinary approach was adopted in a Computer Science major course during 2015 and 2016. The result reveal positive impacts in motivation, as well as in learning aspects of the involved student."
3499;en_US;"The difficulties faced by lecturers and student in order to teach and learn programming on computer science course have been a research topic over the years. The hardship to understand the abstract and logic concepts and consequent demotivation has been resulting in high rates of novices failure and class abandonment. This study adopted statistical concepts to analyze student final grades in programming subjects and compare their performance. Data were gathered from a computer science course at a Brazilian University. The period analyzed was from 2010 to 2015 including six programming subjects from the first and second academic year. The result pointed a significant number of student failure (43%) and abandonment (25%). It was also discovered that even with different teachers, semesters and programming subjects, the student performance mean were nearly equal. The discoveries of this work contributed to point the hardship faced by student and teachers to learn and teach programming."
3502;en_US;"ion, automation, and complex problem solving.  Teaching programming is a common choice to introduce computational thinking  concepts.  When  learning  programming,  student  face  several  challenges,  problem  solving  and  debugging  among  them.  These  activity  are  central  to  the  concept  of  computational  thinking  [Fl​ó​rez,  Casallas,  Hern​á​ndez,  Reyes,  Restrepo  and  Danies  2017]. Previous research shows that teaching logic and programming to undergraduates  is a hard task [Bromwich, Masoodian and Rogers 2012] [Liu, Cheng and Huang 2011].  This finding lead us to believe that the earlier a person is accustomed with those abstract  concepts,  the  easier  it will be for her to learn and use that knowledge when necessary.  According  to  Piaget,  kids  of  age  approximately  seven  to  eleven  are  on  the  concrete  operational  stage [Piaget and Cook 1952], in which they already can construct abstract  ideas and logical structures on their mind.  Children  are  spending  more  time  than ever1 using mobile device. At the same  time,  it  is  becoming  common  practice  to  teach  children  a  very  basic  form  of  1 The Common Sense Census: Media use by kids age zero to eigth 2017 https://www.commonsensemedia.org/research/the-common-sense-census-media-use-by-kids-age-zero -to-eight-2017"
3503;en_US;"​ This paper presents an experience report of the active methodology “Teaching with Research” with the goal of improving the teching-learning process. The basic principles of this methodology were utilized as basis for the teaching planning for the Information system course in an informatics technician class. Two research project were elaborated as guiding elements of the teaching-learning process (according to the adopted methodology). As reflections regarding the methodology application experience, it could be noticed increased participation of the student during the class activity. The professor has a modified role towards the student: acting like an advisor, guiding the developed research activity inside the classroom. With respect to the learning evaluation method, it happened an increased valorization of the research path coursed by the student, mainly due to the methodologic organization of the proposed activity (based on the steps of scientific method)."
3508;en_US;"Augmented reality creates a bridge between virtual and real world, providing stimulating resource for different purposes. This technology enables new teaching possibilities since it can bring more abstract concepts into reality and put the knowledge related to several area, such as Software Engineering, into practice. MetricRA is a tool developed to help Software Engineering student to understand Cohesion and Coupling metrics. The solution was implemented with Augmented Reality technology, where the user can control a class diagram to observe the metrics transformation. This article describes MetricRA tool and presents a study conducted to evaluate its ability to contribute to the understanding of the concepts proposed."
3517;en_US;"The SBC Computer Science Curricula 2017 (RF-CC-17) arranges the competences and skills described in the National Curricular Guidelines for Computing Undergraduate course (DCN16) into axial competences. Also, it associates content topic to each axial competence. This essay presents a method to elaborate a Mapping of Compliance and Mobilization (MCM) as a part of a discipline program, based on RF-CC-17. As an example, the method is applied in the elaboration of two distinct programs of introduction to programming, one based on the imperative paradigm and another, object-oriented. Finally, it discusses the advantages of using the method to review pedagogical project of current course in compliance to the DCN16."
3527;en_US;"This research details an approach to deal with intelligent and adaptive exercise ordering, considering the student dynamic modeling in Computer Programming domain. Then is proposed a heuristic ordering process that indicates capabilities to be developed by the student, as also an adaptive exercise ordering that contributes in this evolution. Thus, overlaying aspects highlight the progress of the learner compared to the domain knowledge, and to the individual contribution of each exercise. The analysis of the result observed the didactic approach adherence, when comparing the exercises suggestions provided by the ordering process with others given by human tutors."
3539;en_US;"The Brazilian Olympiad of Informatics (OBI) mobilizes a large number of student in the country every year. In the competition named “Initiation”, the competitors solve logic problem without using the computer. In order to expand the alternatives for the preparation of the competitors in this modality, we developed ”Logic in a Logic Way”, a mobile application which supports the user in the use of a systematic method of solving textual problem of logic. In this article, we present the design, implementation and test of this application by tutors with experience in preparing student for OBI. The result indicate possible improvements to the application, which is available as an open source software."
3543;en_US;"The teaching of Computing in Brazil has been stimulated with specific activity, but it needs to be encouraged for its consolidation. In order to contribute to this proposal, this experience report presents result of activity carried out in an optional discipline of Robotics in a basic education school. Considering that Robotics allows the introduction of content of Computing and that the student are digital natives, the game was applied that consists of applying the principles of game design to the methodology of teaching. The result showed a significant improvement in the learning of the content worked in the discipline and expansion of social skills."
3544;en_US;"The process of building and sharing knowledge gained ground in academic research in the last decade, as more participative ways of learning became feasible. Difficult learning tasks, like learning how to program, can now count with technological support for more democratic ways of learning. In this article we present AlgPedia, a free encyclopedia about algorithm and programs in a wiki format. Algpedias goal is to serve information not only to humans but also to other programs. Regarding human usage, AlgPedias intent is to support and encourage the creation of collaborative content, besides helping the software developers community to find the best algorithmic solutions and the best suited implementations for their problem. Behind the wiki interface, the AlgPedia web platform supports a semantic database that can be accessed by intelligent non-human agent."
3557;en_US;"Deciding if a graph is Δ-edge-colourable (resp. (Δ + 1)-total colourable), although it is an NP-complete problem for graph in general, is polynomially solvable for interval graph of odd (resp. even) maximum degree Δ. An interesting superclass of the proper interval graph are the proper circular-arc graph, for which we suspect that Δ-edge-colourability is linear-time decidable. This work presents sufficient conditions for Δ-edge-colourability, (Δ + 1)-total colourability, and (Δ+2)-total colourability of proper circular-arc graph. Our proofs are constructive and yield polynomial-time algorithm."
3582;en_US;"Virtual environments such as online stores (e.g. Amazon, Google Play and Booking) adopt a collaborative strategy of evaluation and reputation, where user classify products and service. user opinion represents the satisfaction level of a rated item. The set of ratings of an item is a reference to its reputation/quality. Therefore, the automatic identification of a useratisfaction related to an item, considering its textual evaluation, is a tool with singular economic potential. With deep learning researches evolution in sentiment analysis based in aspects, opportunities to apply several neural network in this context arisen. However, the data representation model applied in these work focus only on Embeddings pre-trained network as a way to perform feature extraction. In this way, this work aims to present a comparison between data representation technique and deep network approaches, to analyze which of them have better result in classifying categories of aspects. Thus, we can seethat TF-IDF with a Convolution Neural Network (CNN) had an F1 measure of 0.93%, being at least 0.02% higher than the others approaches applied in this work."
3583;en_US;"Opinions shared over the Web constitute big volumes of data. Moreover, they may contain stances that are expressed directly or indirectly. Hence, stance detection may help to define the polarity related to a target idea. Here, we present the characterization of a broad set of tweets in Portuguese about the 2018 Brazilian presidential race. Such a set serves as the basis for automatic stance detection through a semi-supervised approach. In our evaluation, we find clues on the presence of bots in the network. We also evaluate three classifier with paired statistical test, and our result present F-Measure above 94%."
3591;en_US;"Facebook news feed personalization algorithm has a significant impact, on a daily basis, on the lifestyle, mood and opinion of millions of Internet user. Nonetheless, such algorithm lack transparency challenging researcher to improve their fairness and accountability. In this paper, we propose a model to capture the dynamics of contents over a timeline (also known as news feed). The input to our model is a fundamental quantity associated to timelines, which we show that can be easily parameterized using real world data: the arrival rate of posts of a given publisher followed by the user. Using real world Facebook traces from the latest elections in Italy, we validate the accuracy of the proposed model and use the model for conterfactual what-if analysis."
3599;en_US;"This work aims to compare the occurrence of negative emotion word in Brazilian broadcast news JN and JR, and also analyzes Twitter posts related to them. We use the Brazilian Portuguese version of LIWC dictionary, which is a Sentiment Analysis software. The result indicate that both JN and JR tend to use negative emotion word, but in JR this tendency is greater. Nevertheless, Twitter posts direct more criticisms towards JN than JR."
3601;en_US;"Disabilities are more related to a social context than to medical conditions. However, the lack of attention to the subject and social support negatively impacts the lives of people with disabilities and their relatives as well. In an exploratory study, it was perceived a trend towards the depreciation regarding this theme, instead of the construction of a support network. In light of these facts, this paper analyzed postings related to mental, physical and intellectual disabilities to identify the main topic discussed and the circumstances of use."
3605;en_US;"Performance benchmarking in Network Function Virtualization (NFV) pose challenging issues due to all moving parts of virtualized infrastructures potentially affecting the packet processing performance of Virtualized Network Functions (VNFs). Despite the advances in best-of-breed network virtualization technologies, the dependencies on the underlying allocated hardware resource, their characteristics and customized configurations, result in benchmarking hazards that call for innovative and standardized testing methodologies towards adequate VNF performance profiling. To this end, we designed and prototyped Gym, a testing framework for automated NFV performance benchmarking we experimentally validated on Open vSwitch as a target VNF. The design principles and implementation of Gym demonstrate an useful apparatus to assist standards organization formalizing VNF testing methodologies."
3623;en_US;"Strings are prevalent in Computer Science and algorithm for their efficient processing are fundamental in various application. The result introduced in this work contribute with theoretical improvements and practical advances in building full-text indexes. Our first contribution is an in-place algorithm that computes the Burrows-Wheeler transform and the longest common prefix (LCP) array. Our second contribution is the construction of the suffix array augmented with the LCP array in optimal time and space for strings from constant size alphabets. Our third contribution is a set of algorithm to construct full-text indexes for string collections in optimal theoretical bounds. This work is an extended abstract of the Ph.D. thesis of the first author."
3635;en_US;"In this dissertation, we evaluate I/O scheduling technique for the I/O forwarding layer of supercomputer. We demonstrate that existing algorithm that work to improve spatiality and request size of the access pattern are only partially effective. We propose TWINS, a new scheduling algorithm to coordinate the access of intermediate I/O node to the data servers. Our solution decreases concurrency at the latter, a factor proved to negatively affect performance. We are able to improve read performance from shared files by up to 28% over state-of-the-art scheduling algorithm and by up to 50% over not forwarding I/O. Our collaborations to the HPC field accounted for 16 paper and also motivated interaction with researcher from Argonne, BSC, INRIA, and LNCC."
3636;en_US;"Visualization method make use of interactive graphical representations embedded on a display area in order to enable data exploration and analysis. These typically rely on geometric primitives for representing data or building more sophisticated representations to assist the visual analysis process. One of the most challenging tasks in this context is to determinate an optimal layout of these primitives which turns out to be effective and informative. However, most technique are able to tackle just a few fundamental requirement simultaneously, impairing their use and flexibility. In this dissertation, we propose a set of approaches for building layouts from geometric primitives that concurrently addresses a wider range of requirement. A comprehensive set of quantitative comparisons against existing method for layout generation and application on multimedia data visualization prove the effectiveness of our approaches."
3637;en_US;"This paper presents our studies on three vertex coloring problem on graph and on a problem concerning subdivision of digraph. Given an arbitrarily colored graph G, the convex recoloring problem consists in finding a (re)coloring that minimizes the number of color changes and such that each color class induces a connected subgraph of G. This problem is motivated by its application in the study of phylogenetic trees in Bioinformatics. In the kfold coloring problem one wishes to cover the vertices of a graph by a minimum number of stable sets in such a way that every vertex is covered by at least k (possibly identical) sets. The proper orientation problem consists in orienting the edges of a graph so that adjacent vertices have different in-degrees and the maximum in-degree is minimized. Our contributions in these problem are in terms of algorithm, hardness, and polyhedral studies. Finally, we investigate a long-standing conjecture of Mader on subdivision of digraph: for every acyclic digraph H, there exists an integer f (H) such that every digraph with minimum out-degree at least f (H) contains a subdivision of H as a subdigraph. We give evidences for this conjecture by proving it holds for classes of acyclic digraph."
3638;en_US;"Measuring the (dis)similarity between time serie is the main procedure of several algorithm for mining this kind of data, which is ubiquitous in the day-by-day of human beings. While providing satisfactory result, similaritybased method usually suffer from a high time complexity. This work summarizes a thesis on developing algorithm that allow the similarity-based mining of temporal data in a large scale. The contributions of the thesis have implications in several data mining tasks, such as classification, clustering and motif discovery, as well as application in music data science."
3639;en_US;"method based on basis functions and similarity measures are widely used in machine learning and related fields. These method often take for granted that data is fully observed and are not equipped to handle incomplete data in an organic manner. This assumption is often flawed, as incomplete data is a fact in various domains such as medical diagnosis and sensor analytics. Therefore, one might find it useful to be able to estimate the value of these functions in the presence of partially observed data. In this work, we present methodologies to estimate the Gaussian Kernel, the Euclidean Distance, the Epanechnikov kernel and arbitrary basis functions in the presence of possibly incomplete feature vectors."
3641;en_US;"In recent years, probabilistic data structures have been extensively employed to handle large volumes of streaming data in a timely fashion. However, their use in algorithm on giant graph has been poorly explored. We introduce the concept of probabilistic implicit graph representation, which can represent large graph using much less memory asymptotically by allowing adjacency test to have a constant probability of false positives or false negatives. This is an extension from the concept of implicit graph representation, comprehensively studied by Muller and Spinrad. Based on that, we also introduce two novel representations using probabilistic data structures. The first uses Bloom filters to represent general graph with the same space complexity as the adjacency matrix (outperforming it however for sparse graph). The other uses MinHash to represent trees with lower space complexity than any deterministic implicit representation. Furthermore, we prove some theoretical limitations for the latter approach."
3642;en_US;"While Network Function Virtualization (NFV) is increasingly gaining momentum, with promising benefits of flexible service function deployment and reduced operations and management costs, there are several challenges that remain to be properly tackled, so that it can realize its full potential. One of these challenges, which has a significant impact on the NFV production chain, is effectively and (cost) efficiently deploying service functions, while ensuring that service level agreements are satisfied and making wise allocations of network resource. Despite recent research activity in the field, little has been done towards scalable and cost-efficient placement   chaining of virtual network functions (VNFs) - a key feature for the effective success of NFV. In this thesis, we approach VNF placement and chaining as an optimization problem in the context of Inter- and Intra-datacenter. We formalize the Virtual Network Function Placement and Chaining (VNFPC) problem and propose a mathematical model to solve it. Our model has established one of the first baseline comparison in the field of resource management in NFV and has been widely used in the recent literature. We also address scalability of VNFPC problem to solve large instances by proposing a novel fix-and-optimize-based heuristic algorithm for tackling it. Further, we extensively measure the performance limitations of realistic NFV deployments. Based on that, we propose an analytical model that accurately predict incurred operational costs. Then, we develop an optimal Intra-datacenter service chain deployment mechanism based on our cost model. Finally, we tackle the problem of monitoring service chains in NFV-based environments efficiently."
3643;en_US;"Random Forests (RF) are one of the most successful strategies for automated classification tasks. Motivated by the RF success, recently proposed RF-based classification approaches leverage the central RF idea of aggregating a large number of low-correlated trees, which are inherently parallelizable and provide exceptional generalization capabilities. In this context, this work brings several new contributions to this line of research. First, we propose a new RFbased strategy (BERT) that applies the boosting technique in bags of extremely randomized trees. Second, we empirically demonstrate that this new strategy, as well as the recently proposed BROOF and LazyNN RF classifier do complement each other, motivating us to stack them to produce an even more effective classifier. Up to our knowledge, this is the first strategy to effectively combine the three main ensemble strategies: stacking, bagging (the cornerstone of RFs) and boosting. Finally, we exploit the efficient and unbiased stacking strategy based on out-of-bag (OOB) sample to considerably speedup the very costly training process of the stacking procedure. Our experiment in several dataset covering two high-dimensional and noisy domains of topic and sentiment classification provide strong evidence in favor of the benefits of our RF-based solutions. We show that BERT is among the top performers in the vast majority of analyzed cases, while retaining the unique benefits of RF classifier (explainability, parallelization and easiness of parameterization)."
3644;en_US;"This paper describes the motivation, contributions and impact of the MSc. dissertation that proposes the first Similarity-aware Division ( ^ ) database operator. The novel operator is naturally well suited to answer query with an idea of “candidate elements and exigencies” to be performed on complex data from real application of high-impact, such as in agriculture, genetics, industrial production, digital libraries and enterprise management."
3645;en_US;"Emerging data source have been increasing the amount of available and useful data, which have a potential for revolutionizing entire business process and decisions in several scenarios, e.g., smart city. However, at the same time that these “big data” open further opportunities, the heterogeneity of their feature often hampers the integration and visualization of data. Therefore, this work presents an approach to handle heterogeneous geospatial big data for supporting a more informative decision-making. Study result advanced the state-of-the-art by understanding decision-makers requirement and developing innovative decision support system. These indeed provided valuable contributions to practice and research."
3646;en_US;"Underwater wireless sensor network (UWSNs) are emerging to enable large-scale ocean monitoring with the goal of reducing the human knowledge gap of underwater environments and the life underneath them. However, several challenges still limit the deployments of UWSNs to small-scale and confined underwater monitoring application. The goals of this thesis is to investigate and develop analytical model, algorithm and protocol in order to tackle the fundamental data communication challenge in the underwater environment, and advance the state-of-the-art towards feasible large-scale deployment of UWSN application."
3647;en_US;"Graphics application with visual quality and increasing levels of interactivity have been of fundamental interest. Within this context, visibility culling algorithm restrict the processing to the objects actually visible by the observer, speeding up the scene visualization. However, state-of-the-art solutions still require a high computational cost, do not scale in complex scenarios and are limited in generalization. In contrast, this work presents RHView, an innovative generic solution for static and dynamics scenes, which is based on a replicated space-partitioning structure and heuristics. RHView uses novel heuristics for rendering time estimation and balance between processing cost and triangle removal accuracy, while maintaining interactive frame rates, even in scenes with billions of triangles. It is the only solution currently available to reduce draw calls, one of the factors that have the greatest impact on graphics processing. Systematic tests have shown that RHView can be up to 2.8 times faster than the state-of-the-art algorithm."
3648;en_US;"Application-level caching has increasingly been adopted to improve the performance and scalability of web application. It consists of an additional caching layer that is manually added to the application code in selected locations. Because it requires a manual application analysis and selection of cacheable points as well as implementation, it is a time-consuming and error prone activity. In this paper, we introduce our key contributions in the context of application-level caching: (i) a comprehensive survey and taxonomy of work on this topic; (ii) a qualitative study that captures the state-of-practice of application-level caching, complemented by proposed guidelines and pattern; (iii) an adaptive component that autonomously manages admission of cache content; (iv) a framework that implements our proposal; and finally (v) an evaluation that provides evidence of the effectiveness of our proposal."
3667;en_US;"In this paper a methodology and a computer-aided diagnosis system for detection of breast cancer are proposed. The approach involves Image Processing resource to extract morphological feature from tumors in mammograms and Image Mining to classify them as benign or malignant. image from BCDR repository were used for the experiment. The result showed the efficacy of the proposed method and system, which reduced the false positive and false negative rates, and allowed a more efficient decision-making process."
3671;en_US;"Prematurity represents the determinant cause of infant mortality. This serious public health problem is directly related to the assistance provided during pregnancy and childbirth. Hence, this paper proposes the use of leading machine learning technique capable of supporting health experts in pattern recognition in the prediction of high-risk situations for the fetus. The proposed model creates an ensemble of nearest-neighbor classifier using the random subspace algorithm, reaching an overall accuracy of 0.937 and area under the curve of 0.721, in predicting the Apgar score, and 0.829 and 0.669 in predicting if the newborn will be small for gestational age, respectively. These result show the model effectiveness in reducing severe pregnancy related-problem."
3675;en_US;"It is a well-known fact that cognitive skills tend to decline in elderly people. There are several approaches that try to reduce the cognitive losses. One of the most prominent is cognitive training through serious game in several game sessions. This paper introduces a data model and a database for storing computer-based cognitive training data. Using this database, researcher have an integrated database that allows for extracting useful information that can be input for statistical analysis and further data mining tasks. In order to evaluate the feasibility of the proposed approach we have performed a statistical analysis on the evaluations of the ”Eye for Detail” game stored in the proposed database. result reinforced the potential of the database as a rich source of information."
3677;en_US;"The usage of Deep Learning technique has become even more frequent in medical research due to the possibilities that it offers to improve the quality of Clinical Decision Support. Several conventional prognostic model have been used in Intensive Care Units (ICU) to evaluate the risk of death. However, those model still cannot accurately predict that risk. For this reason, the aim of this article is to offer a model based on Deep Learning to predict the risk of mortality, especially in the fields of intensive care medicine, in order to make healthcare more efficient. The model consists of a Convolutional Neural Network that is divided into five stages, which contain nine hidden layers. In the proposed model we use quantitative method in its process. An experimental approach is given when comparing the predictive power of the proposed model to one of the most used model for predictions in ICU, the APACHE II. The data used were extracted from medical records available in the Multiparameter Intelligent Monitoring in Intensive Care III (MIMIC III) database. In order to evaluate the performance of the model, measures of accuracy, sensitivity, specificity and Area Under the ROC Curve (AUC) were used. After comparing the performance of the proposed model to the APACHE II, the proposed model presented positive result as it reached an AUC of more than 0,80, whereas the APACHE II reached an AUC of 0,71."
3680;en_US;"Melanoma is the most lethal type of skin cancer when compared to others, but patient have high recovery rates if the disease is discovered in its early stages. Several approaches to automatic detection and diagnosis have been explored by different authors. Training model with the existing data sets has been a difficult task due to the problem of imbalanced data. This work aims to evaluate the performance of machine learning algorithm combined with imbalanced learning technique, regarding the task of melanoma diagnosis. Preliminary result have shown that feature extracted with ResNet Convolutional Neural Network, along with Random Forest, achieved an improvement of sensibility of approximately 21%, after balancing the training data with Synthetic Minority Oversampling TEchnique (SMOTE) and Edited Nearest Neighbor (ENN) rule."
3681;en_US;"Lung cancer is the leading cause of cancer mortality, accounting for approximately 20% of all cancer-related deaths. Nevertheless, despite the development of new therapeutic agent and technologies, only 16% of lung cancer patient are diagnosed at early stages. Therefore, to diagnose in early stages, when the nodules are very small, is a complex task for specialists and presents some challenges. To assist the specialists, the main purpose of this work is to propose the use of Deep Learning to classify 25,200 small pulmonary nodules balanced with diameter 5-10mm. The result was of 0.992 (+/- 0.001) of area under ROC curve using 10-fold cross validation. The proposed method showed to be promising to assist the specialists in classification of small lung nodules."
3685;en_US;"Breast cancer (BC) is the most common cancer among women worldwide, approximately 20-25% of BCs are HER-2 positive. Analysis of HER-2 is fundamental to defining the appropriate therapy for patient with breast cancer. Inter-pathologist variability in the test result can affect diagnostic accuracy. The present study intends to propose an automatic scoring HER-2 algorithm. Based on color feature, the technique is fully-automated and avoids segmentation, showing a concordance higher than 90% with a pathologist in the experiment realized."
3687;en_US;"Glaucoma is an ocular disease that causes damage to the eyes optic nerve and successive narrowing of the visual field in affected patient which can lead the patient, in advanced stage, to blindness. This work presents a study on the use of Convolutional Neural network (CNNs) for the automatic diagnosis through eye fundus image. However, building a perfect CNN involves a lot of effort that in many situations is not always able to achieve satisfactory result. The objective of this work is to use a Genetic Algorithm (GA) to optimize CNNs architectures through evolution that can helps in glaucoma diagnosis using eyes fundus image from RIM-ONE-r2 dataset. Our partial result demonstrate satisfactory result after training the best individual chosen by GA with the achievement of an accuracy of 91%."
3701;en_US;"Medical image usually must have their region of interest (ROI) segmented as a first step in a pattern recognition procedure. Automatic segmentation of these image is an open issue. This paper presents an automated technique to define the ROI for infrared breast exams, based on the use of Fully Convolutional network (FCN). Adequate comparison among new approaches by using available databases is very important, here some comparisons with other technique are made. Moreover, concerning on line diagnosis, the comparison among possible technique must be efficient enough to be done in real time. With our approach the time to segment the ROI was 100 milliseconds and the average accuracy obtained was 95%."
3707;en_US;"Interstitial lung disease (ILD) involves several imaging pattern that are observed in high resolution computed tomography (HRCT). The automated tissue characterization is an essential component of a computer aided diagnostic (CAD) system for ILD research. Deep convolutional neural network learns feature directly from training data rather than extracting them manually, avoiding the need for feature extrator optimization. In this context, the present work investigate about a classification method using a deep learning program, in order to improve the performance of CAD system for the diagnosis of ILDs. Preliminary result achieved a general recognition rate of 74.9 % in the classification of the five classes of ILD refered in this study."
3712;en_US;"Healthcare involves complex decision making from planning to resource management. resource in hospitals are usually allocated by experienced managers, however, due to an inherent process complexity, decisions are surrounded by uncertainties, variabilities, and constraints. Information system must be robust enough to provide support to stakeholders, capable of controlling and support work flows. The present work explores the required synergy when combining business process with discrete event simulation. The objective is to estimate performance indices and address capacity management of a surgical center as a case study."
3730;en_US;"Smart decision support system (DSSs) have been successfully employed in several area. In healthcare, these system offer solutions for uncertain reliably acts and moments. system based on Bayesian network (BNs) can generate predictions even in information lack situations. This paper proposes the modeling and presents a performance evaluation study of the Bayesian classifier named Tree Augmented Na¨ıve Bayes (TAN). result show that the proposed algorithm obtained good performance for a pregnancy database, presenting F-measure 0.92, Kappa statistic 0.8932, and ROC area 0.993. The proposed method allows representing more complex connections between variables. Nevertheless, it requires major computational effort and time that are not needed in other Bayesian algorithm."
3860;en_US;"Software vendors are currently concerned to the development of software-intensive Information system (IS) that interoperate among them, especially in the web and mobile platforms. This phenomenon has raised the concept of System-of-Information system (SoIS), which is a set of interoperable ISs that exchange data and service to achieve some major business goal. The scientific community has explored human interaction, interface design and system development through a growing theoretical and applied research, pointing out sociotechnical challenges in the social web. Since new types of sociotechnical relations can be established to increase gains and productivity in this context, considering technical, business and social dimensions, software ecosystem (SECO) emerge from those SoIS. We claim that the SECO perspective can foster the comprehension about SoIS by exploring the existing relations among constituent ISs within a SoIS as well as the nature of such relations and the human aspects of those system. Thus, the aim of this paper is to introduce the concept of System-of-Information system Ecosystem (EcoSoIS) based on the existing background on IS, SoIS, and SECO, and how the Social Web and Interaction paradigms fit in this context."
3861;en_US;"Given the growing exchange of resource, artifacts and information based on a social web environment, the design and development of information system should ensure high levels of connectivity, communication and interaction. An analysis of technical, human and organizational factors can help researcher and practitioners to better specify, manage and evolve such system, especially in the context of software ecosystem (SECO), in which interoperability is relevant for technology and environment alignment as well as for allowing human interaction in the development of computational system. In this paper, we present an exploratory study about interoperability in the Integrated Water and Environmental resource Management System (SIGA) based on a segment established in politics and specifications of the Brazilian Electronic Government Interoperability Standard (ePING). We investigated whether and how technical, human and organizational factors that affect interoperability in a SECO are part of ePING, more specifically regarding the “Organization and Information Exchange” segment."
3862;en_US;"More and more company have opened up their software and system architectures to allow collaboration among internal and external developers and user who interact with software and system components, creating software ecosystem (SECO). In this context, social web environments (e.g., web portals) are critical for community creation and socio-technical network maintenance in the SECO context, in which there exist cooperation, communication and coordination mechanism supported by a SECO portal. However, a great challenge is how to ensure and assess transparency in such environments in order to provide developers and user with useful information for supporting their interaction with the platform. This paper aims to investigate which transparency characterists can be seen in SECO portals. To do so, an existing, generic transparency assessment questionaire for web sites was adapted and applied to two real cases of SECO portals (Apple Portal and Brazilian Public Software Portal). Auditability and informative were the most observed transparency charateristics in those portals. This result helped us to prepare an initial version of a transparency assessment questionnaire for SECO portals."
3863;en_US;"The growing use of mobile application (apps) presents a scenario in the Mobile Software Ecosystem (MSECO) with user who are increasingly demanding and attentive to new needs. These user interact on the social web through app evaluations they perform daily, and consequently produce large amounts of data, often unused. In this context, the difference in knowing information from app user evaluations (apps review) supports the needs of the target audience of these application. This work presents exploratory and initial research for extracting information from the most frequently used app review in different categories extracted from the Google Play app store. The objective is to know and analyze information from this type of data repository to support new knowledge about the interaction of user with regard to the service offered through the app. In this work, we analyzed 88,130 review application for the extraction of representative data and capable of presenting topic related to the service offered through the app in the context of this work. The result obtained show that there is evidence of information to be extracted and considered to better meet the user needs."
3864;en_US;"Scientific events bring together a large number of researcher and are composed of different types of sessions, which can cause an overload of attention and difficulty in deciding which sessions to participate. To lessen such problem, Recommender system can assist the user by offering options that are appropriate for each attendee. This paper presents a proposal for recommending sessions of academic/scientific events based on social elements. The recommendation are supported by the academic events co-authoring network to improve the quality of session recommendation based on the user previous publications. For authors/participant who do not have publications in previous editions of the corresponding event, the recommendation will be generated through the Collaborative Filtering approach."
3865;en_US;"The UX evaluation, using user´s text, has recently been performed by IHC researcher. However, they invite the user to write about their usage experience and then analyze their text in order to investigate the UX in the evaluated system. Although these evaluations investigate, from the identification of the context of use of the system to the identification of UX goals to evaluate a system, the spontaneous reporting of its user are unreasonable: the human values (personal and social) expressed in user text, and; their intention to report their use in the system. In this paper, an investigation is conducted to evaluate UX in 3,880 posts extracted from Twitter, considers user spontaneous experience reports, investigating: there is a relationship between the user intention to report their use in the system and the values expressed by them during an interaction? result of this paper showed there is a relationship between the user intention of emotion to post a message about the system and her/his values that can be important to the analysis of UX."
3866;en_US;"The online social network develop a great role on relationship visual representation, impacting on peoples interaction. Thus, it is essential that social network is accessible, so that every person with disability has access to the contents and interactivity in a equal way. Nevertheless, current researches only focus on measuring the bene ts during the interaction, leaving aside the identi cation and mitigation of accessibility problem. Therefore, this article identi es, through a systematic review, the existing correlation among the Web Content Accessibility Guidelines (WCAG) and social network, identifying the main di culties faced by disabled people. The review result prove that the di culties are related to content, loss of identity, navigability and accessibility. However, there is a lack of work that correlate to the guidelines applicability in the social network constructions."
3867;en_US;"Social network are now the main means of communication between people. user access them many times along the day and have their data stored in these system. If people are born and evolve in social network, their passing away should be addressed by these system as well. Terms of use and privacy policies are document that determine the relationship between user and digital service company. This paper reports the result from a qualitative analysis on how such document address issues of post-mortem digital legacy in the following social web platforms: Facebook, Pinterest, Instagram, Foursquare/Swarm, Linkedin, Whatsapp, and YouTube. In our comparative analysis, we highlight the different solutions adopted by these social network."
3868;en_US;"Currently, public and private institutions seeking to keep close to technological advances in terms of information and communication technologies. This perspective that the institutions are faced with the Social Web, an era where the relationship and communication over the Internet is one of the main goals. Assuming the mission of creating a bridge between the technological relations Social Media have subsidized much access of institutions to this web social universe. This paper’s objective is to present an overview of how Higher Education Institutions (HEI) has officially adopted the use of social media are behaving regarding aspects defended by Gene Smith in their hive of social media."
3869;en_US;"The collaborative virtual environments are an important category of CSCW system (groupware) and has become increasingly popular for supporting group work and development of a wide variety of application in different area. Currently, there is not a model to build these virtual environments taking into account the approach of the CSCW/groupware. This article proposes to create a framework and test it on a prototype in development. As a result presents the framework Groupware for Collaborative Virtual Environments (G4CVE). This framework is still incipient, but can now be used to direct the development of collaborative virtual environments."
3870;en_US;"The publication of reply in image on digital social network is increasingly commonplace. These image carry text, phrases, thoughts or subjective visual feature that may have meaning through context or user interpretation. This research provides a process for the extraction of semantic feature of image posted as comment and feeds in the online social network Facebook, and through the integration of Facebook GraphAPI and Google Search, create a model of recovery and treatment of meanings traits. The validation of assumptions and inferences of the research was conducted through case studies."
3871;en_US;"A task explored in social media searches is related to the attribution of meaning to the interaction that occur between these user within those system. This task is usually performed from the calculation and interpretation of statistical and / or graph-based measurements. In such a scenario there is a search for a descriptive model of how social interaction are occurring within the system, especially a model capable of detailing the actions performed by the user, the shared media, the application and the types of device used. In this work we present a method capable of guiding the application of a computational technique that allows the construction of software artifacts capable of rendering the representation, mining and measurement of social interaction feasible. The method is used to assess social interaction among Facebook user. As a result, we demonstrate the viability of the computation of the collective behavior of user of Online Social network from the application of the technique and use of the method. In a next step of the work, an assessment is made with potential user who have expressed their opinion about the method potentialities."
3872;en_US;"Hashtags are word or terms which are used to categorize publications in social media, indexing the content and making it available for retrieval. The hashtags creation is free process, i.e, there are no rule or restrictions to create them. Otherwise, there is a convergence of the terms used to explain and semantically enrich the content. This work aims to study the use of hashtags for the crowd to describe major events. The rise and acceptance of hashtags in major events related to politics, disasters, sports and entertainment were analyzed. Although the broad diversity, we identify some language pattern in the use of hashtags created by the population. Moreover, peculiarities were analyzed in each studied event."
3873;en_US;"Many information system have some embedded social interaction tool that allow user to interact with other. For instance, a review forum in an e-commerce system is an example of an interaction tool that can help user to share purchase experiences. Question and answer forums are another kind of tool where people can get helpful information to solve theirs problem. However, an important aspect to assure the usefulness of such tool is the motivation of the user to collaborate with others in such environments. In this paper, we investigate the application of motivation technique to enhance user participation in a virtual learning platform. Our case study uses a customized implementation of the Moodle platform (Moodle IMD) that is used by student in an Information Technology course. Our solution includes the introduction of rewards and recognition mechanism to motivate user. We have added reaction buttons to provide social recognition of activity and we also have implemented a ranking and a leaderboard to display how student participation are going in comparison with other ones. The partial result show that the student becomes more motivated to collaborate with their course partners. In a future study, we aim to evaluate how effective this collaboration is to improve learning."
3874;en_US;"Motivation is considered as an indispensable factor for carrying out any activity, and particularly learning. Also, it is believed that one way to encourage learning is the use of Digital game, especially Serious game as mediating tool of the teaching-learning process. Therefore, we carried out a literature search to identify different motivational theories described in the literature and their application to Digital game. This paper aims to highlight this relationship towards improving the teaching-learning process."
3875;en_US;"Although evidences show that there are many more bilingual and multilingual individuals in the world than there are monolingual, there are few software system that take advantage of this characteristic of their user. This short paper presents an exploratory research on designing interaction for multilingual user. Through the analysis of four websites, five design strategies are identified and corresponding hypotheses are formulated to be further investigated on future work."
3876;en_US;"The lack of mechanism made to check reliability of information on social network is evidenced by the spread of misinformation and rumors in this kind of system. Given this scenario, the provision of tool to assist user with information auditability on social network needs an emergencial approach. This article describes a catalog, followed by a guide of feature that provide auditability on social network. The guide contains guidelines for development of funcionalities in order to promote the adoption of auditability and enable user to identify false information and validate content on social network."
3877;en_US;"New approaches to study urban social behavior use Foursquare check-ins to represent user preferences. In this direction, recently, researcher have proposed a method for identifying cultural boundaries. Our study is based on that methodology, aiming to validate the result and to study some variations. We use a newer dataset to evaluate the result obtained previously. We found that the cultural separation result using our dataset agree with those presented previously. Furthermore, we evaluated the impact of the data observation window size in the result. Finally, we study two additional variations in the studied methodology. The cultural separation quality obtained using these variations is lower compared with the result obtained by the original approach. The result reinforce that, in fact, the methodology originally proposed might be useful to complement large-scale studies on cultural differences. Automatic identification of cultural differences is a valuable information that can enable the reaction of new ubiquitous application."
3878;en_US;"As Information and Communication Technologies (ICTs) permeate peoples interaction, designers face the challenge of creating new forms to promote contact among unrelated individuals and fostering the communication and potential support to leverage the sense of community in public spaces. This work is related to Urban Computing, studying the correlation among people, urban spaces and technologies. Our research is about observing and understanding the impact of ICT social support in a physical and social context. We developed an interactive application aiming at leveraging socialization in a public space inside a University Campus. Using an in-the-wild approach, our system brings some evidences showing to be efficient in supporting ways for people to socialize in situ and remotely."
3891;en_US;"The incorporation of computational technologies in daily life has leveraged issues related to the digital legacy, generating the need for specific application for this domain. This article aims to list the feature that are being contemplated by some of the application in the digital legacy area. To this end, eleven service of this domain were studied and grouped in four categories: inheritance management, memory, communicators and immortality online. When analyzing the functionalities of these service and other related issues, it was noticed that large company have suppressed some specific application of smaller company."
3892;en_US;"This article describes the working of memes in the Social Web that build stereotypes and image that people make of themselves. The theoretical-methodological approach of French Speech Analysis is used. Memes are collected in search result from Google, Google image and Facebook to build the search corpus. It is concluded that memes have discursive peculiarities in their internal structure and in their ensemble for a social group, that people can increasingly read message that are not intended for them and that humor acts for the intense circulation of this communication format."
3893;en_US;"This paper presents an evaluation of Personal Data Transparency performed in application known and used by a large number of user. Transparency seeks to provide information on how personal data are collected, used and shared between system and thus enable the individual producer to be knowledgeable and able to act within this process. The research was carried out with traditional user who evaluated the application policies and answered a questionnaire with 8 questions about aspects that should provide transparency. The result showed that some elements were considered transparent, but others, usually related to computational infrastructure, still require improvements."
3894;en_US;"In social entertainment network, comment and user tips are used to support other user in choosing a location from among the available options. Thus, these system rely on user engagement to aggregate a broad and diverse set of views. A low level of engagement means that tips and comment become outdated over time and are not representative of the current feature of the service offered. The objective of this work is to investigate the perception of user of social entertainment network on the opinions and opinions published and to identify the level of user engagement through the analysis of their interaction. To do this, we used an online questionnaire to capture the perceptions of user about the use of this type of application."
3895;en_US;"In Brazil, the process of industrialization of society has been accompanied by an exponential growth of the resident population in urban centers. Therefore, the need to move people and goods within city also increases, which can be defined as mobility in the urban context. This issue has fostered many studies that show the importance of developing actions that adequately address the issue of urban mobility, seeking to improve the quality of life in the city. Within this context, this research aims to develop an application for smartphone to provide accurate information about bus schedules for public transport in the city of Alagoinhas - BA - Brazil and consequently provide improvements in user experience. According to the data collected, MobiBus was able to alleviate the inconvenience caused by a long waiting time at the bus stop and made user feel more secure."
3896;en_US;"Sustainability is an updated research topic. In Computer Science, researcher especially from Human-Computer Interaction and Software Engineering area have started to focus on how to design and build more sustainable technologies and mainly how to build technologies that could help us to live in a more sustainable way. In this last sense, several solutions have been studied and developed to be used at home. The concept of sustainable houses is growing and generally relies on technological solutions which we should interact with. However, how human-centered aspects have been considered in these work? Which aspects of sustainability have been addressed? In this work, we present a critical view on the work found in literature and also a discussion about the research gap considering the design and evaluation methodologies for such technology."
3897;en_US;"The digital revolution of rapid technological rise and the high movement of urbanization are two factors that determine the transformation of the current society, which creates a scenario favorable to the phenomenon of intelligent city. One of the main objectives for the design of these city is that there is an improvement in the lives of citizens. In order to promote and sustain change behavior among citizens it is essential to recognize the use of gamification as persuasive technology. This article addresses a study based on the management of resource for intelligent city combined with the use of gamification where four articles were analyzed and from them a comparative analysis was elaborated. Keyword: smart city, sustainable city, gamification."
3898;en_US;"Scientific/Academic events promote the meeting of researcher for the dissemination of their work to the scientific community. These events are dynamic, sessions can happen simultaneously, and in this case participant may have difficulty choosing which sessions attend. Recommender system can aid the participant in this choice, as they use information from the sessions, participant and information about the participant social relationships. The goal of this work is to present the proposal of a Model of Social Recommendation for Scientific Events, which can be applicable to any type of scientific event. The model was partially implemented and was applied for the IHC 2017 event, for this, co-authoring relationships were considered. The instantiated model was evaluated through a questionnaire, where we evaluated user perceptions about the utility of coauthoring indication to recommend sessions."
3899;en_US;"A recent trend of small-to-medium enterprises (SME) is their close collaboration to create new products and reach new market niches. In this context, sustainability emerges as an important requirement of an ecosystem formed by company (actors), mainly thinking of its longevity and survival. In this paper, we modeled and analyzed a real case of an emerging SME software ecosystem (SECO) based on a system sustainability framework in order to model and analyze sustainability as a SECO requirement. We also applied a set of SECO factors to the produced model, considering existing relationships between actors. result demonstrate the importance of analyzing this requirement to assist an emerging SECO from the beginning, but also show the difficulty in treating sustainability as a requirement."
3900;en_US;"This article discusses the accessibility in the implementation of system for the Web and seeks to understand the reason why most system are still not very accessible. The work is inspired by Challenge 2 of the GrandIHC-BR, but also corroborates the sustainability aspects identified in challenge 1, especially in the social pillar. It is hypothesized that the main reasons for the low accessibility in system may include the teams lack of time, a supposed increase in the project budget, as well as the lack of knowledge and lack of interest on the part of the programmers. An exploratory research was conducted with programmers seeking to evaluate such hypothesis. These professionals reported on their experience and how to use accessibility resource in their project. The research pointed out that the lack of accessible system is caused, mainly, by the low knowledge of the programmers on the technique of accessible programming."
3901;en_US;"organization are giving greater attention to workers quality of life, seeking to implement measures related to health, safety and the environment. However, to implement these measures, it is necessary to follow standards defined by the Ministry of Labor. Due to the rigidity of standards and the amount of information needed to file in audits, company spend a lot of time and effort. In this context, EHS was proposed, a web system that integrates information on health, occupational safety and environmental process. The system aims to manage the information in a way that facilitates audits and helps management to take decisions and implement preventive measures in the company."
3902;en_US;"The current information revolution, highlighted by the constant use of smart device, smartwatches, tablets, among others, has boosted the continuous production of hThe current information revolution, highlighted by the constant use of smart device, smartwatches, tablets, among others, has boosted the continuous production of hardware and software, with direct operations in the environment, economy and society. What is perceived, however, is that there is no problem with issues related to sustainability in the development of these computational solutions. Inspired by GrandIHCBrs first challenge - Future, Smart city and Sustainability, this paper seeks to provide guidelines that support professionals in this area, and later on the sustainability aspects of their solutions. The work started from a survey of the literature and a consultation to the Computing Community in Brazil. The result allowed to know the state of the art and the tacit knowledge in the subject. One discussion also supported the choice of a reference model that was instantiated with the participation of five system analysts and three Computing researcher. Twenty-one guidelines were formalized and read the professional of industry and the university professor, both researcher, for appreciation. The result suggest that the guidelines raised can be applied to the guiding factors of sustainability for an evaluation of computational solutions."
4043;en_US;"Nowadays, video lectures are a very popular way to transmit knowledge, and because of that, there are many repositories with a large catalog of those video on web. Despite all benefits that this high availability of video lectures brings, some problem also emerge from this scenario. One of these problem is that, it is very dificult ifnd relevant content associate with those video. Many times, student must to watch the entire video lecture to find the point of interest and, sometimes, these points are not found. For that reason, the proposal of this masters project is to investigate and propose a novel framework based on early fusion of low and high-level audio feature enriched with external knowledge from open databases for automatic topic segmentation in video lectures. We have performed preliminary experiment in two sets of video lectures using the current state of our work. The obtained result were very satisfactory, which evidences the potential of our proposal."
4044;en_US;"technique in recommendation system generally focuses on recommending the most important item for a user. The purpose of this work is to generate recommendation focusing on long tail item, and then to conduct the user to less popular item. However, such item are of great relevance to the user. Two technique from the literature were applied in this study in a hybrid way. The first technique is through markov chains to calculate node similarity of a user item graph. The second technique applies clustering, where item are separated into distinct cluster: popular item (short tail) and non-popular item (long tail). Using the Movielens 100k database, we conducted an experiment to calculate the accuracy, diversity, and popularity of the recommended item. With our hybrid approach we were able to improve the recall by up to 27.97 % when compared to the markov chain-based algorithm, which indicates greater targeting to long tail products. At the same time the recommended item were more diversified and less popular, which indicates greater targeting to long tail products."
4045;en_US;"This paper presents a Spatial Keyword Preference Query (SKPQ) enhanced by Linked Open Data. This query selects objects based on the textual description of feature in their neighborhood. The spatial relationship between objects and feature is explored by the SKPQ using a Spatial Inverted Index. In our approach, the spatial relationship is explored using SPARQL. However, the main benefit of using SPARQL is obtained by measuring the textual relevance between feature description and user keyword. The object description in Linked Open Data is much richer than traditional spatial databases, which leads to a more precise similarity measure than the one employed in the traditional SKPQ. We present an enhanced SKPQ and two experimental evaluations of the proposed approach, comparing it with the traditional SKPQ. The first conducted experiment indicate a relative NDCG improvement of the proposed approach over the traditional SKPQ of 20% when using random query keyword. The second experiment shows that using real query keyword, our approach obtained a significant increase in the MAP score."
4046;en_US;"In this paper we present an ongoing research that aims to produce a model to predict success in the musical market. To reach this goal, it is necessary, initially, to identify influence factors in the market, which is the current focus of this research. In this branch, we identify that tweets have influence over the popularity of an album in Spotify. We also found out that Pop has more tendency to have the most popular song of a year, among other analyses. The next steps of this research are to list even more influence factors, generate the model using artificial neural network and validate it with real-world cases."
4047;en_US;"Mobile device user receive a lot of notifications per day. Some important notifications may be lost because of notification overloading. For some user, losing a notification can generate serious problem. This work proposes an Application Programming Interface (API) that uses context-awareness and machine learning to predict user attention to support mobile application developers and increases the chances of a important notification to be attended."
4048;en_US;"Cloud computing is maturing and becoming ubiquitous in peoples daily lives. As a result, cloud environments are providing more and more service with better quality of service. Cloud customers, however, have sufered from the vendor lock-in problem, in such a way that those who wish to migrate to another cloud provider require partial or total reimplementation of application and virtual infrastructure. Moreover, the problem of heterogeneity among distinct cloud environments makes it dificult for the portability of resource between them. Therefore, this work focuses on the development of an ontology to handle multi-cloud heterogeneity, and thus, bring interoperability in the form of a service to perform the portability of virtual machine between diferent provider."
4051;en_US;"This paper presents a Spatial Keyword Preference Query (SKPQ) enhanced by Linked Open Data. This query selects objects based on the textual description of feature in their neighborhood. The spatial relationship between objects and feature is explored by the SKPQ using a Spatial Inverted Index. In our approach, the spatial relationship is explored using SPARQL. However, the main beneﬁt of using SPARQL is obtained by measuring the textual relevance between feature’ description and user’s keyword. The object description in Linked Open Data is much richer than traditional spatial databases, which leads to a more precise similarity measure than the one employed in the traditional SKPQ. We present an enhanced SKPQ and two experimental evaluations of the proposed approach, comparing it with the traditional SKPQ. The ﬁrst conducted experiment indicate a relative NDCG improvement of the proposed approach over the traditional SKPQ of 20% when using random query keyword. The second experiment shows that using real query keyword, our approach obtained a signiﬁcant increase in the MAP score."
4052;en_US;"Cloud computing is maturing and becoming ubiquitous in people’s daily lives. As a result, cloud environments are providing moreand more service with better quality of service. Cloud customers, however, have suff ered from the vendor lock-in problem, in such a way that those who wish to migrate to another cloud provider require partial or total reimplementation of application and virtual infrastructure. Moreover, the problem of heterogeneity among distinct cloud environments makes it diffi cult for the portability of resource between them. Therefore, this work focuses on the development of an ontology to handle multi-cloud heterogeneity, and thus, bring interoperability in the form of a service to perform the portability of virtual machine between diff erent provider."
4053;en_US;"Nowadays, video lectures are a very popular way to transmit knowledge, and because of that, there are many repositories with a large catalog of those video on web. Despite all benefits that this high availability of video lectures brings, some problem also emerge from this scenario. One of these problem is that, it is very difficult find relevant content associate with those video. Many times, student must to watch the entire video lecture to find the point of interest and, sometimes, these points are not found. For that reason, the proposal of this master’s project is to investigate and propose a novel framework based on early fusion of low and high-level audio feature enriched with external knowledge from open databases for automatic topic segmentation in video lectures. We have performed preliminary experiment in two sets of video lectures using the current state of our work. The obtained result were very satisfactory, which evidences the potential of our proposal."
4054;en_US;"In this paper we present an ongoing research that aims to produce a model to predict success in the musical market. To reach this goal, it is necessary, initially, to identify infl uence factors in the market, which is the current focus of this research. In this branch, we identify that tweets have infl uence over the popularity of an album in Spotify. We also found out that Pop has more tendency to have the most popular song of a year, among other analyses. The next steps of this research are to list even more infl uence factors, generate the model using artifi cial neural network and validate it with real-world cases."
4055;en_US;"Social media is a very important tool for businesses, especially those that depend on marketing strategies for greater brand recognition. In addition, social media helps enrich the customer experience and reduce marketing expenses. Social media management allows company to get information that refl ects the overall consumer sentiment of their brand or their products, quickly and securely. However, such management is not an easy task, since the large amount of existing social media requires a lot of eff ort from professionals to deal with all the information that infl uences these social media. Therefore, a reasonable need is identifi ed in creating a specifi c tool to manage social media at once. In this article, we propose WALO, a new open source tool that allows professionals to use diff erent social media simultaneously, providing a new way for these professionals to interact with their clients through a chatbot."
4056;en_US;"Credibility information gives an indication of which user are most likely to share relevant image on social network feeds and consequently may help estimating the relevance of an image for retrieval purposes. Considering multiple credibilty evidences has be shown as an effective method for image ranking. In order to select and combine multiple credibility descriptors, this work proposes a genetic algorithm-based automatic context-adaptive weight adjustment model. The experimental result show promising effectiveness when compared to the baseline."
4057;en_US;"The Internet of Things (IoT) represents a new paradigm in the Internet history and in the way people interact with everyday objects. Academics and several industry segments have been working over the past years to make this vision possible. It is estimated that there will be dozens or hundreds of device simultaneously connected to the user’s network (e.g., in their home) in the next years, which can make the discovery and interaction with smart object more complicated to IoT user increasingly. This work proposes a smart objects discovery approach using image recognition, which aims to make this task quicker and more selective from an user perspective.  An initial assessment has shown that the proposed mechanism can reduce the discovery time in a scenario with several device, and additionally ensure a good level of user satisfaction."
4058;en_US;"Due to the popularity of smartphone and their built-in sensor, Context-Aware Mobile (CAM) application are on the rise. Some libraries and APIs help developers to create CAM application, such as the Google Awareness API. However, the initial configuration, the write of context-aware rule, and code readability persist being complex tasks, specially for beginner developers. This paper proposes an approach to ease the development of CAM application using Awareness API. Our proposal, called EasyContext, includes a Web Configurator and an Android Framework, which hides code complexity and the Awareness API configuration. A PoC using the EasyContext is also presented."
4059;en_US;"In this paper, we report our efforts to add support for data transmission through inaudible sound to the Ginga-NCL Digital TV middleware. We present an algorithm for encoding a bitstream in an inaudible audio signal, and to do so reliably on consumer-grade hardware. We also discuss two attempts to implement this algorithm in NCL, the language in which Ginga-NCL application are written. The first attempt was to transmit prerecorded inaudible audio signals in a Ginga-NCL-compatible set-top-box. And the second attempt was to use NCLua to generate at runtime the inaudible audio signal. For the second attempt we extended NCL with a novel media object type, called SigGen, which can be used to generate arbitrary audio signals. In the paper, we describe in detail the implementation of SigGen and the result of these attempts."
4061;en_US;"Currently, a set of technologies has been developed with the aim of reducing barriers to access to information for deaf people, such as machine tool for sign language. However, these technologies have some limitations related to the difficult of handling some specific grammatical aspects of the sign language, which can make the translations less fluent, and influence the deaf user experience. To address this problem, this study analyzes the machine translation of contents from Brazilian Portuguese (Pt-br) into Brazilian Sign Language (Libras) performed by three machine translators: ProDeaf, HandTalk and VLibras. More specifically, we performed an experiment with some Brazilian human interpreters that evaluate the treatment of some specific grammatical aspects in these three application. As a result, we observed a significant weakness in the evaluation regarding the adequacy treatment of homonymous word, denial adverbs and directional verbs in the translations performed by the application, which indicates the need for these tool to improve in the treatment of these grammatical aspects."
4062;en_US;"The development of Location Based Mobile game (LBMG) is a complex task. To overcome this problem, authoring tool have been proposed aimint at reducing the time and eff ort required to create these application. One of these tool is LAGARTo, a web authoring application to help non-programmers user to create multiplayer LBMGs with augmented reality feature. The first version of LAGARTo presented a usability level below end-user expectations. Therefore, this research proposes a new usability project for the LAGARTo editor to address its current problem. This document presents the result already obtained from a work in progress, with promising result of improvement in the usability of LAGARTo."
4063;en_US;"This  paper  reports  on  the  stages  of  identification  of  existing technologies that can be used to identify and rescue lost animals and  to  disseminate  animals  for  adoption  by  NGOs  of  Animal Protection,  Zoonoses  Center  and  Protective  Guards.  In  this article the developed phases of the Course Completion Work are presented.  For  this,  an  exploratory  research  was  carried  out initially, followed by a questionnaire seeking to identify which technologies  are  used  to  identify,  locate,  rescue  and  adopt domestic  animals.  The  current  technologies  found  were Microchip - RFID, Microchip - NFC, Collar with qrCode, Collar with Tag,  Search  application,  Identification  application,  Social network. In this way the research reports the main technologies used to date and is going to develop an application proposal to improve and expand the dissemination of pets that are lost or for adoption.  "
4064;en_US;"Internet of Things (IoT) is a paradigm that offers the user a novel and intelligent way of interacting with everyday objects. However, the complexity of an IoT scenario, involving the interaction among multiples device, user and service, represents a challenge for the evaluation of user experience (UX). Hence, to assist in the conduction of a more effective UX evaluation in an IoT environment, this paper presents a checklist that assists evaluators with different levels of experience to perform UX evaluation in the IoT scenario. Such tool was built based on three main steps: a literature review, the UX evaluation of an IoT application, and a questionnaire answered by IoT experts."
4065;en_US;"Public access to government information is an important aspect of modern society that allows an active participation of the population in monitoring government actions. Decree No. 8.777, signed on May 11, 2016, establishes the Open Data Policy of the Brazilian Federal Government. From this, the entities of the federal public administration, autarchic and foundational are obliged to make data available in open format. However, many of these institutions are failing to meet the commitments set out in the Decree. One possible explanation for this low number is the need for the technical team to have a good knowledge of their information system and current legislation, allied to the difficulty of extracting the data, since in most institutions the whole process of data extraction, processing and publication of open data is done manually. In this sense, this work presents the OpenData Processor, an automation tool for the process of extracting, publishing and updating open data that brings agility in the publication and periodical updating, saving time and facilitating the management of open data portals."
4066;en_US;"The planning and deployment of a WSN (Wireless Sensor Network)  in a Smart City can be a very challenging work. People involved in such implementation must be aware of how sensor and sinks may behave in the target environment. To aid the development of new WSNs, simulation tool are often used to predict how node will interact before spending time and money in a real deployment. Also, simulator can help student better understand WSNs. In this paper,  we present MobSink, a simulator for WSNs with multiple mobile sinks. MobSink also allows to perform simulation in a Smart City scenario, with streets and movements constraints. It also shows how to configure MobSink for a generic scenario and describes how it work internally."
4067;en_US;"FrameWeb (Framework-based Design Method for Web Engineering)  incorporates concepts from categories of framework commonly used in the development of Web-based Information system into design model, defining the syntax of such model with meta-model. Based on Model-Driven Development (MDD) technique, a CASE tool called FrameWeb Editor was built. In a separate eff ort, a code generation tool was proposed, but did not use the method’s MDD foundations. In this paper, we report on the integration of the code generator into the FrameWeb Editor and the FrameWeb meta-model."
4068;en_US;"Professional sports are increasingly dependents of technological resource given the remarkable level of competitiveness faced by high performance athletes. With such resource, it is possible to analyze matches, avoid mistakes that may be committed by the referee or even to analyze the athletes’ performance. One of these sports is beach volleyball, one of most popular sports in Brazil. In the past 12 years, the Brazilian volleyball teams has been always among the best teams in the world. The athletes’ performance during the jump movement is one of the main factors that one team needs to improve to be successful because it is the movement that is most performed during a volleyball match. There are some approaches that study the jump movement in order to calculate its height and give evidences to improve it. Nevertheless, these solutions are expensive and are not viable to athletes with no sponsorship.  Having this in mind, this work presents VolleyJump, an application created to analyze beach volleyball athlete jumps using machine learning strategies to calculate the jump height and classify it as an attack or block jump. result show that VolleyIoT makes possible to analyze athletes’ jumps using mobile device sensor, helping them to focus on their trainning to improve its technique."
4069;en_US;"The volume of information which contemporary student has access is huge, and they are surrounded by smartphone, tablets, internet and computer in an almost inseparable way from their daily life. Therefore, we think that it is important that school should consider the insertion of technological instruments in the classroom to attend the student’ interest in these device. One of the alternatives is combining Augmented Reality and mobile technology to enable the interaction with virtual objects by overlapping them with real environment. These technologies may become allied in the process of teaching and learning abstract concepts of various subjects. In this context, QuiRA is proposed to help the teaching of Chemistry, an ideal field to explore questions about the use of computer animation due to the difficulty of visualizing its concepts in two dimensions. This article discusses the details about the QuiRA application and the demonstration of its use for visualizing chemical molecules."
4070;en_US;"The presented tool is a fully virtualized videoconferencing MCU (Multipoint Control Unit) system using the standard SIP (Session Initiation Protocol). The proposed tool work in the cloud in a scalable way, with low deployment and maintenance costs. In addition, the proposed tool is more than an MCU, functioning as a universal framework for media forwarding."
4071;en_US;"This paper presents the Slim&Healthy system, focusing on the control of obesity in adults and aiming at the adoption of healthy habits. The system consists of two parts: a) an Android application on the client mobile device; b) an application on a server. The paper integrates different theories to increase user motivation, such as gamification, social network, design heuristics for mobile device and behavioral theories. It was performed an evaluation of the application interface through a questionnaire adherent to standards ISO 9241-11 and ABNT ISO/IEC 25062:2011, and the result are presented for discussion."
4072;en_US;"Serious game are presented as a very promising mechanism in many settings, such as education and health, however its application with the elderly is little verified. In order to reproduce in digital form the result of the elderly cognitive assessments, made and validated on paper, in this study a digital cognitive test tool, with the characteristics of a serious game, was developed using the Unified Design process. As conclusion, it is suggested that it is possible to achieve result similar to those obtained by validated and paper-based tests, from a game, adapted to the needs of the elderly, in a digital cognitive test format."
4073;en_US;"In this paper we present the ESPIM system, a set of tool that enables the authoring of intervention programs with focus on health and education. Created programs are played in a mobile app that generates screens on demand, according to their definition provided by JSON fi les. Using state-of-art technology we aim to provide a platform that can be used by professionals of health and education with no programming skills. To achieve that the system presents an intuitive authoring interface, built with requirement obtained with experts in diff erent area and with continuous feedback from evaluations, and a friendly mobile app, which presents elementsthat user are familiar and a good aesthetic design to motivate them. The system is being successfully used by professionals in health-related area and shows many advantages in comparison tosimilar platforms."
4074;en_US;"The Computer Science Course presents one of the highest dropouts rates among higher education course in Brazil. Besides that, it’s known that the algorithm discipline is the base of the knowledge learnt throughout the course and the first contact of student with computer programming. Having that said, the Ballgorithm was idealized to be a tool that includes a simple programming language and a ludical approach, making use of digital game visual elements. This paper aims to presente the development process of the Ballgorithm tool, the Ballcode language and the design decisions regarding to the system architecture."
4077;en_US;"Deep Learning research has allowed significant advancement of various segments of multimedia, especially in tasks related to speech processing, hearing and computational vision. However, some video service are still focused only on the traditional use of media (capture, storage, transmission and presentation). In this paper, we discuss our ongoing research towards a DLaS, i.e. Deep Learning as a Service. This way, we present the state of art in video classification and recognition. Then we propose the VideoRecognition as DLaS to support the tasks such as: image classification and video scenes,  object detection and facial recognition. We discuss the usage of the proposed service in the context of the video@RNP repository. Our main contributions consist on dicussussions over the state of art and it usage in nowdays multimedia service."
4078;en_US;"The usage of technologies for content authoring, storage, distribution and presentation supported the arise of Virtual Learning Environments (VLEs) such as Moodle and MOOCs (e.g., Udacity, Coursera, EdX). All student’ interaction in these environments can be stored in logs. For instance, video is one of the resource has a greater focus on VLEs. In this paper, we present a state-of-the-art overview of interaction analysis on video players. We noticed that teachers would like to know how and when student interact with video. In order to fill this gap, we propose VideoViz, a tool to analyse logs from interaction on video players."
4079;en_US;"The main goal of this article is to map and review real time video streaming collaborative software, in order to analyze platforms that are also able to edit films. Real time high resolution film transmission (4k, 8k or above) result in the excess of data generated and, consequently, in a high value for investment in editing, storage and content distribution feature. The retrieval and storage of the data (content) becomes complex and expensive. This article aims to design a software review for the use of system that are applicable to the needs directly related to the digital education field, considering that nowadays the video is an important tool to support teaching and learning process and needs a better structuring from the educational managers of communication and information technologies."
4080;en_US;"This work describes a system focused on interactive audiovisual experiences developed for the State of Paraíba Court of Auditors (TCE-PB). The system includes professional and amateur productions to enable social control using multimedia technologies. As a result, the video collaboration solution, based on the Audiovisual Design model, is presented."
4081;en_US;"This paper presents the Multipresence system with a focus on its uses for eHealth. The Multipresence system performs multi-technology videoconferencing, that is, it allows the interoperation of various technologies and device such as: Telepresence rooms in high definition (until Full-HD); Ultra-telepresence room (4K); Sharing of content (image, text, application); Legacy videoconferencing system (SIP standard); software application installed on the personal computer; Web conferencing (via web browser); Mobile device and SIP phones. UFRGS University work in the coordination of the technological development of the Working Group GT-Multipresença in partnership with RNP (National Research and Education Network) and with Mconf Tecnologia Ltda. The project is in its fourth year of development, with functional prototypes very stable, and already been used for transmission and interaction in robotic surgeries. The objective of this article is to disseminate this technology as a driving force in the creation of video collaboration panels and integration within and between countries, in the educational or e-Health area."
4093;en_US;"This work describes a family of binary Edwards curves that admits modular reductions (an operation that can be responsible for up to 30% of the processing time in point arithmetic) twice as fast than the best usual settings, while essentially being as secure as a binary elliptic curve can be (in terms of being rigid and twist-safe). Moreover, we present a hardware architecture with a generic VHDL description that can be synthesized to any FPGA with enough area to support the circuit. For this architecture, we are able to execute a point multiplication by scalar on F562 in 2.28ms on Cyclone 4 GX, in 1.23ms on Virtex7 and in 1.01ms on Zynq7020."
4094;en_US;"Malicious software (malware) are persistent threats to modern computer system and the development of countermeasures to them becomes harder each day due to the emergence of anti-analysis and anti-forensics technique, able to evade software-based monitoring solutions. In this scenario, hardwareaisted solutions are effective alternatives, but still present development gaps. The presented dissertation surveyed the limits of software-based solutions, pinpointed the existing development gaps on hardware-assisted solutions and introduced a lightweight, hardware-based alternative for malware analysis. The developed framework was released as open-source and is being used on further research developments."
4095;en_US;"In 2016, a reaction attack on the QC-MDPC McEliece scheme was presented at Asiacrypt by Guo et al.. This attack exploits one aspect that was not considered in the schemes security reduction: the probability of a decoding failure to occur is lower when the secret key and the error used for encryption share certain properties, which were called spectrums. By detecting decoding failures, the attacker can obtain information on the spectrum of the secret key and then use this information to reconstruct the key. To improve the efficiency of the attack, we propose two different key reconstruction algorithm that are more efficient and use less information on the secret key than Guos et al. one. Furthermore, both algorithm can be trivially parallelized."
4096;en_US;"This paper describes a symmetrical block cipher tailored to be used on Internet of Things (IoT) environment. It was engineered to be lightweight, consuming less computational resource than other ciphers, like AES, and to work with different block and key sizes. Other important characteristic is to integrate the authentication on its basic algorithm. This approach is helps to reduce the resource needs. The algorithm capacity to resist against linear and different cryptanalysis attacks and to generate was verified. The algorithm was also compared to 23 other ciphers implementations using the metrics generated by the FELICS (DINU et al., 2015) framework. The cipher randomness was also analyzed, using statistical tests."
4097;en_US;"This thesis contributes to the state-of-the-art in virtual organization (VO) management, proposing a new framework that facilitates both the ingress of institutions into a VO and the creation of a new VO, collaborating to solve important problem in identity and access management. Beyond to propose a framework - introducing its specification, documentation and implementation - this proposal allows the management and integration of a VO to widely distributed identity and access management solutions, such as identity federations and concepts of access control based on attributes. The framework supports several authentication method, allows to manage specific attributes of each VO, performs the credential translation and provides access control in resource level using distributed policies. In addition, it is generic in terms of shared resource characteristics by VO. Another contribution of this work is to assist institutions to ingress in any VO - regardless of its particular characteristics, such as specific types of credentials or resource management message."
4099;en_US;"In this thesis, we developed a method that exploits the random-like properties of chaotic system as a pseudo-random number generator (PRNG). We explored the k-digits to the right of the decimal separator (less significant digits) of an original orbit of a chaotic map. This approach called as “deepzoom” demonstrated the relationship between the parameter k and the quality of the pseudo-random sequences, since it showed a rapid transition from “weak to strong” randomness as k tends to infinity, thus allowing to manipulate pseudorandomness in a parametrically manner."
4100;en_US;"This work investigates efficient and secure implementations of Curve25519 to build a key exchange protocol on an ARM Cortex-M4 microcontroller, along with the related signature scheme Ed25519 and a digital signature scheme proposal called qDSA. As result, performance-critical operations, such as modular multiplication, are greatly optimized; in this particular case, a 50% speedup is achieved, impacting the performance of higher-level protocol."
4167;en_US;"Human economic behavior arises from primal instincts for survival and, despite our higher aspirations, it seems we just can't escape this fact. History shows that ideologically inspired experiment in egalitarian economic system have always stalled or utterly failed. Nevertheless, after the financial market crash of 2008, many tech entrepreneurs were bewitched with the captivating and viral idea that technology could eradicate the barriers between individuals who wanted to share the resource they had. This led to the sudden much-hyped explosion of so-called sharing economy marketplace start-ups around 2010. However, research that I led showed that idealistic entrepreneurs misunderstood or forgot the basics of human economic behavior and my teams findings predicted the demise of all but the company that were able to compete on classical economic terms (better value for money). I joined one such company, Lyft, because I shared the founders vision for more sustainable transportation. Nevertheless, Lyft and the other rideshare and disruptive transportation company must all compete fiercely to survive. Its a challenging road ahead, with many obstacles to overcome, but the destination is one I remain deeply committed to; I am still an idealist at heart!"
4168;en_US;"With the rise of ubiquitous technology, data-driven design and the Internet of Things, our interaction and our interface with technology will look radically different in the years ahead, incorporating changes like full body interaction, shape-changing interface, wearables and movement tracking apps. These changes offer an enormous opportunityindeed, a necessity-to reinvent the way we interact with the inanimate world. Once-familiar, everyday objects, from our phones to our vacuums, require novel interaction model not just typing text on screens, but, increasingly, movementbased, bodily communication. A qualitative shift is required in our design method, from a predominantly symbolic, language-oriented design stance, to an experiential, felt, aesthetic stance permeating the whole design and use cycle."
4170;en_US;"It has been 20 years since we have organized the first edition of IHC in 1998. So much has changed regarding not only technology, but also how it is inserted in our society. During this time, technology and people´s interaction with it have become ubiquitous and part of our everyday lives mediating many (if not most) of our ordinary activity from communicating with other people, to work, entertainment and Government service. As professionals who generate technology, this change has also raised our awareness, concern and attitude towards the social responsibility and ethics involved with developing technology and its use by society. In this panel, we discuss how social responsibility and ethics have changed and what is our role, as professionals, going forward."
4173;en_US;"Narrative visualization is an emerging data visualization field and has been used for the purpose of communicating information efficiently and intuitively as well as providing greater engagement in data exploration. In this mini-course, we will present and discuss fundamental concepts for interactive narrative visualizations design, and explore these concepts - in theory, and practice - by means of a model that aims to enable reflection on decisions to be taken in narrative visualization’s design."
4177;en_US;"Gamification is the use of game elements in context which the main purpose is not playful and it has been widely applied in order to motivate and engage user [5][11]. However, since each user has different characteristics, the user experience during the interaction with these game elements becomes singular and it does not always have the expected outcome. Many studies point out the influence of user profile on the effectiveness of gamification in relation to the purpose of its application [1][2][4][3][6][7][9], but surprisingly little has been explored about the process of design, development and evaluation of the user-centered gamification to promote a better user experience and, consequently, a greater motivation and engagement [8]. Thus, this course aims to cover personal, functional, psychological, temporal, playful, implementable and evaluative properties of gamification in order to enable the participant to design, develop and evaluate a user-centered gamification, while allowing the improvement of the gamification result. For this, the methodology to be employed by this course involves two parts: theoretical and practical. In the theoretical part, the exposition of concepts related to gamification will be carried out, followed by examples, in an interactive way with the participant. In the second part, participant will be invited to bring examples of scenarios that they would like to work on and the concepts presented will be put into practice so that the public can participate and share their experiences while designing the usercentered gamification."
4179;en_US;"The decision-making process behind the exploitation of petroleum fields requires deciding the best strategies considering the large investments at stake. Software used to simulate and manage petroleum reservoirs, such as MERO, requires an interactive environment to deal with the massive data and numerous parameters that surround the simulation. However, due to the nature of scientific software development, usability was not taken as a specific goal for MERO. In this investigation, we have carried out an user-centered approach to identify usability issues regarding MERO’s interface. We conducted semi-structured interviews with user and analyzed the content of emails sent by user to the support team. This research identified that despite the massive data, most of the issues that user have to deal with the software are related to error message and inadequate documentation."
4182;en_US;"Banking system have been a frequent concern between customers and company, since the number of financial transactions carried out by the Internet has increased considerably. This study investigated the experience of internet banking user of a Brazilian bank. technique such as interviews, access log analysis, user journeys and usability testing were applied to identify the elements of the user experience using a generic model. From the studies carried out, it was verified that the characteristic user of the service had difficulty or are unable to use all the essential service of internet banking and are necessary design improvements of current interface."
4183;en_US;"Using the usability principles brings benefits in the dissemination of information in web environments improving user cognitive process and linked to responsive web technique forming interface with clearer and more effective interactivity. This paper describes the interlinkages between concepts that corroborate with the previous statement, through the redesign of the site frontend for the masters degree program GESTEC (locus of development of this research). Methodologically, applied research is used with a research-action approach for evaluation and result generation. At the end of the process of construction of the site, considering the criteria and subsidiary parameters, it is noticed that the new layout enhances the interaction characteristics for the user, simplifying access to information."
4185;en_US;"Computer mice and keyboards have for long been the dominant input device for desktop computer. Nonetheless, they still represent quite a barrier — especially for people whose upper-limb motor skills are compromised. This work proposes a low-cost, mouth-puffing-based device that is able to perform the mouse click on computational platforms. Additionally, a driver was developed to allow the device to communicate with the computer via audio jack P2 interface. The mouse cursor is controlled by head tracking thanks to eViacam software. The evaluation took place by comparing the proposed equipment with the dwell time method on navigation tasks elaborated over websites."
4189;en_US;"Colors make some aspects of business process model understandability easier. Although paper confirm this claim, they did not deal with color-blind people. Some notations even prohibit the use of colors. Accessibility studies have demonstrated safe colors, enabling wide understandability. This work proposes the use of safe colors for graphic process represented in Citizen language, improving its mandatory transparency."
4194;en_US;"Our current project involves the use of a multistage research method to specify a guideline for mobile application, which intends to support visually impaired user. This paper discusses the employment of this guideline along the development of a mobile application for personal financial management. Such application was evaluated by a group of visually impaired volunteers and the evaluation result were used as a source of insights to refine the guideline and its requirement. Qualitative interviews show that the guideline ensures a higher level of usability when compared to previous experiences of volunteers with other application. Thus, such outcomes confirm the guideline potential as a resource to support the development of a brand new set of accessible application.3-Our current project involves the use of a multistage research method to specify a guideline for mobile application, which intends to support visually impaired user. This paper discusses the employment of this guideline along the development of a mobile application for personal financial management. Such application was evaluated by a group of visually impaired volunteers and the evaluation result were used as a source of insights to refine the guideline and its requirement. Qualitative interviews show that the guideline ensures a higher level of usability when compared to previous experiences of volunteers with other application. Thus, such outcomes confirm the guideline potential as a resource to support the development of a brand new set of accessible application."
4197;en_US;"The experience which emerges from digital game has, above all, an emotional nature, so evaluating the user experience only through objective factors does not seem to be sufficient for the analysis of a game as it is an entertainment product. This article intends to propose a set of metrics that allow evaluating affective, or roughly speaking, emotional aspects of the user experience from digital game. The metrics are applied to a list, found in a related work, of relevant game design components that affect the subjective experience of gaming. The intended experiment in the future is a gameplay session of a game especially designed to include a system that measures in background, through the proposed metrics, players’ actions in the gaming experience. The result in this paper is a set of quantitative and qualitative metrics that will assess players’ choices in the actual experiment and that yield numerical outcomes, even though the analyzed factors are subjective."
4201;en_US;"Studying and applying Human-Computer Interaction (HCI) concepts on Software Engineering (SE) programs is meaningful when society demands more useful, accessible and pleasant software application to be made. However, teaching HCI is perceived as a challenging task in an interdisciplinary aspect. Therefore, this study aims to understand what Brazilian SE undergraduate student are being taught on HCI course. In order to accomplish it, we applied a content analysis methodology on 21 distinct syllabi from 15 universities, which resulted on the categorization of 28 teaching topic. The outcome of this work allow us to visualize the most HCI concepts seen on Brazilian SE programs: Design, Interaction Styles & Paradigms, System Evaluation, and Usability. Moreover, we presented discussions related to the HCI knowledge being offered on SE undergraduate programs."
4207;en_US;"This article describes a teaching experience by using STS (Science, Technology and Society) approach in the HCI (Human-Computer Interaction). The experience was carried out in classes about the use of colors in interface design. It aimed at observing student´ perceptions about the use of STS approach in HCI and its impacts on the course of Project of Information system. The methodology used in the experiment was to organize the content (colors and STS) within a didactic sequence of six classes. In this sequence, class themes, pedagogical strategies, aims and content were defined. result showed more interaction between student and lecture in HCI and more student’ interest on using an appropriated code of colors in interface design in the course of Project of Information system. It was concluded that engaging methodologies such as STS approach are important and can impact positively for teaching-learning process of student in Software Engineering."
4208;en_US;"The goal of this paper is to present a brief report of the Human-Machine Interface course’ conduction, technique used and some result delivered by student. The theme of application during the semester was “Engaged Communities”, according to the Call for Design Competition for student of CHI’18. From competition’s instructions, we simulated Design Sprint sections, during one semester, as a strategy to organize design proposals and learning assessment."
4209;en_US;"Interactive system are increasingly present in people’s daily lives, generating new demands for interface and interaction. Examples of demands are those derived from human values, such as: gender identity, privacy, and the need for system to provide explanations to the people who use them. Therefore, to be successful, professionals working in the area of HumanComputer Interaction (HCI) need to be increasingly sensitive to these values. Unfortunately, there are still few pedagogical resource to help HCI student develop such sensitivity. Seeking to contribute to the solution of this problem, in this work, it is proposed and analyzed the use of the pedagogical strategy denominated Structured Debate. Based on the pedagogies of active learning and collaborative learning, Structured Debate follows three phases: 1) pre-debate phase, which consists of preparing for the debate by reading reference text; 2) execution of the debate in the classroom through a structure of questions, answers, considerations and movements in the room; and, 3) post-debate phase, when the effects of the debate are observed and contextualized in new contents of the discipline. We discuss experiences of the use of the strategy in five classes of the discipline HCI in two bachelor undergraduate course: Information system and Software Engineering. The result suggest that Structured Debate stimulates and engages student with HCI topic about human values."
4215;en_US;"Integrated Project is a type of course offered in the Digital Design program of the Federal University of Ceará, Quixadá Campus. It has the challenge of integrating into a single project some concepts from the area of Computer Science, Design, Communication and Arts. For the interdisciplinarity to be productive, it was specified PD3 (Digital Disruptive Design Process), a design process based on HCI, Design, and Software Engineering methodologies. In this paper, we present the PD3 applied to the Integrated Project course, describing how it has been used and evolved, as well as giving lessons learned."
4217;en_US;"IHCs interdisciplinarity teaching solutions generally focus on supporting teachers to plan classes and organise didactic content. Given this context, some studies show that in the algorithm ' disciplines of a computational course there is a logical complexity that requires more attention. In this perspective, we perceive the need to support those involved to implant the interdisciplinarity of IHC in a course that had algorithm discipline. Thus, this article defines and describes a strategy that describes the key elements and activity for such deployment and evaluation. To do so, a case study was carried out to analyze the difficulties in a course for the student of the algorithm discipline to analyze and correct an example with usability error, verified through a heuristic inspection."
4222;en_US;"In this paper I briefly describe my ongoing PhD work. Together with a rural community in the Brazilian Amazon I study their use pattern of internet application and jointly improve the technical internet infrastructure in this remote area. My work serves to support their desire for increased resilience, and sheds light on how the culture of a technology and the culture of its recipients meet and how process of adaption can be supported by HCI researcher."
4226;en_US;"This paper summarizes the proposal and validation of a Checklist for Usability Evaluation of Multimodal game for Children who are Blind (CLUE). CLUE was designed to assist researcher and practitioners in usability evaluation field studies involving people who are blind, addressing multiple aspects of gameplay and multimodality, including audio, graphics, and haptics. Overall, initial evidence indicates that the use of CLUE during user observation helps to raise a greater number of relevant usability issues than other method such as interview and questionnaire."
4229;en_US;"This research analyzes how user that are also HCI designers behave in the interaction with digital memorials linked to graves through QRCodes. We carried out an immersive practice in the Consolação Cemetery (São Paulo, Brazil), where QRCodes are used to tag graves of famous deceased people and to guide the visitors in the site. The QRCode tags link the graves to an online application for digital memorials called MemoriAll. This paper presents an overview of the study and its main result, promoting discussion on the topic."
4231;en_US;"This paper summarizes the proposal and validation of the Standard List of Usability problem (SLUP), a categorized list of typical problem affecting the interaction of people who are blind with audio- and haptic-based multimodal video game. SLUP can help designers to avoid recurrent usability issues in the design of multimodal game for user who are blind. Besides, evidence decurrent from user tests showed that SLUP may be further expanded and used as a ground to develop specific usability evaluation instruments."
4232;en_US;"The Augmentative and Alternative Communication (AAC) is one of the strategies to deal with communication problem. The AAC exploits more than one communication channel for sending message, but it not guarantee that communication will happen. This research presents aims to promote the communication and social inclusion of children with intellectual disability through the evolution of an augmentative and alternative communication system. This research also aims to support the communication of deaf people and user of Libras by means of collaborative and mobile computing tool."
4233;en_US;"This paper presents an investigation that has been developed at the Federal University of Amazonas through project involving concepts of collaborative system(CS) and humancomputer interaction (HCI) in artistic-cultural and entertainment events scenarios. In the artistic scene, there have been project involving music and interaction through sounds. In the scenario of large entertainment events involving crowds, the project consider issues such as engagement, interaction and collaboration. In these unconventional context the importance of the integration between the SC and IHC area is observed in order to achieve relevant result to change the behavior of the audience aiming at an active, participatory and interactive attitude in the field of the arts and entertainment for the crowds."
4399;en_US;"Automatic short answer grading is the study field that addresses the assessment of student’ answers to questions in natural language. The grading of the answers is generally seen as a typical classification supervised learning. To stimulate research in the field, two dataset were publicly released in the SemEval 2013 competition task “Student Response Analysis”. Since then, some work have been developed to improve the result. In this context, the goal of this work is to tackle such task by implementing lessons learned from the literature in an effective way and report result for both dataset and all of its scenarios. The proposed method obtained better result in most scenarios of the competition task and, therefore, higher overall scores when compared to recent work."
4400;en_US;"This paper proposes an algorithm for controlled natural language processing using a Moore Machine. Initially, a brief description of the concepts involved, such as chatterbot, automata, and ontology, will be presented. Then, an algorithm for controlled and expandable natural language processing will be presented. The algorithm work as a translator that transforms the sentence in natural language informed into executable code to a stack-based virtual machine, executing the processing according to the knowledge stored in the automaton."
4401;en_US;"This paper presents an approach that uses topic model based on LDA to represent document in text categorization problem. The document representation is achieved through the cosine similarity between document embeddings and embeddings of topic word, creating a Bag-of-topic (BoT) variant. The performance of this approach is compared against those of two other representations: BoW (Bag-of-word) and Topic Model, both based on standard tf-idf. Also, to reveal the effect of the classifier, we compared the performance of the nonlinear classifier SVM against that of the linear classifier Naive Bayes, taken as baseline. To evaluate the approach we use two bases, one multi-label (RCV-1) and another single-label (20 Newsgroup). The model presents significant result with low dimensionality when compared to the state of the art."
4402;en_US;"Breast cancer has been a growing problem for women around the world. The correct interpretation of mammographic image is important for the diagnosis of breast cancer. However, this is a difficult task even for a specialist. Image processing is used to make the diagnosis less susceptible to errors. Thus, the present work proposes a new method for the search of lesion candidates in mammographic image. To verify the efficiency of the approach, the behavior of the SURF, SIFT, BRISK and ORB algorithm were analyzed, as well as the Selective Search algorithm for candidate selection. A total of 1210 mammography image were used, from the CBIS-DDSM database. result show that the SURF algorithm presented better performance, generating on average, for each image, 4.11 candidates considered in the internal area of the lesion, reducing exploratory space by 72%, whereas the ORB generated on average 1.6 candidates with a reduction rate of 96.30%.
"
4403;en_US;"Human faces convey a collection of information, such as gender, identity, and emotional states. Therefore, understanding the differences between volunteers’ eye movements on benchmark tests of face recognition and perception can explicitly indicate the most discriminating regions to improve performance in this visual cognitive task. The aim of this work is to qualify and classify these eye strategies using multivariate statistics and machine learning technique, achieving up to 94.8% accuracy. Our experimental result show that volunteers have focused their visual attention, on average, at the eyes, but those with superior performance in the tests carried out have looked at the nose region more closely."
4404;en_US;"Automatic plant species identification is a difficulty challenge for botanical taxonomy field. Many work have been proposed towards the development of automatic plant species recognition system through machine learning method. One of the most popular algorithm for plant classification is the k-Nearest Neighbor (k-NN), given its simplicity and robustness. In this work, we evaluate the performance of two improved weighted k-NN algorithm when dealing with plant classification task. Experimental evaluation includes three real-world data sets obtained from different image processing and feature extraction process. Also, a statistical hypothesis test is employed to perform an overall evaluation of the selected model."
4405;en_US;"Associative classification, which has been widely used in several domains, aims to obtain a predictive model in which the process is based on the extraction of association rule. Model generation occurs in steps, one of them aimed at ordering and pruning a set of rule. Regarding ordering, one of the solutions is to rank the rule by means of objective measures (OMs). The ordering criterion impacts the accuracy of the classifier. In the literature’s work the measures are explored individually. Based on the exposed, this work aims to explore the aggregation of measures, in which several OMs are considered at the same time, in the context of associative classifier."
4406;en_US;"Deep Learning is a research area under the spotlight in recent years due to its successful application to many domains, such as computer vision and image recognition. The most prominent technique derived from Deep Learning is Convolutional Neural Network, which allows the network to automatically learn representations needed for detection or classification tasks. However, Convolutional Neural network have some limitations, as designing these network are not easy to master and require expertise and insight. In this work, we present the use of Genetic Algorithm associated to Grammar-based Genetic Programming to optimize Convolution Neural Network architectures. To evaluate our proposed approach, we adopted CIFAR-10 dataset to validate the evolution of the generated architectures, using the metric of accuracy to evaluate its classification performance in the test dataset. The result demonstrate that our method using Grammar-based Genetic Programming can easily produce optimized CNN architectures that are competitive and achieve high accuracy result."
4407;en_US;"A common tool used in the process of comparing classifier is the statistical significance analysis, performed through the hypothesis test. However, there are many researcher attempting to obtain statistical significance through a blinding evaluating of the p-value<0.05 condition, ignoring important concepts such as the effect size and statistical power. This work highlights possible problem caused by the misuse of the hypothesis test and how the effect size and the statistical power can provide information for a better decision making. Therefore, two case studies applying Student’s t-test and Wilcoxon signed-rank test for the comparison of two classifier are presented."
4408;en_US;"This work describes the development of a type 2 Fuzzy Inference System by using Genetic Programming for application in time serie forecast. The resulting model, called GPFIS-Forecast+ is based on the GPFIS-Forecast created previously, which made use of Multigene Genetic Programming an provided good result. result show that the system with type 2 fuzzy sets improves the performance, especially for noisy data."
4409;en_US;"Automated Planning is the subarea of AI concerned with the generation of a plan of actions for an agent to achieve its goals. State-of-the-art planning algorithm are based on heuristic search. However, the inexistence of a plan can be a challenge for such planners, since they are not always able to discern the difficulty of finding a solution from its inexistence. The problem of plan existence verification, called planex, is computationally hard. Thus, in 2016, the planning community held for the first time the Unsolvability International Planning Competition (UIPC), which aims to evaluate algorithm on the task of verifying plan existence. The aim of this paper is to propose a new algorithm to solve the planex problem that is based on symbolic model checking approach. The proposed algorithm differs from others based on model checking in two points: (i) it is able to reason about the actions represented in PDDL (Planning Domain Description Language) and; (ii) it is based on the α-CTL logic, whose semantics takes into account the actions responsable for the state transitions. We also evaluate the proposed alorithm over the UIPC planning benchmark problem."
4410;en_US;"In this paper, we present a new public and real dataset of labeled image of meteors and non-meteors that we recently used in a machine learning competition. We also present a comprehensive performance evaluation of several established machine learning method and compare the result with a stacking approach – one of the winning solutions of the competition. We compared the performance obtained by the method in the traditional repeated five-fold cross-validation with the ones obtained using the training and test partitions used in the competition. A careful analysis of the result indicates that, in general, the stacking based approach obtained the best performances compared to the baselines. Moreover, we found evidence that the validation strategy used by the platform that hosted the competition can lead to result that do not sustain in a cross-validation setup, which is recommendable in real-world scenarios.
"
4411;en_US;"Eye detection is a preprocessing step in many method using facial image. Some algorithm to detect eyes are based on the characteristics of the gradient flow in the iris-sclera boundary. These algorithm are usually applied to the whole face and a posterior heuristic is used to remove false positives. In this paper, we reverse that approach by using a Convolutional Neural Network (CNN) to solve a regression problem and give a coarse estimate of the eye regions, and only then do we apply the gradient-based algorithm. The CNN was combined with two gradient-based algorithm and the result were evaluated regarding their accuracy and processing time, showing the applicability of both method for eye localization."
4412;en_US;"This paper describes the process of automatic identification of concepts in different language using a base that relies on simple semantic and morphosyntactic characteristics like string similarity, difference in word amount and translation position on dictionary (when exists) and a neural network that has been used as a model of machine learning. All experiment use data that was obtained from a few categories of Read The Web (RTW) project and an endless learning computation system called NELL: Never-Ending Language Learning. The result were compared with dictionary and showed that the introduction of neural network brought a significant gain in the process of equivalence of concepts."
4413;en_US;"The Paraíba do Sul river flows through the most important industrial region of Brazil and its basin is characterized by conflicts of multiple uses of its water resource. The prediction of its natural flow has strategic value for water management in this basin. This research investigates the applicability of the two machine learning method (Random Forest and Artificial Neural network) for daily streamflow forecasting of the Paraíba do Sul River at lead times of 1-7 days. The impact of fluviometric and pluviometric data from other basin sites on the quality of the forecast is also evaluated."
4414;en_US;"The potential for processing car sensing data has increased in recent years due to the development of new technologies. Having this type of data is important, for instance, to analyze the way drivers behave when sitting behind steering wheel. Many studies have addressed the drive behavior by developing smartphone-based telematics system. However, very little has been done to analyze car usage pattern based on car engine sensor data, and, therefore, it has not been been explored its full potential by considering all sensor within a car engine. Aiming to bridge this gap, this paper proposes the use of Machine Learning technique (supervised and unsupervised) on automotive engine sensor data to discover drivers’ usage pattern, and to perform classification through a distributed online sensing platform. We believe that such platform can be useful used in different domains, such as fleet management, insurance market, fuel consumption optimization, CO2 emission reduction, among others."
4415;en_US;"This research consists of the analysis of the method of image recognition, focusing on the problem of food classification, aiming to use the method in a mobile application for the assistance in food monitoring and control. Thus, the development of the work contemplate the use of the deep learning method, focused on the recognition of food in image, with the use of neural convolution network (CNN). For this purpose, a data set consisting of more than 1000 image and 5 food classes was constructed in order to simulate the SimpleNet, MiniVGGNet and Small Xception model, and thus define a learning model for food classification."
4416;en_US;"A computer vision approach to classify garbage into recycling categories could be an efficient way to process waste. This project aims to take garbage waste image and classify them into four classes: glass, paper, metal and, plastic. We use a garbage image database that contains around 400 image for each class. The model used in the experiment are Pre-trained VGG-16 (VGG16), AlexNet, Support Vector Machine (SVM), K-Nearest Neighbor (KNN) and, Random Forest (RF). experiment showed that our model reached accuracy around 93%."
4418;en_US;"Sign language is one of the main forms of communication used by the deaf community. The language’s smallest unit, a “sign”, comprises a serie of intricate manual and facial gestures. As opposed to speech recognition, sign language recognition (SLR) lags behind, presenting a multitude of open challenges because this language is visual-motor. This paper aims to explore two novel approaches in feature extraction of facial expressions in SLR, and to propose the use of Random Forest (RF) in Brazilian SLR as a scalable alternative to Support Vector machine (SVM) and k-Nearest Neighbors (k-NN). result show that RF’s performance is at least comparable to SVM’s and k-NN’s, and validate non-manual parameter recognition as a consistent step towards SLR."
4419;en_US;"This paper proposes a sequence of computational procedures for detecting, interpreting and classifying pattern in frontal two-dimensional image of faces for automatic recognition of pain in newborns. Using data transformation and extraction of statistical characteristics from a real-life, healthy-term newborn image database, it was possible to interpret and model the subjectivity of trained health professionals, quantifying human knowledge in the task of recognizing pain enabling automatic identification. These result were compared with NFCS based classifications by the same professionals of the same image.
"
4420;en_US;"This paper presents a preliminary study on the use of reinforcement learning to control the torque vectoring of a small rear wheel driven electric race car in order to improve vehicle handling and vehicle stability. The reinforcement learning algorithm used is Neural Fitted Q Iteration and the sampling of experiences is based on simulation of the vehicle behavior using the software CarMaker. The cost function is based on the position of the states on the phase-plane of sideslip angle and sideslip angular velocity. The resulting controller is able to improve the vehicle handling and stability with a significant reduction in vehicle sideslip angle."
4421;en_US;"Predicting the stock market is a widely studied field, either due to the curiosity in finding an explanation for the behavior of financial assets or for financial purposes. Among these studies the best technique use neural network as a prediction tool. More specifically, the best network for this purpose are called recurrent neural network (RNN), and provide an extra option when dealing with a sequence of values. However, a great part of the studies is intended to predict the result of few stocks, therefore, this work aims to predict the behavior of a large number of stocks. For this, similar stocks were grouped based on their correlation and later the algorithm K-means was applied so that similar groups were clustered. After this process, the Long Short-Term Memory (LSTM) - a type of RNN - was used in order to predict the price of a certain group of assets. result showed that clustering stocks did not influence the effectiveness of the network and that investors and portfolio managers can use it to simply their daily tasks.
"
4422;en_US;"Ship control in port channels is a challenging problem that has resisted automated solutions. In this paper we focus on reinforcement learning of control signals so as to steer ships in their maneuvers. The learning process uses fitted Q iteration together with a Ship Maneuvering Simulator. Domain knowledge is used to develop a compact state-space model; we show how this model and the learning process lead to ship maneuvering under difficult conditions."
4423;en_US;"Monte Carlo Tree Search (MCTS) has recently emerged as a promising technique to play game with very large state spaces. Ataxx is a simple two-player board game with large and deep game tree. In this work, we apply different MCTS algorithm to play the game Ataxx and evaluate its performance against different adversaries (e.g., minimax2). Our analysis highlights one key aspect of MCTS, the trade-off between sample (and accuracy) and chances of winning the game which translates to a trade-off between the delay in making a move and chances of winning.
"
4424;en_US;"This paper presents the outcomes of an application research of deep neural network to diagnosis incipient faults in power transformer through dissolved gas-in-oil analysis (DGA). Two model was proposed, first, using a Stacked Autoencoder Network and later a Convolucional Neural Network. To the development of the system was used the database TC10 which contains data of faults usually found in electrical equipment in service. This database are described in norm IEC 60599. The outcomes achieved, considering the testing data was 100% and 96,5% of accuracy, showed that this model containing a wide applicability to the problem."
4425;en_US;"Drone use has grown with the use of image processing and computer vision technique, such as autonomous image navigation, mosaic generation, elevation modeling, 3D reconstruction, and object recognition. In all technique, an important step is an extraction of feature, such as method of interest points. This work addresses the modes of application of interest points, such as BRISK, ORB, FREAK, AKAZE and LATCH with the parameters configured automatically using the optimization method for image with different textures. This process is one of the pieces of final software that selects the use of a meta heuristic the best parameters automatically according to an input image."
4426;en_US;"Segmentation of masses in mammography image is an important task to aid the accurate diagnosis of breast cancer. Although the quality of segmentation is crucial to avoid misdiagnosis, the segmentation process is a challenging task even for specialists, due to the presence of ill-defined edges and low contrast image. One of the technique of state of the art for tumor segmentation is the Fuzzy GrowCut algorithm. In this work a study is performed on the behavior of this algorithm when using different membership functions for segmentation. Moreover, this research proposes a new membership function, called Multi-Gaussian, which improves the result of Fuzzy GrowCut with respect to those obtained through the use of classical functions."
4427;en_US;"This paper aims to perform the sentiment analysis of Twitter posts related to the movies nominated for Best Picture of the 2017 Oscars in order to find out if there is a correlation between the posts and the Oscar winners. A tweets database was built, pre-processed, and later evaluated by three distinct approaches: Naive Bayes, Distant Supervision Learning, and Polarity Function. It was possible to predict which movie would be considered the winner and which would be among the less prestigious ones. It was noted that Twitter user prefer to post positive comment about movies rather than saying bad things about the ones they did not like. Furthermore, it was verified that award shows such as the Oscars cause a growth in the number of posts on Twitter."
4428;en_US;"This paper aims to improve the classification process of leaf disease in plantations, reducing the need to have a specialist or prior knowledge of the disease that can affect a plantation, since some disease can spread and end with entire plantations. The proposal is the use of Convolutional Neural network (CNN) to classify leaf disease in plants using image, creating a model that can be implemented in a smartphone application. The model selected for the application, using a dataset with 4485 image separated in 5 classes, had an accuracy of 97% in the test base."
4429;en_US;"Tracking landmarks points of the human face is an essential step for the construction of interface capable of taking advantage of the communicative potential of facial expressions. Many strategies based on parametric model and regression algorithm with boosting can be applied to this problem. This paper proposes a solution based on the combined use of principal component analysis and regression trees. The main purpose of the presented method is to reduce the sensibility of the system to the presence of missing labels when trained with faulty dataset, by the adoption of corrective heuristics. On such cases, the proposed model achieves performance similar to the reference result, obtained by training on fault free dataset."
4430;en_US;"Artificial Intelligence (AI) seeks to bring intelligent behavior for machine by using specific technique. These technique can be employed in order to solve tasks, such as planning paths or controlling intelligent agent. Some tasks that use AI technique are not trivially testable, since it can handle a high number of variables depending on their complexity. As digital game can provide a wide range of variables, they become an efficient and economical means for testing artificial intelligence technique. In this paper, we propose a combination of a behavior tree and a Pathfinding algorithm to solve a maze-based problem using the digital game Bomberman of the Nintendo Entertainment System (NES) platform. We perform an analysis of the AI technique in order to verify the feasibility of future experiment in similar complex environments. Our experiment show that our intelligent agent can be successfully implemented using the proposed approach.
"
4431;en_US;" This paper shows an empirical study of Value Iteration Risk Sensitive algorithm proposed by Mihatsch and Neuneier (2002). This approach makes use of a risk factor that allows dealing with different types of risk attitude (prone, neutral or averse) by using a discount factor. We show experiment with the domain of Crossing the River in two different scenarios and we analyze the influence of discount factor and risk factor under two aspects: optimal policy and processing time to convergence. We observed that: (i) the processing cost in extreme risk policies is high with both risk-averse and risk-prone attitude; (ii) a high discount increases time to convergence and reinforces the chosen risk attitude; and (iii) policies with intermediate risk factor values have a low computational cost and show a certain sensitivity to risk based on the discount factor.

"
4432;en_US;"Classical model of agent for solving well-defined problem are widely used in the literature but are limited to systematic search strategies in order to find the solutions. However, these strategies are not suited for all types of application. This work presents an adaption of classical model of agent for local search strategies. One agent system for neural network automatic design is used to show the feasibility of the proposal. The result are promising, since the model found satisfactory solutions for the proposed problem."
4433;en_US;"Checkers player agent represent an appropriate case study for the best unsupervised method of Machine Learning. This work presents a tool to measure the performance of these method based on the quality of the decision making of these agent. The proposed tool, based on the data of movements performed in real game by the agent under evaluation, provides a statistical way of automatically comparing the coincidence rates between the decision making of the evaluated agent with those that the remarkable player agent Cake would do in the same situations. The tool was validated through tournaments between agent comparing their respective coincidence rates and their performance."
4434;en_US;"Markov Decision Process (MDP) has been used very efficiently to solve sequential decision-making problem. However, there are problem in which dealing with the risks of the environment to obtain a reliable result is more important than minimizing the total expected cost. MDPs that deal with this type of problem are called risk-sensitive Markov decision process (RSMDP). In this paper we propose an efficient heuristic search algorithm that allows to obtain a solution by evaluating only the relevant states to reach the goal states starting from an initial state."
4435;en_US;"An important problem in robotics is to determine and maintain the position of a robot that moves through a previously known environment with reference points that are indistinguishable, which is made difficult due to the inherent noise in robot movement and identification of reference pints. Monte Carlo Localization (MCL) is a frequently used technique to solve this problem and its performance intuitively depends on reference points. In this paper we evaluate the performance of MCL as a function of the number of reference points and their positioning in the environment. In particular, we show that performance is not monotonic in the number of reference points and that a random positioning of the reference points is close to optimal."
4436;en_US;"Sentiment analisys and the polarity classification of text constitute one of the main tool currently used by company and organization for the most varied purposes. This work presents an analysis of the use of word embeddings, built through Word2Vec, in the process of feature extraction for polarity classification of short message written in English. The text used were extracted from Twitter and the result obtained show that, in spite of the possible need to use larger textual bases to obtain better vectors, Word2Vec is a promising tool for the feature extraction of textual data, contributing to obtain good classification result."
4437;en_US;"The heterogeneities are characterized by several sedimentary petro- facies. Petrofacies identification involves manual process and time-consuming analyses. The study of the diagenesis has been encouraged by petroleum company, in order to understand the distribution of porosity in sandstones. This work aims to analyze the use of clustering approaches to identify petrofacies and assist the analysis of petrographic data. In addition, this study introduced the use the phylogenetic analysis tool to understand the diagenetic process that occurred during sedimentary rock formation. The proposed methodology reaches similar result to those obtained by the conventional method of individualization while allows for reducing time and cost in the individualization task."
4438;en_US;"Data streams are transmitted at high speeds with huge volume and may contain critical information need processing in real-time. Hence, to reduce computational cost and time, the system may apply a feature selection algorithm. However, this is not a trivial task due to the concept drift. In this work, we show that two feature selection algorithm, Information Gain and Online Feature Selection, present lower performance when compared to classification tasks without feature selection. Both algorithm presented more relevant result in one distinct scenario each, showing final accuracies up to 14% higher. The experiment using both real and artificial dataset present a potential for using these method due to their better adaptability in some concept drift situations."
4439;en_US;"The problem of controlling mobile robots in dynamic environments is an interesting challenge. This paper investigates the problem of controlling mobile robots in dynamic environments through robust control laws defined by echo state network (ESN). The output weights of the ESN are optimized by genetic algorithm (GAs). Different GAs developed for optimization in dynamic environments are compared in the problem of searching for robust solutions. Two approaches are investigated: through dynamic evolutionary optimization and robust evolutionary optimization. In the experiment, the GA evolved in the static environment produces good trajectories in environments that resemble the static environment (without obstacles). However, it presents unsatisfactory performance in environments that are very different from the static environment. Both GAs evolved in the dynamic and robust optimization approaches present good result in environments that differ from the static environment."
4440;en_US;"In the last decades, researcher have proposed the use of genetically modified organisms that utilize unnatural amino acids, i.e., amino acids other than the 20 amino acids encoded in the standard genetic code. Unnatural amino acids have been incorporated into genetically engineered organisms for the development of new drugs, fuels and chemicals. When new amino acids are incorporated, it is necessary to modify the standard genetic code. Expanded genetic codes have been created without considering the robustness of the code. The objective of this work is the use of genetic algorithm (GAs) for the optimization of expanded genetic codes. The GA indicates which codons of the standard genetic code should be used to encode a new unnatural amino acid. The fitness function has two terms; one for robustness of the new code and another that takes into account the frequency of use of amino acids. experiment show that, by controlling the weighting between the two terms, it is possible to obtain more or less amino acid substitutions at the same time that the robustness is minimized."
4441;en_US;"Among the phenomena that occur on the surface of the Sun, solar flares may cause several damages, from short circuits in power transmission lines to complete interruptions in telecommunications system. In order to mitigate these effects, many work have been dedicated to the proposal of mechanism capable of predicting the occurrence of solar flares. In this context, the present work sought to evaluate two aspects related to machine learning-based solar flare forecasting: (i) the impact of class imbalance in training dataset on the performance of the predictors; and (ii) whether the incorporation of a pre-clustering step prior to the classifier training contributes to a better prediction."
4442;en_US;"It is possible to reveal whether a subject received musical training through the neural activation pattern induced in response to music listening. We are particularly interested in analyzing the brain data on a global level, considering its activity registered in electroencephalogram electrodes signals. Our experiment result, with 13 musicians and 12 non-musicians who listened the song Hungarian Dance No 5 from Johannes Brahms, have shown that is possible to differentiate musicians and non-musicians with high classification accuracy (88%). Given this multivariate statistical framework, it has also been possible to highlight the most expressive and discriminant changes in the participant brain according to the acoustic feature extracted from the audio."
4443;en_US;"Discovering regions that have sports interest in a set of image acquired from a scene at different times and possibly from different viewpoints and cameras is a crucial step for many application. Physical activity can be effective at all stages of chronic disease, therefore, finding regions with the presence of physical activity might contribute to is important for the elaboration of public policies to minimize the presence of disease such as obesity. This work addresses the problem of sport/non-sport image classification. We combine Convolutional Neural Network (CNN), traditional classifier and geographical information to provide robust training and testing stages. As result, we achieved a high area under the curve (AUC) in a social network dataset. The experimental result show the feasibility of our proposed model. These result can be used and applied to develop public health policies based on statistics of sports interest.
"
4444;en_US;"Diagnosing Tuberculosis is crucial for proper treatment since it is one of the top 10 causes of deaths worldwide. Considering a computer-aided approach based on intelligent pattern recognition on chest X-ray with Convolutional Neural network, this work presents the proposition, training and test result of 9 different architectures to address this task as well as two ensembles. The highest performance verified reaches accuracy of 88.76%, surpassing human experts on similar data as previously reported by literature. The experimental data used comes from public medical dataset and comprise real-world examples from patient with different ages and physical characteristics, what favours reproducibility and application in practical scenarios."
4446;en_US;"This paper presents the proposal of an electrocardiogram (ECG) signals classification system through a competitive structure of Convolutional Autoencoders (CAE). Two Convolutional Autoencoders were trained to reconstruct ECG signals for the cases of patient with arrhythmia and patient with signals considered normals. After the training, the two network were arranged in a competitive parallel structure to classify these signals. For the development and testing of the system, the MIT-BIH Arrhythmia Database of ECG signals was used. An accuracy of 88,9% was achieved considering the database used for system testing."
4447;en_US;"Vale do São Francisco in Pernambuco is one of the most
economically important poles in the state and among its cultivars, it is worth mentioning the grape culture. This sector faces challenges related to the response time between identifying a field infestation and taking corrective actions, in order to minimize losses. This work comprises a comparative analysis between deep learning architectures, applied to identification of disease in grape cultivars. result suggest that the use of these technologies is plausible to differentiate healthy grape leaves from leaves presenting one of three different types of disease, obtaining near 100% accuracy in studied database using an architecture that can be employed in embedded device."
4448;en_US;"Facial Expression is a very important factor in the social interaction of human beings. And technologies that can automatically interpret and respond to stimuli of facial expressions already find a wide variety of application, from antidepressant drug testing to fatigue analysis of drivers and pilots. In this context, the following work presents a model for Automatic Classification of Facial Expression using as a training base the dataset Challenges in Representation Learning (FER2013), characterized by examples of spontaneous facial expressions in uncontrolled environments. The presented method is composed by a Convolutional Neural network Ensemble architecture, using a non-trivial voting system, based on a smart model, Xtreme Gradient Boosting - XGBoost. As performance criteria for validation of the proposed model, were used K-fold and F1 Score Micro technique to guarantee robustness and reliability of the result, which are competitive with state-of-the-art work."
4449;en_US;"Modern machine learning technique, such as Deep Learning, have been successful in many complex Bioinformatics tasks. The capacity of Deep Neural network to handle large volumes of data has made them essential tool for multiple area of knowledge. However, developing the best model for a given task is a hard work. Deep Neural network have a very large number of hyperparameters, making them as powerful as complex to be adjusted. Therefore, in order to better understand the behavior of Deep Neural network when applied to biological data, we present in this paper a performance analysis of a Deep Feedforward Network in piRNAs classification. Different configurations of activation functions, initialization of weights, number of layers and learning rate are experienced. The effects of different hyperparameters are discussed and certain organization are proposed for similar domains of data."
4450;en_US;"The circadian rhythm is responsible for the daily routines without metabolism and its disorders have great repercussion, such as obesity and mental disorders. This study is, the work approach has metate the study of synchronization and synchronization cycle circadian and influenced the variable of the, in the perspective of an integrated system with an computational system and computational. result show the circadian rhythm periodicity is modified by the pain variable.
 "
4451;en_US;"This paper presents the proposal of a mathematical model for ischemic stroke, which is implemented with multiagent system, in a general purpose tool known as NetLogo. The objective of this simulator is to obtain a partial view of the stroke for didactic purposes and to motivate future work for the treatment of the disease. Given the importance of stroke, we want to know how it evolves after its initial symptom, over time. This simulator allows a study of the evolution of the disease, regarding the speed of growth and the affected area in certain region of the brain.
"
4452;en_US;"The environmental impacts of human action have led several countries to create stricter laws and tax breaks to reduce this damage. Thereby, the Green Logistic has been increasingly sought to meet the requirement and needs for a more sustainable development. This work presents an ILS (Iterated Local Search) algorithm combined with RVND (Random Variable Neighborhood Search) and compare it with a GRASP (Greed Randomized Search Procedure) algorithm where each one has two variations: minimize distance and minimize emission. The result show the effectiveness of the ILS approach and heuristics that minimize the total distance covered do not present themselves as good solutions in terms of sustainability."
4453;en_US;"Flower Pollination Algorithm (FPA) has been widely used to solve optimization problem. However, it faces the problem of stagnation in local optimum. Several approaches have been proposed to deal with this problem. To improve the performance of the FPA, this paper presents a new variant that combines FPA and two variants of the Opposition Based Learning (OBL), such as Quasi OBL (QOBL) and Elite OBL (EOBL). To evaluate this proposal, 10 benchmark functions were used. In addition, the proposed algorithm was compared with original FPA and three variants such as FA–EOBL, SBFPA and DE–FPA. The proposal presented significant result."
4454;en_US;"Optimization problem such as the Uncapacitated Single-Allocation p-Hub Median Problem represent good model for real network design issues, hence an increasing research interest has emerged. A good hub location reduces costs and improves the quality of delivered service on network-based system. In this work, two artificial immune system are employed in order to address the problem, where the numerical result indicate good quality of solutions."
4455;en_US;"In this paper, the classical polynomial model for wind turbines power curve estimation is revisited aiming at an automatic and parsimonious design. In this regard, using genetic algorithm we introduce a methodoloy for estimating a suitable order for the polynomial as well its relevant terms. The proposed methodology is compared with the state of the art in estimating the power curve of wind turbines, such as logistic model (with 4 and 5 parameters), artificial neural network and weighted polynomial regression. We also show that the proposed approach performs better than the standard LASSO approach for building regularized sparse model. The result indicate that the proposed methodology consistently outperforms all the evaluated alternative method.
"
4456;en_US;"Agent-based simulation can be used to study and formulate evacuation plans, however the traditional simulation model for this context are not suitable for daycare and school settings where the population of these settings has unique physical and behavioral characteristics. This paper proposes a simulation model based on classroom evacuation agent from daycare centers that takes into account the physical and behavioral characteristics of the student and that is able to provide data to evaluate the impact of teachers’ behavior in the evacuation process. The model was built using the Netlogo tool, using as basis the structures of the Brazilian classroom environment and using data from the literature on human behavior. The tests were performed in different settings of parameters for environment, population, student behavior and evacuation strategies. The experiment showed that the model was able to reproduce result consistent with the expected values and scenarios described in the literature, as well as being an effective tool to evaluate the impact of teacher behavior in the evacuation process, especially in rooms where student have a high degree of dependency."
4457;en_US;"In a fire situation it is known that one of the main causes of deaths is the inhalation of smoke. Therefore, it is essential that at the start of emergency situations people leave quickly to avoid possible injuries. We have investigated the dispersion of smoke in closed places and simulate the crowds’ behavior in these situations. This paper aims to present a new proposal to model the smoke dispersion in closed environments using the concept of potential fields joined to cellular automata. To validate the work, a behavioral model for the simulation of people evacuation using the multiagent approach was implemented."
4458;en_US;"This paper aims to present a new problem in the context of the collaborative transport named Profitable Tour Problem with Passengers and Time and Cost Restrictions. The problem consists in finding the best tour for a courier who needs to perform service in several locations. The tour is made by car. To reduce costs may give rides and share travel cost with the riders. A mathematical model is proposed which is implemented in a solver and applied to instances of the problem. Heuristic algorithm are presented according to the Variable Neighborhood Search and Greedy Randomized Adaptive Search Procedure meta-heuristics. result of a computational experiment with 36 instances with up to 150 vertices are reported."
4459;en_US;"Group profiling method aim to construct a descriptive profile for communities in social network. Before the application of a profiling algorithm, it is necessary to collect and preprocess the user’ content information, i.e., to build a representation of each user in the network. Usually, existing group profiling strategies define the user’ representation by uniformly processing the entire content information in the network, and then, apply traditional feature selection method over the user feature in a group. However, such strategy may ignore specific characteristics of each group. This fact can lead to a limited representation for some communities, disregarding attributes which are relevant to the network perspective and describing more clearly a particular community despite the others. In this context, we propose the community-based user’s representation method (CUR). In this proposal, feature selection algorithm are applied over user feature for each network community individually, aiming to assign relevant feature sets for each particular community. Such strategy will avoid the bias caused by larger communities on the overall user representation. experiment were conducted in a co-authorship network to evaluate the CUR representation on different group profiling strategies and were assessed by hu- man evaluators. The result showed that profiles obtained after the application of the CUR module were better than the ones obtained by conventional user’ representation on an average of 76.54% of the evaluations."
4460;en_US;"The cost of losing profitable customers in competitive markets is driving company to engage in customer retention. Therefore, anticipating client churn (i.e., cancellation) becomes essential. Among the researches on churn prediction model, we highlight those that are based on sequential pattern detection. Although promising, such initiatives do not take into account the sentiments present in the client’s interaction with the company. Given the above, this article proposes a method that generates churn prediction model from the combination of sequential pattern detection with sentiment extraction from the interaction with the clients. Experimental result confirm the adequacy of the proposed method."
4461;en_US;"Time serie are sequence of values distributed over time. Analyzing time serie is important in many area including medical, financial, aerospace, commercial and entertainment. Change Point Detection is the problem of identifying changes in meaning or distribution of data in a time serie. This article presents Spec, a new algorithm that uses the graph spectrum to detect change points. The Spec was evaluated using the UCR Archive which is a large da- tabase of different time serie. Spec performance was compared to the PELT, ECP, EDM, and gSeg algorithm. The result showed that Spec achieved a better accuracy compared to the state of the art in some specific scenarios and as efficient as in most cases evaluated."
4462;en_US;"Recommender system have become an extremely attractive topic, mainly because of the growth of the Internet, the use of service on mobile device and also the growth of e-commerce. Therefore, it is necessary to filter, prioritize and provide relevant information in order to effectively address the problem of information overload. Based on that, the aim of this work is to present scientific contributions to the Artificial Intelligence field in order to demonstrate how to recomend products for user that do not have specific technical knowledge about the products, using classification technique. Our approach is evaluated using the recommendation accuracy obtained by the application of machine learning algorithm applied to training dataset."
4463;en_US;"In this paper, over-specialization in content-based recommender sys- tems is explored through the definition and analysis of recommendation strate- gies aiming at quality in terms of relevance, diversity and serendipity. Clustering is applied as the basis for building these strategies, applied to the news context. The result show the feasibility of the proposed strategies."
4464;en_US;"Data mining has been an area of high visibility in recent years and many researches have shown good efficiency in this area to find information in large databases. This paper presents an approach to find fraud traces applying data mining technique to public databases of the Brazilian Federal Government bidings. The aim is to find evidence of fraud, such as stunts and cartels. The task of finding fraud evidences in large amount of data is complex for auditors since they have correlate data. The proposed approach was used to develop a prototype which has been used by auditors in the Ministry of Transparency and General Comptroller of the Union (CGU)."
4465;en_US;"The individualism of each composer is shaped in an inherent way to his personality, aiming for recognition of particular form through the own songs. In this way, it is possible to categorize a musical subgenre at a deeper level by identifying the composer from his work. However, the characteristics of each composer are so varied that they are difficult to identify. In this paper it is proposed to use machine learning to classify work of twelve-tone music according to the composer, under the hypothesis that in choosing the twelve-tone serie a part of his signature was reflected. Experimental result showed promising performance and confirmed the existence of a relation between composer and serie."
4466;en_US;"Semi-supervised learning algorithm are able to train classifier from a small portion of initially labeled objects. The reliability of the classification process depends on several factors that include the type of classifier used and a set of parameters that customize them. One of the most important factors is a threshold that determines which instances are included per iteration, allowing to label only instances with high confidence values. This article analyzes different values for the variation factor of the FlexCon-C algorithm and measures the impact of this change on its accuracy. The result consider thirty different databases, four classifier and five different percentages of pre-labeled data."
4467;en_US;"The popularization of web platforms promoted a significant increase in the publication of financial news and reports in digital media. In this sense, a multidisciplinary research area called “learning to sense” (or sensor learning) has received attention recently. Unlike traditional machine learning method, in sensor learning there is an interest in obtaining a time serie that indicates the activity of a particular topic over time. A sensor is represented by a set of parameters learned from a historical news events dataset. The sensor generates time serie as news events are processed and these time serie are used in decision support system. This paper presents an overview of sensor learning for financial news. We compared six parameter selection measures for sensor learning, with the differential of considering an unsupervised scenario. The general idea is to use the concept of k-recurrent events, i.e, news events that are similar and occur together in different periods of up-trends and down-trends of a financial time serie. Thus, if a specific event (extracted from news) occurred at least k times in the past always associated with up-trends, then such news is labeled as positive news. Analogously, it can be labeled as negative. The experimental result from real data provided evidence that the approach investigated in this work is a promising alternative for sensor learning from financial news events, especially in context where there are no domain experts or external information to label a training set."
4469;en_US;"In Meta-learning, training examples are generated from experiment performed with a pool of candidate algorithm in a number of problem (real or synthetic). Generating a good set of examples can be difficult due to the low availability of real dataset in some domains and the high computational cost of labeling. In this paper, we focus on the selection of training meta-examples by combining data manipulation and Transfer Learning via One-class classification. So, the most relevant examples are selected to be labeled. Our experiment revealed that it is possible to reduce the computational cost of generating meta- examples and maintain the meta-learning performance."
4470;en_US;"This paper describes the application of KIII, a biologically more plausible neural network model, for forecasting economic time serie. K-sets are connectionist model based on neural populations and have been used in many machine learning application. In this paper, this method was applied to IPCA, a Brazilian consumer price index surveyed by IBGE. The values ranged from August 1994 to June 2017. experiment were performed using four non-parametric model and seven parametric method. The statistical metric RMSE was used to compare method performance. Freeman KIII sets worked well as a filter, but it was not a good prediction method. This paper contributes with the use of non-parametrics model for forecasting inflation in a developing country.
"
4472;en_US;"The world trend in employing UAVs and drones is remarkable. The main reasons are that they may cost fractions of manned aircraft and avoid the exposure of human lives to risks. However, they depend on positioning system that may be fallible. Therefore, it is necessary to ensure that these system are as accurate as possible, aiming at safe navigation. In pursuit of this end, conventional Data Fusion technique can be employed. Nonetheless, its high computational cost may be prohibitive due to the low payload of some UAVs. This paper proposes a Data Fusion application based on Computational Intelligence – Adaptive-Network-Based Fuzzy Inference System (ANFIS) – which is able to improve the accuracy of such position estimation system."
4473;en_US;"This paper describes an ONFC (OnLine Neurofuzzy Controller) application with a dynamic learning rate to control the water flow of a real plant. A revision of ONFC is presented and the ONFCDw version is used, which has an action that minimizes the increase in the difference between the controller weights. The dynamic learning rate used to update the controller weights is described and the result of experiment performed in a water flow control process are presented, comparing the result with the PID controller used in the process."
4474;en_US;"Artificial Intelligence (AI) plays an important role in digital game nowadays. With players becoming increasingly demanding, it is vital to provide an AI that challenges and entertains them. The use of Adaptive Artificial Intelligence (AAI) has shown potential to adapt to each player by learning their technique and offering a consistent challenge. This research consists on the analysis of an AAI technique known as Dynamic Scripting (DS) and in the development of a new algorithm (called Tactic Replacement) to improve it. result show that, in comparison with the default DS algorithm, the proposed algorithm achieved a time reduction of ≈ 50% to achieve convergence. Also, it was able to reduce by 40% the average number of rounds to reach the convergence.
"
4475;en_US;"With advances in machine learning, natural language processing, processing speed, and amount of data storage, conversational agent are being used in application that were not possible to perform within a few years. NELL, a machine learning agent who learns to read the web, today has a considerably large ontology and while it can be used for multiple fact query, it is also possible to expand it further and specialize its knowledge. One of the first steps to succeed is to refine existing knowledge in NELL’s knowledge base so that future communication between it and humans is as natural as possible. This work describes the result of an experiment where we investigate which machine learning algorithm performs best in the task of classifying candidate word to subcategories in the NELL knowledge base."
4476;en_US;"Technological advancements and the interest of company that operate in digital environments have made the categorization of mediatic products increasingly popular. This is often a multi-label scenario, where an item may be labeled with many categories. Most of the literature approach film genre classification as a mono-label task, usually relying on audio-visual feature. In this paper we explore the use of text-based feature extracted from film synopses for multi-label film genre classification. We experimented with 19 feature extraction approaches combined with 4 multi-label classifier. Our experimental result show f1-scores of up to 54.8%, which are significantly higher than other similar studies presented in the literature."
4477;en_US;"The use of word embeddings is becoming very common in many Natural Language Processing tasks. Most of the time, these require computacional resource that can not be found in most part of the current mobile device. In this work, we evaluate a combination of numeric truncation and dimensionality reduction strategies in order to obtain smaller vectorial representations without substancial losses in performance.
"
4478;en_US;"This article presents Luppar, an Information Retrieval tool for closed collections of document which uses a local distributional semantic model associated to each corpus. The system performs automatic query expansion using a combination of distributional semantic model and local context analysis and supports relevancy feedback. The performance of the system was evaluated in databases of different domains and presented result equal to or higher than those published in the literature.
"
4479;en_US;"This work proposes and evaluates an approach to query expansion in Information Retrieval based on Local Context Analysis using a Distributional Semantic Representation. In general, the approach performed better compared to that of query expansion using non-distributional, local or global technique, running over dataset of different application domains."
4550;en_US;"Mobile ad hoc network pose stringent challenges for the implementation of efficient interactive on-demand streaming system. Mobile node are dynamically and arbitrarily located in such a manner that the interconnections between them change on a continual basis, thereby making timely content delivery hard to achieve. To tackle this issue, we propose two BitTorrent-like algorithm. As innovative aspects, we explore (i) data dispersion, indirect reciprocity, and geographical distance as criteria to select node to receive data, and (ii) introduce a sliding window to decide which data segments to request first. By means of simulation on distinct multimedia scenarios, the proposals are evaluated according to four performance metrics. Among the major findings, the result highlight the effectiveness of our proposals compared to a theoretical optimal content-delivery scheme. For instance, it is shown that our proposals yield average download rates which exceed over 23% of the actual needed rate. Within this context, the key contribution of this paper is to provide valuable algorithmic insights for real-world protocol designs targeted at mobile ad hoc network. Lastly, avenues for further research are included at the end of the paper."
4551;en_US;"In this paper, we investigate the impact of online economic news on BM&FBOVESPA, the leading stock exchange in Brazil. We collected economic news published in high circulation online Brazilian newspaper between 2000 and 2015 and extracted, from each news, the reader comment, the amount of shares in social media sites and its associated sentiment. From this, we built several feature that were used as input for machine learning model with the aim of predicting the trends on different sectors of BM&FBOVESPA concerning their average price, amount of trades, amount of contracts traded and financial volume. Our assumption is that the more predictable a sector is, based on these feature, the more sensitive to news it is. Besides showing that sectors are indeed affected differently by news, we also show that the machine learning model employed performed better than random and other simpler baselines for all sectors, thus providing evidence that news data carry indeed an important signal for understanding BM&FBOVESPA dynamics."
4552;en_US;"Nowadays multimedia application are employed in different fields as entertainment, education, government service, health and e-commerce. Moreover, some application incorporate sensory effects along with traditional multimedia content, stimulating other human senses beyond sight and hearing to convey information. Those application are called mulsemedia application, where the maintenance of synchronization among media objects and sensory effects is a key point for user quality of experience. In order to minimize delays or failures on content reproduction, this paper proposes a new operation on media objects and sensory effects that can be offered to authors of mulsemedia application. This operation enables the preparation of media object presentation or the preparation of sensory effect rendering, considering device limitations on which the application will be executed. As proof of concept, our proposal is implemented on multimedia application using the NCL language, through specification of a new NCL event type, named preparation event. Furthermore, a new NCL media property is presented, allowing the control of continuous media reproduction. Finally, three use cases are defined to demonstrate the use of the preparation event in multimedia and mulsemedia application."
4553;en_US;"University campi, start-ups and conferences venue are places where there is a constant flow information exchanged between individuals. Part of this exchange takes place in formal, scheduled meetings, presentations, lectures and workhops. Another part, however, occurs in ad-hoc encounters such as coffee breaks, or when we meet colleagues or supervisors in corridors or at the canteen. Some have the habit of recording the information and decisions from formal encounters by taking notes on paper or capturing audio or video. However, this is not always possible in ad-hoc meetings, either because of lack of means to carry out the notes or because participant do not realize the need to record what was discussed, thus many information and decisions taken in ad-hoc meetings are lost. In this paper we present a case study that investigates how common is the occurrence of ad-hoc meetings in university campi, and proposes the Context-Based Opportunistic Capture, a Capture & Access technique that uses mobile device to detect possible occurrence of meetings from user close proximity and alerts them that a meeting may be held, and suggests that they use their device to record the meeting in audio or video. As proof of concept we developed an Android application and a context server that were evaluated by means of a case study. Partial result indicate that ad-hoc meetings are indeed common, that these are not usually recorded and that the provision of an infrastructure for the capture and registration of these meetings proves feasible, especially for the aforementioned environments."
4554;en_US;"The investment market has been growing every day, performing an important role in the lives of individuals and corporations. Therefore, there is a need to better understand the situations that occur in the capital market, by means of strategies and indicators that can assist in pattern recognition, analisys and investiment decisions. This work performs a study of characterization and analysis of a historical time serie data of 10 asset codes (i.e., BBAS3, USIM5, PETR4, JBSS3, KROT3, LAME4, MRVE4, NATU3, RADL3 e TIMP3) of the Bovespa index and sentiment analysis of polarity news and Twitter data with the proposal of evaluating a prediction model. It proposes the combination of deep learning and machine learning computational intelligence model for prediction, allowing the execution and cancellation of buy and sell orders. Finally, it evaluates the behavior of each proposed trading strategy by Accuracy, Percentage of Financial Return and other indicators to provide a better understanding of financial market behavior."
4555;en_US;"This paper aims to identify research cluster from a collection of paper associated with the provision of ubiquitous and intelligent service to vehicle occupants. In order to achieve this goal, it was performed an evaluation of result from six academic search engines from submission of search strings that consolidates this study needs. This process identifies, initially, 37,328 publications that, after filterings, reduced the scope of evaluation to 2,946 articles. Analysis of paper title and abstract terms revealed the existence of five active research cluster and, also, indicates a path of research from 'traffic issues, 'intelligent transport system' and 'profiling' to smart city, internet of things, 'big data', 'fog computing' and 'internet of vehicles in recent years."
4556;en_US;"The amount of data and events that Web application deal with has increased largely in the recent years. This scenario tends to become even larger as new smart things are constantly being connected using Web technologies in the so-called Web of Things. Meanwhile, ways to react to those occurrence of events have been explored by distinct communities with different points of view. Two solutions have stood out, namely Complex Event Processing (CEP) and Reactive language (RLs). While both share similarities, RLs lack expressivity with regard to time and temporal operations. Furthermore, events play a major role in CEP, whereas RLs have time-changing values as their main abstraction. In this paper, we propose an integration of CEP and RLs by extending a functional reactive framework with CEP concepts and operations."
4557;en_US;"The burden of neuropsychiatric disorders is increasing and there is a considerable problem in being able to deliver quality treatment to all affected population. The advance of mobile and ubiquitous computing in the last decade can open new ways of monitoring and treating neuropsychiatric disorders. The aim of the review was to systematically search the literature for studies applying ubiquitous computing and understand which disorders are being researched. A systematic mapping was conducted in ACM, IEEE, PubMed and PsychINFO including paper up to March 2018. 1425 paper were found during academic database search, of which 213 were selected for analysis given the predefined selection criteria. Preliminary result for one question show that the research of ubiquitous and mobile computing applied to mental healthcare is clearly growing over the past decade, with majority of the work focused on Depression, Bipolar, Schizophrenia, Mood disorders and PTSD."
4558;en_US;"In this paper we present a new architecture for mobile crowdsourcing system which leverages the infrastructure of service widely scalable. We successfully developed a proof of concept and discussed an alternative architecture that uses direct communication between device to eliminate the additional financial contribution needed in the solutions developed with elastic/cloud computing. We also presented a new incentive mechanism and evaluated its scalability with up to 1500 simultaneous accesses. Our result show that it is capable of serving one of the largest crowdsourcing system on the internet."
4559;en_US;"We describe how we modified an NCL player to accept as input, in addition to NCL document, Lua scripts. These Lua scripts evaluate to a table in a particular format, called NCL-ltab, which is a Lua table encoding of the NCL players internal model. One advantage of our modifications is that they allow the NCL parsing to occur in the Lua script, i.e., outside the formatter but integrated in its execution flow. The same applies for parsers of dialects of NCL or similar language. Another advantage is that new parsers can be plugged dynamically into the formatter (if they are written in Lua or can be called from Lua). In this paper, we detail the internal model of the NCL player we are using and the NCL-ltab input format. To evaluate our proposal, we present two parser-integration use cases, one for NCL itself, using the DietNCL parsing toolkit, and another for sNCL, an alternative, user-friendlier syntax for NCL."
4560;en_US;"In ubiquitous computing, Human Activity Recognition (HAR) system have an important role to enabled continuous monitoring of human behavior. This technology can be useful in healthcare application, for monitoring patient health and encourage a healthy lifestyle. In this paper, we focus on feature extraction stage of a HAR system. Many studies for mobile and wearable sensor-based HAR have applied manually engineered feature that need domain expert knowledge. However, trust on such knowledge is problematic when aiming to generalize across different application domains. To overcome this problem, we present a novel approach for HAR based on symbolic data representation of time serie that extract structural feature without human efforts. The Bag-Of-SFA-Symbols (BOSS) method is extended to multi-dimensional time serie, in order to enable that symbolic representation can be used to process the inertial sensor data. A comparative study between the proposed method and four machine learning classifier with handcraft feature is presented. experiment on accelerometer data from three publicly dataset were executed for subject-dependent and subject-independent evaluation. The result show that our method achieves good accuracy performace across dataset and aplications, and substantial recognition improvement over a baseline."
4561;en_US;"dataset refinement is a primary activity mainly related to data cleansing and enrichment. Usually, refinement is performed by publishers, although consumers often clean and enrich dataset in their consumption activity. However, in general, consumers effort is lost, since most times the result of the refinement is not shared back with the publisher or other consumers. In this context, this work proposes a refinement strategy based on the principles of social coding to allow the refinement of dataset published on the Web in a collaborative way."
4562;en_US;"This paper describes a system developed for verb tenses classification in the English language and automatic generation of verb-tenses-oriented exercises, based on text for study chosen by the user. The classification rule were analyzed iteratively. This research brings a method for generation of exercises of transposition of verb tenses. By this method, it is possible to transpose each verb tense on a sentence to another verb tense. The verb tenses transposition method can also be applied in other context, making it easy to choose an action (verb) and applying it to verb tense."
4563;en_US;"This paper proposes MultiSEM (Multimedia Sensory Effect Model), a conceptual model for representing multiple sensory effects in interactive multimedia application. MultiSEM is an extension of SIMM (Simple Interactive Multimedia Model) and allows the spatiotemporal integration and synchronization of sensory effects with traditional media content. MultiSEM is designed in order to ease the development of mulsemedia authoring tool based on it. To do that, sensory effects are modeled as document node, using a similar abstraction as media node. The proposed model also aims at supporting the development of authoring tool to be used by those who do not have knowledge of mulsemedia authoring language and model to create interactive mulsemedia application. In order to demonstrate that the model can support the development of an authoring tool, MultiSEM is implemented in STEVE 2.0 (Spatio-temporal View Editor), which is an editor for authoring hypermedia application with sensory effects. Compared with existing mulsemedia model, MultiSEM is the unique model that represents sensory effects as first-class entities and is designed to underlie mulsemedia authoring tool. Besides, an example of mulsemedia application is described and specified using MultiSEM entities. We also present how the application can be created using STEVE 2.0 with sensory effects."
4564;en_US;"Reuse technique are a common way of decreasing the development cost and time whilst increasing the quality of application. The sNCL language was first designed intending to decrease the verbosity required by hypermedia application for the Ginga-NCL middleware, at the same time keeping equal expressiveness power. However, it removed almost all the reuse elements of NCL. This work presents the reuse elements introduced on the language as a method of increasing the reuse for Digital TV application developers. It consists of macro elements, that can be used to reuse any generic information and a template system, a common theme in the literature as a form of increasing or introducing reuse on hypermedia authoring. The paper shows an study case with positive result of the new feature when specifying five Digital TV application from a public repository."
4565;en_US;"Collecting data and carrying out interventions with different populations of interest is a common procedure in the professional life of specialists such as psychologists, gerontologists, etc. The ESPIM is a platform designed to enable the authoring of intervention programs by specialists of different domains. The programs authoring is done via a Web interface, and a mobile player is used to display the intervention programs elaborated for the populations of interest of these specialists. This paper reports on the evolution and improvement of the components of this platform. Evaluations conducted with health and education experts point out that the current Web version of the platform is effective for program authoring and is easy to use. Meanwhile, the mobile player has been used by populations of interest of these experts who report on ease of use and engagement with intervention programs. Two real studies using the ESPIM are discussed in this paper and the analyzes conducted in the data collected indicates that most of the participant had a more positive experience with programs when the interaction involves multimedia resource, such as video, image and audios."
4566;en_US;"Augmented e-books provide the reader with a better quality of experience (QoE) by enriching the e-books with multimedia content and interactive elements. In the multimedia field, an improve in QoE has been performed by the use of sensory effects, creating the so-called mulsemedia application. In this paper, it is considered that e-books augmented with mulsemedia content influence the reader perception of the history environment, besides improving its QoE. It is presented a mulsemedia setup with light, wind and audio effects, which are synchronized with a written history. Among other discoveries, the collected data suggest that such elements have a more significant influence on the reader when the environment description tend to be vague, whereas in scenes whose details are precisely described this influence is rather minored."
4567;en_US;"Visual Question Answering (VQA) is a task that connects the fields of Computer Vision and Natural Language Processing. Taking as input an image I and a natural language question Q about I, a VQA model must be able to produce a coherent answer R (also in natural language) to Q. A particular type of visual question is one in which the question is binary (i.e., a question whose answer belongs to the set {yes, no}). Currently, deep neural network correspond to the state of the art technique for training of VQA model. Despite its success, the application of neural network to the VQA task requires a very large amount of data in order to produce model with adequate precision. dataset currently used for the training of VQA model are the result of laborious manual labeling process (i.e., made by humans). This context makes relevant the study of approaches to augment these dataset in order to train more accurate prediction model. This paper describes a crowdsourcing tool which can be used in a collaborative manner to augment an existing VQA dataset for binary questions. Our tool actively integrates candidate item from an external data source in order to optimize the selection of query to be presented to curators."
4568;en_US;"People are overloaded with the everyday massive amount of information they consume. There are several options available for choice, from TV shows, books, traffic routes to graduate course. In this scenario of multiple choices, the manual search and evaluation of all possibilities to make decisions is unfeasible. In the academic context, the HEIs (Higher Education Institutions) offer several graduate course and, with so many options, student need mechanism to choose relevant course to their interest in order to reduce the dropout and financial loss risks. In this article, we propose a recommendation approach that filters graduate course for student using their LinkedIn professional profiles. experiment show that feature based on competences and activity area are more effective than professional summary and experiences to recommend graduate course within a content-based approach. In addition, our proposed approach performs recommendation with precision of up to 68.50% in the top-1 recommendation lists, achieving 100% coverage."
4569;en_US;"Recommender system (RSs) are usually based in User Profiles (UP) to identify item of interest to a user, among the item of a usually vast collection. Traditional RSs are mostly based on ratings of item made by user and do not attempt to estimate the reasons that led the user to access these item. Furthermore, such system may suffer from the lack of rating data, the so-called data sparsity. This paper proposes a hybrid recommender system that considers, besides the ratings of the user, a feature description analysis of the item accessed by the user. This analysis is based on ontological UP, described in accordance with a set of ontology, one per feature. The use of ontology provides a weak coupling between the proposed RS and the domain of the item to be recommended. The effectiveness of our proposal is demonstrated and evaluated in the movie domain using the MovieLens dataset. The experiment demonstrated an improvement in the quality of the recommendation and a greater tolerance to the data sparsity, compared to state-of-art system."
4570;en_US;"Recommender system have been extensively used to provide meaningful and personalized content to user. A recurring issue, especially in collaborative filtering method, is the cold-start problem, which can be related to new item or new user. This problem can be smoothed by aggregating item information into the recommender calculation, thus the semantics behind these item representations are important. In this paper, we propose four rich item representations, based on three kinds of semantics: sentiment analysis, sense embeddings and similarities. The item feature are disambiguated concepts extracted from textual user review, which are known for possessing a great information load with both item descriptions and user preferences. We apply these four representations in two classic collaborative filtering algorithm, which were adapted to be attribute aware. We compare our approach against the original recommenders, and evaluate our result in two very different dataset to show the generality of our approach. result show a very positive influence of the item representations to reduce prediction error."
4571;en_US;"A large amount of information available on the Web challenges people to find the relevant ones. Here, we propose a new approach to help researcher to find the best references for given keyword. Such approach is based on the foundations of Lotka and Zipf laws. Also, we apply different information organization technique to treat, store and index publications available in Scopus database. Our result reveal that our new approach is promising to identify relevant publications."
4572;en_US;"Recommender system have become an important issue on Web application, but its research is usually focused on algorithm and data optimization. However, as the recommendation technique improve and these system become more commonly used in software application, there is the need of easily adapt and evolve them. To address this need, we propose a model-driven approach to evolve recommender system and present an architecture solution from our research, using an events management system as the domain for an use-case scenario. Future work might demonstrate the architecture feasibility."
4573;en_US;"Temporal segmentation of video into semantically coherent scenes is a fundamental step to enhance video operations like browsing, retrieval and recommendation. Available automatic scene segmentation method in the literature are still far, in terms of efficacy, from reasonable practical application requirement. Towards to lowering this gap, this paper presents a new multimodal early fusion based scene segmentation method, which extends the classical and powerful singlemodal bags-of-feature latent semantics discriminative capability to a multimodal paradigm. This approach was designed to refine the latent semantics from singlemodal data by identifying and representing audiovisual pattern while still preserving singlemodal visual/aural word pattern. experiment have been performed over a publicly available dataset where the proposed method achieved higher average values for the FCO metric than previous state-of-the-art approaches."
4574;en_US;"In this work, we explore how Convolutional Neural network can be applied to the task of sentiment analysis in visual media. We compare four different architectures and propose a new approach where attributes that represent the main categories used for scenes description are combined with the output of the convolutional layers before the classification process. In the first dataset, composed of image tweets, we obtained accuracy improvements over previous work. The second dataset, constructed in this paper, contains only image from outdoor area and labeled in three sentiment classes: positive, neutral and negative. Sentiment analysis of outdoor image helps to enable new service, e.g., to better uncover the semantics of area compared to indoor image. In general, the use of the attributes improves the accuracy of the result."
4575;en_US;"Nowadays, video lectures are a very popular way to transmit knowledge, and because of that, there are many repositories with a large catalog of those video on web. Despite all benefits that this high availability of video lectures brings, some problem also emerge from this scenario. One of these problem is that, it is very difficult find relevant content associate with those video. Many times, student must to watch the entire video lecture to find the point of interest and, sometimes, these points are not found. For that reason, in this work we propose a novel method based on early fusion of low and high-level audio feature for automatic topic segmentation in video lectures. We have performed experiment in two sets of video lectures where we obtained very satisfactory result that evidence the applicability of our method on improving content search in those video."
4576;en_US;"Social media posts and other time-stamped text can carry lots of useful information. However, their proper analysis requires capturing the semantics of what is mentioned in their contents, filtering what is of interest for particular application domains, and structuring the extracted information for analytical purposes. This work proposes an approach to analyze the incidences of mentions of interest for some domain in these text, by combining Semantic Web and Business Intelligence (BI) technologies. This approach is supported by an automatic ETL process that semantically annotates textual clips with Linked Open Data (LOD), filters LOD resource of interest in the annotations by using bridges between LOD classes and a high-level domain ontology, and adapts existing LOD hierarchies accordingly to serve as analysis dimensions. Experimental result show that our proposal: (i) is able to find a considerable number of mentions to things of interest for business in tweets recently sent from Brazil; (ii) allows the identification of the most mentioned (classes of) things of interest; and (iii) enables new useful query for information analysis on data cubes with some dimensions derived from existing LOD hierarchies."
4577;en_US;"The recent development of deep learning technique, like convolutional network, shed a new light over the video (story) scene segmentation problem, bringing the potential to outperform state-of-the-art non-deep learning multimodal approaches. However, one important aspect of the multimodality still needs investigation in the context of deep learning: the multimodal fusion. Often, feature are directly fed to a network, which may be an inadequate approach to perform the underlying multimodal fusion. This paper presents an evaluation of early and late approaches to deep learning multimodal fusion. In addition, it proposes a new deep learning model to perform video scene segmentation, based on convolutional network feature extraction capabilities and a recurrent neural network architecture. The result show the early versus late fusion discussion is reopened regarding deep learning. Moreover, the result prove the proposed model is competitive against state-of-the-art technique when evaluated over a public documentary video dataset obtaining up to 64 of average FCO, while also maintaining a lower computational cost when compared with a related convolutional approach."
4578;en_US;"FrameWeb is a method for the development of Web-based Information system whose architectures are based on popular types of framework, such as Front Controller, Dependency Injection and Object/Relational Mapping framework. Also commonly used, Security Framework provide role-based access control through authentication and authorization feature that can be reused if properly configured. In this paper, we extend FrameWeb to support Security Framework, allowing developers to model the aforementioned feature in architectural design model using a graphical editor and generating code for the configuration of the framework and related artifacts. The proposal is validated using the code generator and comparing with artifacts from real project."
4579;en_US;"Counting objects or living beings is a common necessity in many area of industry, commerce and service. Automating this activity can promote an optimization of the process involved and, consequently, the reduction of time and costs. With this in mind, computer vision is an approach that provides new possibilities for the digital processing of image, giving the computer a capacity of interpretation increasingly similar to humans. This work aims to compare the efficiency of volumetric counting technique, both using traditional computational vision and deep learning, in counting audiences in face-to-face events. As a case study, this preliminary investigation focused on audience counting of film and / or theater sessions from audience photos. Gauge billing automatically, accurately and transparently is a recurring need of the entertainment industry. From our experiment it was possible to observe the great potential of the application of deep learning in this context. When compared to several automatic volumetric counting technique available, deep learning was the strategy that presented the best result, reaching sensitivity and precision above 96%."
4580;en_US;"Nowadays, the non-linear multimedia service, such as Netflix and YouTube, have become increasingly popular. In this scenario, the user deciding what, where and when to consume the contents. This behavioral change led the content-producing company outsource tasks related to video distribution to content-management company, which are specialized in managing video streaming in high quality. These company are also responsible to provide a more qualified feedback about the user behaviors in order to help content-producing company to produce more attractive contents. In this paper we present a methodology for characterizing and analyzing multimedia streaming service. We validate it using actual data from Samba Tech, a content-management company leader in Latin American. The result showed that there are many possibilities to improve both the quality of the content and the system administration."
4581;en_US;"Rap surpassed Rock as the most popular musical genre in the United States, according Nielsen Music. Understanding how this process occurred is of paramount importance for researches on prediction of musical success. Analyzing data from Billboard Year End Hot 100 rankings, we were able to identify that outstanding artists, such as Beatles and Mariah Carey, and movements, like New Wave and Trap, are the major factors influencing the success of a particular genre. Plus, we noticed that Pop Music is more inclined to be in the top spot."
4582;en_US;"Offensive posts are a constant nuisance in many Web platforms. As a consequence, there has been growing interest in devising method to automatically identify such posts. In this paper, we present Hate2Vec -- an approach for detecting offensive comment on the Web. Hate2Vec relies on a classifier ensemble. The base learners include: (i) a lexicon-based classifier which leverages the semantic relatedness of word embeddings; (ii) a logistic regression classifier based on comment embeddings; (iii) and a standard bag-of-word (BOW) classifier based on unigram feature. Our experiment with dataset in English and Portuguese have yielded high classification result (F-measure above 0.9) and significantly outperformed a traditional BOW classifier."
4583;en_US;"Social media platforms have been increasingly used by modern society. In most platforms, user usually share content on various subjects and, in particular, politics is a favorite one. There are many interests in detecting and analyzing such a political content. However, there is a challenge in the process of detecting specific subjects from social media data mainly due to its informality. In this paper, we propose and compare two technique, based on supervised classification, for the detection of tweets with political content. The result obtained by our approach have demonstrated satisfactory performance, which motivates further research to be undertaken."
4584;en_US;"Estimating the similarity between entity names plays an important role in several tasks, such as entity resolution and recommendation tasks. Identifying the similarity between entity names, such as between titles of scientific articles, may not be feasible from direct comparison or using knowledge-based similarity approaches. Being an immeasurable source of data, Web can aid in this similarity check. In this work, we propose a method to calculate the similarity between two values of textual names, based on feature inferred from data obtained from the Web and with the aid of genre terms. experiment show that the method is able to check the similarity between names even those names no share terms in common."
4585;en_US;"One of the major problem when using lexicon in sentiment analysis is that they do not cover all possible word in a text and frequently they miss the more expressive to describe the emotions of the text author efficiently. This problem occurs because people in non-official, on formal channels, communicate using slangs, neologisms, new pattern based on abbreviations (as aka, brb and asap) and the different meanings, making challenging to analyse text using a finite subset of a language. This is a problem because some unknown word can completely change the meaning of a sentence, producing misunderstandings. In this paper we present an approach to expand an emotional lexicon for a specific author, producing a customised lexicon which represents how the author feels the word. In our experiment, we got an increase of 35.34% and 107.02% in the dictionary size when compared to the original lexicon using two different authors, and identifying different emotions from the same text according to each authors lexicon, i.e. interpreting the text according to the authors point of view."
4586;en_US;"Recent research in convolutional neural network (CNN) has provided a variety of new architectures for deep learning. One interesting new architecture is the local binary convolutional neural network (LBCNN), which has shown to provide significant reduction in the number of parameters to be learned at training. In this paper, we study the influence of network parameters in the scenario of face recognition, comparing LBCNN against other famous network available in the literature in terms of sensibility and processing time. In our study, we also propose a pre-processing step on image to increase the accuracy of the model, besides investigating its behaviour with noisy image. Our experiment are carried on the Chokepoint dataset, whose face subimage were collected from video frames under real-world surveillance conditions, including variations in terms of illumination, sharpness, pose, and misalignment due to automatic face detection. The conclusion is that by using the Laplacian step and a reduced amount of LBC modules, it is possible to train LBCNN more quickly and with improved accuracy. In addition, it was found that LBCNN is very sensitive to noise and better result can be achieved when noisy image are inserted in the training set."
4587;en_US;"Assistive Technology (AT) resource enable people with disabilities to have access to products, service and information, favoring inclusion in various spheres of society. To enhance the autonomy of people with disabilities in the use of such resource, it is important to conduct evaluations of these to ensure that they are in accordance with the needs and expectations of the target audience. It is common for user-based assessments to be based on questionnaires, interviews, or focus groups. However, these traditional strategies are inadequate when the user participating in the evaluation of the AT resource are deaf, not fluent in Portuguese. In order to guarantee the autonomy of the deaf user in the process of evaluating AT resource assigned to them, a solution of a multimedia and online questionnaire adapted to the Brazilian Sign Language (LIBRAS) was elaborated from interaction with teachers/interpreters of LIBRAS and people Deaf TUTAForm comprises questions for collecting data about the user profile, their level of satisfaction and emotional state after the use of the resource under evaluation. In order to verify the suitability of TUTAForm with its potential user, experiment were carried out to observe the interaction of a two groups of 5 deaf participant in the use of the fork game in datilology and use VLibras-Mobile, followed by the application of TUTAForm. As a result, a good understanding of the contents was perceived, however suggestions were made to improve the representation of some options of answers, due to the confusion to understand the scales used to define levels of schooling and deafness, for example."
4588;en_US;"Learning a gesture pertains to learning a expression of motion by a human, involving the hands, arms, face, head, and/or body. In this work, we propose to employ haptic feedback as an additional tool in the gesture following/evaluation loop. Accordingly, the user wears a haptic wearable device in the form of a bracelet which vibrates according to the trajectory error. Our research hypothesis is then to investigate whether such haptic device aids the user in correcting his movement in relation to the prerecorded trajectory."
4589;en_US;"Advertisements using video content (video ads) are currently one of the leading forms of revenue on todays Internet. Within this setting, we present the first study that sheds some light on understanding why individual user view or decide to skip video ads. Unlike previous related efforts, which looked into aggregated sets of data and did not address the user actions and experiences when exposed to video ads, we here perform a user experience focused investigation employing surveys and diaries with a set of real YouTube viewer. Our study is driven by the following research question: How does the user experience, when exposed to video ads, affect the user actions (decision to skip or watch an ad)?"
4590;en_US;"Nowadays, there are a lot of technique to evaluate the hedonic experiences of user with the use of technological products. The main problem is that, the fact that these technique use different denominations for each type of feeling they can collect, make hard for evaluators to identify what exactly each technique can evaluate. Moreover, it is important to know the potential of each feeling, so the evaluators can choose the most appropriate technique for each type of evaluation. looking on that way, this article presents a new approach to identify the feelings that each User eXperience (UX) technique manages to encompass and what its potentialities are. The result of the study are promising, having as a legacy the description of the approach and the result of the evaluation of five UX technique based on a self-report questionnaire."
4591;en_US;"The Web presents an extensive information content available to diverse people, with different abilities and needs. For this reason, the evaluation for the universal accessibility and the usability are difficult tasks, even though having automatic tool to support them. In this context, it is also observed that the relationship between usability attributes and accessibility is too little explicitly considered, consisting of a research issue to be investigated. To support the integrated evaluation of accessibility and usability criteria, it was developed an environment for analyzing result of accessibility and usability assessments, thus allowing human evaluation, and the inclusion of evaluation result generated by semi-automatic tool, leading the evaluator to produce improvements on both fronts. We performed a case study, in which we observed the difficulties of inexperienced developers related to the description of the guidelines documented by the W3C and the U.S. Department of Health and Human service (HHS). The cost for ensuring the objective criteria was the number of criteria to be checked, which tends to be high, leading to excessive time to review the application, but the experience in considering the concepts related to accessibility and usability, in the same environment, was positive."
4592;en_US;"Internet of Things is a paradigm in which sensor, actuators, device or things seamlessly interact with each other to achieve common goals. Such interaction is reachable if an expressive, interoperable and lightweight representation of context information exists. The literature has recommended ontology as the main formalism for context information representation, but depending on the ontology being used it can be complex and heavy to run on resource-constrained device. This paper presents a mobile service which represents context information using the emergent IoT-Lite ontology. An experiment with such service is performed in terms of time behavior and memory utilization when representing an increasing amount of data. result demonstrate our service is lightweight if considered the amounts of time and memory spent for representing ontology-based data even in a resource-constrained device."
4593;en_US;"Visual monitoring is an important service for various emerging and traditional application in the Internet of Things (IoT) field, since still image and video streams can be gathered and processed for different kinds of multimedia-based tasks. Frequently, a set of targets may need to be covered by interconnected cameras, providing concurrent multiple views under different perspectives for the application, besides enhanced resistance to camera failures. In this context, if targets have different monitoring priorities, the configuration of the cameras can be optimized, demanding proper algorithm to maximize redundant coverage over more relevant targets. This paper proposes a lightweight greedy algorithm and a costly but more effective evolutionary algorithm to optimize redundant visual coverage by cameras, both aimed at reduction of uncovered targets and maximization of redundant coverage over the most relevant targets, which may improve the overall quality of different visual IoT application."
4594;en_US;"Mobile live streaming is expected to increase significantly in the coming years. However, general changes in infrastructure, Internet access, and user device may have created a gap between the current understanding of the transmission and the real problem, considering that video streaming is one of the most popular Internet application. This work proposes, from the log files of a large CDN, to evaluate which factors most influence the quality of transmissions of mobile user in popular live video transmissions."
4595;en_US;"Mobile computing provides new ways to help people in daily routine through ubiquituos, collaborative and social computing. Herein, we combine collaboration with ubiquitous and pervasive sensing to provide a service that helps on prediting waiting time in service queues. We argue that combining GPS information with collaboration can improve queue waiting time prediction. Our experimental evaluation uses an actual minimarket service queue, achieving a mean error of 59.56 seconds for predicting queue time in queues with observed waiting time from 120 to 240 seconds. Our result show that this tool could be useful and can be extended for other different classes of service queues."
4596;en_US;"Through the IoT and Internet application integration emerges the Web Of Things (WoT). Currently, WoT solutions generate data that can be used for decision making. Among the technique of data flow analysis, one that has gained prominence is Complex Event Processing (CEP). Considering a WoT device may have connectivity, memory and processing power enough to perform CEP locally, it is possible to reduce the response time of data processing as a whole. Based on this premise, this work investigates the execution of a CEP system in an WoT device, analyzing the CPU and memory consumption in three scenarios: Mist (in the device itself), offloading in the Fog and offloading in the Cloud through WebSocket and HTTP protocol. The result show we can run CEP code on a WoT device, but its performance depends on the time window processing and the throughput of the data that reaches the device."
4597;en_US;"Human Activity Recognition (RAH) has become a field of high interest and relevance in the Context Awareness area. When knowing what the user is doing a system can provide good information to increase the quality of the delivered data. Commercial smartwatches and smartphone contain several sensor that can sense an userś movement and help identifying which activity an user is performing in a certain moment. In this paper we compare the smartwatch and the smartphone on human activity recognition, observing accuracy and comfort while user are practicing fitness activity. While analyzing the result of the comparative experiment executed between a Smartphone and a Smartwatch, the second one showed to be a good choice on a qualitative and a quantitative way which can form the basis of new a fitness application, including application that automatically track the activity done."
4598;en_US;"This work aimed to characterize how Instagram Stories supports the sociability among its members and to discuss the impact of this proposed sociability in the social interaction of user. We conducted this research in three steps. First, we executed an evaluation in a perspective of Human-Computer Interaction (HCI) experts, which aimed to analyze whether the feature offered by Instagram Stories are adequate to user experience (UX) and sociability guidelines. Next, we performed an evaluation from the user perspective, in order to investigate user experience while they are interacting through Instagram Stories. Finally, we made a triangulation of the result and we discussed the impact of Instagram Stories in the social interaction of user. The result showed that the interface and interaction model of Instagram Stories reflects directly on the experience of use and sociability of its members. As contributions, we present recommendation and insights to HCI community about the design and evaluation of ephemeral communication service."
4599;en_US;"Online social network (OSNs) have become an extremely relevant way for modeling social interaction among people in a group or community. A comprehensive set of studies has analyzed how to predict which new interaction will occur between the participant from OSNs. The problem of predicting new interaction is formally stated as link prediction. Most studies related to link prediction is based on similarity functions that use data from different types such as topological (data about the network structure), temporal (chronological interaction data) or contextual (participant and link attributes), usually available on OSNs. However, none of those studies uses the different types of data simultaneously, leading to poor incorporation of the different aspects of the OSNs in link prediction. To address this issue, the present paper introduces a new similarity function called Context-based Time Score (CTS), which combines topological, temporal and contextual data to improve accuracy in predicting the occurrence of new connections. experiment with ten different dataset revealed that CTS can outperform similarity functions that do not take the three types of data simultaneously."
4600;en_US;"Sharing economy represents activity between people to obtain, provide, or share access to goods and service, coordinated by online service. Airbnb and Couchsurfing are examples of sharing economy, where user offer hosting service in their own houses to the public. In both service, guests can review accommodations. In hosting service of the sharing economy, there is personal contact between those who offer and contract the accommodation, which can affect user decision to make negative review. This is because negative review can damage the offered service. To evaluate this issue, we collected review from two sharing economy platforms, Airbnb and Couchsurfing, and from one platform of the formal economy that work mostly with hotels, Booking.com, for some city in the United States and Brazil. We performed a sentiment analysis in the shared text and found that review in the sharing economy tend to be more favorable than those in the formal economy. This can represent a problem in those system, as an experiment with volunteers performed in this study suggests. In addition, we present some of the main feature of these comment, as well as a proposal on how to exploit the result obtained."
4601;en_US;"Patient-oriented medical social network aim to help their user, with different levels of knowledge, by providing information and support on specific medical and health issues. As one of such pioneering network, the MedHelp includes forums which allow interaction between user seeking health and medical information with other user who know or live in the context of the information, so they can share their experiences. However, there is no explicit control over what is being answered by user. Therefore, filtering and sorting the answers are fundamental tasks. This work presents PERank as a method and a tool which aim to order answers to questions on forums of medical social network. By manipulating document about Type 1 Diabetes disease, experimentation result demonstrate the feasibility of PERank for a low number of best-ranked answers being analyzed."
4602;en_US;"In social network, the relationship between individuals is defined by many forms of interaction. Here, our goal is to measure the strength of the relationship between GitHub user by considering social and technical feature. Thus, we model GitHubs heterogeneous collaboration network with different types of interaction and propose new metrics to the strength of relationships. The result show the new metrics are not correlated, bringing new information to the table. Finally, these metrics may become important tool to determine user influence and popularity."
4603;en_US;"Twitter is a microblog which contains large amounts of user who contribute with message for a wide variety of real-world events. It is possible to identify user who share interests using the message published in their timeline. However, this task is an exhausting process because the algorithm has to analyze all user message. In this project, we propose a semantic recommendation system based on SWRL rule to recommend accounts to be followed or unfollowed. In order to evaluate the recommendation, we conducted an experiment with real user. The result show that 80% of the recommendation were generated to unfollow and 20% to follow some account."
4604;en_US;"With the raising of social network and social sensing, several method and application focused on urban and economic analysis emerged to assist urban planning and business solutions. Thus, the inhabitants of a city share social data according to their context, acting as sensor. In this way, location-based social network have become important because they associate social data with precise locations, which allows promising studies. In this work, we present a method of popularity analysis in urban regions through Foursquare, using the concept of functional regions. For this, we used 204,737 check-ins for 2 years from the same locality for a case study. In this way, we consider not only the main functions of each region, but also the secondary functions. We also present a machine learning model in which a neural network is used to define strategic regions for venues considering not only the subcategories of Foursquare, but also the macrocategories."
4605;en_US;"In Brazil, 48% of the population use WhatsApp to share and discuss news. Currently, there are serious concerns that this platform can become a fertile ground for groups interested in disseminating misinformation, especially as part of articulated political campaigns. Particularly, WhatsApp provides an important space for user to engage in public conversations that worth attention, the public groups. These groups are suitable for political activism and social movement organization. Additionally, it is reasonable to assume that a malicious misinformation campaign might attempt to maximize the audience of a fake story by sharing it in existing public groups. In this paper, we present a system for gathering, analyzing and visualize public groups in WhatsApp. In addition to describe our methodology, we also provide a brief characterization of the content shared in 127 Brazilian groups. We hope our system can help journalists and researcher to understand the repercussion of events related to the Brazilian elections within these groups."
4606;en_US;"Nowadays, anyone with an initial idea can become an entrepreneur. But experts advise that the idea be well thought out before applying it to the market. The analysis of business competitors is one of the ways that helps the entrepreneur devise strategies to seize the market. However, the manual process of this review is time-consuming and tiring. Considering the great interaction of company and their clients in social network and Internet application, this work presents LISE as a solution. This solution is a system developed to automate the process of analyzing competitors, using the application of Google Maps to collect data of the competitors of the locality that the entrepreneur wants to develop his company. As an expected contribution, this paper intends that this tool helps entrepreneurs to analyze their competitors quickly and easily."
4607;en_US;"The combination of data from sensor embedded in vehicles and smartphone promises to generate great innovations in intelligent transportation system. This article presents Driver Rating, an application to evaluate the behavior of drivers based on the data gathered from vehicles and smartphone sensor. The Driver Rating application analyzes five variables (fuel consumption, carbon dioxide emission, speed, longitudinal acceleration, and transverse acceleration) to evaluate drivers behaviors while driving. In order to test the Driver Rating application and identify its potentialities, an experiment was carried out on an urban environment, showing good result regarding the classification of drivers behavior."
4608;en_US;"Hypermedia content consumption has grown due to recent technological evolution, such as communication protocol and technique. Developing hypermedia application has become increasingly challenging because authoring tool have limited resource for the debugging task. Thus, this work aims to propose an architecture for the presentation engine focused on the development and debugging of these application. The architeture is agnostic regarding the hypermedia model used by the content author. For this, the architecture is based on events, allowing the communication between its components to be monitored or even synthesized. In this paper we present how the architeture can be instantiated over the Qt framework. In addition, a specialization of the propose architecture is presented taking the NCL language as a the underlying model."
4609;en_US;"The smart city concept envisions the use of a plethora of system providing different data and service to assist public agent in making strategic decisions for the city based on reliable information. However, the high heterogeneity and lack of standardization of these system and their data challenge the development of value-added application, which can be enriched with geographic information to allow for more effective actions over the real-world urban space. This paper introduces Smart Geo Layers (SGeoL), a geographic-layered data middleware platform conceived to integrate data provided by heterogeneous source in a smart city environment. Besides easing such an integration, SGeoL allows correlating data with geographic information and it provides functionalities such as data aggregation, visualization, query, and analysis. This paper also presents the use of SGeoL in the development of a urban planning application as well as result of some computational experiment aimed to assess the performance of the platform."
4610;en_US;"Advances in telecommunications and the arrival of mobile phones in the hands of population allowed expensive sensor to become much more accessible to the masses. As a result, research focused on the use of such sensor has also grown. This increase has shown the ability of such device to collect their user day-to-day data, enhancing daily activity. However, a bad practice was developed in the midst of these findings. The vast majority of the work involving mobile technology and the use of its sensor recreates the algorithm used for data collection, cleaning, normalization and/or presentation. These work generate a loss of reuse of technologies already created and already executed, just for the sake of customization of the application. This work offers a platform in which the objective is to modularize the steps that are repeatedly recreated in these project providing a certain degree of customization."
4611;en_US;"The text mining literature shows a growing body of work concerned with the automatic identification of sentiment in text. Sentiment polarity classification is one of the most important text mining tasks. The typical approach to polarity classification uses lexicons to count word usage from linguistic or emotional aspects. One of the most widely used lexicons is the Linguistic Inquiry and Word Count (LIWC). LIWC assigns word to categories (e.g., positive emotion) based on a lexicon of word associated with psycholinguist categories. It has been widely used in polarity classification task with good result. However, it only accounts for word count, discarding the text structure and ignoring important semantic relationships between word. In this work, we present LIWBC, an algorithm to count bigrams using the lexicon provided by LIWC. The goal is to incorporate text structure information to improve the polarity classification task with LIWC lexicon. We conducted experiment to evaluate LIWBC with two real dataset: the first one consists of blogger posts; the second one is the movie review dataset, which contains full-text movie review from IMDB. Both dataset were processed with LIWC and LIWBC. After that, we ran four classification algorithm in the data processed by LIWC and LIWBC. The SVM algorithm executed with LIWBC data yielded the best result in both dataset. The F1 score of SVM in blogger posts and movie review dataset had an improvement of 2.2% and 2.5%, respectively."
4612;en_US;"All over the world, analog TV system are being replaced by digital schemes, which, besides having better image and sound quality, can provide user interaction via an interactivity middleware. NuGinga is a web driven solution of the Ginga-NCL standard adopted in Brazil and other countries in South America, delivered on some digital TV capable device from Latin America since the beginning of 2018. This paper intends to give an overall architecture description of NuGinga solution, a brief resume of some other solutions, and why developers have chosen such approach."
4648;en_US;"Quality is a crosscutting element both to the software development process and to the products and may be analyzed under different perspectives. The MPS.BR is a model that aims to improve quality in software process. It was observed that these qualities are related to the characteristics of the Software Transparency model, demonstrating that the quality of Transparency is a driver of improvements in software products and process. In this work the relations of the process of Organizational Process Definition, present in Level E of the MPS.BR, with the characteristics of Software Transparency, are investigated. Based on the identification of the qualitative relationships, some operational procedures are proposed to both instantiate the MPS.BR process and increase its Transparency degree."
4649;en_US;"Today, the inefficiency in the dissemination of the open data related to the prices of medicines by the Brazilian government to the population is a critical social issue. It is especially true if we consider the constant occurrence of the ever increasing price of medicines in the country. Thus, to assist Brazilian citizens to find the maximum allowed price of the medicines, we developed a web application that uses the distributed computing, open data and Human-Computer Interaction technique to aid them. This paper presents our work presents FarmaJusta, discusses of the adoption of these technique, and analyses the access and usage of the application considering a large set of anonymous user."
4650;en_US;"The understanding of public service process by citizens is a complex task, because they do not know how these service work and the institutional challenges when performs them. Aiming the improvement of that understanding, serious game could contribute, once these game have the potential for teaching and engaging players in many different context. Therefore, this paper presents the initial result of scientific initiation project, which is grounded in the digital game design for public service process."
4651;en_US;"During the last decades, a serie of cutting-edge Information and Communication Technologies (ICTs) gained momentum in industry and academia. Including several technologies such as the Internet of Things, Clouds, and Smart sensor, to name a few. As a digital paradigm that fosters decentralized planning and control along with mass personalization in manufacturing, Industry 4.0 is currently paving the road to a fourth industrial revolution. In this paper, we depict important challenges in this context of ICTs and mass personalization of Industry 4.0, ambitioning the achievement of conflicting production goals of price and customization. In our holistic vision, we discuss these challenges under both the prisms of computer science and production engineering."
4652;en_US;"Smart campus concept is related to the improvement of the quality of life of different groups that share spaces and service in universities. Social, organizational, and technological factors must be considered when building solutions and leveraging a smart campus. This work presents smart campus concept under the perspectives of innovation ecosystem, digital ecosystem, software ecosystem, and system of system. We expect that such perspectives help identifying challenges and opportunities related to smart campus deployment."
4653;en_US;"Sexism is a prejudiced behavior or discrimination based on sex or gender existent in digital game environment and system requirement can consciously, or not, enable it. In a previous work, the worlds most played and disseminated online digital game presented a great number of sexism cases reported via a questionnaire referring to sexism in digital game, being highlighted as most negatively cited by respondents. This work aims to provide an understanding about this fact by analyzing the technical aspect of the non-functional aesthetic system requirement of the game to validate the presence of sexism. Concluding, sexism is present in the analyzed aspect of the game."
4654;en_US;"Floods are defined as hazards caused by water flow abnormal behavior. In the present work, we evaluated a platform to study hydrological disasters caused by water flood in urban regions. MOHID (Modelagem Hidro- dinâmica - Hydrological Modelling) computational platform is presented as a system to simulation the model of water flow and runoff in mountainous urban watersheds, allowing simulation of different scenarios. The importance of computational modeling and simulation as auxiliary tool for disaster risk reduction is discussed, showing MOHID as a system to decision support. simulation result are presented for a real case-study with data from the Bengalas River watershed, in Nova Friburgo region."
4655;en_US;"Among the various problem faced by clinics and doctors’ offices, it is worth noting the no-show of patient at their scheduled exams. In a scenario with high volumes of data, where the analysis of patient profiles becomes a non-scalable task to be done manually, a data sampling algorithm was proposed to assist the work of patient classification algorithm, in order to predict patient who will or will not attend the exams based on data from consultations and previously obtained patient. result pointed out that a balanced sampling and using the proposed algorithm was crucial for a good result achieved by the technique of machine learning classification when compared to a randomized and random sampling."
4656;en_US;"This paper proposes the generation of generic test cases from UML model annotated with OCL constraints. The proposal applies a Boolean satisfiability-based UML/OCL model validation technique. The application of the process of validation of the UML/OCL model is performed through the USE tool and its extension called ModelValidator. Two quasi-experiment were carried out in order to test the viability of the approach. Initial result indicate the usefulness of test case generation approach to structure and range of values of a system under test, considering class model of little complexity."
4657;en_US;"The following article describes small crops monitoring system working process in the light of precision agriculture (P.A). The equipament was build based on Internet of Things (IoT), with its sensor conected to a wifi microcontroller, wich sends all the data gatered to a Monitoring Center where the information is saved and showed to the user. This way, one can take notes from all the possilities, in a cheaper and precise manner, making it possible for the user to do external measures do increase the productivity and quality of the monitoring crop."
4658;en_US;"In Brazil, almost 500 thousand people under 20 years old suffer with autism. This chronic disorder is characterized by symptoms like language disorders, difficulties to communicate, repetitive behaviors, amongst others. Educational ludo game, executed in computer or mobile device, are presented as alternatives to improve the quality of life of patient with ASD, teaching them new skills that will assist them in the execution of their daily activity. In this work, the importance of this type of approach is discussed, highlighting its contribution to those with ASD and team members participating in the treatment."
4659;en_US;"Brazilians has a free health system named SUS, which has motivated many complaints concerned bad experiences faced by people. This paper shows the result of the analyses about the use of social media (SM) to communicate about SUS. This research is a preliminary study related of how opportunistic colaboration could to enhance the experience of patient of SUS when they need of medical treatment. The result support the initial insight about the use of SM as source of information to support patient when they need to decide where to go in order to get medical support. As a contribution, a set of classes were proposed to cluster message according their content."
4660;en_US;"Educational Data Mining (EDM) may be a very useful technique as much to understand student behavior as to plan and manage government investments in education. EDM helps to analyzes and to expose the hidden information of educational data. Particularly, an important application of EDM is to predict or analyze the student’ dropout. This problem affects several educational institutions in Brazil and the world, and identify its origin has been a relevant research motivator. This paper presents a brief introduction about EDM applied to predict student’ dropout and analyzes some important articles during the period from 2013 to 2018."
4661;en_US;"The use of web application grows in Brazil along with a big number of virtual attacks once this kind of application are usually more vulnerable to malicious user that intend to compromise the quality, authenticity, privacy and availability of the information. Considering this context, it is assumed that web developers must be prepared to deal with these attacks. This paper shows the result of a survey research made through an interview with web developers that tries to measure their level of knowledge about some of the main types of web application attacks and their ability to identify, analyze and correct such threats in vulnerable pieces of source code."
4662;en_US;"This paper discusses the steps of identifying existing technologies that can be used to identify and rescue lost animals and to disseminate animals for adoption by Animal Protection NGOs, the Zoonoses Center and Independent Protectors. For this purpose, a questionnaire was carried out to identify which technologies are used to identify, locate, rescue and adopt domestic animals. In this way the research reports the main technologies used so far and is moving towards the development of a proposal for a system to improve and expand the dissemination of animals that are lost or for adoption."
4663;en_US;"A distributed computing environment provides high processing power to execute elevated performance application and desirable performance for the end user. Warewulf is a clustered environment management platform that provides tool for installing and execution application based on MPI. However, a major weakness of this project is the graphical monitoring of the resource used in the cluster of computer. The objective of this work is to propose a centralized monitoring of the computational resource in network , collaborating to observe the use of these resource in distributed system processing node. It is proposed, to develop an interface to ensure usability and accessibility to the processing node, and to presents the status of each node beyond the global state of the cluster."
4664;en_US;"Several important service with limited resource require uninterrupted support for a vast amount of customers. For example, internet provider, hospitals, distribution utilities and so on. When a customer’s call is received in the proper channels, the reported problem pass through a screening phase in which the operator judge whether or not a support should be sent to the customer. However, not all problem are responsibility of the service provider. For instance, when a distribution utility sends a maintenance team to solve an energy issue that is out of company scope’s, this action generates an improper dispatch problem. Improper dispatches bring high costs regarding fuel and logistics, and can result in heavy penalties to the company. For tackling this problem, we propose RDI, a decision support system that combines supervised machine learning algorithm and model predictive control (MPC) technique. RDI receives customer’s calls information and recommends when a maintenance team should be dispatched or not. Our first result indicate an assertiveness of 83% in the number of true positives (proper dispatches) and a decrease of 51% in the number of false positives (improper dispatches) within a real dataset from the industry. Moreover, RDI is capable of calculating the associated risk of each occurrence and by predicting changes in the current number of unsolved customer’s calls using a Markov chain model. We show how we built this system, how this solution was applied for diminishing dispatch costs inside a distribution utility and possible directions for further research."
4665;en_US;"This article describes the use of Wiki tool in knowledge management in corporate environments. company are looking for alternatives in the collaborative system to disseminate the knowledge acquired by their employees."
4788;en_US;"This paper presents a case study on application of usability evaluation technique like do-it yourself (DIY) in the development of a social network on the web. Through hybrid technique of qualitative data collection was possible to understand some aspects about the quality of the software interface in development. Usability tests like DIY, after the initial software design, have provided useful data for interaction redesign closer to the characteristics of the potential user and, therefore, it was possible to adjust the next iteration of the software development process."
4789;en_US;"Recommender system help user to cope with information overload and have become one of the most powerful and popular tool in electronic commerce. In order to provide better recommendation and to be able to use recommender system in arguably more complex types of application, most of the typical used approaches need significant extensions. On the video recommendation domain, one of these extensions is based in Segments of Interest (SOI), i.e., video segments that the user liked more or is interested. For this work, our intention is to stress and discuss interaction design issues about SOI based video recommender system and discuss the relation between SOI and collective intelligence. We present two approaches to marking SOI on a Web social environment and discuss their advantages and disadvantages, and we show why SOI can be seen as a source of collective intelligence and that information and knowledge emerged from a community that had marked SOIs can be used on consensus decision-making and to bring improvements to society."
4790;en_US;"The advancement of social media technologies has enhanced the Brazilian experiences in e-gov, developing the government process and providing the creation of new policies to connect the citizens with govern. In Brazil, one of these initiatives is the Brazilian Open Data Policy that aims to make information (and its use) by citizens feasible. In parallel, the growth of mobile device popularity and wireless network had allowed the access to the Brazilian government open data in a faster and easier way as well as extending the social web potential. In this context, this paper discusses a preliminary proposal to provide open georeferenced data called GovMobile. Additionally, it is shown a system composed by a Web application (where governmental institutions publish open georeferenced data) and also a mobile application (where these data are available). The contribution is preliminarily to show how the access to information by society is being planned by the government and motivate the publication of open data by government organization to integrate citizens in the process of political and social change."
4791;en_US;"language and Design pattern are concepts that were purposed by Christopher Alexander. The main motivation to draw those concepts is to enforce the conception as well as the reuse of sucessful experiences whithin project. On the other hand, the purpose of this work is to outline an approach where these concepts could be used to share teaching experiences. In other word, guiding through the reusing of pattern of solutions to complex educational concerns such as assessment, motivation and student’ evasion, this work aims to show an way to diminish such gaps."
4792;en_US;"The engagement of user in collaborative system is essential so that user achieve their goals more easily. In this way, this paper aims to investigate the use of gamification to increase engagement of user in collaborative system. Thus, four system were selected, and we examined which technique were used and the result obtained from this. The result suggest that the use of gamification raises the engagement and user experience in collaborative system."
4793;en_US;"Sensemaking activity of social network involve network exploration and representation so, visual tool are designed to support these two activity. Existing social network analysis tool are usually weak in supporting complex analytical tasks and also in providing a collaborative environment for interaction. The analysis of data using a visual tool is rarely a task done in isolation, it tends to be part of a wider goal: that of making sense of the current situation, often to support decision-making. This paper discusses the storytelling design of a software environment to support organization in sense-making activity and to support accidents investigation. A case study ACR-C describes petroleum industry employees investigating the root cause of an accident issue observed in one (or more) platforms. It is used throughout the paper as an example of human computer interaction where the ontology becomes a tool with domain knowledge to assist expert persons building a root cause tree leading to accidents. The framework will also provide with a collaborative recommendation module assuming that the user build up cluster based on their similar analysis in rating of item. A case study ACR-C describes petroleum industry employees investigating the root cause of an accident issue observed in one (or more) platforms. It is used throughout the paper as an example of human computer interaction where the ontology becomes a tool with domain knowledge to assist expert persons buildind a root cause tree leading to accidents. This paper reports the experience gained in ACR-C, a project that aims to support knowledge management (KM), sharing and reuse across different media in oil and gas industry. We report the storytelling design approach adopted and the design phases that led to the First prototype. A user interface was designed to assess how different levels of data, information and knowledge were mapped using alternative visual tool. The result show that a clear separation of the visual data analysis from other sense-making subtasks helps user in focussing their attention and comprehension of root causes of the problem. Further work is needed to develop more fully intuitive visualizations that exploit the richer information and make the multiple connections between data more easily accessible."
4794;en_US;"In June 2013, Brazil witnessed several manifestations different from anything previously seen, since president Collor’s impeachment. However, there is a big difference: now they are organized in few days. With Facebook, physical and virtual communities spread fast and easily organize demonstations. Popular mobilization for mutual concern issues, supported by technology, allowed the gathering of information by collective intelligence. The fanpage of the demonstration and that of the demonstration events in Facebook are studied in this paper, in order to analyze the interaction among user and to identify if this social networking can be considered a virtual community."
4826;en_US;"<p>A software architecture is an organization that contains the structure of a software and the relationship of its components. As a result, software architectures dictate the way software is created and updated. We propose a software architecture to help developers to create Android-based application for user with motor disabilities – specifically. The architecture supports using one or more hardware components of mobile device including built-in sensor, camera and microphone. Also, it encompasses a straightforward way of using and integrating such resource, which may lead to application that provide alternative ways for accessing and managing data by user with disabilities. The solution also provides functionalities to work with raw sensor data, and offers a model for storing medical information of user. An evaluation with 19 software developers indicate that the architecture can be useful for creating not only solutions for people with motor disabilities, but diverse application</p>"
4827;en_US;"Current Web-based service are highly heterogeneous not only on data but also with regard to service interaction. Despite their heterogeneity, composition of these service is required in order to achieve additional functionality. Description language and composition algorithm for heterogeneous service have been recently proposed. However, existing technique do not take the Publish/Subscribe paradigm into consideration or do not offer sufficient support for interaction through hypermedia controls as required by the REST architectural style. Analyzing current heterogeneous composition technique, this dissertation identifies limitations hindering automatic composition of these heterogeneous service. It proposes an architecture and two technique, adaptiveness and replication, that when combined with a graph-based composition algorithm, enable planning and execution of heterogeneous compositions. In addition to supporting heterogeneity, our prototype achieved similar or better performance than two state-of-the-art homogeneous composition algorithm in most cases."
4828;en_US;"The purpose of this paper is to present a methodology to guide a service secure development for agile development teams. The proposal is guided by a Reference Architecture (RA) based on a threat and risk modeling. The methodology predicts emphasis on behaviors that consider threats, attacks, vectors, risks, actors, device, and assets. Into the agile concerns, the RA concerned with presenting a lightweight process focused on the efficiency and reduction efforts for good practices for secure development, considering design and coding, as well as acceptance tests. In its current state, the proposal was validated in two ways, namely: through ten “top threats” catalogs, such as [15, 18]. In addition, applying the proposal as an agile tool for threat predictability and risk control over the source-code. As a result, it was possible to characterizing as a mechanism that provides a guided methodology for threat and risk driven-development."
4829;en_US;"The exception handling has necessary elements for the development of a fault-tolerant Web system. Although, even with its high importance, studies indicate a neglect and low quality of the exception handling development. This research aims to conduct an in-depth analysis of exception handling, exploring human and technical relevant aspects obtained from a corporate environment Web system. We have initiated the first unit of analysis. It regards the developers’ perception of exception handling on an organisation. Among the obtained result, it is possible to realise that the importance of the exceptional flows is recognised, and developers suggest its normalisation would bring benefits to the developed system. During the case study is intended to assess the quality of the exception handling on the target system comparing to the developers’ background, moreover, institutionalise rule to the implemented exception handling."
4830;en_US;"In recent years, many approaches and tool have emerged to assist in the semantic enrichment of Web service. Many researcher have been directing efforts in enriching service descriptions. However, the automatic enrichment of data representations provided by Web service has been of little concern in the literature. This work aims to present OntoGenesis, an architecture capable of constructing and evolving domain ontology for data service and enriching their data with semantic concepts from such ontology. The proposed solution also takes into account external semantic source to enhance the reuse of well-known concepts by means of ontology property matching technique. Preliminary result show the applicability of our approach under a scenario within real-world dataset."
4831;en_US;"The current Web is syntactic and it is impossible for machine to process it. The Semantic Web with its technologies can bring more meaning to web content. UFBA’s IR is on the Syntactic Web and the recovery of deposited item isn’t always done efficiently. Information about the deposited item is stored in their metadata, but it is done manually and, not always, the chosen terms are able to help with the description process. The automatic semantic annotation method would certainly help librarians during the validation of the production’s deposit as well as enabling the recovery of UFBA’s IR item. The main proposal is to create a solution to semantically annotate the academic repository item in a semi-automatic method so to extract relevant terms that will be suggested to annotate the UFBA’s IR item making it a semantic repository."
4832;en_US;"Hate speeches published and difused via online environments have the potential to cause harm and suffering to individuals, and lead to social disorder beyond cyber space. In this context, we propose a novel approach to identify and monitor groups of user which propagate such contents. As preliminary result, we detail a methodology for hate speech identification based on Information Theory quantifiers (entropy and divergence) to represent document. The result show that our methodology overperforms technique that use data representation, such as TF-IDF and unigrams combined to text classifier, achieving an F1-score of 86%, 84% e 96% for classifying hate, offensive, and regular speech classes, respectively. Compared to the baselines, our proposal is a win-win solution that improves efficacy (F1-score) and efficiency (by reducing the dimension of the feature vector). The proposed solution is up to 2.27 times faster than the baseline."
4833;en_US;"The community of volunteer web subtitlers uses pattern that indicate how the subtitle should be created. pattern are defined by each team as part of the creation process. However, the impact of these pattern on the viewer´s experience isn´t known. This work tries to answer the following research question: What are the limits to the synchronization of the subtitles so as not to have a negative impact on the user experience? In conjunction with this analysis, there is also the intention to evaluate the impact generated by the other pattern used for the creation of subtitles. In order to answer this question, a review of the literature was carried out where characteristics were identified about the use of the pattern, both from the perspective of the linguistic and language area, as well as from the multimedia area. Subsequently, an exploratory study was performed with the community of subtitlers that enabled the collection of diverse information regarding the process of creation and distribution of subtitles, the functions and responsibilities, the motivations of the enthusiasts and the pattern used. At the moment a new study is being prepared so that the data necessary for the conclusion of the master´s thesis can be obtained. Therefore, the Webmedia´s community feedback is very important to refine the current research path, leading to a satisfactory conclusion."
4834;en_US;"Multi-device (or distributed) multimedia application are programs designed for exploring multiple device during their execution. Most of these application allow user to interact with them, defining their flow of execution. We argue that current programming approches still lack proper support for developing these application. In a previous work we have discussed the use of the synchronous language Céu for programming multimedia, which has led to the development of the library Céu-Media as a partial result of this work. Now we are extending our work for approaching distributed application. More precisely, we are devising a GALS (Globally Asynchronous Locally Synchronous) middleware that supports the development and execution of multi-device multimedia application and guarantees the consistency between device."
4835;en_US;"The popularization of mobile application enabled the development of solutions for several area such as mobile technologies for healthcare. This study investigates the use of computational resource to support the rehabilitation of patient in therapeutic treatment based on the mirror therapy. The mirror therapy presents relevant result in the rehabilitation of individuals who report phantom limb pain or in rehabilitation after Stroke, among others. The literature reports computational solutions that allow visualization of the healthy limb using conventional expensive augmented reality technologies. This work aimed to investigate a computational solution for the remote monitoring of mirror therapy with the support of low cost augmented reality resource. The result obtained include a computational model for smartphone and Google Cardboard. Mirror therapy specialists considered our contribution of great potential to reach the elderly and children, given their difficulty in focusing their attention when using conventional mirrors."
4836;en_US;"Driving is changing due to more embedded intelligence in cars and to the networking capabilities now rising, making possible that vehicles, infrastructure units, drivers’, passengers’ and pedestrians’ smartphone and any other device communicate with each other. A smart city can make use of the information available due to the connectivity of these device to improve several aspects of its inhabitants daily life, traffic being one of the most important. Excess of information, however, can be harmful in a dangerous environment such as transit, where driver’s attention is key to the safety of everyone in cars and streets. Given this scenario, we propose researching the use of context-aware system to identify the proper information to be provided to human drivers without distracting them from the driving activity, or to autonomous vehicles without saturating them with non-important information, thus reducing the processing power needed and improving the latency and quality of decisions made. In order to narrow the investigation, this work will be focused on the Quality of Information (QoI) to drivers and autonomous vehicles."
4837;en_US;"IoT (Internet of Things) technologies are underway. They allow the inter-connection of physical device (also called smart objects) that are embedded with electronics and network connectivity allowing these objects to collect and exchange data. Smart objects can be used in residential environments turning objects of everyday life (e.g. lamps, thermostats and speakers) into digital products that can emits data about its usage, location and state, can be tracked, controlled, personalized and even upgraded remotely. On the other hand, currently TV device have extended their traditional usage by allowing application such as web navigation, social TV and gaming. This work proposes an approach for integrating the TV with surrounding smart objects through a middleware approach, taking as its base Ginga-NCL, the Brazilian middleware for digital TV, and M-Hub, a middleware that allows the discovery, connection, communication, and data distribution of IoT smart objects. The proposed software infrastructure is evaluated in different usage scenarios that allows: (i) the TV application to modify the surrounding environment through the use of actuators, (ii) to adapt the content being presented according to the perception of the environment provided by sensor; and (iii) to provide new modes of user interaction with the TV."
4838;en_US;"In spite of the increasing processing power of smart handheld device, their capacity is always a few steps behind their contemporary desktop counterparts. Besides, mobile device have limited power supplies, which leads software designers to keep energy consumption in mind. An alternative to help overcome this issue is using the offloading (or cyber foraging) technique, which allows a mobile device to offload an expensive task to another device, for the sake of performance or energy saving. This second device may be a remote server hosted in a public cloud, or in the same Wi-Fi network as the first mobile device (i.e., a cloudlet). This proposal for master’s thesis aims to develop a framework – called CAOS D2D – which allows a mobile device to offload tasks to another mobile device, as well as acting as an offloading server too. We briefly describe the development process of our implementation, starting from another offloading solution developed by our research group. We also describe CAOS D2D architecture, and finally, we define some future work to guide the evolution path of our solution"
4839;en_US;"Recommendation system have become an increasingly present element in the purpose of detecting and recommending important feature to user. The challenge in such system is to present information that is in accordance with interest of the user. For that, they make use of technique for filtering content to associate them to user. In this sense, this article aims to demonstrate an ontology called Profiler User YouTube Wikipedia, which aims to represent and store user´ information, and their digital traits relative to their preferences about video, channels, YouTube playlists and Wikipedia text. This ontology will support the Youubi recommendation system in the search and selection of content associated with the characteristics of the learner."
4840;en_US;"Nowadays it’s observable the increase of web solutions and collaborative system based on wikimaps (WikiMapia.org, Colab.re, Google My Maps etc.). The development of the Buracos Monitor project helped to identify significant challenges of Information Governance, related to this kind of application, motivating the research on the subject. An analysis of similar system is performed, from the point of view of the 3C Collaboration Model and Groupware Engineering, to identify common practices and components of this type of solution. The knowledge acquired, as a result of this analysis and exploratory research, was compiled and presented as the GEORGIE framework. A set of tool and components are listed and described, and a new analysis is presented from the point of view of Information Governance. The validation method of this research was focused on academic acceptance with specialists, and a case study is exposed, describing the use of the framework in the implementation of improvements to the system Buracos Monitor. Finally, It’s proposed that GEORGIE, the result of this research, as fundamental and introductory content for analysts, developers and interested in develop system of this family, and for conducting similar research."
4841;en_US;"Software Defined network enable significant gain in network management through separation of control and forwarding plans. In this work, the authors propose the implementation of a Virtual Patch Panel in order to restrict traffic to certain device in an SDN approach, denoting the management flexibility and security optimization. GNS3 is used as a network simulation tool and OpenDayLight is used as the controller. The installation of rule in the controller is accomplished by different tool: OpenFlow Manager, Postman and cURL."
4842;en_US;"Social network are useful to represent social relationships like friendship and work. In a movie, they can represent the relationship between characthers. These network are called character network. In this scientific initiation, we are interested in analyse the character network of five successful movies at box office: Avatar, Titanic, Star Wars: The Force Awakens, The Avengers and Frozen. The aim is to check if there is some kind of pattern in the social network of these movies. The result show that the character network have similarities that may be related to their perfomance at box office. Furthermore, we show that the analysis with centrality measures and communities detection reflects the main characters and the story’s main nuclei."
4843;en_US;"This study presents partial result of an ongoing investigation, in the context of the project CNPq-UrbComp, regarding the exploration of data from the location-based social network (LBSN) Untappd, which is an LBSN for sharing beer preferences. We explore Untappd data in two main directions. First, in the context of urban planning in Curitiba. Curitiba recently announced the creation of a Craft Beer Street, to promote local beers. By using this as a real case study we investigate a new approach that could help create this kind of attractions. Second, we show the potential to explore the preferences for beer to study urban social behavior, particularly related to the automatic identification of cultural aspects. Automatic identification of cultural differences is a valuable information that can enable new service."
4844;en_US;"The ways of relationship between company and customers have changed dramatically due to web-user engagement with Online Social network, impacting on the way consumers make purchase decisions. As a consequence, this phenomenon brought up a new concept, the Social Customer Relationship Management. In this context, Electronic Word-of-Mouth plays a significant role since customers are more exigent and having easy access to steadily more information about products, service and brands reputation. However, many reputation platforms do not provide an interface for automatic data collection. Thus, these data are not used in business decision making. Aiming to fill these gaps we propose an automatic data retrieval and analysis method to knowledge extraction from Electronic Word-of-Mouth platforms, providing more reliability to the decision-making process. The analysis consists in topic modeling using Latent Dirichlet Allocation to identify most frequent complaints and their correlations. Both, the data retrieval method and the analysis method are platform independent. A well-known reputation platform in Brazil was used to evaluate our proposal, the ReclameAqui."
4845;en_US;"The Social Network Sites (SNS) has become a major source of communication. Through SNS, we can communicate with people who are in many part of the planet and by using the information contained in these sites, we can turn user into social sensor. Based on this, this project aims to compare crime reports collected through social sensor to official police reports. As a case study, we validate our model with real data from New York City. The main result obtained were the training of a classifier with precision of 86% and a classified database with 491.415 tweets. Even with this result, it was not possible to find a correlation between the official dataset and our dataset."
4846;en_US;"VisiUMouse is a solution that enables accessibility to computer’s use by people with upper limbs motor disability. This Assistive Technology uses the concepts of Computational Vision to recognition and face tracking, using the eye as reference point. Through video input, that tracks the eye movement, we control the mouse cursor by webcam, providing an amplification in the functional abilities of these user and, consequently, promoting inclusion. The VisiUMouse was evaluated following the Fitts’s law protocol, which involves common pointing, select and click tasks, used as metrics to verify interaction with the computer. KEYword Computer Vision, Assistive Technology, VisiUMouse, Accessibility, Ubiquitous Technology, OpenCV, Face Tracking"
4847;en_US;"This paper presents the development of IOM4Home, an IoT (Internet of Things) based application for home environment controlling, specially designed for people with motor disabilities. The main goal is to provide a software/hardware solution that relies on IOM (Interface Óculos Mouse) to control home environments. IOM consists in an Assistive Technology based device used to control a computer in a hands-free way. To achieve this objective, this paper details a proposal composed by two main elements: an assistive Interface designed especially for IOM; and an IoT system to manage and exchange data between the available home domotics and the developed interface. The paper also presents a test scenario, highlighting the main result obtained with the evaluation. Finally, the article presents its conclusions and the future developments of the project"
4848;en_US;"Accessibility is an important challenge to be faced during the designing of new application, functionalities and technologies. To identify whether the feature developed conform to user´ characteristics and expectations, usability testing and user experience assessment are common alternatives. These practices are even more necessary when user have some type of disability (sensory, motor, cognitive, intellectual, etc.), because their participation is often neglected in the design process. In this paper, we present a practical case of usability testing and user experience evaluation with the VLibras mobile application, an Assistive Technology for deaf user. This evaluation was carried out with five deaf user, literate in Libras. The result indicate a good acceptance of the mobile version of VLibras, but also indicated the need to make some adjustments in the interface to improve the comprehension of textual elements."
4850;en_US;"In the scientific literature, there are several solutions developed for machine translation of digital contents into sign language. Generally, these solutions aim to reduce communication and access to information barriers for deafs in Information and Communication Technologies (ICTs). One of the main challenges of this type of system is the creation of visual representations (animations or video) for the signs of the language, generally thousands of signs, which is a very time-consuming task. Thus, in this work, we propose a process (or methodology) for the semi-automatic construction of sign language dictionaries. This process combine automatic tasks, such as motion capture (e.g., using Microsoft Kinect) with manual tasks involving 3D animators and sign language specialists. To evaluate this proposal, a case study was developed for the Suíte VLibras platform, an open-source machine translation platform to Libras. The result was the creation of a Libras dictionary with more than 13,000 signs which is currently used in more than 1500 websites."
4852;en_US;"Multimedia application involve the development of tool for creating and digitizing multimedia contents and their distribution through communication network. tool that appear in different domains of application and offer service increasingly present in our daily life. For example, museum spaces that use the digital medium as an expansion of their physical limits. This paper presents a tool for managing digital collections of academic museums. The tool allows the user, at different levels, the manipulation of collections and their parts. In addition to facilitating the management of content, the tool feeds the database available to the general public, thus acting in the dissemination of content."
4853;en_US;"This paper contains a comparison between some market consolidated device which use a Human–Computer Interface through the user’s natural actions (Natural User Interface), such as gestures and speech. The goal is to identify their main functionalities, so that they are used later on to define the requirement needed for developing project with similar characteristics. The idea is to also gather this information so that it is possible to compare these marketed device to the developing project called Interface Óculos Mouse (IOM). IOM uses a Natural Interface to allow physically challenged user to control the cursor through head movements. This study will verify which feature still need to be developed in order to make the IOM prototype an industrialized product."
4854;en_US;"This work discusses the development of a new platform and mobile application (app) to minimize the problem of lack of blood donation. In order to do this, interviews were conducted with blood bank professionals and we perform a specific research to identify the best solution for this problem, which can be considered one of the most important demands for Brazilian Health Service. We design and develop a electronic platform, containing a Web and a mobile application (#PartiuDoarSangue) whose main characteristic is to connect donors to those who need blood donation. Through this platform it was possible to identify a great acceptance from user, providing a tool to centralize the donor registry and link them to those who need donation, besides allowing a greater diffusion of this cause. The platform achieved its goal, as demonstrated by our real validation blood donation campaign and it is available in all Brazilian Federal Units."
4855;en_US;"The growth and popularization of the Web has enabled several solutions of what has called e-democracy or cyberdemocracy. The most frequent manifestations of cyberdemocracy occur in the interaction between the political system and citizens, in particular mechanism such as direct participation and debates, which tend to facilitate and amplify citizen participation in view of the direct interaction that facilitates and the removal of Geographical limits for participation. This work presents the proposal, implementation and evaluation of an analytical intelligence platform for the social participation process, which contemplate all the traditional steps of the process of knowledge discovery in databases. The tool was validated using actual data from a public consultation about Personal Data Protection."
4856;en_US;"In spite of the increasing processing power of smart handheld device, their capacity is always a few steps behind their contemporary desktop counterparts. Besides, mobile device have limited power supplies, which leads software designers to keep energy consumption in mind. An alternative to help overcome this issue is using the offloading (or cyber foraging) technique, which allows a mobile device to offload an expensive task to another device, for the sake of performance or energy saving. This second device may be a remote server hosted in a public cloud, or in the same Wi-Fi network as the first mobile device (i.e., a cloudlet). This paper presents CAOS D2D: a framework which allows a mobile device to offload tasks to another mobile device, as well as acting as an offloading server too. We briefly describe the development process of our implementation, starting from another offloading solution developed by our research group. We also describe CAOS D2D architecture and provide a small usage example with code snippets. And finally, we define some future work to guide the evolution path of our solution."
4857;en_US;"An event is defined as “a particular thing which happens at a specific time and place” and can be extracted from news articles, social network, forums, as well as any digital document associated with metadata describing temporal and geographical information. In practice, this knowledge is a digital representation (virtual world) of various phenomena that occur in our physical world. The manual analysis of large event collections is not feasible, thereby motivating the development of intelligent data analytic tool to automate the knowledge extraction process. In this paper we present a computational tool called Websensor Analytics that uses machine learning method for learning sensor from events to monitor and understand various phenomena in the real world. Websensor Analytics is the first initiative to analyze events in Portuguese and currently contains all the necessary feature for extracting and analyzing knowledge from events: (i) web crawling to collect events in real time, (ii) statistical and natural language preprocessing technique for event extraction (iii) machine learning method for learning sensor, and (iv) Application Programming Interface (API) using the Websensor Analytics infrastructure. The Websensor Analytics tool is potentially useful for media analytics, opinion mining, web engineering, content filtering and recommendation system – for both academic research and industrial application."
4858;en_US;"Increasingly powerful and miniaturized mobile computing device have been used in many area and new possibilities of Internet of Things (IoT) have been created. In this context, there are wearable device. They are characterized as intelligent device, equipped with sensor sending signal to components, in the form of clothing or accessories, used near the user´s body. The sports area benefits with these device, relating to data about the performance and health of the practitioners. The provision of this collected information is important, however, much of the device collect and make available data individually, not allowing a macro view of groups and teams. The objective of this work is the construction of a prototype vest for the data capture of sportsman, together with an application able to evidence the information, meeting the demands of individual and collective sports, validating its relevance as an aid platform for decision making to health professionals and/or technical staff."
4859;en_US;"Nowadays, epidemiological surveillance is the main challenge in the Brazilian public health system due to the problem to maintain information in real time about disease. In this context, dengue, zica and chikungunya are increasing disease and the number of cases in different regions is not updated in real time neither presented in an easy way. Consequently, the Brazilian government has the constant challenge to efficiently distribute public health resource in the locations for the high number of dengue cases. Therefore, this paper presents DENGOSA, a low cost web system that analyzes the number of dengue cases by region as well as presents epidemic regions in maps. Finally, DENGOSA provides interoperabilty service for the system communication and optimizes the decision-making process for the managers of public health system. Besides that, it is flexible to provide service to notify the population about epidemic regions."
4860;en_US;"In this work we present Agro 4.0 , a system that receives data such as soil quality, water quality, pesticides utilized, farming and agricultural activity -, carefully collected by a rural technician from one or more rural properties and evaluates those properties according to the aspects of an agroecosystem regarding sustainability. The collected data is used by the system to compute indicators used to generate a Sustainability Index for each rural property. The data and indicators also feed statistical model, through data mining technique, to aid in the extraction of useful information about the relation between the collected data and the indicators obtained. With this information in hand, the rural proprietaries have relevant and quantitative information to aid them in making decisions and taking actions to increase their properties’s sustainability."
4861;en_US;"In Brazil, cancer is the first cause of death due to illness among children and adolescents from 1 to 19 years. The Brazilian National Cancer Institute (INCA) estimates about 12,600 new cases of childhood and juvenile cancer in 2017. Although childhood and juvenile cancer is potentially curable, it is necessary an early diagnosis and urgent treatment. In this context, this article presents a Web system that assists health professionals and managers in the decision making process in order to optimize the treatment of children and adolescents with cancer. Since 2016, the system has been used at the Peter Pan Association (APP), an association for the Fight Against Child and Adolescent Cancer, located in Fortaleza-CE. The large volume of data collected by the system is organized, analyzed and monitored to feed reports, dashboards with flags and alerts, as well as spatiotemporal maps. We show how the proposed solution can contribute to increase the cure rate and improve the quality of life of children and adolescents with cancer and their families."
4862;en_US;"This paper introduces CrowdNote, a crowdsourcing environment for complex video annotations without the need for trained workers or specialists. CrowdNote is based on a cascading microtasks approach to achieve complex video annotation by aggregating and processing multiple simple annotations collected from the crowd. The approach consists of dividing complex annotation tasks into simpler and smaller microtasks and cascading them to generate a final result. Moreover, this approach allows using simple annotation tool rather than complex and expensive annotation system. Also, it tends to avoid activity that may be tedious and time-consuming for contributors, that are the workers in crowdsourcing scenarios. The CrowdNote instance presented in this paper produces enriched video in which all extra content added is provided, selected and positioned by the crowd."
4863;en_US;"The FrameWeb method defines a standard architecture to facilitate the integration with widely-used Web development framework, proposing a set of model that bring to architectural design the concepts inherent to these framework. In this paper, we present the FrameWeb Editor, a CASE tool built on top of the meta-model that define the syntax of the FrameWeb language, providing a graphical editor for the creation of valid model in this language and serving as foundation to other functionalities such as, e.g., code generation. The tool has been successfully used to model project in the context of student course assignments, showing potential for its use in industrial settings."
4864;en_US;"With the growth of multimedia content available on internet to user, music playlist generators is gaining importance nowadays. People search for ways to generate enjoyable playlists satisfying their tastes, and that suit the situation in which they are. Although many authors have proposed method to generate music playlists satisfying certain restrictions, defining the qualities a good playlist should have is a difficult task. This paper revise and presents the implementation of a general method presented on literature that generates heterogeneous music playlists based on a simple input given by the user. The method was constructed to satisfy five quality constraints: heterogeneity, smooth transitions, novelty, usability and scalability. The tool is available on a website, where is posible to choose between two algorithm named ROPE and STRAW, and listen on YouTube to the playlist generated."
4865;en_US;"Online Social network are more than a source of large amounts of data, but a potential treasure for company and institutions that seek information about how they are perceived by their audience. Sentiment Analysis (SA) is a technique that allows the automatic mining of opinions, which can be applied in this context. However, such approach faces many challenges reported in the state of art. Among those, there is the lack of labeled dataset for sentiment classification algorithm. This work presents a platform for SA annotation, with crowdsourcing (CS) and gamification principles, aiming to solve this challenge. Differential aspects of this tool are the possibilities of labeling data for fields related to SA, such as emotion and subjectivity tagging, besides other common tasks in the area, planned to be added in a future version of the tool."
4866;en_US;"The purpose of this paper1 is to show an architectural project to develop an application that aims to connect data from existing plants to available repositories on the Web, generate content and provide the mapping of these plants and museums, herbariums and research institutes engaged in studying them, highlighting their collaboration network. To this end, the ETL tool Knime was used, with the aid of LOD technology and open data extracted from GBIF, in order to provide an automatic method for creating dynamic pages where information of medicinal plants can be viewed and the mapping of the collection linked to the plant image in association with the related research institutes, providing user with a wide view of the georeferenced area."
4867;en_US;"Currently, with the popularization and maturation of the Web, the Internet is seen as a service platform, and the physical objects used in daily life start earning computational capacity. This objects become addressable and are used to identify and provide information on the web for the environment to which they are inserted. In this context, the paper presents a model that uses IoT concepts for notification of resource state changes and the integration of service into Home Care Smart Environments."
4868;en_US;"The number of research area that model information through ontology is increasing, but there is an absence of publications referring to the persistence of these data model. Taking into account that the use of suitable managers for its storage could be a key factor to the scalability of application, it is perceivable that an analysis of said managers is necessary. Therefore, this work presents a comparison based on query execution time in three triplestore database managers. AllegroGraph, Stardog, and Virtuoso were analyzed using the WatDiv benchmark. In the performed tests, Virtuoso achieved the best performance in the vast majority of the query."
4869;en_US;"people around the world to daily record and share they activity, tastes and habits making them accesible both by other user and potential researcher. Analyzing the activity of the members in those network, it’s possible to identify shared behavior pattern that determine the formation of virtual groups of people who are culturally close even not knowing each other, and whose boundaries cross over the political and natural borders of countries in the real world. In this paper, we propose the development of a information model capable of explain how those virtual groups are formed and what is it’s connexion with typical cultural habits that define certain countries and societies."
4870;en_US;"Monitoring environments is a increasing need in different context, such as emergency, safety and health. Obtaining the location of people and setting the best route to evacuate a burning building; restrict access to an environment only to authorized people; or monitoring seniors or people in medical treatment in their homes are necessities in these three context. Thus, monitoring by identifying and locating people indoors is still a nontrivial task considered by some as an open challenge. The difficulties in identify and locate people result from the lack of precision of the various sensor and the cost to getting it. This project aims to develop a solution based not only on the usual sensor but also through the collaboration of people as sensor to help detect other people. The objective of this paper is to show that the human factor can be the difference in increased precision of identification and detection system people in indoor environments."
4871;en_US;"This paper presents a systematic review of the literature on the subject of continuous offline voice recognition for Android mobile device. We examined 222 articles from four digital repositories, which followed a methodology containing search questions, search expression, and inclusion and exclusion criteria. After reading the abstract, introduction and conclusion, 12 articles were selected and synthesized through answers to the research questions. Based on the synthesis, we provide information on how to select the best practices for neural network utilization, and also suggest technique for reducing error rate.1"
4872;en_US;"The use of information system to aid in the practice of medicine is currently under study, aiming to evaluate its possibilities to improve the quality of patient care. Among the application for this purpose, it is possible to highlight those that focus on the extraction of characteristics in medical text and image. This work proposes a model that uses different input formats with the objective of providing, in an integrated way, support to the doctor or specialist."
4873;en_US;"We propose a software architecture to help developers to create Android-based application for user with motor disabilities – specifically. It supports using one or more hardware components of mobile device including built-in sensor, camera and microphone, and encompasses an easy way of using and integrating such resource, which may lead to application that provide alternative ways for accessing and managing data by user with disabilities. The solution also provides functionalities to work with raw sensor data, and offers a model for storing medical information of user. An evaluation with 19 software developers indicate that the architecture can be useful for creating not only solutions for people with motor disabilities, but diverse application."
4874;en_US;"Public speaking anxiety is a very frequent condition, which can lead to tremors, nausea, complications to move in between slides and difficulty in monitoring the length of a presentation. In this scenario, this article aims to contribute with the development of a wearable presentation device capable of detecting anxiety. This device enables to move forward and backward in the presentation. Moreover, the device has a laser pointer."
4875;en_US;"In this paper we investigate the reasons why enthusiasts dedicate time and effort to create subtitles for third-party video shared on-line. Based on result obtained from a survey research with a community of Brazilian subtitlers, we highlight basic feature of these enthusiasts as well as their motivations and main objectives. Our observations suggest that this is a volunteering and collaborative activity after all."
4876;en_US;"In the Internet of Things vision, smart objects are interconnected providing application at everyday life places (e.g., house, cars, school, buildings). The number of smart objects will increase every year, which creates a need for contextual discovery service of those device and their provided service. Web based protocol are widely used by IoT application to interact with smart objects, among them, the most used is the CoAP protocol. This work presents a discovery mechanism that uses contextual information to select the things that are relevant to the user or to the system itself. To perform the discovery, the mechanism extends the default discovery service from CoAP, adapting it to the new IoT requirement while keeping the Web compatibility provided by CoAP."
4877;en_US;"A Pervasive Game is based on a combination of hybrid interface involving mobile device, wireless network, positioning system and context sensing technologies. Location-Based Mobile game (LBMGs) are a subclass of pervasive game. They make use of location technologies and add the position of their players in the game rule. A state of the art survey involving locative mobile game, LBMGs authoring tool, and modeling pervasive game was conducted. This research aims at presenting a language that allows the representation of LBMGs and the media used in the mechanics of these game. We want to support temporal aspects, as well as, spatial relationships. Also, the research will investigate checking mechanism for generating LBMGs to be incorporated into LAGARTO tool."
4878;en_US;"Study of Ubiquitous Computing concepts began in various universities, in course related to Computer Science, which sought to develop the study of ubiquitous system and technologies. In general, these course have practical classes or even small ubiquitous application development project. However, one of the greatest difficulties in teaching Ubiquitous computing is putting into practice the theoretical knowledge acquired since the existing tool already require high-level programming skills or are not designed for educational purposes. As a result, this proposal for master’s thesis aims to design, develop and evaluate a tool that helps to teach practical classes involving concepts of Ubiquitous Computing."
4879;en_US;"Mobile crowdsourcing for task distribution has been proposed to solve problem that require collective intelligence. Mobile device collects information from participant and sensor using tasks. In a crowdsourcing system for urban administration, a task can be assigned to citizen in order to collect data related to the problem. Context is deﬁned by any information that can characterize an entity and is relevant for performing an application activity. This work aims to propose a model for task distribution for campus management. The model focuses on assigning tasks to potentially interested user representing a context-aware distribution. This paper also presents an experimentation plan to investigate if using context in a crowdsourcing system, increases the number of tasks performed by user."
4880;en_US;"The Data Storage industry is facing challenges in the management of heterogeneous storage device, which in most cases, have their own protocol and proprietary management interface. Software Deﬁned Storage(SDS) has emerged as a solution to abstract this heterogeneity. Among the existing requirement in a storage system, availability is a requirement that if not met, prevents the use of the storage solution. For some scenarios, performance requirement can be as important as the availability. In such cases, the search for algorithm and eﬃcient strategies for SDS has entered the agenda of not only professionals but also researcher. This work aims to present the PREA, a strategy for data replication in SDS environments focused on availability and performance. The proposed solution takes into account local replication environments, remote replication and hybrid replication (local and remote). This work is in the development stage and in the course of this article will be presenting the advantages, disadvantages, strengths and weaknesses of the proposed approach."
4881;en_US;"This doctoral thesis aims to propose a methodology for authoring of extra content that can be embedded in video, or presented coherently with them into multimedia system. The proposed methodology will be based on Human Computation and Crowdsourcing, using Production template to design the required tasks and activity, and to select the adequate authoring tool according to the characteristics of the ﬁnal outcome. It will also be developed a supportive environment for the extra content production process that will ensure that the methodology is followed, allowing the authors to focus exclusively on the activity that really demand human intelligence. In this environment, will be available a set of authoring tool that can be used, and further modiﬁed if necessary. In addition, a classiﬁcation proposal will be presented to aid the authoring process of extra content for video, according to three dimensions: Purpose, Nature and Type. Based on these characteristics the production model will be designed, and will be created a template library that can be used to conﬁgure the supporting environment and the very process of authorship. The proposal methodology will be called ExCAM (Extra Content Authoring Methodology) and the supportive environment will be called ExCAME (Extra Content Authoring Methodology Environment)."
4882;en_US;"Temporal segmentation of video into scenes is a prerequisite to various tasks on Multimedia Information Retrieval, like video summarization, content based video retrieval and video recommendation. There isn’t, however, a satisfactory method to automatically segment video into scenes. Stateof-the-art scene segmentation method are multimodal, in order to match the multimodal nature of video. Aside from being multimodal, no true early fusion method was found in literature. Early fusion have shown to be useful in related multimedia tasks where potential correlation between data streams of diﬀerent source are discovered before the main processing step, improving result. Motivated by this situation, the proposal of this PhD Project is to investigate the impact of a true early fusion multimodal approach on the temporal video scene segmentation task."
4883;en_US;"Thanks to improved quality of life in general, people are living better and longer. In this scenario, the elderly want to live alone and independently. This choice has led researcher to investigate system designed to monitor and assist older people in their daily life so that senior citizens and their family feel more secure. Several studies report result that involve sensor, bracelets and other device, even though these technologies are part of the reality of a few user. Also, while sensor must be installed in environments which implies high costs and limits the monitoring to speciﬁc environments, technologies like bracelets are considered limited and as well as costly. On the other hand, mobile device such as smartphone and tablets increase in popularity and interaction capabilities while decrease in cost. In addition, wearables, such as smart watches, are becoming aﬀordable and its integration with mobile device provides new interaction possibilities. Considering these deﬁciencies and opportunities, this project aims to propose monitoring technique that make use of mobile and wearable device in the scenario of monitoring and supporting the daily health care of senior citizens."
4884;en_US;"This paper presents a implementation of an architecture for audience and interactivity measurement in IPTV scenario. The implementation shown in this paper is in line with the recommendation defined by ITU (International Telecommunication Union). The architecture proposed here is intended to be a resource that can be exploited by research institutes, broadcasters, content provider and others stakeholders in the audience measurement data for different purposes."
4885;en_US;"The MedPill aims to help elderly people who need to manage different medications at different times. The box bear up four types of drugs and may be loaded with a maximum of 15 caps of each sort. In addition to the box, the project has two components: a bracelet and an application for smartphone. The bracelet is responsible for signaling the time taking each medication. To this end, it has a WIFI ESP8266 module configured in LUA. The application is developed in HTML, JavaScript and XML Intel XDK platform that will generate installers for various operating system: Android, iOS, Windows Phone, Blackberry, among others. It will be responsible to set the initial settings and replenishment of the box, inform the caregiver as the amount of inventory on available medication and generate graph on the regularity of intake."
4886;en_US;"This research work investigates the design, development and evaluation of a context-aware notification system. We designed a mobile application called AvisaE. It implements theˆ concept of context-aware notification, i.e., a notification that is triggered when a pre-defined context is validated. The software enables the registration reminders, if the user is on a schedule and at a specif location then a notification warning is triggered. We interviewed ten user following the System Usability Scale model (SUS) to assess the acceptance of the proposed system, which was considered“good”by the evaluators. Sixty percent of respondents showed interest in using the system continously."
4887;en_US;"Due to recent technological evolution, the provision of IPTV service has grown considerably. One of the service normally included in IPTV is Linear TV, where audiovisual contents are made available in the form of program schedules. In this context, challenges emerge regarding the distribution of multimedia content over this serevice. One of these challenges is speciﬁcally the user’s perception about the quality of the IPTV service, measured in terms of quality of experience (QoE). Thus, this article aims to analyze the problem that may occur when receiving content and to propose solutions to these problem. Speciﬁcally, due to the congestion of transmission media or overload in the endpoints, a key issue is the statistical variation of time delay for multimedia content delivery (packet jitter). This paper’s proposal comprises a dynamic management of buﬀers in IPTV terminal device, taking into account the individual characteristics of Linear TV service, thereby improving the quality of user experience."
4888;en_US;"The development of wikimaps based groupwares represents big challenges in its analysis, design and implementation. The development of the project Buracos Monitor, a platform to mark holes in the road, and its repercussion has allowed to experience the challenges about specifying requirement, components and other needs of this kind of solution. The goal of this research is to build a set of recommendation and best practices for the analysis and design of this type of system, exposing common problem and solution proposals, compiled as a framework. Correlated system were analyzed, from the point of view of the 3C Collaboration Model (Communication, Coordination, Cooperation), using method proposed on the RUP-3CGroupware. As result, a set of identified components are presented and classified based on the 3C Model. These result are proposed as fundamental and introductory knowledge for analysts, developers and designers interested in develop wikimaps based groupwares."
4889;en_US;"The Brazilian Terrestrial Digital TV System (SBTVD-T) uses the NCL language for multimedia application’s authoring. Although such language has been designed to be easy to understand by producers of such application, the fact of being XML based introduces a reasonable level of verbosity, which hinders or delays more experienced software developers. This paper proposes sNCL (simpler NCL) a domain speciﬁc language (DSL) focused on the reduction of verbosity in the construction of NCL document. The sNCL approach does not act as a replacement to the use of NCL, but facilitates its use. Therefore, this scientiﬁc initiation research also proposes the development of a compiler, which generates the ﬁnal NCL document from a sNCL document. This compiler will be implemented in Lua with LPeg library, generating a symbol table, where each table identiﬁer corresponds to a diﬀerent identiﬁer of the XML elements to be generated in the ﬁnal document. The compiler development process will be guided by Test Driven Development (TDD), which ensures a lower probability of errors."
4890;en_US;"Enuresis is defined as frequently involuntary urination in children in ages whose control should already exist. It is estimated that about 5-10% of the worlds children present nocturnal leakage or difficulty in urination during the day. Thus, various treatments have been proposed, one being the behavioral therapy, which aims to modify inappropriate behavior pattern that contribute to the persistence of enuresis. A mobile application will enable the realtime monitoring and analysis of childrens activity compared with the downtime. This work aims to develop a context-aware application that will help in the treatment of children aged 5 to 10 years with enuresis during behavioral therapy. The contribution of this research is to verify the effectiveness of the context-aware application in the behavioral treatment of enuresis through data collection and analysis with children in several countries."
4891;en_US;"Case Recommender is a Python implementation of a number of popular content-based and collaborative recommendation algorithm which use implicit and explicit feedback. The framework aims to provide a rich set of components from which developers can construct a customized recommender system. One diﬀerential of the framework is the possibility to combine multiple recommenders in a post-processing ensemble approach to produce more accurate result. Case Recommender can be used for rating prediction and item recommendation tasks, and it includes diﬀerent metrics and procedures for validation and evaluation."
4892;en_US;"People can lose motor capabilities for a variety of reasons, like accidents and infirmities. In extreme situations, as found in patient diagnosed with ALS (Amyotrophic Lateral Sclerosis), individuals lose full motor capabilities, only being able to move their eyes[1]. As a consequence, communicating, for these individuals, becomes a challenge. The use of eye-tracking device associated with virtual keyboards can solve this issue, however, the difficulty for choosing the characters could derail this solution. This research had the purpose of studying, conceiving, implementing and testing communication alternatives using eyetracking, which wouldn’t demand effort to choose characters with precision. The solutions were conceived based on pattern of eye movements. During tests, it was noticed that the writing speed had to be improved, and to achieve it, an autocomplete feature has been added to the application. An implementation is currently functional, grouping the best decisions and insights so far, and according to the stablished requirement. The tool, as it is, can be used with a low-precision eye-tracking camera, achieving acceptable levels of writing speed and a high learning curve."
4893;en_US;"The Internet of Things (IoT) paradigm is associated to the concept of Ambient Intelligence, in which a set of smart objects interact and exchange data, with the common goal of using data collected from the context to automate everyday activity. In the context of working places, the Internet of Things can improve the effectiveness of the overall work as well as the convenience and quality of interaction between people, and between people and device. In this paper, we introduce the mobile Android application GreatRoom, which uses wireless tags (beacons) distributed in places and/or objects, in order to detect the presence of user nearby and automatically create both Virtual Rooms for sharing files - especially in the context of meetings, seminars and workhops – and a check-in list of the participant."
4894;en_US;"This work presents a tool that allows user to synchronize live video from multiple source such as YouTube or any other video streaming source. The proposed approach to proceed the multiple camera video synchronization is based in crowdsourcing technique, using the power of a crowd of collaborators to synchronize video, requiring from each user the sync of only a pairs of video. Additional sync relations are inferred from the known contributions, using transitivity properties and an appropriate structure for this inference, the Dynamic Alignment List."
4895;en_US;"Network management is already an extensively investigated topic in academia, as well as implemented in countless commercial and Open Source solutions. However, the network management scene is rapidly becoming more complex, not only because of the growth of telecommunication network, but also from the advent of new technologies such as Software Deﬁned network (SDN) and Network Function Virtualization (NFV)[6, 3]. In this context, service provider are faced with a challenge in the form of implementing large scale strategies for obtaining accurate measurements about the quality of the provided service. This paper describes the NetMetric tool, a solution which employs active measurement technique to determine fundamental indicators of the IP network performance. This document presents the tool in its general architecture, its high scalability aspects, as well as a brief case study to depict operation."
4896;en_US;"Our proposed web tool called OWL-S ComposerW aims to develop heterogeneous semantic compositions in a visual manner. Its main objective is to interoperate SOAP and RESTful web service to embed into device. This tool was evaluated in two fold: a case study and a questionnaire ﬁlled by developers. Our result stated that OWL-S ComposerW is considered useful and achieves its main proposal to visual compose heterogeneous service."
4897;en_US;"One of the biggest problem faced by the elderly population is the occurrence of falls. To help in the detection of such situations, sensor can be used. Based on this, firstly, it was created fAlert, an app that runs in a smartphone and uses accelerometer and microphone to detect falls. However, for a more precise drop detection, the smartphone would be located in the user’s chest. Due to the limitations of this, we not only evolve it to run in a smartwatch but also improve the way of fall detection. This evolution, called WatchAlert, uses the same sensor, accelerometer and microphone, and adds the gyroscope. Thus, WatchAlert performs the detection of falls with a less invasive and more natural way."
4898;en_US;"The video shot segmentation is a useful step on multiple video-related tasks, including research ones like automatic video summarization or high-level segmentation, along with video production like editing and/or post-production. Although it can be useful, there is not an user-friendly automatic video shot segmentation application: those whose can be used requires either paid subscriptions, advanced user knowledge or has an complex installation process. That way, this paper presents an efficient video shot segmentation with an user-friendly web-interface. The application, along with its OS independent interface, feature a fast segmentation process with a number of customizable parameters to achieve a high-quality shot segmentation."
4900;en_US;"Pervasive game utilize contextual data from the player as a fundamental game input. Processing this data, acquired by sensor subject to noises, imprecisions and errors, is an important task in order to guarantee a consistent gameplay experience and prevent player frustration. Thus, this paper presents an approach to pervasive game development capable of handling the uncertainty of sensor data. The proposed approach consists of applying fuzzy set theory to transform the game input into fuzzy sets, by mapping the range of sensor readings into descriptive linguistic variables (i.e., qualitative values) and their respective membership functions. Then, the linguistic variables are utilized in the definition of fuzzy rule – if...then rule statements – describing the behavior of one or more game elements. Finally, in order to output a value which describes the game element’s behavior, we employ a fuzzy inference system based on the fuzzy rule definitions. To illustrate our approach, we present a pervasive game prototype that uses location and movement contextual data to control the pace of the game. By employing fuzzy system in the development of pervasive game, we expect to abstract much of the complexity of handling imprecise and uncertain sensor data during the implementation of the game logic and facilitate the design of rule-based behavior by allowing game designers to compose rule using linguistic terms instead of numerical values."
4901;en_US;"The use of mobile technology has been a great ally to the quality of Brazilian health, this because in a single device there are aggregation tool that allows us to create innovative solutions appropriate to the context of any user. Initially, the system was based on the digital TV technology in scenarios of home care. Nowadays, the system adds new functions to support urgent and emergency care of individuals in mobility. In both cases, the key idea of VITESSE is to improve the time of consuming process, taking into account the real time and contextual information, in particular in the case of mobile user accidents. Therefore, VITESSE is a context aware system that makes use of ontology in the process of generating inferences, increasing the efficiency of health care system."
4902;en_US;"Anxiety disorders affect a lot of people and can cause feelings of breathlessness, chest pain, sweating, among others. When uncontrolled, anxiety can influence individuals lives in a rather negative way. In Sa˜o Paulo, for example, it is estimated that 12% of the population has had some kind of anxiety disorder. This paper proposes a website in which user write daily text. This website process the word in these text and, if anxiety word are found, the interface color scheme is changed. The theoretical foundation comes from scientific studies that highlight the effect presented by the colors. For example, some colors tend to calm (e.g. blue) while others tend to cause excitation (e.g. red). In this scenario, our proposed website can change, in real time, its interface, providing an user-adapted content. Preliminary result point in a promising direction."
4903;en_US;"An efficient strategy to disseminate knowledge of playful and fun way is through digital game. In this scenario, educational game are interesting for help in learning why simulate real situations. In this article, we present the Human-game Quiz, which was designed to assist the learning of concepts related the transindividuais rights. The Human-Quiz is a 2D game, multi-phase, multi-platform, aimed at the general public, which will provide a stimulating learning environment."
4904;en_US;"Monetization plays a main role in the design process of game that aim to generate profit, especially if you are trying to expand your market to a more casual player base that is not willing to pay for a game they never played. However, the current absence of a formal method to implement and organize monetization strategies makes the process of monetizing a free to play game harder. The meta-model Meta-F2P was developed to assist game designers in the process of abstracting, defining and applying the most popular monetization strategies to their game. The main goal of this work is to validate the expressivity of the Meta-F2P meta-model by modeling the monetization strategies of five popular game, and based on the result, discuss the meta-model’s current applicability and suggest future possible improvements."
4905;en_US;"In this paper we propose a multiple-input, multiple-output (MIMO) multiuser communication scheme with spatial modulation. The motivation is to improve the system’s spectral efficiency, by sending information through the index which indicates a subset of active antennas. An improved method based on phase shifts at the base station increases the spatial detectability. Computer simulation shows the improved biterror rate over a reference scheme under the same spectral efficiency."
4906;en_US;"Small and medium-sized enterprises (SMEs) usually have little budget for market research. That prevents them from developing sophisticated surveys or carrying out focus group sessions with current and potential customers to better understand their needs and wishes. Social media may be a rich source of information to support sound business decision making. This paper discusses the possibility of collecting data that people share in message on social media and analyzing their content in order to build relevant knowledge for strategic business decisions, among which, location decisions. To exemplify that, we collected and analyzed message generated by Brazilian user of Untappd, a mobile phone app for sharingbeerdrinkingexperiences. Amongotherthings,itwasvery easy to notice that user from a few city in the country have developed a more sophisticated taste for beer and are keen to trynew types of beer and tell their friends about it. Is information like that useful for an entrepreneur who wishes to settle a new small craft beer business and needs to decide on the best place to do it? We believe so."
4907;en_US;"Advances in technology allows us to carry a computer in our pockets. smartphone are a tendency and almost mandatory to anyone living in an urban and modern context. Considering this, we realize malls are indispensable to our society. Nevertheless, with hundred of stores and products, people tend to loose themselves or to waste a lot of time finding something in the midst of its hugeness. This paper proposes a model to assist and to recommend customers to find what they consider relevant at malls. Using a mobile application, InMap, the model does recommendation based on user activity and they rely on content-based technique that provide the most relevant result."
4908;en_US;"Multimedia application are usually composed by audiovisual content. Multiple sensorial media, or mulsemedia, application consider the use of sensorial eﬀects that can stimulate touch, smell and taste, in addition to hearing and sight. Traditional multimedia conceptual model, and consequently multimedia authoring declarative language, which are used for representing multimedia application, do not support the deﬁnition of multiple sensorial eﬀects. This paper discusses new issues and requirement brought by mulsemedia application that should be considered in the deﬁnition of a mulsemedia conceptual model. A new model must be deﬁned in order to extend multimedia authoring language to be capable of representing mulsemedia content."
4909;en_US;"Recently, Digital TV Broadcasters have been concerned on how to adapt their workflow in order to embrace the production and delivery of interactive content. Due to the involved changes and costs, broadcasters could not yet fully explore the possibilities of interactivity that would enable an enhanced, pleasing user experience. It becomes essential for broadcasters to rely on new technologies that can lower the costs and assist the production of interactive content with a level of automation as high as possible. In this context, this work proposes an object detection method to be used during video capturing (offline or real-time) that delivers this information as a structured Object Timeline, which can be easily handled for the automated creation of interactive content and other application. In order to lower the cost of object detection and making it faster and precise, this work evaluates the use of Radio Frequency Identification (RFID) as the relying tehnology for the proposed method."
4910;en_US;"IoT (Internet of Things) technologies are underway. Both industry and academia have been proposing technologies to support IoT. In particular, some IoT scenarios include audio-video data and aims at integrating multimedia content and IoT technologies. In this paper, we investigate the support for those scenarios through a multimedia language. More precisely, we use NCL (Nested Context Language) to take advantage of IoT device and to specify interactive multimedia application synchronizing sensor and actuators, besides the media objects. To help evaluate our approach, we present a usage scenario using an NCL application that synchronizes media objects and IoT device."
4911;en_US;"The ltering relevant content amid a big database is a complex, hard-working and time consuming. With the spread of the use of cloud storage system, big databases migrated to these system and the data also followed the problem encountered in ltering relevant content in big data sets. This paper proposes a hybrid methodology for recommendation les in cloud storage system using the main recommendation technique and cloud feature."
4912;en_US;"It presented a proposal for a Digital Learning Object to the acquisition of Brazilian Sign Language (BSL), in view of the determinations of the legal provisions No. 10.436/02 and No. 5,626/05, the visual need, own dynamics and gestural language. The article develops in theoretical and conceptual aspects of Libras and Object Digital Learning and highlights the work related to the proposal. In conclusion, it points to the approach and the importance of education and technology knowledge to promote accessibility and inclusion through Digital Learning Objects. Keyword: Libras. Object Learning. Accessibility."
4913;en_US;"Mobile device such as smarthphones have become a common tool in our daily routine. Mobile application (a.k.a. apps) have increasingly demanded access to contextual information, such as environment and system data, as well as user profile. These apps adapt themselves according this context data in order to improve their service. Mobile application with this behavior are known as context-aware application. Several software infrastructures have been created to help the development of mobile context-aware application, but most of them do not store the historic of contextual information, once mobile device are resource constrained (computing and memory capabilities). They are not built taking into account the privacy of contextual information either, due the fact that apps can expose contextual data, without user consent. This paper addresses this topic by extending an existing middleware platform called LoCCAM to store and process large volumes of contextual information generated from several mobile device (crowdsensing); and the definition of privacy policies that avoid dissemination of unauthorized contextual information."
4914;en_US;"Sign language (SL) are the natural way of communication among the deaf. Unlike the spoken language that uses sound in communication, the SL uses a visual channel, i.e., a set of hand, facial and body linguistic elements for presenting the signs. As a result, many deaf people have difficulty to understand and communicate using spoken language. In addition, the Information and Communication Technologies (ICTs) rarely consider the requirement and needs of deaf. Therefore, to reduce these problem, we developed a computational solution for translating general text for gloss (a Brazilian Sign Language textual representation) efficiently."
4917;en_US;"A large portion of the current information are distributed on the web in a non-structured way without being stored in any database, e.g. WebTables. Considering that the computational system operate efficiently over structured data, many studies are performed to perform the extraction of this non-structured data to structured data model. This present article has the goal to demonstrate the implementation of a propose [1] of extraction of WebTables which includes an algorithm capable of to partition the rows of a table in a compartment per similar characteristics. The goal of the developed algorithm, called by the authors as logarithmic binning, is to find similarity among the rows to classify and extract them precisely. The result generated by the algorithm consists in a group of values that when united, will identify the role of each row has in the table, making the extraction process reachable in an automated way."
4920;en_US;"Audio description (AD) is a fundamental accessibility feature for people who are blind or have low vision. This paper presents a system for automatic generation of audio description, called CineAD. The system detects gaps in speech and generates these descriptions from the analysis of the original script and subtitles. To evaluate the solution, we automatically generate the audio description script of two movies. The preliminary result indicate that the solution is able to generate descriptions of the most important events of the lm and the size of the descriptions is a major challenge related to the automatic creation of AD scripts."
4921;en_US;"This paper describes the Hermes infrastructure to supporting the development of context-aware application. Hermes provides software components that handle the semantics of context information as well as event management through a middleware for real-time distributed communication. A case study on monitoring of human vital signs has been developed for validation purposes of the Hermes infrastructure."
4922;en_US;"The use of our body language to communicate with computer system is an increasingly possible and applicable feature in the real world. This fact is potentiated by the evolution of gesture recognition based commercial solutions. A gesture interface complements or replaces navigation in a conventional interface, it is up to each developer to choose the most appropriate option for their application. Therefore when opting for gesture usage, the gestures will be responsible to activate the system functions. This work presents an interface development process centered on the selection of gestures. The proposed process should help interface designers to incorporate gesture based natural interaction into their application in a more systematic way."
4923;en_US;"The use of mobile device brings great benefits of connectivity to its user. However, access to information through these device is a new challenge of interaction for user who have some kind of disability. Currently, most mobile application have accessibility barriers that make it difficult or impossible the usage for many individuals with special needs. To ensure access to the content to all user regardless of their health status, this paper proposes a model for evaluating user interface accessibility focused on mobile device. The proposed model takes into account the user experience without neglecting the specificity of mobile context and accessibility scenario. As partial result, there is a group of perceptions observed from tests at evaluating a mobile application developed for the deaf. result show the challenges and new perspectives to evaluate the mobile accessibility, since few method consider these two context."
4925;en_US;"This work aims to present a thesis proposal in the context of Ginga-NCL, proposes a solution that allows analyze the interactive TV application in this context from two perspectives: structural and behavioral. Thus, seeks to present the theoretical context, emphasizing the problem identification and the proposed objectives. Moreover, presents research planning and development, detailing the current stage of work, the proposed solution and a proposed evaluation. Finally, details the state of the art, assessing the related work."
4926;en_US;"Recent research in mobile media sharing show the possibility to delivery multimedia content on mobile network. This paper describe the TouchSlide, an Android based application for media content sharing with educational purpose. The authors present an application for improving student-professor interaction in a class environment. student and professor share slide content and can interact whith presentation using mobile device. Based in a client-server architecture, the professor controls media exhibition into student’s mobile device."
4927;en_US;"The advancement of internet allows the representation of real places through virtual environments. This paper presents the development of a 3D virtual campus that represents the Universidade Federal Rural do Semi-Árido called UFERSA Virtual. Through this environment, student, teachers and the entire community will have access to some service offered by the institution. One of service provided by UFERSA Virtual is the navigation between the structures of campus. The user will have the opportunity to meet structures of buildings, classrooms, as well as various other places that is part of university. In addition to navigation, other functionality provided by the smart campus is the video streaming recommendation service for distance learning. which will provide educational video content according to user preferences, previously registered. The virtual campus also supports the integration of virtual environment with real structures, allowing, for instance, the reading and control of real status of lamps."
4930;en_US;"Memorization game were always used as a form of distraction, generating a long period of fun and social interaction. Furthermore, it is known that such game result in development of fast reasoning, spatial sense and improving photographic memory. Among the many existing memory matches, a well known compound of the type is an array of colors, which gave a gradual difficulty produces a sequence where the user is expected to interact in some way with the game and that it is capable of entering with the correct sequence of colors presented above. The objective of this paper is to present a different and updated version of the game using the Genius Android platform and the differential use a tangible device a robotic ball, with wireless communication marketed under the name Sphero. The technologies used in this project are essentially the Android mobile platform, which in turn was chosen because it is an open and leader of its segment platform, ensuring a greater potential user for the game. The Sphero is a robot into a ball, can be controlled by smartphone and tablets, among other feature, several feature such as sensor, the ability to emit sounds and colors, we can also mention its defining characteristic, communicate via Bluetooth, enabling use them as a tool for user interaction. It was attempted with the aid of Sphero, the interaction reimagine the classic game of memory Genius modernizing it and adapting it to a new pattern of interaction from the perspective of Internet of Things."
4931;en_US;"With the digital TV (DTV), t-learning arises as an opportunity to promote learning to a major amount of people and that traditional e-learning can not reach. However, most of the time, watching TV is not a collective experience. Thus, using portable device to display television content can bring benefits to viewer. This article aims to build a framework for creating interactive application for mobile device (second screen) in the t-learning / m-learning environment, integrating the Ginga middleware and the OSGi integration technology device."
4932;en_US;"Twitter has hundreds of millions user sending message (tweets) and expressing their opinions about a myriad of subjects, for instance, what they think about a certain product, or if they liked or not a movie, or their reactions during a soccer game. This massive amount of message carrying opinions about di erent things could be valuable for business and institutions. Because, it is possible to monitor many people in real time to obtain what they are expressing in their message in an automatic, fast, and authentic way. In this work, I present Emotte, a tool to analyze sentiment in message sent to Twitter using machine learning and natural language processing algorithm. The tool monitors the tweets according to query, classify their sentiments, and display the result using a chart. Thus, someone using Emotte can compare over time the evolution of the opinion of the Twitter user about certain subjects."
4933;en_US;"The integration of GPS in smartphone, tablets and digital cameras become increasingly present, but GPS receivers do not work well indoors. This malfunction can generate information far removed from the actual location of where the picture was taken or no information. Thus, the paper presents PG++ a location annotation in personal digital photo collection tool which allows automatic location propagation between photos. The focus of the tool is to minimize the number of photos geotagged by the user and to maximize automatically geotagged photos. Besides the proposed minimization, PG++ extracts metadata and organizes the collection into spatial cluster."
4934;en_US;"Annotation tool have already been applied in the educational context successfully for a few years, supporting teachers and student in marking relevant parts of a content and in associating additional information with this content. This paper presents DLNotes2, an e-learning tool that supports the creation of structured and semantic (ontology-based) annotations on HTML document."
4935;en_US;"This paper presents a system for detection and warning of falls for people with special care needs, using real-time evaluated data from accelerometer and magnetometer sensor of mobile device with android operating system, using algorithm to detect pattern of falls, device position and voice recognition to determine a possible fall. We performed 240 tests in a young healthy user using the Samsung Galaxy S3 I9300 device strapped to his chest in order to ensure efficiency in detecting falls."
4936;en_US;"Learning about Web Design can be difficult and time consuming, yet student often do not learn from their errors and struggle to understand some differences between document structure, styling, scripting and temporal synchronization. In this paper we present Ambulant Sketchbook, an easy-to-use Web playground designed to enable student to understand and learn from their errors. In particular, this application simplifies the process of learning how to write and debug Web document by exploring aspects of immediate feedback, coding assistance, direct manipulation and playback control. We have deployed and used Ambulant Sketchbook in a course of Web Design Foundations over a 2- week span. Based on the positive feedback from a group of postsecondary student, we expect the functionalities and experiences discussed in this work can yield significant insights to be considered in the design of next generation authoring tool and in the process of teaching Web Media related disciplines."
4937;en_US;"Forecast pointed that video will account for 90 % of network traffic by the end of the decade. This paper presents a set of monitoring tool that allow to get data of video consumption distributed over the Internet, related to the degree of consumer knowledge absorption, their satisfaction with the video and the content´s quality and your behavior towards web pages presented, as compared with the consumption of resource used. For the tool’ validation, they were integrated to the video on demand system (video@RNP) and evaluated within a scenario of video being used as a tool for teaching / learning and for cultural dissemination."
4938;en_US;"The paper aims to describe the architecture and the main feature of LoCCAMConfigurator, a tool for visual modeling of context information and contextual rule. This tool assists mobile application developers in the task of modelling context information from their application and to define context-aware behaviors. LoCCAMConfigurator uses model-driven engineering approach for context modeling and subsequent automatic code generation. The tool uses the model created by the user in order to generate an Android project and a configured version of the context-aware middleware LoCCAM (Loosely Coupled Context Acquisition Middleware). This Android project includes the library and method of communication between LoCCAM and the future application being developed. All the code for dealing with context gathering, filtering, detection and query is generated by the tool, then, developers can concentrate in the business part of their application."
4939;en_US;"In recent years, after the great proliferation of mobile device, the relationship between usability, context and emotions of the user is a widely discussed in studies related to user experience (UX) theme. Evaluations show that humans typically interact with computer system in unusual ways and have different feelings about the application. To contribute to this area of study, this paper presents a platform for the collection and analysis of data related to the user experience of mobile data. To evaluate the potential of the platform, an experiment was conducted with the participation of 68 people, for thirty days. The study result are presented and discussed throughout the paper."
4946;en_US;"Navigation in the Web can be improved when the user can receive information instead of only document. The development of aggregated searchs using semantic Web resource may contribute to a better navigation. The adoption of Web service may be a support technology to suplly data to such navigation. Web service have become a standard of fact and law in the whole computational media, since its concepts are simple and functional. Along with this model, several proposals have been built to add semantics to Web service. However this speciﬁcation still suﬀers from a lack of standardization in order to describe their syntactic and semantic service. Furthermore, despite their evolution, the discover and composition of Web service to execute a task is a ﬁeld still open. In this paper, we present our proposal for a research about an architecture for semantic navigation in the Web of data. Additionally, we will propose a model for semantic Web service discovery adopting SERIN semantic interface. SERIN, an extension of Active OWL model proposed for semantic Web service SOAP, applying it in the context of RESTful model. SERIN deﬁnes conceptual model that describe Web service syntactically and semantically. Finally, we intend to evaluate the proposal architecture in a government open data environment."
4949;en_US;"The scientific method dictates that experiment must be reproduced before they are considered valid. In computer science, reproduction requires open access to all code, scripts, and data used to produce the result. In particular, the validation of large scale distributed system is a huge challenge to be performed in a real Internet-based testbed. In this work, we propose DiSTInTo as a tool designed to allow user to control their experiment at large-scale distributed testbeds. The tool supports the reproducibility of scientific experiment, since the setup instrumentation of machine until the crawling of the data. It provides feature such as file transfer, experiment execution, real time monitoring and visualization of distributed machine. The time for experiment deployment, execution and crawling has been reduced in our P2P large scale network tests."
4950;en_US;"Recently, the production and availability of multimedia Web content, as video, have increased. In this scenario it is important to consider accessibility requirement so any user can whelm the barriers to access content regardless of limitations imposed. One of the main barriers found is to make video accessible on the Web but few researches have been made on how to overcome those limitations. In this paper we describe a video player, called Facilitas, designed in order to provide the rationale of how some of video related barriers or limitations could be overcome. Facilitas player has new controls different from the ones in other players. We describe a user testing to explain which controls participant frequently use to complete a task. Finally, result are discussed."
4951;en_US;"This paper aims to describe the behavior and the architecture of GREat Tour, a mobile and context-aware application developed for the Android platform. This application is a product of a Software Product Line called Mobiline and has the goal of guiding user in their tour in the laboratory of the Group of Computer network, Software Engineering and system (GREat). The application uses QR Codes and NFC tags to capture the user location and to show a map with the user current position and the lab’s information related to it."
4952;en_US;"This article presents the result of the project IFBATeX which is a web tool, open source, whose aim is to facilitate the development of academic text. The application provides an integrated environment for online editing of LaTeX document and has the interface as one of its diﬀerentials. It allows the user to edit, compile and visualize LaTeX document without the need to install the numerous components that represent this enviroment."
4953;en_US;"This paper aims to present a simulation environment that can be used to run interactive application developed in JavaDTV and NCL, focused on digital television. The proposed environment diﬀers from others because it allows the simulation of both the digital TV environment sides: 1) the broadcaster which is responsible for transmission of both main and extra content, and 2) the receiver which is responsible for receiving all contents and executing application to allow content presentation."
4954;en_US;"This paper proposes a study and comparison among a variety of metadata types in order to identify the most relevant pieces of information in movie recommendation. We used three algorithm available in the literature to analyze the descriptions, and compared each other using the metadata extracted from two dataset, namely MovieLens and IMDB. As a result of our evaluation, we found out that the movies’ genres are the kind of description that generates better predictions for the considered content-based recommenders."
4959;en_US;"With the DTV, t-learning arises as an opportunity in order to promote the learning to a major amount of people than the traditional e-learning doesn’t reach. This paper describes a proposal for an tool that generates learning objects for Interactive Digital TV (iDTV) based on hierarchical concept maps created by the tool Cmaptool."
4960;en_US;"This work is inserted into a context-server where we extract the context whether it is mobile device, user, physical or time of any activity performed by the user of the system. In this paper is presented the module responsible for handling any video submitted to the context-server, this module extracts the meta-data required for processing the video, then the video will be processed to meet the specifications of each type of hardware that can access it also the video is segmented into several parts with a fixed size as it is transmitted using HTTP Streaming."
4961;en_US;"This paper proposes and evaluates an efficient distributed video transcoding. Unlike known solutions that require modification of the encoder or restrict the performance of the solution, we present a optimized technique for video search, allowing the creation of independent segments that can be transcoded in parallel. Preliminary experiment demonstrate that the distributed transcoding in a cluster of 4 node runs 5.6 times faster in comparison with the same video transcoding running 48 threads on a dual quad-core node."
4962;en_US;"Visualization research emphasizes the need for system that assist in decision-making and visual analysis. This paper outlines a recommender system that supports the interactive construction of charts using statistical data. Based on a sequence of simple user interaction, the interface automatically generates an elementary view. This process yields knowledge in an implicit manner, which enables the system to analyze the selected dataset, suggest visualization options and provide guidelines for selecting the most appropriate representation for a given problem."
4964;en_US;"The emerging scenario of interactive Digital TV (iDTV) is promoting the increase of interactivity in the communication process and also in audiovisual production, thus rising the number of channels and resource available to the user. This reality makes the task of finding the desired content becoming a costly and possibly ineffective action. The incorporation of recommender system in the iDTV environment is emerging as a possible solution to this problem. This paper aims to propose an approach to content recommendation in iDTV, incorporated to the middleware Ginga, based on data mining clustering technique and knowledge representation, considering the iDTV as a digital convergence environment (DTV and Web)."
4965;en_US;"This work aims to define a framework, based on Semantic Data Layer of DIGO architecture for open government data, for the purpose of automating the generation and publication of open government data (semantic data) obtained from structured data maintained in Relational Databases."
4967;en_US;"Looking to reduce the problem of knowledge acquisition bottleneck, this work takes on the hypothesis that the folksonomy induced from collaborative tagging data on the Web, based on parameters of authorship and motivation of categorization, can represent a shared conceptualization of a domain. Thus, it is expected that the use of such data can generate a reduction of divergences in the elicitation of terms that will be part of the conceptual model when compared with folksonomy induction algorithm that do not use these parameters."
4968;en_US;"The Brazilian Digital TV System (SBTVD) started signal transmission in S˜ao Paulo on 2 December 2007. Currently, all the Brazilian main city already have DTV channels available. The adoption of the H.264/MPEG-4 AVC standard provides advanced technologies for encoding digital video signals with high definition video. This standard, also allows transmission of three-dimensional video, but this is not considered by SBTVD yet. This research aims to study the encoding of three-dimensional video content with H.264/MPEG-4 AVC standard, and the insertion of these encoded signals in the SBTVD broadcasting stream. Was investigated technique for capturing video from two and more cameras, encoding three-dimensional video streams, and transmission of 3D video in the Brazilian Digital TV system. The multiple views were coded with the side-byside technique as well as with multiple-view coding. The video were transmitted, decoded, and analyzed in a laboratory simulation environment. The objective quality of each video was measured within a wide range of transmission bit rate, and we concluded that good quality 3D video is possible to be allocated in the transmission stream."
4970;en_US;"With the introduction of new modes to control user interface like speech, gesture and multi-touch Post-WIMP interface increasingly substitute classical WIMP (windows, icons, menus, pointer) user interface. In this paper, we describe a toolchain of three connected tool to design and monitor custom Post-WIMP interactors using model-based user interface design (MBUID) method. We use state charts and mappings as the basic modeling technique. Different to other MBUID approaches our model are get created to specify the behavior of existing widgets. These model are then used to attach further control modes and connect interactors using mappings. We explain the toolchain by an interactive music sheet web application that can be controlled by head movements to turn the sheets."
4971;en_US;"The taxonomic description of a specimen is an essential task carried out by biologists aimed to identify and study living beings. The usual approach involves analysing and describing a given specimen in a physical laboratory. Nevertheless, several tasks are being virtualized. image, sounds, and video of living beings are being digitalized; records are stored in spreadsheets and databases and the description task itself are being supported by specialized software. This work investigates a step beyond, where the laboratory itself becames virtual."
4972;en_US;"The Semantic Web is a way to associate explicit meaning to the content of web document to allow them to be processed directly by machine. To allow this processing, computer need to have access to structured information collections and rule sets to reason about these content. The Semantic Web Rule Language (SWRL) allows the combination of rule and ontology terms, defined using the Web Ontology Language (OWL), to increase the expressiveness of both. However, as rule sets grow, they become difficult to understand and error prone, especially when used and maintained by more than one person. If SWRL is to become a true web standard, it has to be able to handle big rule sets. To find answers to this problem, we first surveyed business rule system and found the key feature and interface they used and then, based on our finds, we proposed technique and tool that use new visual representations to edit rule in a web application. They allow error detection, rule similarity analysis, rule clustering visualization and atom reuse between rule. These tool are implemented in the SWRL Editor, an open source plug-in for Web-Protégé (a web-based ontology editor) that leverages WebProtégé’s collaborative tool to allow groups of user to not only view and edit rule but also comment and discuss about them. We evaluated our solution comparing it to the only three SWRL editor implementations available in the literature and showed that it implements more of the key feature present in traditional rule edition system."
4973;en_US;"This article presents a result of the Mconf project. The Mconf-Mobile is an application for mobile device with Android operational system. It makes possible to interact with other user in a BigBlueButton videoconference. We present some goals of the project, the solution’s architecture and its main functionalities."
4974;en_US;"Most of the content on the World-Wide Web is designed for desktop computer. Nowadays, with the evolution of mobile phones, smartphone, tablets and Digital TV, this content must be adapted to these different device, where each have specific characteristics and constraints, like screen dimensions. This adaptation task can consume time and computationl resource, since most solutions resolve it by creating different content versions for different device. A CMS (Content Management System) is a software that keeps track of every piece of content that is used by websites and portals. A CMS can be adapted for others consumers, like mobile device. This adaptation can be done by developing plugins for each different device, or creating different resource for each different device, because most of the adaptation needs to be done for each device. In this work, a novel CMS adapter architecture is presented, which is made to adapt the content on CMSs for different device, through the use of template that describes how the content must be transformed. Also, since most application need some form of offline content and normally the cost of network is high, the architecture also provides cache management layer on the client side, in order to provide offline cached content, a data compression mechanism for keeping the data exchange in the network low, and a content version control. This way, the architecture avoid higher data transfers throught the network which in some cases can be slow and expensive over mobile network."
4975;en_US;"There are several available NCL (Nested Context Language) authoring and formatting tool using their own metamodel to represent the code they are working on. This paper presents an API that implements a metamodel specifically created to represent NCL document. This API helps the creation of tool to manipulate NCL document and brings some benefits to code reuse to the Digital TV system development context. The API here presented is called aNa, an acronym for API for NCL Authoring. aNa is available for free download and open for contributions. aNa has already been used for the development of some NCL authoring and analysis tool."
4976;en_US;"Ginga-NCL is the Brazilian declarative middleware that provides support for the development of interactive TV application. Ginga-NCL indicates the use of NCL (Nested Context Language), which is a declarative language for building interactive multimedia application, and Lua, which is a script language that can be used together with NCL. NCL itself does not provide facilities to build forms, as HTML does. However, form components can be implemented in Lua and included in NCL document. This work proposes an API, named NCLForms, to provide the creation of Lua form components inside NCL programs. Using NCLForms, it is easy to create and manipulate forms inside an NCL program, without the need to program in Lua."
4977;en_US;"Segmentation is an important preprocessing step for a number of current multimedia application using video, like recommendation, personalization or indexing. Since manual segmentation is prone to interpretation error and are time demanding, researcher concentrate efforts in developing automatic segmentation method. Automatic technique need a number of technical input parameters, requiring specialists to be operated. Moreover, these technique need the specialist to give a threshold, used to decide when a shot or scene transition occurs. Obtaining an adequate threshold is time consuming and mostly an empirical process. The precision is greatly affected by particularities of the input video, so, an inadequate threshold can lead to over or under-segmentation. To addresses these problem, this paper presents a friendly user application developed in Java which has two main contributions: perform video segmentation using both an automatic method for calculate the needed threshold and a heuristic to overcome some gradual shot transitions issues. The application, named AVSA, uses the video histogram intersection or histogram absolute differences to perform the segmentation. Furthermore, performance tests are presented in order to testify the precision and the recall of the application when segmenting newscast video."
4981;en_US;"Using the declarative approach, interactive application for the Brazilian digital TV system are developed using NCL (Nested Context Language). Although declarative language facilitate building interactive TV application, the author needs to have at least a basic knowledge of NCL. This paper proposes a wizard tool to allow the authoring of NCL document for those with no knowledge about NCL. The proposed tool uses composite template built with the XTemplate 3.0 language, which specify generic structures for NCL programs. The wizard presents a graphical interface which has drag-and-drop support for filling template components with specific media content node chosen by the author, making the creation of interactive TV application easier. To do so, such media node are stored in a repository that organizes them by type. Furthermore, the graphical editing of content anchors for continuous media node is also provided. This wizard tool is a new version of a plugin of the graphical authoring environment for digital TV programs called NEXT (NCL Editor Supporting XTemplate)."
4987;en_US;"The large volume of content provided by digital TV motivates the development of solutions that facilitate the choices of the viewer. This paper presents the architecture of an electronic programming guide based on web service using the REST architectural style. We also present the development of EPGdroid, an application on the Android platform, which consumes resource of the web service and provides a friendly interface to the end user."
4988;en_US;"The growing volume of Linked Data source has motivated the interest in developing application and tool focused on consuming linked data. One of the main challenges of developing such application is the identification of relevant source, i.e., source that could contribute significantly to the result of user query submitted to the application. In this paper, we discuss this problem and present an approach to detect source that are potentially relevant to a specific application that uses linked data. One distinguishing issue of our approach is that the process of identifying new data source employs the user requirement expressed in SPARQL query posed to the application."
4990;en_US;"In this paper, a multimodal interaction system for people with disabilities is presented. The system combines four different interaction technique in a single graphical user interface for playback multimedia content. The combination of different interaction modalities aims to expand the number of potential user, by allowing the selection of appropriate interaction that fulfil their specific needs. In this work, we validate, for a study case, the idea that different method of interaction allow a higher accessibility, this way, individuals experiencing permanent or temporary disabilities could benefit from technology application."
4993;en_US;"This work proposes a web environment based on cloud computing paradigm. The created environment has the purpose to provide and manage a large amount of virtualized resource among its user, with specific characteristics, optimizing computing power, sharing files and information to meet the demand. Through customizable dedicated and virtualized platforms, the application provides workpaces remotely accessible, with secure connection, through the browser."
4995;en_US;"With the expansion of TV channels in the digital era, viewer are exposed to an excessive amount of programs to choose from. Consequently, personalized recommendation system are desirable in order to enable viewer to navigate and find interesting programs. This paper describes an application that provides program recommendation for viewer in real-time. The application, called suggesTv, shows the top rated content and the programs that are being broadcast at the moment, based on information stored in his ContentWise profile."
4996;en_US;"The emergence of Digital TV brought in novel possibilities of interaction between TV viewer and TV programming. There is a clear tendency of convergence between TV and the web. One of the challenges in this scenario is to provide solutions to assist application development in this new media. This work defines and implements an open source architecture that not only streamlines the access of NCL application to web content but also supports the so-called social network, one of the strongest current trends."
4998;en_US;"This paper presents PuzzlEdu, a tool designed to provide education as a service by making use of cloud computing and thus aiding student and teachers in the teaching and learning the discipline of programming language, particularly the concepts of object-oriented paradigm. We describe in detail the objectives of the tool, its architecture and infraestructure development, as well as its main feature."
5001;en_US;"This paper presents the Componere Mundi, a tool integrating the preexisting Componere authoring tool with an infrastructure to access and present data captured from the real world by sensor. It fuses the principles of multimedia authoring with strategies adopted in supervisory system, enabling to mix real world data with other media and/or synthetic data. Even though this is an ongoing work, we achieved to implement a prototype comprising the complete cycle: from capturing data of sensor, to access and present them in an authoring product. A practical experiment involving physics is presented."
5002;en_US;"This article presents the specification and implementation of a tool that aims to be an alternative to the problem of excessive data replication in order to be considered a reliable platform from the perspective of data availability. The tool work with the concept of data federation. The validation scenarios are presented, along with the result achieved."
5003;en_US;"Digital television (DTV) is poised to a highly popular means of entertainment and information. However, physically disabled user may have serious problem to perform simple tasks like switching channels and controlling the viewing experience. This article describes an approach that replaces the conventional remote control a device that allows to interact with the TV by capturing brain signals and following head movements with a gyroscope. An already running prototype is also presented."
5004;en_US;"This paper presents the open source webconference solution developed in the project Mconf, that integrates the webconference system BigBlueButton with the web application Global Plaza. This solution called Mconf-Web that being developed, that is based in the open source web application Global Plaza and that was integrated with BigBlueButton to enable webconferences through a social network environment. Another goal in the Mconf project is to integrate with the BigBlueButton development team and this paper shows the developments already done in this context."
5005;en_US;"This paper presents an ongoing PhD work involves interface evaluation based on real user interaction data, including contextual aspects. The model involves aspects of usability metrics establishment, mapping and instrumentation of the application’s source code from experts interaction, final user interaction capture and analysis of the result obtained. The objective is to automatically gather quantitative data so that can be analyzed in a qualitative and subjective way, making it possible to detect usability problem and measure the quality of use of the interface."
5006;en_US;"Document production tool are present everywhere, resulting in an exponential growth of increasingly complex, distributed and heterogeneous document. This hampers document exchange, as well as their annotation, indexing and retrieval. Existing approaches to these tasks either concentrate on specific formats or require representing document’s content using interoperable standards or schema. This work presents our effort to handle this problem. Rather than trying to modify or convert the document itself, our strategy defines an intermediate and interoperable descriptor – shadow – that summarizes key aspects and elements of a given document, improving its annotation, indexation and retrieval process regardless of its format. Shadows can be used with different purposes, from semantic annotations and contextensitive annotations, to content indexation and clustering."
5008;en_US;"Semantic Web Rule Language (SWRL) is a rule language that enables rule to be conbined with Web Ontology Language (OWL) to provide even more expressitivity to them. However, as rule when trying to control them. A large rule set becomes difficult to understand and prone to errors. To resolve this problem, technique and tool are needed to organize, view and create rule set in SWRL. This paper presents a set of solutions to improve the use and management of SWRL rule, wich include the development of visual representation and some technique that resulted in a visualization and composition rule tool. As a case study we used a rule set on biomedical autism (Autism Phenologue rule) wich illustrate a large and complex SWRL rule set. From this study, a new visual representation specific to these rule was developed, allowing a medical expert, without much computer knowlege, can more easily manage the rule."
5010;en_US;"Understanding content popularity growth on Online Social network (OSNs) is of great importance to Internet service provider, content creators and online marketers. However, most previous studies of OSNs are based on static views of the system, thus neglecting the temporal evolution of the network, and a possible correlation with content popular- ity growth. Moreover, previous analyses also greatly neglect the impact of the referrers (i.e., incoming links from exter- nal sites) on content popularity. We here provide some ini- tial result on the analysis of content popularity growth in YouTube video. Our study is based on three video dataset, namely popular video, randomly collected video, and copy- right protected video, with distinct characteristics in terms of temporal popularity evolution. We also characterize the different referrers that most often lead user to YouTube video. Our result shed some light into aspects that impact content popularity growth."
5013;en_US;"The progress of science and technology coupled with the improvement of communication network favoring the emergence of service to handle with growing volumes of data and the high transmission power available. There are many scenarios that include such feature: telemedicine, sporting events, artistic events, techno-scientific events and so on. So, this work has the purpose of presentation a generic architecture that integrates all of these scenarios in a framework for developing application related to digital video."
5015;en_US;"This article introduce a comparative study between two types of databases in order to assess whether the database object-oriented are a viable alternative to replace relational databases with application that work with multimedia data. For the four tests were chosen SGBDs: MySQL, PostgreSQL, Neodatis and Db4o. Measurement in an environment that simulates conditions of actual use was the method adopted for the evaluation of performance. The result that it is possible to use a SGBDOO this type of application. However, there is still a greater maturity of this model so that it can reach the level of the prevailing paradigm in the market, the SGBDR."
5016;en_US;"This paper describes a proposal to extend the Rational Unified Process (RUP) to include the practices recommended by the System Security Engineering Capability Maturity Model (SSE-CMM). Initially, an assessment that found that several area of process proposed by the SSE-CMM are not covered by the RUP. The incorporation of security, based on SSE-CMM, the RUP is considered important, since every day is a need for new security mechanism for protection of information system. In this sense, this paper proposes the inclusion of a new discipline in the RUP in order to satisfy security requirement, as described by the model SSE-CMM (ISO / IEC 21827), so that security is integrated into all phases of software development."
5018;en_US;"This paper describes a Digital TV usability research that aims to explore different navigation paradigms in interactive TV application using the remote control and their acceptance by average spectators."
5019;en_US;"In a visual information retrieval process that considers the image semantics, several levels of query can emerge, from simple statements as find pictures with a boat, to more abstract ones, such as find pictures depicting happy atmospheres. Usually, the abstract level refers to the affective or emotional content of the image and is considered a relevant dimension in which user specify their query. Clearly, due to its inherent complexity, affect is difficult to model and consequently quite difficult to be handled by a retrieval system. In this work, we present a preliminary evaluation of the Self Assessment Manikin (SAM) method for the affective description of image, in a collaborative tagging environment. image from the International Affective Picture System (IAPS) dataset were used in the study. The result show that the affective dimensions valence and arousal and the SAM method can be effciently used for tagging and further retrieval of image."
5020;en_US;"The use of voice in computational system interface have been utilized for many user who can enjoy the voice to communicate. The performance of current voice technologies and the business demand to improve usability and accessibility in their products and service has been increasing the use of voice interaction in multimodal interface (MMI) application [11]. This paper presents the previous work improvement [6] through a Voice Interface (VUI) extension for Mozilla Firefox Web Browser. The BrowserVox extension is a plugin with improvements, where some problem of paper [6] was solved. During BrowserVox developement arose project questions about interface and interaction. This questions are described in this paper."
5023;en_US;"This paper describes the architecture of a text and image retrieval distributed system for the EPCT digital library. The system was designed to run on commodity hardware cluster, solving scalability and high availability problem of the current version of the system. It shows also some technologies that will be used. Finally, some preliminary tests demonstrate the effciency of the indexing architecture."
5024;en_US;"This paper presents the architecture and implementation of a data provenance system in the field of scientific experiment processed in collaborative research environments. The text highlights the contribution of basic scientific research to the project and tangible bene ts for undergraduate student."
5028;en_US;"The Digital and Interactive TV (TVDI) is being characterized as a tool for digital convergence that is capable of integrate other device household with the television. This paper presents an investigation of the use of interaction device in the Brazilian digital TV. Our challenge is through experimentations, assess the impacts of integration of these device on the TV, as well as to investigate the interaction between different device such as form of innovation in developing application for Digital TV Interactive."
5029;en_US;"Ginga is the middleware for SBTVD, the Brazilian Digital TV System. The purpuse of this study is to extend Ginga, creating a software component that enables it to communicate in a peer-to-peer network, and exposing an API that developers can use to exchange les and message in the Ginga ecossystem without the need to explore the details of peer-to-peer communication. This required understanding of the workings and structure of the middleware and development tool, and also the investigation of possible protocol for le and message exchange in the new component. This work resulted in the adoption of the XMPP-Jingle protocol in a prototype component, its speci cation and a test case, showing the middlewares proneness to be componentized for use in non-conventional application."
5030;en_US;"Digital TV and Interactive (TVDI) is increasingly gaining importance in digital media and in daily life. With the possibility of developing interactive application, the number of studies in this area is becoming larger. This work focuses on interactivity in an application that aims at measuring the amplitude of movements of the joints of patient who do physiotherapy."
5032;en_US;"This paper proposes the integration for the different WebApps on Web-PIDE platform, in Monitoring Program of Education (INEP/CAPES), through a messaging channel preset with a XML format based WebService. Approaching the visualization problem of educational assessments data indicators in a single knowledge repository, the proposal is validated with the Amb-PIDE specification, which provides resource for educational databases indicators through a WebApp inserted in the Integrating Environment of Web tool on Web-PIDE Platform. By result, a visual environment that facilitates indicators and related information consultation be available, public and open for the community on the Web, where user are, potential, public managers, researcher, members of civil society organization and citizens who are looking for educational assessment indicators."
5033;en_US;"An important academic task is the submission of the nal year project (FYP) by the undergraduate student, that in general are presented individually to a board of teachers. Thus for scheduling the various presentations, the assistance of GCSs (Groupware Calendar system) becomes esential. We developed a tool for scheduling the FYP presentations, as an instance of CMS (Content Management System). We highlight the potential of CMS to meet speci c requirement and maintain the general characteristics to optimize the resource of the interactive Web environment."
5035;en_US;"Topic hierarchies are very useful for managing, searching and browsing large repositories of text document. Several studies have investigated the use of hierarchical clustering method to support the construction of topic hierarchies in an unsupervised way. In this paper we present the Torch - Topic Hierarchies software tool that implements the main feature of the method IHTC - Incremental Hierar- chical Term Cluster, aiming to build topic hierarchies from growing text collections. A simple experiment is described in order to illustrate the use of the Torch to support the construction of digital libraries."
5036;en_US;"This paper presents a strategy for navigating virtual learning system. Given the particularity of this type of system, usually composed by various interactive and collaborative feature, a new form of navigation may be interesting to provide a more dynamic interaction with the interface. student and instructors can, through this new approach, visualize a real-world metaphor in the sense that the navigation windows proposed here resembles paper and books arranged in a desk. To validate our proposal, we present a case study conducted with elementary school teachers and corresponding evaluation of its interface."
5038;en_US;"This paper describes a tool to provide user with available service for multiple device, such as TVs and mobile phones, by having TV as the main media. The integration between the broadcasters and the other telecommunication network happens in a transparent way for the user, that is, the user will access content that can be either in broadcast transmission or telecommunication network. These contents were modelled according to TvILO Concept."
5039;en_US;"This paper presents the authoring tool Contextual Ginga and the result gathered in its evaluation. This tool’s objective is to allow the development of interactive digital TV application, which are user context-sensitive. These produced application must be executed in Ginga-NCL machine. It is just necessary to understand about TV and context-sensibility concepts to produce these application through Contextual Ginga."
5040;en_US;"The game are ancient tool of entertainment for humans, but also serving as a tool for your intellectual growth. The game are also a way to overcome our limits, since they essentially have the character of a challenge. A game should give the player the ability to solve problem generated by the dynamics of the game. Thus we have a simple definition of play: the game is an activity of problem solving that provides fun. Due to its large capacity for game, it is important to explore the capabilities of game for the DTV, for that we present a propose of a framework for developing game that aims to facilitate the development of game for the Ginga, and other studies on game for DTV."
5041;en_US;"We describe the use of a social network called chain of authorities to improve the information retrieval in folksonomy-based system. This social network is generated by using the Folkauthority concept, which describes the activity of granting cognitive authority to the information source through the use of foksonomy. With the development of the proposed work it is expected to contribute to the improvement of information retrieval in folksonomy-based system as well as to enrich the discussion on the area of Social Information Retrieval."
5042;en_US;"As many other countries, Brazil is moving from an analogical to a digital TV system. Besides providing a better audio and video quality, an interactive digital TV (iDTV) system will make it possible to user interact with the TV in many ways. Such an interaction will contribute to the emergence of an array of new application and possibilities, such as new approaches for interactive advertising. In particular, iDTV will provide an environment suitable for the placement of personalized advertisements which have the potential to be interesting for user and financing effective for advertisers and service provider. This kind of advertising approach has being successfully employed in another interactive environment, the Web, with large net gains for advertisers and content provider. Our aim in this work is to propose an architecture for a Web-like personalized advertising system (WPAS) and implement it for the Brazilian Digital Television System (ISDB-Tb), along with all the complementary mechanism necessary in the ISDB-Tb. In particular, we present the design of the WPAS client module, describing the mechanism necessary to the identification of the characteristics and interests of the user, the selection of the most appropriate ads, and their insertion into the content broadcasted by the service provider."
5044;en_US;"NCL is used to write interactive application for DTV. This paper presents the first steps of our approach towards the formalization of the semantics of NCL. We use Time Petri Nets (TPN) as target formalism for giving mathematically precise meaning to NCL. We rely on Visual Timed Scenarios (VTS) to graphically specify the behavioral properties the NCL application should satisfy. We sketch the method to translate NCL programs into TPN model and to verify VTS properties on the obtained model. We illustrate the approach with “O Primeiro João” from club.ncl.org.br."
5046;en_US;"This work presents the integration of a web system for teaching and learning, named AulaNet, for interactive digital television. This article describe some technological problem encountered and the integration architecture adopted. An analysis was made to determine the advantages and limitations of digital TV and how the base system tool can be utilized in this context. The resulting application of this project is a digital TV system named AulaNet TVD."
5048;en_US;"The interactive TV broadcasting chain involves many environments and actors, from the content producer to the broadcast operator, from the editing studio to the broadcaster head-end. They all have different needs on interactive content creation and editing. Even TV viewer in their homes are demanding tool to enrich content and to promote the so-called Social TV. Nowadays, a single authoring tool cannot fulfill their different requirement. This paper discusses the creation of a brand new version of the Composer authoring tool, towards to meet the different authors requirement, relying on its extensibility, adaptability, robustness and scalability."
5050;en_US;"The Brazilian Digital Terrestrial TV System (SBTVD-T) defines support for several media types of codification (audio, video, image and so on), which can be presented in an interactive application using its middleware Ginga. In order to establish relationships and to synchronize these media objects, Ginga-NCL, which is the Ginga declarative subsystem, uses Nested Context Language (NCL). This article aims to present NCL as an extensible language, since that it allows new media types, those which have not been standardized by SBTVD-T, to be played. NCL is extended by using Lua imperative objects implementing players for those new media types. As an use case, a SubRip Subtitle Format (SRT) player is presented. SubRip is a codification not included by SBTVD-T standards. The work secondary goal is to reaffirm NCL characteristics as a glue language, showing that NCL separates media contents from its relationship specifications."
5054;en_US;"After creating a new standard for Digital Television (DTV), Brazil began to develop interactive content for its system. The middleware specification (Ginga) provides a solution for advanced interactivity, which allows the development of high value application. This article shows how DTV application that can be integrated with Web 2.0 content, allowing a more interactive user experience, through the use of an application for social networking through Twitter and content enrichment using Google and Wikipedia. Both application were developed using Ginga-NCL."
5055;en_US;"Digital Television in Brazil is being implemented with extensive support of public policies to promote social inclusion through e-government service and the formation of a network of distance education. The Interactive TV (iDTV) allows a lot of service that combine video and data offering the user more control over the content and service compared to traditional service of TV, thus becoming an interactive form of communication. Consequently, new content should be researched and developed in the form of learning objects (LO) specifically for T-learning. This article aims to discuss paper existing in international databases whose subject is about adaptation of LO to the context of iDTV. The result of the research have presented that there are several initiatives for the production of LO for iDTV in the world, with emphasis on the T-MAESTRO project and the ATLAS project in Spain and the BEACON project in Brazil/Europe. However, it is perceived that the development of the content and service are in the beginning, because today is largely used primarily for the information and communication technologies and should be adapted to iDTV."
5056;en_US;"NCL (Nested Context Language) in its current version 3.0 has been evaluated both through empirical and analytic method, which have provided important insights on how to interpret the meaning and impact of syntactic and semantic feature of NCL on human cognition. The several evaluations raised some very interesting issues that lead to the design of the new NCL 3.1 version. This paper presents the new feature of the NCL 3.1 Enhanced Digital TV profile and gives good reasons for them, recognizing the evaluation result."
5057;en_US;"The advent of Digital TV has ensued the growth in the volume of TV programs. Consequently, the difficulty in finding the content the TV viewer wishes in a transparent way among the available TV programs increased. Within this scenario, the recommender system stand out as a possible solution for this problem. Thus, this paper presents a software infrastructure in an Interactive Digital TV environment to support context-aware recommender system for Digital TV – entitled PersonalTVware. To demonstrate and validate the functionalities in a use scenario was developed a context-aware recommender system as a case study which uses the PersonalTVware."
5058;en_US;"The recent publication of the middleware standards for the Brazilian digital terrestrial TV system has caused a growing interest in iTV based service. This fact, together with the familiarity of the Brazilian population in operating legacy analog TV sets (present in 98% of the households) and the very low availability of Internet (present in 24% of the households), has motivated researches on platform independent iTV service that could contribute to overcome the digital divide in Brazil. These are the main topic of the SMTVI (Multiplatform service for Digital Interactive TV) project, sponsored by Brazilian Ministry of Communications R&D Program (FUNTTEL). In this paper, we describe the conception and the specification of t-CoD, an iTV content on-demand service. The work is substantiated by demand analysis of Brazilian Internet-based service and on surveys in countries which deployed similar service. The functional requirement for two t-CoD application and a business model for the deployment of commercial t-CoD service are also presented."
5059;en_US;"This article describes a development case inside a project called “TV DIGITAL – SOCIAL” made by a public company. The aim of this project is to offer interactive public service through Digital Television Technology and also contributes to achieve Digital Inclusion process. By all of its economics, socials and politics aspects, has a great potential to become the biggest interactive case all over the world."
5063;en_US;"
      	Teaching of algorithm and data structures is present in the curriculum of the most computer course, having great influence on the performance of student in some subsequent disciplines, as well as student training. However, many student present difficulties in learning of the subject due to the abstraction ability and logical reasoning often have not developed. This research aims at presenting an open educational resource to assist student in learning algorithm and data structures. After applying the case study, the main result showed that the tool proposed is a good alternative to be used in the classroom contributing to learning the theme.
      "
5064;en_US;"
      	This article carried out a systematic mapping of the literature, observing the collaborative aspects of the tool of Support to Pair Programming (PP). He analyzed the resource of these tool regarding the support of the PP process, also verified the metrics used by the studies to evaluate these tool. From the human point of view, he analyzed how the formation of the pair relates to the aspects of progress, performance and satisfaction of the peers in the application of PP. To perform the systematic mapping, the model proposed by Pettersen was used. After applying the mapping we identified the tool most evaluated by the studies and the resource available in them, we identified gaps regarding the feedback to the pair and the mediator of the PP process. It was also identified that specific tool are used to support the teaching and learning process using PP, and we identified that these tool have few communication, coordination and cooperation resource.
      "
5065;en_US;"
      	We present BROAD-PLG, a Software Product Line to support the construction of educational game, with a set of feature that will integrate the artefact to be developed. The evaluation was based on the development of the infrastructure and the generation of new products. It followed two steps: the development of a game for teaching Logic using the defined feature and, in the second step, we describe the game in use in two virtual learning environments - the Moodle (free platform) and youKnow (private platform). For evaluation in a real learning environment the game was wrapped as a service. The result point to the feasibility of using the solution and the set of feature for automatic or semi automatic generation of educational game.
      "
5066;en_US;"
      	Recommendation system (RS) deal of the overload of information online, allowing the user to find desirable item quickly, without being surprised by irrelevant information. Individual preference and interpersonal influence are important contextual factors for social recommendation, as they affect user decisions about information retention. The goal of this paper is to identify the state of the art in RS with the use of social elements. For this, a systematic mapping of the literature was conducted, revealing a growing trend in the number of articles published in the last ten years, especially in China, and with more frequent proposals for new model, system and framework for recommendation. Almost half of the mapped articles present as a domain Entertainment or Product Review/Evaluation, with the collaborative filtering approach being the most common of the approaches used, and the similarity of friends as the most common of the social components considered. As an evaluation strategy, more than half of the mapped articles use offline experiment in a previously populated database to simulate user actions. The mapping showed that although RSs are considering social elements, there is still a lack of work that explore these elements in real context of use.
      "
5067;en_US;"
      	Currently, virtual and real social network overlap through wide access to Internet-connected device, which use software and websites that promote interaction among individuals, groups and network of dynamic relationships. The use of mobile device such as smartphone, offers wide range of possibilities for solutions to peoples everyday problem. However, it is important to investigate the acceptance and appropriateness of these alternatives in relation to different user profiles. Thus, this research aims to investigate the perception of a user group facing the possible adoption of the Life360 application in seek for improvement of family safety. The study was conducted by means of questionnaires and interviews with people from the city of Itajubá -- MG. The perceptions collected were analyzed from the perspective of the Diffusion of Innovation Theory and the progressive model of adoption. As a result, a low-cost model that allows evaluating critical points in the process of adoption was obtained. It is concluded that the Life360 is more suitable for people with higher income and education, given the feature found in the progressive model of adoption
      "
5068;en_US;"
      	Startups ecosystem is a creative environment to aim promoting entrepreneurship and the birth of innovative business. In this complex social network, the activity derive from the relationship of interdependence and co-evolution between actors with different purposes, who share resource to achieve common goals. The dynamic of this environment requires understanding the interests and capacity of each participant as a way to identify convergences and possible partnerships that can help in the development of new businesses. This paper presents a method to assist the identification interests and vocations from relationships extracted from interaction in social network tool in startups ecosystem. To verify applicability, an empirical study was conducted from a conversation group by Whatsapp held by managers of technology business incubators from Brazilian federal institutes of education and research.
      "
5069;en_US;"
      	Technical evolutions and the Social Web potentialize and facilitate the migration from Cultures of Consume to Cultures of Participation, in which user profile changes to a more active one. New quality criteria for social system, such as the ability to promote user engagement in solving social problem, have driven researches on the HCIs Project and Evaluation in Cultures of Participation. With the objective of supporting HCI designers in the development of social system focused in engaging user in the resolution of social development problem, we proposed the Fischer-Fogg Framework. This paper presents the result of a qualitative research, composed of two empirical studies, to evaluate the engagement of user in the use of Sobra Zero, an application developed with this framework. The result of the research indicate that Sobra Zero engages both participant who were already sensitive to the global problem of food waste and those who did not care about the subject before. However, nothing can be concluded about a change in long-term habits.
      "
5070;en_US;"
      	Software requirement engineering is the process of discovering, analyzing, documenting and verifying information system requirement and restrictions. Traditionally, requirement identification is performed with the presence of end-user. Nevertheless, in the context of mobile application, there may be difficulty in contacting future end-user. requirement elicitation technique such as personas and empathy map can be applied in such context, allowing analysts to better understand end-user. However, such technique are criticized due to the lack of scientific basis, difficulty in application, and risks in describing false user. In order to improve the reliability of those technique, this paper proposes the use of social network as a source of information to support these requirement elicitation technique. We developed an application for fighting depression from requirement that were derived based on personas and empathy map together with the analysis of data from social network. Our result show a positive end-user validation regarding the representation of a persona that suffers from depression based on social network data. Also, requirement elicitation can be applied for identifying end-user needs when developing such software application.
      "
5071;en_US;"
      	Software measures are underused due to the difficulty of interpreting their result and associating them to software quality. Different environments, language, and development methodologies require specific measures and range of values. Thus, this paper proposes MCL (Metrics-based Constraint Language), a language that allows to specify, for different system components, the measures to be used and the expected range of values for each measure. We implemented a tool, called MCLcheck, to verify if a system conforms to the specified MCL restrictions and to report the detected violations. We explored different context of language usage through the MyAppointments system, demonstrating the applicability of MCL and its effectiveness as a language that provides support for preservation of quality factors, maintainability, and performance of information system.
      "
5072;en_US;"
      	Software testing is an essential activity for software quality, since it allows the identification of bugs. However, testing is an expensive activity, because it requires time and experts. As a means of reducing the testing costs, many software company have bet on the tests automation. As the main benefit, this automation cuts down the time spent to execute the tests. Nevertheless, there are few studies in the literature about the effort required to automate tests. This experience report describes a test automation experience in a Test Factory, describing the time spent, challenges faced, and lessons learned. In addition, this article presents a process for this activity, which was defined based on the gained experience.
      "
5073;en_US;"
      	Refactoring consists of improving the internal structure of the code without changing the external behavior of a software system. However, the task of refactoring is very costly in the development of an information system. Thus, many tool have been proposed to support refactoring the source code. In order to find tool cited in the literature, this work presents a Systematic Literature Mapping about refactoring. As a result, this paper summarizes the refactoring tool that have been published in the last 5 years in terms of the tool profiles developed, which programming language have support for refactoring and which are the main refactoring strategies that are handled by tool. It has been identified that publications on refactoring have remained constant over the past 5 years. Also, most of the refactoring work describe tool, being they for system written in the Java language, that perform code refactoring automatically and the main refactorings are: Move Method, Pull Up Method, Extract Class and Code Clone. Finally, we performed an analysis of the data returned by the DBLP library. As a result, it was observed that the paper returned by the DBLP have a high level of similarity with the other research bases studied.
      "
5074;en_US;"
      	Open Government Data has been made available by public institutions in Brazil and the world, and can add value to various sectors of society. Open data is also linked to smart city, and hence important in this context, as it is the first step towards public transparency. Despite the wide range of Open Government Data, interpreting such data sets is a non-trivial task, due to the massive amount of raw data. This stimulates the search for technique and methodologies that allow the interpretation of implicit information and deduction of new knowledge. One of the approaches used for these tasks involves the use of data visualizations. In addition to data visualizations classically used in descriptive statistics for data analysis, such as line or bar charts, many web sites have been used map visualization technique. This type of visualization is important, since visualization of georeferenced data combined with other types of information can aid its interpretation. However, for data visualization construction on maps, it is necessary that the objects to be visualized are georeferenced. There are standards for turning such data available, however they are diverse, which may make it difficult for a single tool to display views from different source. This work aims to present a framework that defines data standards for constructing data visualizations on maps of various types. Based on this framework, a tool was implemented to facilitate the creation of different map views, both by developers of open data portals and by user who analyze such data.
      "
5075;en_US;"
      	Public organization face difficulties in manipulating data essential for implementing efficient management, which compromises the quality of the service provided by these institutions. The use of Business Intelligence (BI) tool can contribute to the improvement of the organizational process of these organization. However, the high financial cost, in many cases, makes it impossible for public institutions to acquire proprietary BI solutions. An alternative is the use of solutions based on free and/or open source software. To identify, among the available OSS-based BI tool, which is the most appropriate for implementation in public bodies, it is necessary to apply some specific model for evaluation and selection. The literature describes several generic method for assessing and comparing OSS. In this work, we select a suitable method and derive a model for the comparison and selection of OSS-based BI tool able to meet the demands of public organization. In addition, through a case study, we demonstrate how this model can be used in the selection of a tool that can contribute to the improvement of information management in an organizational environment.
      "
5076;en_US;"
      	This paper is aimed to propose and exemplify an A/B test execution framework. The proposed framework, that was named IPEAD (acronym for Ideation, Prioritization, Execution, Analysis and Documentation), was based on Sean Ellis High Tempo Testing framework and in the concepts explored by Eric Ries on its Lean Startup book. A real case study is presented to illustrate each step of the proposed framework as well as the tool used on the process. The proposed framework could be used by company or institutions that wish to improve their result through the use of A/B tests.
      "
5077;en_US;"
      	Because of the variety of IaaS cloud provider, the available information to the clients becomes confusing. Likewise, due the lacking uniformity of provided service and data representation, the combination of diversified rate, the complexity of the settings, the uncertainty about settings and necessary resource result on a challenge in target provider selection. To attenuate the problem, on the present project the multicriteria method is used to analyze the hierarchy process, optimizing the decision-making process. From experimental result, based on genuine administrators opinions, it is noticed that clients have trouble in the selection of the provider, showing a latent necessity of tool that automate and simplify decision-making. Mainly, the proposed mechanism, not only optimizes the provider selection of IaaS clouds, but also makes it easier.
      "
5078;en_US;"
      	Identifying fraudulent or anomalous business procedures is today a key challenge for organisations of any dimension. Nevertheless, the continuous nature of business conveys to the continuous acquisition of data in support of business process monitoring. In light of this, we propose a method for online anomaly detection in business process. From a stream of events, our approach extract cases descriptors and applies a density-based clustering technique to detect outliers. We applied our method to a real-life dataset, and we used streaming clustering measures for evaluating performances. In particular, we obtained Cluster Mapping Measure of 95.3% and Homogeneity of 98.1% discovering anomalous cases in real-time.
      "
5079;en_US;"
      	The reduction of electric energy consumption is considered as one of the main challenges in diverse sectors of the economy. To residential customers, the management of energy consumption can bring significant costs reduction and decreased environmental impact. The challenges to achieve this goal are related to (i) non-existence of device containing sensor with affordable prices to manage the expense in real-time of device power, and (ii) lack of a home system to control and help in the decision-making process when power consumption goes beyond desirable values. These system should assist the user when unwanted situations related to energy consumption arise. This work presents a solution that helps the user to reduce the consumption of electric energy through its own residence. The practical result obtained in a real-live scenario confirmed the option of collecting information directly of electrical appliances and inform the user of their energy expenditures in real-time, allowing the knowledge and the management of their expenses.
      "
5080;en_US;"
      	The search for computational model based on the prediction of scenarios has attracted the attention of many researcher over the years. Within this context, Fantasy game work as social media environments that mix real information on a virtual world, offering a challenging scenario. This work aims to explore this scenario by introducing a simulation, analysis, and visualization tool, based on the Fantasy Game -- Cartola FC. This tool automatically generates teams by using two distinct strategies based on statistical model for each tournament round, simulating an entire championship. From these theoretic model, we create a visualization tool to support user analysis. Lastly, we perform the planning of experiment to determine the influence of certain aspects of teams composition.
      "
5081;en_US;"
      	In agriculture, land use knowledge is very important for the analysis of agricultural, to estimate production and propose crop production forecast model, environmental monitoring and sustainable planning. Therefore, to coffee agribusiness the mapping of cultivated area is essential. In the southern region of Minas Gerais, this mapping has been performed using geotechnologies. However, this strategy has some limitations resulting in maps of land use with classification errors. In this work, the proposed solution to minimize this problem is the combination of remote sensing with citizen science. For this purpose, a mobile application, named Demarcafé, has been developed. The Demarcafé allows citizens (non-researcher) to collaborate with this mapping. Hence, the technology assumes the role of facilitator of this connection. The Demarcafé has been evaluated and the result suggest that the tool can represent an important advance in this mapping.
      "
5082;en_US;"
      	The Internet of Things (IoT) brings a great change to the daily life and well-being of people. sensor and platforms connected to the Internet transform the routine of user in a transparent and gradual way. This work proposes an intelligent water consumption monitoring system, associated to the construction of a database for analytical studies of stored values. The interconnected Internet system which controls the water supply process in residential and corporate environments, monitors the individual consumption of water outlets, detects leakages, send alerts and creates consumption graph, thanks to a middleware able to manage sensor and trigger actions such as checking the tank level, measuring the water flow, and handling solenoid valves. The system, named IoTAgua, was implemented and simulation experiment were performed for its evaluation, considering two different scenarios.
      "
5083;en_US;"
      	Software-intensive information system can be aggregated to form system-of-Information system (SoIS) and provide novel functionalities to achieve high-level goals, also known as missions. Missions represent an important concern in this context since they are related to both capabilities of constituent system and how they shall interact with each other within a SoIS. Due to such a relevant role, we conducted an exploratory study to evaluate how a state-of-the-art language for mission specification has supported mission (renamed as goal in this study) specification for SoIS. This investigation has been carried out in the context of a space SoIS composed of independent ground information system, satellites and other system to provide territory monitoring and environmental data distribution. result indicate a lack of support for the specificity of SoIS goals, such as the representation of interdependency among activity and dynamicity support. As main contributions, this paper comes up with a set of design principles and a corresponding conceptual model to be followed by language tailored to support goal specification in SoIS.
      "
5085;en_US;"
      	In this article, based on of open legislative data mining, we propose a methodology to create a model capable of indicating which characteristics have a positive or negative impact on the approval of a bill by the Chamber of Deputies. Added to the explanatory capacity, the model can also predict whether a bill will be approved or not. The model was submitted to experiment and analysis that measured and validated its explanatory and predictive capacity. In order to identify the most relevant characteristics we use an impact formula that calculates the relevance of the characteristics of the model in its final approval or archiving decision. In the end, the generated model contributed by clarifying characteristics relevant to the approval or not of the bill and achieved a good performance in its predictive capacity.
      "
5086;en_US;"
      	Conversational agent for natural language interaction, in general, face some challenges in providing content to support the responses requested by user. Usually of the content of the responses is manually defined, which is not an adequate solution. This work presents an approach to enabling these system to use automatically the concepts and relationships stored in Knowledge Bases. The main contribution of our approach is the generalization of the system, which can answer questions related to multiple domains. This is accomplished based on linguistic information as support to the activity of natural language understanding. The result obtained in the classification of question types and identification of nominal complements are presented and indicate promising result.
      "
5087;en_US;"
      	Business Process Management (BPM) has been receiving increasing attention in recent years. Many organization have been adapting their business to a process-centered view since they started noticing its potential to reduce costs, improve productivity and achieve higher levels of quality. However, implementing BPM in organization requires time, making the automation of process identification and discovery highly desirable. To achieve this expectation, the application of Natural Language Processing (NLP) technique and tool has emerged to generate process model from unstructured text. In this paper, we provide the result of a systematic literature review conducted in preparation and processing of natural language text aiming the extraction of business process and process quality assurance. The study presents technique applied to the BPM life-cycle phases of process identification, process discovery and process analysis as well as tool to support process discovery. This review covered paper from 2009 up to 2016 and identifies 518 articles of which 33 were selected as relevant to our work. The result of the present study may be valuable to support research in extraction of business process model from natural language text.
      "
5088;en_US;"
      	Elaborating an useful questionnaire represents an important task for descriptive research. Poorly elaborated questions can lead to answers with meaningless brased or naive interpretations. Therefore, it may be interesting to reuse, partially or totally, questionnaires already created with the same purpose. In this paper we compare QSMatching with the vector model to calculate the similarity between questionnaires and consequently to obtain a ranking of questionnaires according to the user query. In order to verify the effectiveness, an experiment was carried out comparing QSMatching and the vector model. The result of the analysis of the experiment shows that QSMatching is more effective than the vector model for questionnaires retrieval.
      "
5089;en_US;"
      	This paper presents a case study of the construction and execution of a model for the ranking of project submitted to the Scientific Initiation Program (PIBIC) of the University of Brasilia (UnB). In the execution of this work the Multiple Criteria Decision Analysis (MCDA) AHP and Promethee II method were applied. The result obtained in each method were analyzed and compared. Hence, a model proposal for PIBIC project selection is presented. The proposed model can be used in several project selection process, maintaining a coherence and standard in the evaluations.
      "
5090;en_US;"
      	The integration of inventory management, vehicle routing, and scheduling decisions is known as Inventory Routing Problem (IRP). In this problem, the main objective is to determine: (i) the quantity of products to be delivered based on customers demand; (ii) the delivery periods and (iii) the route of vehicles. IRPs that include time window service constraints are found in real scenarios and the attendance of this type of constraints brings benefits to both the supplier and the customer. This systematic review of the literature aims to identify trends in the area that studies Inventory Routing problem with time windows. We identify and analyze the proposed approaches, the characteristics of the solved problem and the type of experiment performed in 9 primary studies.
      "
5091;en_US;"
      	The inventory routing problem with stochastic demand includes the inventory control, product transportation and scheduling decisions, considering an estimation of customer demands. This problem appears in several real situations, playing a fundamental role in reducing costs and improving the efficiency and reliability of the service. In practice, there are often restrictions on the time window, which corresponds to a certain period of the day on which deliveries can be made. Despite the great relevance of this type of constraint, there are no result in the literature that combine stochastic demand and time window constraints. In this work, we propose a system, using advanced technique of operational research, to solve the inventory routing problem with stochastic demand, considering time window constraints, as well as additional constraints of maximum inventory capacity in both the client and the depot and individual confidence level of the customer service.
      "
5092;en_US;"
      	In this work, we investigate an important problem from the biology field, which consists in searching for specific pattern, named motifs, in network which represent certain biological interaction, such as metabolic network, regulatory network or Protein-Protein Interaction (PPI) network. Two linear integer model are proposed, one of them using the concept of representatives. We present computational experiment made with instances generated from PPI network with approximately 8.000 proteins and 29.000 interaction among them. As experimentally verified, the two proposed model were able to solve all instances in a very satisfactory amount of computational time.
      "
5093;en_US;"
      	According to estimates from the Federal Government, 200,000 people disappear from their homes every year in Brazil. In 2002, Brazilian national network for identification and location of missing children and adolescents established four important goals to tackle this serious problem. Our work is motivated by two of them: to create an unified register of missing people data and reported cases, and to promote information sharing among network members. Aiming at these goals, we developed Myosotis, an information system that performs analysis inside an unified database about Brazilian missing people. Data is collected autonomously from different source. Our first empirical result show that our system outperforms all existent solutions in the country, including the official database from Brazilian government, by up to 122% when considering the number of distinct registers. Also, our pattern analysis module is capable of giving insights about what peoples characteristics make them more statistically susceptible to disappear. All this consolidated information and the aggregated database as well are publicly available through a friendly open-source web application and a public API. We show how we developed this system, first in the country and still rare in the world, and the main challenges that this system still needs to overcome.
      "
5094;en_US;"
      	Over the years, SaaS (Software-as-a-Service) and DaaS (Data-as-a-Service) have respectively become common model for application delivery and cloud data delivery. However, the heterogeneity of these service makes it difficult to automate this process. In these cases, a solution for interoperating SaaS and DaaS is required. MIDAS (Middleware for DaaS and SaaS) is a proposal that does not present any mechanism that dynamically searches and updates DaaS, although it allows interoperating these layers. This limitation of MIDAS compromises interoperability, as it may result in outdated or non-existent DaaS. Therefore, it is necessary to have a repository inside the MIDAS, called DIS (dataset Information Storage), to store DaaS metadata in the clouds. However, DaaS information must be registered in an automated and periodic manner, in order to guarantee the traceability and updating of DaaS. Thus, the present paper proposes the development of a Web Crawler to be incorporated into the MIDAS middleware, to (i) periodically update the DIS information, guaranteeing the consistency of DaaS, and (ii) analyze the existence of semantic similarities among DaaS, so that the DaaS are aligned semantically. experiment were carried out with the purpose of validating the proposed work, in order to evaluate correctness, recall, execution time, overload, ontological consistency, and correction of alignments. The result obtained demonstrate the effectiveness and efficiency of our proposal.
      "
5095;en_US;"
      	In relation to alarming rates of feminicide and hospitalization of women due to domestic / familial / conjugal violence in Brazil and the high level of naturalization of violence by society, we see the need for mechanism to address this phenomenon through prevention. Thus, the objective of this research is to support women in the identification of abusive relationships, through an expert system, as well as to alert about the different manifestations of violence and to inform the procedures for reporting. In order to achieve this goal, a web application called Estamos Juntas has been designed and developed. Preliminary validations have pointed promising result related to the use of expert system associated with a website to solve the problem.
      "
5096;en_US;"
      	Investing in the stock market is a complex process due to its high volatility caused by factors as exchange rates, political events, inflation and the market history. To support investors decisions, the prediction of future stock price and economic metrics is valuable. With the hypothesis that there is a relation among investment performance indicators, we applied multi-target regression (MTR) method to estimate 6 different indicators aiming at creating an automated prediction tool for decision support. The experiment were based on 4 dataset, corresponding to 4 different time periods, composed of 63 combinations of weights of stock-picking concepts each, simulated in the US stock market. We compared traditional machine learning approaches with four state-of-the-art MTR solutions: Stacked Single Target, Ensemble of Regressor Chains, Deep Structure for Tracking Asynchronous Regressor Stacking and Multi-output Random Forest (MORF). With the exception of MORF, traditional approaches and the MTR method were evaluated with Random Forest and Support Vector Machine regressors. By means of extensive experimental evaluation, our result showed that the most recent MTR solutions can achieve suitable predictive performance, improving all the scenarios (12.6% in the best period, considering all target variables). In this sense, MTR is a proper strategy for building stock market decision support system based on prediction model.
      "
5097;en_US;"
      	Facial recognition system in controlled environments have presented satisfactory identification result. However, we can not make the same assertion when the collection environment is uncontrolled. The factors responsible for these low recognition rates are variations in illumination, pose, expression and occlusion, which introduce intraclass variations and degrade recognition performance. Compared with problem of pose, illumination and expression, the problem related to occlusion is relatively little studied in the area. In the literature there are some technique based on subspace with initiatives to reconstruct the partly occluded face. However, there is no study showing the pros and cons of each variation. The objective of this work is to investigate the different existing technique based on subspace, and with this to present the pros and cons of each technique. In this paper, the Wavelet transform was used to extract a set of characteristics of face image. According to the result we can see that the Fast Recursive PCA, Recursive and GPCA strategies achieved better performance, in terms of recognition rate, after evaluation with the Extreme Learning Machine classifier.
      "
5099;en_US;"
        Human Activity Recognition (RAH) aims to classify the activity performed by a user collecting data from heterogeneous sensor. The RAH allows the monitoring of user actions, offering service in the area of medical care, in the accompaniment of the elderly, health monitoring, fitness tracking, home and work automation, among others. The RAH can be seen as an Information System composed by three steps: data collection and preprocessing, feature extraction and classification. Despite the abundance of work proposed for this subject, an important issue to be addressed is how to choose the tool and method to be used in each step of the RAH. This choice is a difficult process, because it involves comparing the result obtained by other work, most of which use private dataset, extract different sets of feature, and use different classification algorithm. This paper aims to characterize and compare the main tool, method and databases for the RAH task. In addition, it aims to provide guidance and guidelines for future research in the area. experiment were performed in order to identify the main attributes to be used in the classification. It can observed the attributes mean, standard deviation, and variance produce the best model to the classification task.
      "
5100;en_US;"
        Among the agricultural crops used for human consumption, 75% depends on pollination. As the principal pollinating agent, bees are essential for the food production for humans and the ecosystem sustainability. However, a combination of habitat destruction, climate change and exposure to pesticides and pathogens has led to a significant decrease in bee population. Here we propose a method to recognize status pattern of Apis mellifera colonies through the application of data mining technique. Using a real dataset from the HiveTool.net containing Apis mellifera temperature, humidity and weight data, we identified 3 status pattern in the observed hive. Our result suggest that the recognized pattern are consistent with a honey bee colony life cycle. Based on the found pattern, we propose a high accuracy classification model capable of automatically identifying colony status for new sample.
      "
5101;en_US;"
       Automatic image classification strongly depends on image representation, commonly made using visual descriptors. Several work compare the variety of the available ones, aiming to guide analysts in which one to choose for each scenario, but they consider only numerical accuracy result, which may limit the understanding of reasons for these performance differences. This paper employs Neighbor Joining similarity trees to visually analyze three image descriptors, focusing on their application in an automatic classification scenario. The result demonstrated that these trees provide means to comprehend important information about the descriptors, such as how they describe image characteristics, which image aspects they focus in the representation, and which criteria they consider to distinguish image into different classes, revealing their strengths and limitations regarding the representation of a specific categorization scheme. We believe such analysis may help specialists to better choose which descriptor is adequate to be used in this data mining task. 
      "
5102;en_US;"
       The complexity of real-world problem requires, in most cases, optimized solutions considering multiple objectives. For this reason, the multi-objective optimization has been increasingly used to treat this kind of problem. In this work, an approach is proposed to deal with multi-objective routes generation considering multiple metrics and traffic congestion estimates. The experiment include vehicles that intend to perform routes with multiple stops in large-scale road network. The OpenStreetMap data was used to create the road network that contains all information needed. Four scenarios were simulated with different levels of traffic congestion. After this, the obtained result were compared with the best solutions computed by Dijkstras Algorithm. The proposed approach has obtained good computational performance and shown efficiency, offer good trade-offs, highlighting the best result for scenarios with higher traffic congestion levels. 
      "
5103;en_US;"
        Currently, social network has been used for its user, and exploited by mechanism of quality measurement system and recommendation of products and service. The Recommendation system (SR) have used the data of the social network and in parallel they have applied the sentiment and affective analysis in such data. However, there is still a concern in increasing the accuracy of the sentiment and affective analysis. This article introduces an SR, which extracts the text of the user of the social network and suggests musical styles based on the sentiment analysis by lexical approach and based on the affective analysis through the machine learning. The Convolutional Neural Network algorithm used for the emotion classification of hapiness, sadness, anger, fear, disgust and surprise presented a precision higher than the found in related work. Classification result of the F-Measure were of 0.98 e 0.96 for the emotion of sadness and anger, respectively. In addition, SR was assessed by means of subjective tests and the experimental result show that 97% of user approved the SR proposal.
      "
5104;en_US;"
       The Peer-to-Peer (P2P) on-line lending is an emerging lending modality that brings creditors and borrowers closer while enabling a significant reduction of bureaucracy in the lending process. Despite its appealing, the increase in the demand for this lending modality depends on a rigorous settlement of the risk assignment to the potential borrowers. Considering this issue, this article discusses an experimental analysis of classification method for P2P on-line lending default prediction. The performed experiment were based on the application of the implemented classification algorithm over the data mass formed by borrowers profiles and loan history records of the P2P Lending Club platform. As the main contribution, the study revealed that it is possible to obtain satisfactory prediction result with a set of attributes smaller than those that were used in studies previously presented in the literature. In addition, it could be verified that, since the algorithm based on decision trees have proved highly effective, the use of these method is a feasible approach to support the development of lending negotiation tool. 
      "
5105;en_US;"
       application 1 may contain vulnerabilities for a variety of reasons, one of which is the use of vulnerable components. One of the solutions adopted to eliminate the vulnerabilities inserted by such components is to update the component to a more recent version that corrects the vulnerability. However, updating a component may require code refactoring, updating other components and inserting new vulnerabilities in the application. There are several tool that perform the analysis and management of dependencies of the project, but few tool present information about vulnerabilities of the new versions, incompatibilities and updates of the dependencies of the components. This article, therefore, presents dep|ct (depict), a tool that aims to identify the known vulnerable components used by the application and help in the decision on the updating of such components, in order to mitigate the vulnerabilities added to the project through the vulnerable dependencies. result of the empirical evaluation carried out on two project show that the tool can be used to assist in deciding on the update of known vulnerable components. 
      "
5106;en_US;"
      The benefits of using the BYOD (Bring Your Own Device) concept are many, but information security needs to be remodeled to ensure the basics of information. The article describes the development of a framework that integrates open-source security tool. The tool selected to compose the suite were: NetworkMiner, Universal Password Manager, Password Strength Meter, NetCalculator, jNetMap and IP Monitor. The selected software work as originally developed or integrated into the framework. Tests conducted on two network, wired and wireless, showed that the framework reach the proposed goals.  
      "
5107;en_US;"
        Section 404 of the SOX Act requires company to certify to the effectiveness of their internal control over financial reporting. After investigating this context considering the scope of Database Security (DB), it was verified that the related work explore in detail the strategic vision of the internal controls, but neglect their operational and practical aspects. Aiming to give a contribution to this problem, this work proposes a guide of operational and technical controls to evaluate the security of the DB according to the SOX Act. As a proof-of-concept, the guide is used to the development of the tool SOXSecurity4DB, which was used in a case involving a multinational company of the retail industry.
      "
5108;en_US;"
      Denial of service attacks has shown to be one of the principal problem in the information security field on the Internet. Numerous work propose methodologies and tool to detect and mitigate DDoS attacks, and many of them use dataset to validate their proposal. The goal of this work is to identify undesirable, ideal and feasible characteristics of dataset used in DDoS researches. Moreover, an analysis of some dataset widely used in this research field in the light of the proposed characteristics will be made. The result have shown that dataset used broadly by researcher nowadays are outdated and unreproducible. On the other hand, there are more detailed and specific dataset on the attacks under discussion.  
      "
5109;en_US;"
       Person identification is an important factor for information system. Emerging technologies for security such as biometric identification based on EEG signals, although promising, still require extensive research and further refinement before applied in practice. This work address the problem of EEG channel selection for biometric identification. Five forms of EEG signal segmentation are explored before the feature extraction by autoregressive model (AR model). Channel selection is performed with two approaches, genetic algorithm and search-based ranking, and we use the classifier k-nearest neighbor (KNN) and support vector machine (SVM) for identification. The result indicate that it is possible to decrease up to 9 channels, regardless of individuals, and hold an accuracy close to the one obtained with all the 64 channels. 
      "
5110;en_US;"
       People Management (PM) is part of software project management since the Software Development Process (SDP) depends on the people who do it. In order to maximize the success of software project, agile method focus on people and their interaction. However, agile project still suffer from the risks of failure. Understanding that PM is a complex and central activity in the SDP, this paper aims to map how academic studies describe the PM in the software development environment, what good practices are described by these studies and how the software industry has applied the PM. Therefore it is intended to build a PM model for agile software development approaches. A Systematic Literature Review (SLR) was carried out in order to obtain data regarding the state of the art of PM in the agile development, and also a questionnaire format survey, which was answered by professionals working in the industry to map the application of PM mechanism in software development organization. From the data obtained in the SLR and in the questionnaires applied it was proposed a model of People Management. The proposed model was generically constructed to serve as a PM guide in agile project, regardless organization characteristics and the development team where the model will be implemented. 
      "
5111;en_US;"
       Context: One of the leading challenges in Distributed Software Development (DSD) is to communicate correctly and promptly, as factors such as physical distance and lack of face-to-face contact can hinder this process. In this context, the Communication Maturity Model (C2M) was proposed as an option to support the improvement of communication in DSD. But this maturity model could not be effectively used in organization, due to the absence a specific C2M based assessment method. Objective: This work aims to present the Standard C2M Based Assessment Method (SCBAM) in its basic dimension, the Basic Standard C2M Based Assessment Method (SCBAM-B). An assessment method to determine the maturity level of communication in DSD organization, based on the C2M model. Method: The SCBAM-B was designed according to a methodology that included a review of the DSD literature, maturity and capacity model, evaluation method, the development of a software tool, and evaluation with experts. result: The SCBAM-B was perceived by experts as a relevant approach for assessing the communication level in organization and propose a path for improvements. Conclusions: For being lightweight and capable of automation, the SCBAM-B has the potential to help the communication improvement in DSD organization, in the light of the C2M model. 
      "
5112;en_US;"
       Communication is one of the pillars of collaborative work and has been addressed in the literature as one of the critical factors that impact the result of a software project. However, there is a lack of computational tool to support communication analysis. This paper introduces ColMiner, a tool capable to measure the communication quality in an issue tracking environment through the calculation of the issue comment relevance for the main theme of the discussion (thematic relevance). Its purpose is to identify failures in the communication process. The approach of communication analysis uses some text mining technique based on the use of graph to represent the comment textual content. To validate the approach, the relevances calculated by ColMiner are compared with those manually defined by some developers. Finally, the work presents the main funcionalities of ColMiner, highlighting the support to the communications management in software project, and discuss some threats to validity. 
      "
5113;en_US;"
       Increasing in the creative economics, growth in the demand of mobile application, and necessity of rapid product availability to the customer promote arising from project that have a life cycle of a few days. These type of project are called super agile. Among them are innovation project with emphasis in mobile application and elaboration of proof of concept to study the technical viability or others project developed, for example, by startups. However, the field of super agile software development still is in its initial stages, maybe because it is a recent problem faced by company and startups. Thereby, this article proposes a development process that meets the feature of project with short life cycles of up to 2 weeks. The proposed process based on market demands, identified in field research, integrates the most current used agile method and methodologies. An initial evaluation in three organization showed that the process is adherent to necessities of these company. 
      "
5114;en_US;"
      This paper presents a proposal for a framework for Information and Communication Technology governance aiming at smart city with a focus on enterprise architecture. A case study in the area of education was chosen to present a view of the modeling in archimate language. Five enterprise architecture implementation methodologies were reviewed. Eleven axes were recognized and compared with other methodologies to evaluate the maturity level of city governance. This led to a questionnaire of diagnostic assessment to identify the maturity level in city councils. This method generated the score of each axis, which allowed visualization of the maturity model of council governance. The result showed that the organization diagnosed in relation to the eleven defined axes are between 11.43% and 58.22%, with the objective of reaching 100% for a high-performance rate in relation to the enterprise architecture.  
      "
5115;en_US;"
       Agile approaches are known by making the use of informal elicitation technique for requirement specification. The exclusive use of these technique may cause some issues, such as ambiguous specifications and information lack. In this work we investigate better approaches to specify requirement in agile project. Thus, we conducted an empirical evaluation about applicability of a formal method as specification technique, using mathematical logic as a possibility to solve limitations of informal specification. Initially, we conducted a survey to obtain the agile team practitioners opinion. Furthermore, we conducted two separated case studies in two agile teams to evaluate the applicability of Z notation in the requirement specification. Our initial result pointed out that formal specification assists on making complex requirement clearer and decreasing the time to understand their meanings. 
      "
5117;en_US;"
       Different technique for eliciting requirement from business process model have arisen due to the importance of software requirement to be aligned with the business in order to achieve organizational goals. Although there are several ways to represent these model, the BPMN notation has been considered the most adequate for facilitating the communication between different types of stakeholders. This paper aims to present a systematic review with the support of the snowballing technique, to raise studies on how to elicit and specify requirement from business process model in BPMN. As main result it is pointed out that this type of elicitation is recent, well automated, uses supporting heuristics, is mainly concerned with functional requirement, and the most of primary studies specify the requirement as use cases. 
      "
5118;en_US;"
       Fast-changing business environments have become enterprise information system more heterogeneous and complex. This extreme uncertainty leads to continuous development and integration of architecturally relevant components developed in parallel. In this context, the proper composition of such components is critical to reduce the development effort. However, the current composition tool are still considered imprecise and inflexible for this purpose. This article, therefore, proposes MoCoTo, a model composition tool to support the integration of UML component diagrams. It exploits equivalence relationships between the UML component elements to improve integration precision and accuracy. Developers and system analysts can benefit from using MoCoTo when evolving or maintaining architectural model of enterprise information system. MoCoTo was implemented as an Eclipse platform plug-in. The tool was used to support the composition of architectural components in three realistic evolution scenarios of a Software Product Line. Our preliminary result indicated that MoCoTo was able to integrate architectural model represented with UML component diagrams. The metrics used to evaluate the effectiveness of the proposed tool (i.e., precision, recall and F-measure) presented values higher than 0.6 in all evaluation scenarios. 
      "
5119;en_US;"
       Knowledge-intensive process (KiP) are poorly structured, dynamic and highly complex. The Knowledge Intensive Process Ontology (KiPO) constitutes a semantically rich conceptualization (encompassing a set of logical rule) about the domain of KiP that may serve as a basis to understand, identify and manage KiP effectively. However, applying KiPO in real scenarios requires its instantiation, validation and simulation in an application level, which are complex tasks for user that typically are not experts in non-trivial issues on conceptual modeling. This work proposes a rule-based strategy to validate or simulate KiP model. The proposed strategy transforms the KiPO rule into the existing specifications in the Alloy logic-based language, using the Alloy Analyzer model analyzer. The main contribution of this research is to show the applicability of the Alloy tool to this context in a case study with four different scenarios. A process modeler can directly benefit from these result. 
      "
5120;en_US;"
       Business area managers should have access to business process indicators of their organization to be capable of obtaining and analyzing information at real time during critical situations. However, the monitoring approaches commonly provided to such managers usually address only indicators at the level of the service implementing the business process, which are technical measures directed to Information Technology (IT) managers. This paper introduces the StrAli-BAM (Strategic Alignment with Business Activity Monitoring) approach to assist strategic alignment between business and IT through monitoring non-functional business process requirement based on Quality of Service (QoS) levels. StrAli-BAM aims to enable business area managers to monitor the execution of business process by focusing on the indicators that are really sensitive to the execution of business process. StrAli-BAM consists of: a non functional requirement monitor and an infrastructure for SOA event-based execution and monitoring. This paper was performed following the research method of project science. The proposed approach is evaluated via a proof of concept in an online shopping scenario with non-functional response time requirement monitoring. 
      "
5121;en_US;"
       All organization perform process to reach their business objectives, aiming to get competitive advantage, improving them by means of innovation and redesign activity. Some approaches, like Social BPM, argue that own clients can contribute with the business process innovations, but these clients have also own interests and motivations, making that collaboration a challenge. It is argued that before contributing with a process, people should understand it. One way to give the process particularities is using digital game. In that sense, the research proposal is to study the interaction of process through digital game, and such is necessary to think how design digital game, aiming to make easier the process representation in game. Therefore, this paper presents a mapping method between process model elements and digital game design elements, focusing in facilitate the process representations in game. From this method, have been made case studies in order to check the mapping similarities performed with the same process, and the mapping replicability to different process. As result, we have observed that the mapping method seems useful to get digital game design elements based on business process model, helping the representation of them as digital game. 
      "
5122;en_US;"
       Studies have shown that most Brazilian federal universities do not fully comply with e-government standards and fail to deliver software that meets the requirement and expectations coming from different source at the same time: stakeholders, institutions, and the federal government. One of the main issue in this scenario is the great effort spent on the development of tailor made software instead of standard products meant for a wider range of customers, such as product lines, for instance, specially because many institutions face problem related to increasing demand and technical staff shortage. Software Product Management (SPM) is a discipline proposed to govern software products to ensure that business goals are achieved and resource are responsibly utilized. Since federal institutions can benefit from such type of management strategy, we present an investigation aiming to understand the main differences between the actors and business process proposed in SPM reference model and those present in public universities when it comes to deliver software products and service. Accordingly, we propose a high level SPM model for federal universities which was adapted from a well known SPM reference model. result and discussion provided in this paper can shed light into how to tailor a detailed SPM model for this specific domain.  
      "
5123;en_US;"
       Software size estimation may be costly due to the time spent in estimation, even using referenced method, such as, Functional Size Measurement method. This research objective is to reduce estimation cost in the very early stage of software development life cycle based on user stories and COSMIC method. We propose automated size estimation in order to reduce estimation cost and increase the accuracy. We conducted a quasi-experiment where the control group is composed of certified professionals and the experimental group is actually the proposed automated estimation tool. result show promising evidence of success in terms of estimation precision. Based on these preliminary result we conclude that user story size automation is valuable and may be more objective and precise that manual estimation. 
      "
5124;en_US;"
       Testing and debugging are key tasks during the software development cycle. Spectrum-Based Fault Localization (SFL) is a consolidated debugging technique due to it is relative low execution cost. SFL pinpoints the most suspicious program elements by ranking lines, method, classes and packages that are more likely to contain faults. Recently, SFL tool have been proposed to help developers during debugging. These tool use different metaphors to represent the suspiciousness of program elements. In this paper, we compare two SFL tool that utilize different metaphors: Jaguar and CodeForest. Jaguar uses a textual representation, presenting the most suspicious elements of a program as a list sorted by suspiciousness. CodeForest uses three-dimensional visualization metaphor, presenting a program as a cacti forest in which basic blocks are represented as thorns, method as branches, and classes as cacti. We present the result of an evaluation with 76 student using both tool. The perception of usability of the tool was assessed using a questionnaire based on the Technology Acceptance Model (TAM). Three factors were considered to measure the impact of use of the tool in the debugging activity: intention of use, usefulness, and ease of use. The result suggest that there is not statistical difference in the perception of usability between CodeForest and Jaguar. 
      "
5125;en_US;"
       The use of smartphone technology is now ubiquitous as they become part of peoples day-to-day lives. Mobile apps have been explored in a number of use cases including medical, education, entertainment - to cite a few. A growing number of mobile interface are now designed to be persuasive with respect to the Fogg Behaviour Model (FBM). This work carried out a structured user survey to evaluate the effectiveness of a persuasive interface in a smartphone energy setting. The mobile phone app brings awareness of energy consumption and help engaging with user towards good practices for electricity cost savings. In this study it was possible to evaluate the level of communication obtained between interface and user of the persuasive technology, being possible to verify item to be optimized in the interface design. 
      "
5126;en_US;"
       CASE tool are software products widely used as support for the development process of information system. However, a problem reported in the literature is the deficiency presented by these tool regarding their usability, which can have a negative impact on the tasks performed by the developers. In this context, this article presents a systematic mapping of the literature, in which was identified, catalogued, and classified studies whose focus is the usability analysis in CASE tool. This article aims to improve the knowledge of researcher and professionals regarding the existing standards for usability evaluation of this type of tool, as well as highlight the main challenges and research gaps related to this area. 
      "
5127;en_US;"
       The development process of free information system has been explored in several studies, pointing out problem about the low usability of these system. However, there is little knowledge about the insertion of usability issues into the development process of these system when it comes to Assistive Technology resource. Those system have particularities regarding the way user are involved, since they serve specific user (e.g., visually disabled user). This paper presents an investigation about the development process of a free information system, the NVDA (NonVisual Desktop) screen reade. The study analyzed the inclusion of of usability and accessibility practices in activity of the process applied in its development. Thus, observed practices were grouped according to ISO/IEC 12207 standards. The study demonstrated that several principles of User Centered Design could be indirectly detected in the process, considering the particularities of a free software project. 
      "
5128;en_US;"
       With an evolution of mobile device, as people have passed a generation and share a significant amount of data about their derivatives in service or platforms on the Web. In this context, this data can be collected, processed, stored and used by third parties, many times, in an imperceptible way to the user. Thus, an emerging area, called Human-Data Interaction (HDI), seeks to consider an inclusion of human factors in the data flow, providing mechanism for managers to interact more transparently with system that use their data. Moreover, there are difficulties in interacting with these mechanism and understanding what they can do. Thus, it is important to create designers on how to convey the HDI capabilities to the user, contributing to the best use. Based on this vision, this work presents a communication strategy and enables Human-Data Interaction through the identification of the application of HDI concepts in data management application, using the Semiotic Inspection Method (SIM). 
      "
5129;en_US;"
       The Brazilian Electronic Government Accessibility Model, the e-MAG, propose a set of recommendation to support the implementation of digital accessibility. However, it does not have specific recommendation for mobile application digital accessibility. Using recommendation devised for web pages, as proposed by the e-MAG, may not be intuitive or straightforward. In practice, studies show that mobile application developed by the Brazilian government present several accessibility flaws. Therefore, this paper presents a set of 35 accessibility recommendation for mobile device extracted and adapted from the e-MAG. Additionally, 12 e-government mobile application were evaluated based on the recommendation proposed. result show that all application analyzed present accessibility issues. 
      "
5130;en_US;"
       This study presents Doric, a software architecture for data-intensive real-time application. Dimensions of data-intensive real-time application are introduced, as well as technologies that enable the implementation of such dimensions. A case study involving a portable electroencephalogram (EEG) enabled data collection based on realistic scenarios found in data-intensive real-time application. The Doric architecture was implemented using recent technologies (e.g., Apache Kafka) for building real-time data pipelines and streaming application. This prototype was evaluated in five scenarios containing different volumes of data. The obtained result were encouraging and show the potential for applying Doric as a structure to foster the development of modern information system in organization and to support serve as a guideline for new corporate architectures. 
      "
5131;en_US;"
       Cloud computing introduces a new level of flexibility and scalability for provider and clients, because it addresses challenges such as rapid change in Information Technology (IT) scenarios and the need to reduce costs and time in infrastructure management. However, to be able to offer quality of service (QoS) guarantees without limiting the number of requests accepted, provider must be able to dynamically and efficiently scale service requests to run on the computational resource available in the data centers. Load balancing is not a trivial task, involving challenges related to service demand, which can shift instantly, to performance modeling, deployment and monitoring of application in virtualized IT resource. In this way, the aim of this paper is to develop and evaluate the performance of different load balancing heuristics for a cloud environment in order to establish a more efficient mapping between the service requests and the virtual machine that will execute them, and to ensure the quality of service as defined in the service level agreement. By means of experiment, it was verified that the proposed heuristics presented better result when compared with traditional and artificial intelligence heuristics. 
      "
5132;en_US;"
       The need to recommend resource in many different application domains and to develop solutions focused on recommender system (RS) components reuse create an interesting scenario for the adoption of Software Ecosystem (SECO) perspective. In this way, the problem addressed by this study is how to integrate the various method of existing recommendation system in a systematic and centralized way. This paper proposes R.ECOS, a reuse-based ecosystem platform for RS. The proposal evaluation was carried out through a case study. The result point to the solution feasibility, along with the platform components. The main contribution is the implementation of the platform that supports the proposed SECO. 
      "
5133;en_US;"
       Service Oriented Architecture (SOA) reuse has been used strategically in organization to reduce development costs and increase the quality of application. This article analyzes a systematic literature review in order to identify concepts, goals, strategies, and metrics of SOA reuse. The result show that the main goal of SOA reuse is to decrease development costs. The factor that most negatively influences SOA reuse is the existence of legacy system. The strategy used most to potentialize SOA reuse is business process management. Metrics proposed by studies to measure SOA reuse are related to modularity and adaptability indicators. The study is relevant because it increases the body of knowledge of the area. Additionally, a set of gaps to be addressed by researcher and reuse practitioners was identified. 
      "
5135;en_US;"The treatment of image captured in situations where there the we
have bad visibility like smoke or foggy weather conditions is a great challenge.
In this sense, we have developed a technique of filtering smoke and foggy in
image that have the potential to benefit many application of understanding
and computational vision. Our algorithm is based on a serie of mathematical
method to capture the noise by means of its density, in the end our result
demonstrate that the method is quite effective to solve the problem of the test
image"
5136;en_US;"In recent decades, the high rates of suicide worldwide have been
drawing the attention of government agencies and society in general.
Strategies for treatment and prevention have been formulated, however, there
is a great difficulty in detecting people in situations of risk. In this context, the
present work proposes a method for suicide risk classifier using Natural
Language Processing (NLP), which seeks to identify suicidal intentions in text
message. The classifier is a Naive Bayes learning algorithm that delivers
70.45% accuracy, 54.2% acceptance rate for suicidal message and 95% for
non-suicidal."
5137;en_US;"This paper creates a methodology capable of performing gesture
recognition, where the idea is to extract characteristics of the segmented hand,
from dynamic image captured from a webcam, and to identify signal pattern.
With the creation of this mechanism it will be possible develop tool to facilitate the manipulation of an robotic arm that performs specific movements. The
method used consists of the Continuously Adaptive Mean-SHIFT algorithm,
Canny operator and Deep Learning through Convolutional Neural Network.
The method obtains a accuracy rate of 97.50% in recognizing the gesture pattern as observed in the statistical data obtained."
5138;en_US;" The internet provide social media tool by which people communicate
and influence the social, political and economic behavior of others. In this
context, this work shows how the process of Feeling Analysis can obtain the
evaluation of people in relation to products through the analysis of text. The
contributions of this article were the creation of the database and generation of
the predictive model."
5139;en_US;"The proposal of the present work was to use the ESP8266 nodeMCU
wifi with the IoT Admin API for the automation of the control and monitoring
of the cultivation of hydroponic cultures of the NFT (Nutrient Film Technique)
technique and aquaponics in Real-Time. We present the following automation
model in prototype format. The experiment found that its operation is of great
importance in the automation, since besides giving convenience to the owners of
the cultures of hydroponic crops, it covers a great facility in the administration
of its components and development of the crop."
5140;en_US;"In daily activity, we demand to move several organs that are coordinated by a network of body system (muscular, nervous and osseous). In the
Functional Evaluations(FE), several tests are performed, among them there is
the palmar grip that analyzes the behavior of corpora system and offers feedback to patient about possible command failures. Thus, in this work we implemented a glove, using Velostat, to assist Physiotherapists in end-to-end palmar
grip tests, offering result with muscle strength progression and touch sensitivity
identification. Tests were performed to determine the viability and function of
the glove. In addition, we perform detailed examinations on ”normal”people."
5141;en_US;"This work approaches an HCR system using a genetic algorithm to estimate the kernel parameters of an SVM for the recognition of the manuscript characters of the MNIST database with the objective of increasing the correct- ness percentage of the classifier by finding the best parameters. Digital image processing (PDI) technique for image processing are also addressed. In the first topic are presented related introductory concepts and some work found in the literature. In the following topic, we describe the methodology used with the main concepts addressed, and the result achieved and conclusions about the approach taken."
5142;en_US;"Skin cancer is the cancer form with the highest incidence in the population, and although melanoma is a small fraction of these incidences, it is
usually the most severe type of skin cancer. Several types of approaches in the
area of automatic detection and diagnosis of this type of disease are being explored as pattern recognition technique along with machine learning. This work
aims to study binary local pattern associated with the spatial decomposition
of the lesion region for the automatic detection of melanoma. The study, which
compares the performance of the application of three different classifier to the
problem, achieves the best 0.88 result of accuracy and accuracy for the PH2
base demonstrating the methodology’s efficiency to the problem of melanoma
detection."
5143;en_US;"This work proposes a computer vision system for wheelchair control
based on facial coordinates and head position estimation. This work comprises
the design of a low-cost motorized wheelchair, which aims to promote independence and quality of life for people who have motor difficulties to manipulate a
joystick. The tests resulted in an accuracy of 87.78 %, an precision of 90.00 %
and a sensitivity of 87.70 %."
5144;en_US;"This paper presents a certifying board, as well as a software
specially developed for it, which, allied with the Brazilian Technical
Standards Association rule for incubators performance may, regardless of
brand and manufacturer, determine if the equipment reaches the minimal
operation requirement."
5145;en_US;"The learning of Analytical Geometry can become a challenge for
the student in the face of teaching model that are based on expository
content classes, only. Context-sensitive u-learning can be a tool capable of
assisting in this teaching process, as it adapts to the student individual
environment and needs. Another aid tool is the use of educational game,
aiming to arouse interest and motivation. This article proposes a mobile
educational game, in development, context sensitive u-learning of user
location, based on the game Naval battle. The game aims to make the
learning of Analytical Geometry more playful, making it easier for the
student to create a link between theory and practice."
5146;en_US;"This paper presents an experience report about the development of scientific
articles and image editors, presenting their contributions in favor of teaching and
learning computer graphics. The research comes from the quanti-qualitative analysis of
the editors and articles developed, as well as a dissertation questionnaire applied to the
student who studied the discipline. The analyzed result allowed the positive
visualization of the development of editors and articles as a methodological approach
facilitating the teaching and learning process in the discipline of computer graphics."
5147;en_US;"This article evidences the use of basic computer science integrated to
the disciplines of elementary education. With the objective of presenting the
contributions that this integration promotes to the student of this public, the
research was carried out with student of the 3rd year of elementary school from
observation in the classroom and the verification of the non-use of information
technology. This is an action research, with practical classes of 3 hours for each
discipline: Religious Education, English, Arts, Mathematics, Portuguese,
Science, Physical Education, Geography and Writing. The integration of
informatics with the disciplines offers great relevance to the pedagogical
process and to the digital formation and inclusion of the student."
5148;en_US;"This article discusses the development process of a mobile platform
that offers geographic points of criminal cases in different regions in a
collaborative way. The public security, as with all the service provided by the
government, has been discussed. The objective is to try and find ways to
maximize and improve their service. In order to do that, new issues have been
discovered and possible solutions proposed. The proposal is the development of
digital platforms to maximize sharing of critical information."
5149;en_US;"As well as other area of the body, the eye is the target of several kinds
of disease that directly affect vision, something essential to the human condition. This work proposes an application method for a Computer Aided Diagnosis system that uses corneal image marked by an ophthalmologist. The method
seeks to segment the injured area using Supervised Machine Learning algorithm, evaluating the performance of three different classifier: Multi-Layer
Perceptron, Random Forest and Support Vector Machine. Among the result obtained, the Random Forest algorithm performed best with Accuracy, Sensitivity
and Specificity rates of 93.47%, 94.41% and 93.61%, respectively."
5150;en_US;"A key step in animal breeding programs is the genetic evaluation, that is, the identification of genetically superior individuals for traits of economic importance. One of the consolidated method for calculating the genetic values of animals in evaluations is the resolution of the Best Linear Unblased Prediction (BLUP). However, due to the size of the system of linear equations that result from the BLUP resolution, it is necessary to use efficient computational system. In this work, we present the implementation of a web service for the genetic evaluation of goat and sheep flocks using BLUP. To verify its functioning, an experiment was carried out, where the result were compared with another tool commonly used in genetic evaluations. The result of the experiment showed that the implemented tool can be used by breeders and researcher, facilitating the evaluation stage in the genetic improvement process of small ruminants."
5151;en_US;"Quality is an essential feature of software. However, the quality of a software usually decreases during development. This occurs most often by actions taken by the development team that bring short-term benefits, but compromise the quality and evolution of long-term software. This phenomenon is known in the literature as Technical Debt. Because of this, in this paper presents a module called TDVision to identify and visualize technical debt present in software, in order to support management and quality inspection activity."
5152;en_US;"The difficulty of student in learning programming content worries
several IT teachers. In this perspective a study was carried out with student of
the Technical Course in Informatics to ascertain the effectiveness of Greenfoot
as a tool to aid learning. This study aims to verify the efficiency of Greenfoot as
a teaching tool of Object Oriented Programming. The methodology was based
on bibliographical research and the case study carried out with a second-year
class. The result were positive regarding learning with Greenfoot software. The
work revealed the importance of the use of software as a mechanism to support
the teaching-learning of programming contents."
5153;en_US;"Information Technology (IT) is present in most company, the
Brazilian computer market grew by 6% in 2017 and the annual cost per user
reached R$ 35 thousand. It is necessary to use some IT methodology, seeking
to improve IT management and reduce risks. This work investigated the main
methodologies of IT management and produced parameters for its selection, in
a systemic way and adhering to the reality of the company. The selected
parameters were applied in a case study and the result was satisfactory."
5154;en_US;"Automatic gesture and pose recognition by machine learning is a significant challenge. This work proposes a simple method for human pose recognition using exclusively depth image. The method consists in background
removal, feature extraction via histograms of oriented gradients (HOG) and
classification through support vector machine (SVM). The method is validated
in a test with five human poses, in which a 95.6% success rate is obtained."
5155;en_US;"Glaucoma is one of the leading causes of blindness worldwide. This
pathology has no cure and its treatment in the early stages is fundamental to
avoid loss of vision. In these cases, computer system can be used to aid
diagnosis. Thus, this study aims to develop an efficient method for detecting
glaucoma. The proposal uses new approaches to image preparation, active
contour segmentation and extraction of Local Binary Pattern (LBP) texture
feature. Finally, the classification is performed, validating the methodology.
The result were significant, showing better metrics to the Artificial Neural
Network, with accuracy of 96.13%, sensitivity of 94.17%, specificity of 98.13%,
and kappa statistic of 0.922."
5156;en_US;"This paper presents a study evaluating the delay in packets transmission to PMP (Point-to-Multipoint) topology in WiMAX network. To analyze the
delay in packet transmission we considered different modulation formats: BPSK
(Binary Phase Shift Keying), QPSK (Quadrature Phase Shift Keying) and QAM
(Quadrature Amplitude Modulation), and for the QoS (Quality of Service) class:
UGS (Unsolicited Grant Service), RTPS (Real-Time Polling Service), NRTPS
(Non-Real-Time Polling Service) and BE (Best Effort). For the realization of the
simulation, the NS-3 (Network Simulator - version 3) was used. In terms of
modulation format, the result show that QAM64 34 compared to BPSK 12
showed a lower delay time between packets of 89.96%, or 16.91 ms (milliseconds). In terms of QoS class, the UGS showed a minimum delay time between
packets of 123.61% or 10.38 ms."
5158;en_US;"This paper aims to analyze and describe the basic assembly of a prototype for a Alert IoT (Internet of Things) System for usage of Controlled Medicine. The system is composed by three components: the first one is a tabletop
container with six drawers, each one with its own medicines and sensor. The
second one is a online module which one allows the user to schedule the times
he wants to take the medicine kept in a certain drawer. Finally, the third one
component is a circuit microcontrolled by an ESP8266 that is able to fire two
alarms: a visual one, connected to the drawer whose time the user scheduled in,
and a sound alarm in the form of a beep. The proposed system was implemented
in a real situation an it work as expected."
5159;en_US;"The use of application has been widely used for the most diverse activity. Contributing even significantly to the marketing of candidates in electoral periods. The purpose of this paper is to show the importance of digital marketing through tool for mobile device, facilitating access to candidate information by voters. The methodology adopted is based on bibliographic research and the construction of an application through the Intel XDK software. The result were quite promising with regard to the purpose of the application. With this work it is evident that the use of mobile application facilitates the interaction between candidates and voters, approaching them positively in the electoral contest."
5160;en_US;"The congresses and scientific fairs have an important role in the academic environment by gathering a large audience and passing ideas that arrive faster to the student. The management of these events is not easy, requires some level of organization to more effectively allocate the available resource. The internet is currently the best way to publicize these events, but the technical knowledge required for document publishing becomes an obstacle for many professors and organizers. Therefore, this study aims to describe an alternative to the efficient management of scholar events and the same time the disclosure creating an web tool called Scholarevents."
5161;en_US;"The Educational Game In Search of Knowledge makes possible the social
inclusion of religious education through pounds and makes the teaching of the second
official language of Brazil more attractive for deaf people and for the society in general
that seeks to know this language. Developed without hurting the religious principles of
any people, the work accomplished goes far beyond a simple educational game,
developed through C ++ (Compiled multi-paradigm programming language), since the
level of quality of the graphics is exceptional, and the interaction with the technological
world, through the internet in the game itself, makes the experience interesting where
the player learns in a playful way."
5162;en_US;"It is known that studies on Assistive Technologies aim to provide quality of life and the inclusion of people with disabilities. In these terms, the objective of this work was to demonstrate the use of speech synthesis software,
facilitating the communication of people with speech difficulties and with low
mobility. The article was based on bibliographic research and the construction
of the TuVoz application, using the Android Studio development environment,
with Java and Groovy programming language. The system presented satisfactory result during the simulation performed, returning sentences according to
the user’s choice by touching the screen."
5163;en_US;"The mobile platform is no longer a promise to become a reality, with
an exponential growth in the most diversified area, makes it one of the most
sought after development area for software implementation. With this in
mind, the idea was to develop a project to implement an App that seeks to
disseminate and popularize the historical context of the city of Caxias, through
the use of cellular technology in a practical, precise and attractive way. As a
development methodology, the descriptive model was chosen. As a result, a
QR-Code reader application was implemented, using cards installed with the
support of the city of Caxias-MA, which enables the visualization of the
information. Contribution, the application is available on the Play Store
platform for free."
5164;en_US;"The article is about a systematic review regarding alternative
methodologies in the teaching of Software Engineering. After the primary
search, 36 studies were cataloged, read and verified according to inclusion
and exclusion criteria, thus generating a sample of 10 studies. It was noticed
that the common problem related to the analyzed work is the excess of
theoretical classes applied to several concepts of the area in question. The uses
of these methodologies aimed to improve the motivation and permanence of
student thus attracting interest to the area. The most used technique were
those aimed at game that could simulate the randomness and problem found
in the labor market."
5165;en_US;"The contents of Physics are well known for presenting difficulties of
understanding on the part of the student. In this perspective, a study was carried out with student from the 1st year of high school in order to ascertain the
effectiveness of Algodoo as a tool to aid learning. Aiming to verify the efficiency of Algodoo as a facilitating teaching and learning tool. The methodology
adopted was based on bibliographical research and on the case study carried
out with a first-year class. The result were positive regarding learning with the
Algodoo software. The work revealed the importance of the use of software as
a mechanism to support the teaching-learning of physics contents through 2D
simulation."
5166;en_US;"Cloud Computing is a technology that provides on demand service to individuals, company or governments using the Internet. The shared cost of cloud infrastructure has made this technology one of the most important in recent years. On the other hand, both customers and provider are increasingly concerned about the privacy of their data in these distributed environments. This work is a systematic review of 20 selected studies that report on the challenges and difficulties in maintaining data security and privacy in cloud computing technologies and more recently in Docker container technology."
5167;en_US;"<p>Autism and Down syndrome are disorders that affect the ability to communicate and interact. In this perspective, a study was carried out with children to ascertain the effectiveness of the LeNuVo APP as a teaching tool. Aiming to verify the efficiency in teaching-learning numerals and expanding vocabulary. The methodology was based on bibliographical research and the case study carried out with two classes of elementary school. The result were very promising based on the evaluation made with the support of the teachers, giving children the opportunity to learn, numerals and vocabulary. From this perspective, the need to use resource to assist the learning of children with special needs was identified.</p>"
5168;en_US;"This article describing the experience of supervised internship IV,
where the use of digital information and communication technologies was
developed as methodological resource in order to show the feasibility of its
use in the multifunctional resource room, which is aimed at student with
special educational needs (NEE). The proposal consisted in making use of
technological tool as a way of teaching learning to student with NEE.
During the observation period it was seen that the student did not have
fluency with such technologies, in that the work was based on inserting the
student in the technological world showing ways of teaching using diverse
digital technologies. It was seen a development of the student to the
knowledge taught and still an increase in the fluency of some technological
tool. In this, it becomes viable the use of digital technologies, widening the
scope of knowledge of the student with NEE, causing new doors to open."
5169;en_US;"This paper presents an analysis on the application of the Floodlight
controller in order to demonstrate the possibilities of the test combination in a
simulated environment of Software Defined network (SDN) through the Mininet
simulator. Through experiment it was possible to realize that in most cases,
Floodlight was able to get better or equal result to the native controller. Thus,
a great versatility of the Mininet simulator was observed, allowing the creation
of customized SDN structures."
5170;en_US;"The present article consists in the development of a system that
monitors the energization of electric charges, allowing to connect or
disconnect electronic device through a web page. The system developed in
this article aims to monitor computer remotely. The proposed monitoring is
made possible through the use of a Linux embedded system based on the
Raspberry Pi (Rpi) platform, relay board, web server and database. You can
also check, in real time, whether the computer is on or off. The proposed
system was built with device easily found in the Brazilian market and aims to
contribute to the convenience of remotely connecting and disconnecting loads
and to energy efficiency through the control of the drive and consequently of
the electric power consumption of the computer."
5171;en_US;"Embedded computing system are increasingly present in peoples
daily lives due, mainly, to the cheapness of electronic components. This type of
system is dedicated to specific tasks and allows the creation of several
solutions for the most varied application. An example of application using
embedded system is presented in this article, where the system as a whole is
responsible for monitoring the electrical energy consumption of domestic
electrical appliances. This will allow us to see how much a particular circuit
is consuming, in real time, any device on the network with a web browser."
5172;en_US;"The term autism was first cited in 1908 by a psychiatrist in Switzerland. For people with Autism Spectrum Disorder (ASD), daytoday tasks as well as the assimilation of knowledge are performed with great difficulty. Several technique are used for the treatment of ASD, among those researched it can be seen that music therapy has shown great result. The present work proposes the development of a computational platform that will apply music therapy technique to optimize the teaching learning strategies of grade 1 autistic children, aiming to assist in their cognitive development and learning, especially in the literacy phase."
5173;en_US;"This paper presents a general purpose and low cost Web System based
on the Internet of Things principle for temperature/humidity monitoring and
activation of loads in remote environments. The system hardware consists of an
ESP8266 microcontroller that controls a DHT11 sensor to collect temperature
and humidity data and an LED, which intends to emulate a load. State control
and management of these device occurs through the real-time database of the
Firebase platform."
5174;en_US;"This article describes a retrogaming central developed using Linux
embedded system based on Raspberry Pi platform. The retrogaming center uses
Internet of Things (IoT) principles to enabling monitor user’ data. Thus, using
minimum hardware and the free Linux operating system, the administrator can
continuously optimize the project in low cost. The proposed system can be easily
configured by beginners in electronics and computing, and also be applied as a
didactic tool."
5175;en_US;"The increase in the consumption of electric energy has brought to light the importance of solutions that contribute to the optimization of energy ef iciency in the electric sector, seeking, mainly, the awareness for the reduction of consumption. Therefore, it is essential that there be means of monitoring and control from Generation to Distribution, through the Transmission of Electric Energy, in order to achieve an automated and therefore intelligent energy matrix, according to the concept of Smart Grids, whose objective proposes the application of new tool for electric power system, using Information Technology, Industrial Automation and Telecommunications, in such a way that it is also possible to involve the final consumer of electric energy. Thus, the importance of providing the consumer with a greater participation in the electric power management process is explicit. The objective of this study is to study and present the methodology used to develop a system to monitor the energy consumption of electrical equipment, so that it is possible to read data that reveals the energy consumption of such equipment, as well as real-time exposure of your information through an android application. For that, an Arduino-based electronic system and a network interface were developed. The result contribute to Home Energy Ef iciency by allowing reports with precious details on the use of electric energy in homes."
5176;en_US;"<p>Currently, the use of image in medical examinations has become more popular as it consists of a less invasive procedure for patient. In order to improve the performance of this procedure, a semiautomatic algorithm with superpixels is proposed. The algorithm has the objective of automating the segmentation of the image, being only necessary a prior appointment of some regions by the specialist doctor. PH² containing exactly 200 image from public archives was the basis of our assessment. The result obtained demonstrate the applicability of our algorithm, since in the tests performed the Kappa index reached values considered Excellent.</p>"
5177;en_US;"The purpose of this paper is to make an analysis about Researches’
quotes in scientific work obtained through Google Scholar. The paper
consists in a script developed in Python that returns the index of quotes. From
those indexes was done an analysis of scientific events and graduate programs,
obtaining the indexes of events and programs. Additionally, we made an
analysis to verify which of the events and programs have the
most experienced researcher. Lastly, the result allowing the new student and
researcher to do an analysis of the events to see which of them are more
appropriated to publish their work."
5178;en_US;"​With the development of the most diverse routing technique in the
network scenarios, performance information needs to be processed and
related in order to present more relevant result through a process of
composition of metrics. This work aims to verify the latency of the network,
based on the performance metrics studies, with RIP and OSPF routing
protocol, under a data stream, simulating a real scenario. This article makes
use of a software to create two scenarios simulating a real network
architecture, where a large packet stream was injected, to obtain the latency
of the network for each protocol."
5179;en_US;"The present paper provides a brief analysis of the aliasing effects caused by the aliasing problem that frequently occur in electronic game image, as well as the main reasons behind these graphic errors. From this perspective, this paper aims to present the main ways to solve this problem, as well as a comparative analysis between these so-called anti-aliasing algorithm that were explained and contrasted according to cost and performance. The analysis showed that these two elements should be aligned for the best cost-benefit."
5180;en_US;"Parasitic disease are causes of losses in goats and sheep. One of the process to solve this problem is the analysis of characteristics related to animal health and the subsequent application of anthelmintic drugs. Aiming to automate this process, this work presents a computational module responsible for indicating the need for anthelmintic treatment in goats and sheep. For this, a fuzzy system was developed that has as input measurements of Eggs Per Grass of Feces, FAMACHA and Body Condition Score of the analyzed animals and from these measurements makes an indication of treatment for the animals. The indications performed by the system were compared with indications from professionals in the animal health area for measurements of 30 animals, resulting in a high compatibility rate in the responses.
"
5181;en_US;"The purpose of this article is to understand and analyze the potential of
digital and social inclusion offered by the basic computer science course of the
ETec Brazil network, as well as its contribution to the enhancement of educational
process and the favoring of citizenship, the student perspective of this course.
The research was based on the quantitative-qualitative analysis of an open
questionnaire applied to the student participating in the course. And based on the
arguments analyzed, it is possible to affirm that digital inclusion is intrinsically
related to social inclusion, one existing in favor of the other, demonstrating the
importance of offering didactic - methodological strategies that facilitate them."
5182;en_US;"This article presents a hardware prototype for generic presence detection system, built from the design of an old mouse, with the objective of
contributing to the practice of reusing hardware, the formation of a tool for the
reuse of equipment and components, and are already discarded, for the development of new products. The main task of this work was a quick, easy and
inexpensive task for the problem of the accelerated increase of electronic waste
and its actions for the environment. Tests and evaluations of the applicability of
the prototype were produced, and the result were satisfactory"
5183;en_US;"This paper presents a performance analysis of the XG-PON network,
considering the individual transfer rate of each ONU (Optical Distribution
Network) and the delay of propagation. simulation were performed to evaluate the average network delay, considering the transmission from the client
to the server and from the server to the client, as well as the average transmission rate according to the number of ONUs. The simulation were done using
the NS-3 (Network Simulator - version 3) tool. In addition, the PTM (Pointto-Multipoint) topology and Transmission Control Protocol (TCP) architecture
were adopted. The result indicate that the number of ONUs directly influences
the downstream speed, and consequently, it influences the delay."
5184;en_US;"DWDM network emerges as an important ally to keep up with the demand for data on the Internet, because it allows multiple channels on the fiber.
In the modeling of a DWDM network, it is necessary to understand the importance and influence that each equipment (transponders, optical fibers, amplifiers, multiplexers, chromatic dispersion compensators and switches) offers to
the transmission quality. In this way, this article presents some characteristics
of these equipments that compose a DWDM network, as well as, the mathematical formalism necessary to model the contribution of each equipment in the
network. Finally, the result obtained from a tool developed using the Python
language to perform the feasibility calculations of the links are shown."
5185;en_US;"This article describe the development of a software solution for the
management of academics project, whose objective is
provide greater participation and interactivity of student in research activity
in undergraduate course, as well as facilitate the management of these by
teacher researcher, that often takes time and effort to follow the development of
the work performed. Moreover, it shows the effectiveness of the system in a
digital terminal, intended to interactive assistance and access to information."
5187;en_US;"Even in the face of several existing methodologies, it is noticed that
software is often developed without proper planning and monitoring. In this
way, the present article aims to explore hybrid model of software project
management. A literature review was carried out, of the qualitative type,
elaborated through content analysis. Nine hybrid methodologies were
analyzed and categorized according to their applicability. From the analyzes
made, improvements were identified that highlight the importance of the
hybrid methodologies in the development process, as an alternative to
generate a better performance in software production. From the
methodologies adopted articles, Scrum was the most used, being applied in six
hybrid model, with 27%."
5188;en_US;"<p>This article is justified in an experience report of the Supervised Internship, aiming at the use of information and communication technologies as a support tool in the process of teaching learning in the 5th year of elementary education, with the objective of providing the use of differentiated teaching strategies, in favor of a pleasant and quality teaching. It was concluded that the use of ICT makes it possible to incorporate information technology independently of the methodology used, developing competences that cover the whole society.</p>"
5256;en_US;"Among the several vehicles of social communication, digital signage displays have been playing a remarkable role in both public and private spaces. Such Digital Out-of-Home (DOOH) media allows for the rapid dissemination of collective, multimedia information to a large number of people. It is observed, however, that there is a large distance between the graphical abstractions offered by DOOH authoring tool and the underlying language for the representation of hyper/multimedia content. Document representation becomes complex, sometimes makes use of scripting language, and therefore is illegible by authors and even difficult for automated information extraction. In this context, this paper proposes STorM, a hypermedia model and its language STorML that defines higher-level entities related to the concepts found in the audiovisual industry, such as scenes, tracks and media."
5257;en_US;"This paper presents a general approach to perform crowdsourcing video annotation without requiring trained workers nor experts. It consists of dividing complex annotation tasks into simple and small microtasks and cascading them to generate a final result. Moreover, this approach allows using simple annotation tool rather than complex and expensive annotation system. Also, it tends to avoid activity that may be tedious and time-consuming for workers. The cascade microtasks strategy is included in a workflow of three steps: Preparation, Annotation, and Presentation. A crowdsourcing video annotation process in which four different microtasks were cascaded was developed to evaluate the proposed approach. In the process, extra content such as image, text, hyperlinks and other elements are applied in the video enrichment. To support the experiment was developed a toolkit that includes Web-based annotation tool and aggregation method, besides a presentation system for the annotated video. This toolkit is open source and can be downloaded and used to replicate this experiment, as so to construct different crowdsourcing video annotation system."
5258;en_US;"Mobile computing can be a facilitator for collecting data due to the fact that user carry their smartphone almost everywhere and all the time and because they can collect a wide range of data – textual, audiovisual and data collected automatically by sensor. Considering this opportunity, we developed the ESPIM (Experience Sampling and Programmed Intervention Method), an computeraided method for programming multimedia data collection forms and carry out remote interventions. Using the ESPIM, professionals of area such as healthcare and education can plan data collection and define intervention programs using method and procedures from their own area. The programs containing the query and tasks are retrieved by a mobile application installed in the device of user who participate in the data collection. The mobile application runs the programs according to query and tasks planned by the specialists. Both query and responses can contain text, audio, and video data. In this paper we discuss about the technological infrastructure used in ESPIM system and also about the preliminary result obtained through tests and evaluation carried out with stakeholders of the target population. These result allowed us carried out improvements in the system."
5259;en_US;"A particularly challenging situation in amateur multimedia authoring is ad-hoc collaborative capture, i.e., a process that, having no pre-production phase, demands live coordination between multiple authors. Important problem to realize such scenarios include proper synchronization of media elements by multiple device, and which information to include in the resulting collaboratively authored multimedia document. In this paper, we report how our collaborative authoring system tackles these ad-hoc multimedia capture problem by combining mobile and web application. We present a case study in the educational domain and discuss the result of a user study"
5260;en_US;"A pervasive game extends its experience beyond the virtual world by extrapolating its boundaries to the player’s physical world. One outstanding example of pervasive game is the Location-Based Game (LBG) genre, which takes into account the players’ geographic position in the game rule and mechanics. In this paper, we present an initial evaluation of LEGaL, a language to model and represent the structure and multimedia contents of LBGs. LEGaL allows the modeling of mission-based game by supporting spatial and temporal relationships between game elements. In fact, LEGaL is an extension of NCL (Nested Context Language). We evaluated the proposed language with a group of five NCL developers aiming at investigating if LEGaL is still NCL-friendly. result indicate LEGal is easily used by this kind of developers."
5261;en_US;"In this paper we concentrate on the study of the collaborative practices of enthusiasts that create and share subtitles for thirdparty video. Based on preliminary result from interviews with some volunteers, we formalize the subtitles creation and sharing process using a business process management model and compare it with other collaborative and crowdsourcing model. We expect that our initial observations can bring a new understanding of the process and, thus, help in the design of next generation video enriching tool."
5262;en_US;"This paper presents a quality analysis of 3D video encoded with the 3D extension of the High Efficiency Video Coding (HEVC) standard, 3D-HEVC, using the Early Skip/DIS heuristic to reduce complexity. In addition to comparing the heuristic from a quality point of view, the analyses were performed with objective and subjective methodologies with the goal of comparing the reliability of the metrics. Three metrics were employed in the objective evaluation: Peak Signal-to-Noise Ratio (PSNR), Structural Similarity (SSIM) e Most Apparent Distortion (MAD). The subjective analyses considered the Mean Opinion Score (MOS) metric using double stimulus. The evaluation result demonstrated that the Early Skip/DIS solution has no significant impact in image quality in comparison with video encoded with the unmodified 3D-HEVC reference encoder."
5263;en_US;"Video streaming is one of the greatest application on the Internet, and mobile device became more powerful and popular every passing day. Understanding live-streaming-mobile-user behavior is imperative to map issues, to then seek solutions. The purpose of this work is to characterized mobile user watching popular live events, such as Dilma’s Impeachment and Opening of Rio2016 game."
5264;en_US;"Recently, Multimedia Web content has gotten so much popular worldwide (e.g., YouTube and Netflix). Traditional corporations are also contracting online multimedia platforms to provide content to their user. These service are called non-UGC (non User Generated Content), where these company produce and publish content for client consumption. In this work we present a methodology for characterizing and analyzing multimedia streaming service. We validate it using actual data from one of the most popular online video streaming provider of Latin American, called Samba Tech. Our methodology is divided in four modules that allow evaluating and understanding different views and data characteristics."
5265;en_US;"The rise of Software-Defined Networking afforded a new cycle in research of Content Distribution network. Among this, many studies have investigated the approach of InformationCentric Networking. However, as already identified, this model has several limitations regarding their application in the context with global reach, i.e., on the Internet. In order to address this problem, this paper presents an architecture that integrates the CDNs and SDNs. Thus, It is proposed the use of a network abstraction layer that provides network service to intermediate the CDN service and the network’s infrastructure. The result obtained preliminarily, demonstrated that the proposed architecture allows you to apply traffic engineering mechanism implemented in SDN to optimize the distribution of content through the CDN. Finally, we advocate that the proposed solution allows optimizing the distribution of content using SDN on the Internet, that is, even in context in which the CDN is operated by a different administrative entity that operates the SDN."
5266;en_US;"Due to recent technological evolution, the provision of IPTV service has grown considerably. One of the service normally included in IPTV is Linear TV, where audiovisual contents are made available in the form of program schedules. Another service is Video on Demand, where the viewer can perform actions like pause, play and seek (trick mode). In this context, challenges emerge regarding the distribution of multimedia content over these service. One of these challenges is specifically the user’s perception about the quality of the IPTV service, measured in terms of quality of experience (QoE). Thus, this article aims to analyze the problem that may occur when receiving Linear TV and VoD content and to propose solutions to these problem. Specifically, due to the congestion of transmission media or overload in the endpoints, a key issue is the statistical variation of time delay for multimedia content delivery (packet jitter). This paper’s proposal comprises a novel dynamic management of buffers in IPTV terminal device, taking into account the characteristics of both Linear TV and VoD service."
5267;en_US;"This work presents the analysis of a software architecture for the measurement of audience and interactivity in IPTV (Internet Protocol TV) environments. The implementation used is in accordance with the recommendation of the ITU (International Telecommunication Union), taking into account its mandatory requirement. We analyzed factors that may interfere with the architecture performance and may generate the need to treat aspects related to the scalability of the solution. Load tests were performed through stochastic model that simulate the interaction of user with the IPTV environment. Thus, besides presenting the viability of the implementation, the aspects that must be taken into account for the implementation of an IPTV audience measurement architecture in a real environment are analyzed."
5268;en_US;"NCL (Nested Context Language) is a notation for hypermedia application authoring, designed to facilitate the modeling and authoring of Digital TV application for authors with different levels of programming knowledge. However, the ease of use of NCL is questionable due to XML notation and has been the subject of study of several work that analyze its usability while proposing other solutions. This work presents sNCL (simpler NCL), a declarative domain specific language, projected using guidelines established by the CDN (Cognitive Dimensions of Notation) framework applied to NCL. To validate the proposal, an experiment with a questionnaire on the success factors in NCL and sNCL is applied to user with experience in authoring with NCL, comparing their opinions on both language. The experiment demonstrates that sNCL gains in usability, which can improve, therefore, the performance of authors in the development of application."
5269;en_US;"In this paper, we present the conversion of NCL to Smix and discuss its main implications. NCL is a declarative language for the specification of interactive multimedia presentations which was adopted by the ITU-T H.761 recommendation for interoperable IPTV service. Smix is a synchronous domain-specific language with a similar purpose, but with a simpler and more precise semantics. By implementing NCL over Smix, we bring to the former the notions of reaction and execution instants, and with them some benefits. From a practical perspective, we fix the semantics of the converted document, get a leaner NCL player (the Smix interpreter), and simplify further conversions. From a system-design perspective, the structured conversion of NCL to Smix helps us tame the complexity of mapping the user-oriented constructs of NCL into the machine-oriented primitives that realize them as a multimedia presentation. In the paper, we present NCL and Smix, discuss related work on document conversion, and detail the conversion process and a prototype implementation."
5270;en_US;"Today, mobility is a key feature in the new generation of Internet, which provides a set of custom service through numerous terminals. smartphone, for example, are a tendency and almost mandatory to anyone living in an urban and modern context. Most of the developed city have at least one shopping mall full of mobile device user. These shopping malls provide a number of stores, and people tend to have difficult in finding what they really need. This paper proposes a solution called RecStore. RecStore is a recommendation model to assist customers in reaching what they consider relevant at malls. The recommendation model considers user activity, 330 stores, 30 user and 3 baseline model. The precision, recall and f-measure improved at rates of 118%, 70% and 88% respectively in comparison to the second best model of each metric. Additionally, a mobile application — called InMap — was implemented based on RecStore."
5271;en_US;"Recommender system are information filtering tool that aspire to predict accurate ratings for user and item, with the ultimate goal of providing user with personalized and relevant recommendation. Recommender system that rely on the combination of quality metadata, i.e., all descriptive information about an item, are likely to be successful in the process of finding what is relevant or not for a target user. The problem arises when either data is sparse or important metadata is not available, making it hard for recommender system to predict proper user-item ratings. In particular, this study investigates how our proposed collaborative-filtering recommender performs when important metadata is reduced from a dataset. To evaluate our approach use the HetRec 2011 2k dataset with five different movie metadata (genres, tags, directors, actors and countries). By applying our approach of metadata reduction, we provide a comprehensive analysis on how mean average precision is affected as important metadata become unavailable."
5272;en_US;"In a previous work, we proposed a direction-based navigation framework for large media collections. We implemented Mixtape (www.projectmixtape.org), a web application with a simple interface that allows user to navigate in a large music collection using online feedback and a geometric similarity space. In this work, we analyze user-generated data during an experiment on Mixtape. We collected all user actions on Mixtape over a course of two weeks, resulting in the participation of 800 user, generating a total of over 2 000 navigation sessions. We analyzed the trajectories that user followed within the music similarity space, and collected implicit and explicit feedback about user satisfaction. In particular, we compared geometric relationships, such as distance and direction similarity, between consecutive songs within individual and between different navigation trajectories. The navigation technique called Vector, which uses the concept of directions in this space of similarities, was able to keep the analyzed user for a longer time in the application. This may indicate a preference among user for navigating in their songs using the concept of directions."
5273;en_US;"The phonographic scenario has changed the way of measuring the artists popularity. The measurement of an artists popularity by selling discs or plays on radios was replaced by the artists dissemination in digital media. Magazines such as Billboard and Rolling Stone build artists rankings, and we may observe that, despite producing many different result, they are accepted in the phonographic scenario. However, they do not have a totally open methodology. In this context, this work aims to apply a methodology for the construction of rankings of artists considering data coming from digital media and TV in the national phonographic scenario. We concluded that the methodology presents satisfactory result and important insights, consistent with the reality of the Brazilian phonographic scenario."
5274;en_US;"In this paper, we aim at determining whether or not we can predict the success of a music album, based on the comment posted on social network during 30 days before the album release. For that matter, we focused on the Twitter network for gathering the user comment. As success measures, we considered the Spotify Popularity and the Billboard Units. The reason for those choices is that Spotify represents the most popular type of music consumption today (audio streaming), while Billboard ranking still favors the old school market (physical albums). As a result, we found out that the amount of Positive Tweets (30 days before the album release) can explain 95.5% of the variation in the Spotify Popularity with a simple linear model. On the other hand, we could not find statistical evidence that the volume of comment on Twitter correlates with the album success measured by the Billboard magazine."
5275;en_US;"A social network consists on a finite set of social entities and the relationships between them. These entities are represented as vertices in a graph which represents this network. Usually, the entities (or vertices) can be classified according to their feature, like interaction (comment, posts, likes, etc.) for example. However, to work directly with these graph and understand the relationships between the several pre-defined classes are not easy tasks due to, for instance, the graph size. In this work, we propose metrics for evaluating how good is a graph transformation based on graph homomorphism, measuring how much the relationships of the original one are preserved after the transformation. The proposed metrics measure the edge regularity indices and indicate the proportion of the original graph vertices that participates in the relations, moreover they measure how close to a regular homomorphism is the graph transformation. For assessing the regularity indices, some experiment taking into account synthetic and real social network data are given."
5276;en_US;"device with built-in GPS (e.g. smartphone) are producing a huge amount of data objects with spatial, temporal and textual information. For example, a signicant part of Twier message sent from smartphone has spatial location (latitude and longitude), temporal information (timestamp) and textual information (the message itself). Therefore, there is a growing interest for new approaches that are able to select the data objects that are spatially, temporally and textually relevant from huge dataset. In this paper, we specify the spatio-temporal-textual query that returns the relevant data objects considering these three criteria simultaneously, presenting new indexes and algorithm to process such query eciently. e proposed approaches are evaluated taking real dataset, potentially providing more accurate result."
5277;en_US;"In Community Question Answering, recency ranking refers to put the freshness answers with high quality in top positions of a ranking. Freshness is not related to how recent is the answer creation date, but to how up-to-date is the answer content. This is extremely important because the user need to get best answers quickly to solve their questions and, usually, they expect up-to-date solutions. In this paper, we propose a new approach to provide recency ranking in these environments and present a set of experiment that show the effectiveness of our proposal."
5278;en_US;"Development of Context-Aware and Mobile application have signicant challenges, such as the complexity of sensor access code and the heterogeneity of device. The Google Awareness API is an initiative to mitigate this complexity. This paper presents an analysis of GitHub project involving Awareness API. However, the result showed that the spread of this API among the developers community is still incipient. We propose to extend a tool to allow high-level modeling of context acquisition and code generation compatible with Awareness API. It reduces the complexity of acquiring contextual information and managing contextual rule."
5279;en_US;"One of the main research opportunities regarding the use of contextual information is the context and relational databases integration. This integration allows the better contextualized retrieval of data. This paper presents a set of rule, which used with an ontological model, allows the integration of context and domain data. This approach enables the data retrieved through SQL query to be returned in a contextualized manner, without the need to change the database schema originally used. Another advantage is the use of query originally defined in system, thus, it is not necessary to perform a re-engineering of the system. The model evaluation was carried out through the development of a case study applied to a virtual learning environment. The result show that the rule allow a filtering using the context of interest, resulting in a more meaningful data recovery."
5280;en_US;"Search strategies for Learning Objects (LOs) in repositories, by using purely syntactic structures, can make that task of searching and retrieval become time-consuming and unproductive, and consequently can decrease the possibilities for reuse of these resource. The present work has as its main goal to use generic-purpose thesauri of the Portuguese language to establish semantic structures in the search for LOs. For this purpose, an architecture proposal is presented, as well as the development of a semantic search tool based on thesauri and federated search at three distinct repositories with Portuguese language support. The result show improvements in the search and the increase of the quantities of the recovered LOs. The semantic search tool is available for download under GNU 3 license."
5281;en_US;"Making good governance decisions is a constant challenge for Public Health administration. Health managers need to make data analysis in order to identify several health problem. In Brazil, these data are made available by dataUS. Generally, they are stored in distinct and heterogeneous databases. The Linked Data approach allow a homogenized view of the data as a unique basis. This article proposes a ontology-based model and Linked Data to integrate dataset and calculate the probability of maternal and infant death risk in order to give support in decision-making in the GISSA project."
5282;en_US;"Because of the ubiquitous use of the Internet in current society, it is easy to find groups or communities of people discussing about the most varied subjects. Learning about these subjects (or entities) from such discussions is of great interest for company, organization, public figures (e.g. politicians) and researcher alike. In this paper, we explore the problem of learning entity representations using online discussions about them as the only source of information. While such discussions may reveal relevant and surprising information about the corresponding subjects, they may also be completely irrelevant. As another challenge, while regular text document usually contain a well structured language, online discussions often contain informal and mispelled word. Here we formally define the problem, propose a new benchmark for evaluating vector representation method, and perform a deep evaluation of well-known technique using three proposed evaluation scenarios: (i) clustering, (ii) ordering and (iii) recommendation. result show that each method is better than at least one other in some evaluation"
5283;en_US;"This work aims at creating a tool for analyzing the psychological and linguistic changes of text translated from English into Brazilian Portuguese. The aim is to analyze differences between text translated by automatic translators and human translators. For this purpose, a tool named LIWC is used in its Brazilian Portuguese version. LIWC is a tool that distributes lexical word in categories with linguistic and psychological characteristics. Through accounting the word categories, this work seeks to evaluate the percentage of psycholinguistic changes in automatically translated document in comparison with a reliable translation performed by a human expert. In this way, this study aims to contribute to the improvement of the process of automatic translation of document. Experimental result indicate promising directions for further research."
5284;en_US;"Learning a new language is fundamental in the globalized world we live in. English stands out as the most studied language nowadays, mostly because of its use in production of the most diverse media, like films, music, game, serie, among others. The need to learn a new language, and especially the English language, has been driving the development of new learning method. However, teaching methodologies remain standardized and embedded, not considering the individuality of each student in the learning process. A teaching methodology that is adequate to the individuality of each student demands method capable of generating knowledge to the student through the use of topic that are of interest to them. In this way, this work proposes the development of a methodology for automatic generation of vocabulary exercises, in order to enable the generation of exercises from a document used as input. The study showed the feasibility of the application in automatic generation, reaching the precision of 100% for given scenarios."
5285;en_US;"Nowadays, the enormous variety of identity document that exist makes it difficult to standardize a system capable of extracting all the information of interest presented by them. Therefore, system that use template to classify information based on their positions are limited by the number of template they could recognize. Thus, in this paper, a novel mechanism intended to automatically classify the major information of interest exposed by generic identity document is presented. The proposal is created to be easily adaptable to any system capable of detecting and extracting text information from an identity document image. To assign meaning to the text extracted from the identity document, the proposal is based on a novel mechanism to structuring the data using semantic analysis. The mechanism consists of two main steps, first, all the text data are classified as sentences or near sentences based on the Euclidean distance between word; second, the sentences are analyzed to find keyword that allow structuring the information based on its semantic to show it as abstractions. The proposal has been designed to be able to store the data as abstractions of its meaning. This allows improving the scalability of the system and a better use of this information by different service, by the end user or to be interpreted by an automated process of decisionmaking."
5286;en_US;"Mobile app review are important as a crowdsource to improve the quality of these software. App stores, which have app review, provide a wealth of information derived from user. These information help developers to fix bugs and implement new feature desired by user. Despite the review usefulness, one of the challenges of application developers is the huge number of review published daily, making manual analysis laborious. Hence, the delay in satisfying user may influence the loss of customers. Current researches into this topic have adopted a supervised approach to classify the review of the user. In this paper, we used an unsupervised approach to categorize the review aiming to generate a summary of the main bugs and new feature pointed by user, assisting the application developers to improve the quality their apps. We evaluated the approach empirically and obtained promising result to generate user review summaries."
5287;en_US;"Changes in our society have been contributing to the raising number of people who will be under the effects of night sleep deprivation. This can harms health in the physical, mental and social aspects. This research work is intended to evaluate if there are differences between the affective characteristics in entries posted in two different time interval, analyzing psycholinguistic process and dominant emotions associated to social network user, using the LIWC in portuguese. In this preliminary study, it was possible to show a small difference in emotions expressed by user who posted between 6pm-23:59 and user who posted between 0am-5:59am."
5288;en_US;"The freedom of expression provided by the Internet also favors malicious groups that propagate contents of hate, recruit new members, and threaten user. In this context, we propose a new approach for hate speech identification based on Information Theory quantifiers (entropy and divergence) to represent document. As a differential of our approach, we capture weighted information of word, rather than just their frequency in document. The result show that our approach overperforms technique that use data representation, such as TF-IDF and unigrams combined to text classifier, achieving an F1-score of 86%, 84% e 96% for classifying hate, offensive, and regular speech classes, respectively. Compared to the baselines, our proposal is a win-win solution that improves efficacy (F1-score) and efficiency (by reducing the dimension of the feature vector). The proposed solution is up to 2.27 times faster than the baseline."
5289;en_US;"In recent years, educational video are becoming more and more popular. Due to this increase in the amount of didactic content in the video format present on the web, it is interesting to make it possible for a search term to be related to a specific segment of the video. Better navigability allows the user to have quicker access to the topic that interest him, avoiding irrelevant content. This article proposes a method for automatic segmentation of scenes in educational video through the use of automatic audio transcription and semantic annotation. With this targeting, you can improve content search on these video by improving the user experience on e-learning platforms or educational video repositories."
5290;en_US;"Face recognition has received significant attention during the past several years. It is a challenge task because faces can be affected by scale, noises, face expression, illumination, color or pose variations. The most robust methodologies related to these variations are based on “key points” localization, followed by the application of a local descriptor to each surrounding region. Such descriptors are associated to clustering algorithm or histogram representation based on Bag of feature (BoF). In the BoF approach, the codebook can effectively describe objects by their appearance based on local texture. Based on texture descriptors proposed previously for image detection, we propose in this paper the application of such descriptors for face recognition. We evaluate the performance of our methodology using Feret, ORL and Yale databases, comparing our descriptor against SIFT and LIOP descriptors, and also other methodologies recently published in the literature."
5291;en_US;"Web image play an important role in delivering multimedia content on the Web. The text embedded in web image carry semantic information related to layout and content of the pages. Statistics show that there is a significant need to detect and recognize text from web image. This paper presents an architecture that efficiently integrates localization, extraction and recognition algorithm applied to text recognition in web image. In the recognition step is proposed a procedure based on super-resolution and an iterative method for improving the performance. The approach is implemented and evaluated using Matlab and cloud computing, making the system flexible, scalable and robust in detecting text from complex web image with different orientations, dimensions and colors. Competitive result are presented, both in precision and recognition rate, when compared with other system in the existing literature."
5292;en_US;"In the field of Web Engineering, there are several method proposed for the development of Web-based information system (WISs). FrameWeb is a method that aims to develop WISs that use certain types of framework in their architecture, proposing model that incorporate concepts of these framework during system design. The method’s modeling language is based on Model-Driven Development technique, making it extensible to support different framework and development platforms. In this paper, we present a code generation tool for FrameWeb which harnesses the method’s extensibility by being based on its language’s meta-model. The tool work with an associated visual editor for FrameWeb model and showed promising result in initial evaluation efforts."
5293;en_US;"The Websocket protocol enables a full-duplex communication, besides it simplifies an exchange of data and reduces network overload. This paper proposes the use of the Websocket protocol in control and service device through web within real-time requirement. Through tests made in a virtual environment and another one in embedded experiment, It is possible to validate an initial proposal of implementation the Websocket protocol. From the analysis of the result obtained, it can be seen the use of the proposal in question provides a considerable reduction in the quantity of requests and transferred data in relation to traditional approach to sending data in HTTP-based communications. Consequently it seems to be a very promising technique for this type of application."
5294;en_US;"Despite the increasing popularity of electronic sports (eSports), there is still a scarcity of academic work exploring the playing behavior of teams. Understanding the feature that help to discriminate between successful and unsuccessful teams would help teams improving their strategies, such as determine performance metrics to reach. In this paper, we identify and characterize team behavior pattern based on historical matches from the very popular eSpor League of Legends web API. By applying machine learning and statistical analysis, we clustered teams’ performance and investigate for each cluster how and to what extent these feature have an influence on teams’ success and failure. Some cluster are more likely to have winning teams than others, the result of our study helped to discover the characteristics that are associated with this predisposition and allowed us to model performance metrics of successful and unsuccessful team profiles. At all, we found 7 profiles in which were categorized into four levels in terms of winning team proportion: very low, moderate, high and very high."
5295;en_US;"Consider the problem of creating a wedding reception playlist. Such playlist should ideally satisfy a very diverse crowd by nding a perfect eclectic mix of songs to keep everyone satised. In fact, music playlists for large parties are usually composed by a very heterogeneous set of songs, so everyone can listen to songs of their liking at some point. Such playlists, which we call heterogeneous playlists, are also very appropriate in dynamic context, when the mood of the listener changes with time, such as workout sessions or road trips. e challenge of automatically generating heterogeneous playlists is to nd the appropriate balance among several conicting goals. For instance, the generated playlist should have smooth transitions between successive tracks while covering a highly diverse set of songs in the time the user has available to her/him. In this paper, we formulate the problem of automatically generating high quality heterogeneous playlists and propose two method for solving it, namely ROPE and STRAW. We demonstrate the usefulness of our proposed algorithm by applying them to a large collection of songs. When compared with the state of the art algorithm, ROPE and STRAW are the only ones that can eectively satisfy all of the following quality constraints: heterogeneity, smooth transitions, novelty, scalability and usability."
5296;en_US;"Recommender system are widely used to minimize the information overload problem. A great source of information is user’ review, since they provide both item descriptions and user’ opinions. Recent work that process review often neglect problem such as polysemy and sinonimy. On the other hand, system that rely on word sense disambiguation focus their efforts on item’s static descriptions. In this paper, we propose a hybrid recommender system that uses word sense disambiguation and entity linking to produce concept-based item representations extracted from user’ review. Our findings suggest that adding such semantics to item’ representations have a positive impact on recommendation."
5297;en_US;"This paper presents a recommender system on clinical cases and materials that may help the student in the learning process. The experiment involves the development of collaborative and content based filters and also three hybrid method. The system was qualitatively evaluated, using accuracy metrics in prediction and classification tasks. The obtained result show promising values on the collaborative filters."
5298;en_US;"Events can be defined as “something that occurs at specific place and time associated with some specific actions”. In general, events extracted from news articles and social network are used to map the information from web to the various phenomena that occur in our physical world. One of the main steps to perform this relationship is the use of machine learning algorithm for event classification, which has received great attention in the web document engineering field in recent years. Traditional machine learning algorithm are based on vector space model representations and supervised classification. However, events are composed of multiple representations such as textual data, temporal information, geographic location and other types of metadata. All these representations are poorly represented together in a vector space model. Moreover, supervised classification requires the labeling of a significant sample of events to construct a training set for learning process, thereby hampering the practical application of event classification. In this paper, we propose a method called TECHN (Transductive Event Classification through Heterogeneous network), which considers event metadata as different objects in an heterogeneous network. Besides, the TECHN method has the ability to automatically learn which types of network objects (event metadata) are most efficient in the classification task. In addition, our TECHN method is based on a transductive classification that considers both labeled events and a vast amount of unlabeled events. The experimental result show that TECHN method obtains promising result, especially when we consider different weights of importance for each type of event metadata and a small set of labeled events."
5299;en_US;"Currently, a lot of resource are connected to the Internet, many simultaneously requesting and providing service. The adequate selection of resource that best meet the demands of user with a broad range of options has been a relevant and current research challenge. Based on the non-functional parameters of QoS play a significant role in the ranking of these resource according to the service they offer. This paper aims to aggregate machine learning in the pre-classification of EXEHDA middleware resource, to reduce the computational cost generated by MCDA algorithm. We presented the proposed software architecture (EXEHDA-RR), and the obtained result with the integration of machine learning in the classification process are promissing, and indicate to the research continuation."
5300;en_US;"In the Internet of Things (IoT) paradigm, a context management system (CMS) should support the context life cycle including acquisition, modeling, reasoning and distribution of context information. The context modeling phase is responsible for the representation of context information in a format which should meet IoT requirement such as expressiveness, reuse, extension and interoperability. In this paper, we present the Hermes Widget IoT service, which represents context information using the semantics of IoT-oriented ontology such as IoT-Lite and Semantic Sensor Network (SSN). As contribution, Hermes Widget IoT allows any context provider object (e.g. a sensor) to be located, used, and have its corresponding context information represented and made available for querying through the Internet."
5301;en_US;"The growth of video surveillance device increases the rate of streaming data. However, even working in the Fog Computing environment, these smart device may fail collecting information, producing missing or invalid data. This issue can affect the user quality of experience, because the PTZ-controller may lose the target object tracking. Therefore, this paper presents the Singular Spectrum Analysis - (SSA), as the method to replace missing values in this complex environment of intelligent surveillance cameras. SSA is characterized within time serie field by performing a nonparametric spectral estimation with spatial-temporal correlations. The values not correctly monitored, were estimated by SSA with accuracy, allowing the tracking of a suspect object."
5302;en_US;"The Internet of things (IoT) emerged with the objective to integrate physical objects into classical computer network. These objects usually generate larges amount of data, transferring the bottleneck of data processing from sensor to communication system. For example, analyzing IoT data often demands data centralization before running a mining algorithm. Thus, in order to reduce the data transference commonly required by the data clustering task, this paper proposes a grid-based data summarization approach. The proposed approach uses a single uniform grid to partition the space into cells and to summarize data before centralization. Summarization ensures the reduction of the amounts of data transferred. This approach also includes a data clustering algorithm that deals with the summarized and centralized data. Our preliminary experiment revealed good result in terms of data compression and quality of clustering with a two-dimensional benchmark dataset."
5303;en_US;"MulSeMedia application aim to stimulate other human sensory receptors such as mechanoreceptors, chemoreceptors and thermoreceptors. They increase the degree of immersion of user as well as improve the Quality of Experience and are standardized by MPEG-V. It is currently possible to identify a gap in the definition of process, method and tool to support the systematic development of MulSeMedia application. This paper presents a tool called MulSeMaker for the development of MulSeMedia application in the Web domain. It was developed based on the application family concept from the Generative Software Development. In order to investigate evidence to confirm the benefits of the proposed tool, empirical studies were carried out to collect and analyze qualitative and quantitative data."
5304;en_US;"Numerous platforms in the field of machine translation of oralized language to sign language are available nowadays, and accessibility has been gaining more and more space. However, it is noticed that most platforms use only a unique 3D avatar, and this character is responsible for all the reproduction of signals, with no alternative of choice for user. Such a limitation may have an impact on the acceptance of automatic translation by the deaf community, since there must be empathy of the deaf with the animated agent. Having only one available avatar makes impossible a more precise choice, which may involve personal characteristics and affinities. One of the reasons for this is the great effort, human and technological, that is necessary for the construction of a sign dictionary, which can scale proportionally with the addition of new avatars. In view of such a scenario, the present study aims to investigate mechanism that allow multiple avatars to be oered in sign dictionaries without necessarily needing to reshape them again and manually, one by one. The initial premise is to analyze the functioning of each signal in a particular avatar, in order to predict possible problem in the reproduction of the signals after the permutation to a new one (retargeting), such as improper collisions or mesh invasions. As main contributions of the work, technique are proposed to facilitate the identification and automatic correction of nonconformities in the movement of the signals and also some practical recommendation for the modeling of new avatars in order to minimize the occurrence of errors."
5305;en_US;"Recommender system have assumed a prominent role in e-commerce domains, affecting decisively distinct business phases, such as convert new user into customers. The total absence of information about new user is one of the main challenges in this area, and it is known in the literature as Ramp-up Problem. In this scenario, non-personalized strategy are chosen for simplicity, domain independence and effectiveness. State-of-the-art strategies assume that popular item are more likely to represent useful recommendation when the user profile is not known. In contrast, other strategies consider that diversifying recommendation represents potential chances of attracting new user. This work performs an extensive characterization of this problem, in order to contrast the main existing technique. Our analyses point to a trade-off of popularity and diversity, suggesting that these two dimensions are essential to the Ramp-up problem. However, the main e-commerce system insist on presenting only strategies that consider accuracy, prioritizing popularity over diversity. The result show that, indeed, both dimensions are relevant to this important scenario in e-commerce."
5306;en_US;"The most popular Recommender system (RSs) employ Collaborative Filtering (CF) algorithm where user explicitly rate item. Based on these ratings, a user-item rating matrix is generated and used to select the item to be recommended for a target user. An important step in this process is to determine the neighborhood of a target user, i.e. a set of user who rate item similarly to this user. One of the limitations of CF is precisely the need of rating data provided voluntarily by user. The lack of interest of user to provide this kind of information increases the sparsity problem of the ratings matrix. In this paper, we propose the use of implicit feedback for neighbors selection to alleviate the sparsity problem in CF-based RSs. In this proposal, user profiles are built based on the characteristics of item that have been accessed or purchased, and not necessarily rated by the user. This user profile is used exclusively to the neighborhoods formation, which considers not how they have rated item, but by the characteristics of the item that they have accessed or purchased. Our technique was implemented with Apache Mahout Framework and evaluated across experiment in the domain of movies by using a dataset from Movielens project. The result demonstrated that our technique produces better quality recommendation when compared to the classic CF mainly in presence of sparsity of rating data."
5307;en_US;"In the delivery of hypermedia content over communication network, the specified intermedia synchronization must be assured, despite the inherent delay and jitter of most transmission media and network. This kind of content typically provides user multiple interaction paths, with different sets of media objects each one. In spite of that, when the hypermedia content is transmitted in push mode, user receive all media objects, regardless of the chosen interaction path. Transmission strategies that take into account the occurrence of both deterministic and non-deterministic hypermedia presentation events can decrease the waste of storage resource in the receiver side, as well as the need for network bandwidth. This work proposes a framework for an adaptable management of pushmode hypermedia content transmission. Adaptability is achieved by supporting multiple transmission strategies that may employ multiple transmission channels, which are built upon a content analysis for the identification of deterministic and non-deterministic hypermedia presentation events. method for instantiating the framework in the context of Ginga-NCL application transmission are also discussed over multiple transmission scenarios, in comparison with the existing, unmanaged content transmission."
5308;en_US;"Remote video application over the internet have been a trend for the last few years. As they grew in popularity, several area of knowledge have started to take advantage of their functionalities and the possibility to make collaborative environments using video arose. From videoconferences to educational telemedicine video streamings, these collaborative application are usually hard and tedious to configure and deploy and usually limit the number of participant. This work proposes a scalable architecture for collaborative video application that makes the development and deployment of collaborative video application easier and supports a high number of user simultaneously producing and consuming video in these application."
5309;en_US;"The dynamics of social network have increasingly driven TV viewer to interact while watching their favorite shows. By using polls, chats, news and other mechanism in order to dialogue more directly with these viewer. However, social network provide only a partial way of interaction for this type of media, since they were not designed to deal with the peculiarities of TV programs. To such purpose Second Screen application were created, and they can be understood as an extension of the TV screen in which any information or interaction can be presented to user through apps for smartphone or tablets. Unlike social network, Second Screen apps are made available by broadcasters specifically for TV user. For TV Stations, it is necessary to develop several application in order to cover the various programs in their schedule, and as a consequence this generates expenses to company, which may explain the massive use of social network by these broadcasters in order to interact with viewer nowadays. Therefore, this paper aims at presenting a supporting architecture to a dynamic update of a generic Second Screen app. Such architecture enables the deployment of broadcasters, programs, media, quizzes and any other Second Screen feature without the need to create new apps by broadcasters or install new apps by user. The result demonstrated several benefits that the versatility of the proposed architecture offers to all those involved in the chain of television content production."
5310;en_US;"Microservice (MS) are a new approach designed to promote greater scalability and flexibility in large application. One of the major challenges in the MS approach is to properly develop a single microservice in terms of scope, efficiency and reliability. In this work, we propose an architectural model based on the concepts of reactive programming to internally structure microservice. This model is internally coordinated by asynchronous queues, which allows preserving compatibility with most monolithic components. A comparative study between the standard approach and the proposed architecture was carried out in order to measure the impacts of this strategy in terms of performance."
5311;en_US;"Internet of Things (IoT) describes how the world, where daily-live objects are connected to the Internet, is increasingly present in people’s lives. However, actual solutions that enable the IoT are designed to be used only by IT experts. This article proposes a Behavior Definition Model for IoT Ecosystem (BDM4IoT), a model designed to enable non-IT experts to easily design and configure the behavior of their own environments for IoT according to their needs. The validation of the proposed model is carried out through a graphical modeling tool called Êxodo GUI, which allows user to easily configure, manipulate and create behavioral model using BDM4IoT. The obtained result prove the viability of this approach for the inclusion of non-IT experts in the creative and managerial IoT process."
5313;en_US;"The recognition of user physical activity through data analysis of smartphone inertial sensor has aided the development of several solutions in different domains such as transportation and healthcare. Mostly of these solutions have been supported by the cloud communication technologies due to the need of using accurate classification model. In an attempt to solve problem related to the smartphone orientation (e.g. landscape) in the user body, new types of feature classified as orientation independent have arisen in the last years. In this context, this paper presents an extensive comparative study between all the feature mapped in literature derived from inertial sensor. A number of experiment were carried out using two databases containing data from 30 user. result showed that the new orientation independent feature proposed in literature cannot discriminate properly between the user’ activity using the inertial sensor. In addition, this paper provides an extensive analysis of these type of feature and a tool that implements all methodological process of human activity recognition based on smartphone."
5314;en_US;"Wireless sensor network are an important part of smart city, but there are still many challenging issues, demanding optimizations in those network for higher efficiency. Events of interest may be identified analyzing data posted in social media, and such events may be used to assign priority levels to sensor node. This paper proposes an automatic mechanism to update sensor’ priorities based on events mined and identified in social media, which may be then optimized for higher monitoring efficiency."
5315;en_US;"This paper presents a rate and complexity-aware coding scheme for fixed-camera video that are designed to improve image quality in Regions of Interest (ROI) by prioritizing the encoding of such regions through the use of a modified mode decision equation. ROIs are defined in this work as faces, with the application of a face detection algorithm. Background image (BGI) are also detected with the aim of reducing bitrate in coding blocks belonging to these area. Finally, the proposed scheme also applies an early decision method intending to reduce coding time. Experimental result show that the proposed scheme is capable of improving the image quality in 0.99 dB in ROIs, reaching an improvement of 1.16 dB in the best case. Also, the scheme achieves an encoding time reduction of up to 55% (about 5.5%, on average) with unexpressive variations in the required bitrate."
5316;en_US;"Zika has drawn international attention in 2015, both for its epidemic proportion and its consequences. Scientific advances are made, but is the population aware? Allow the population to understand the scientific advances of a disease, achievements made and current risk situation is important to avoid panic, prejudice and violence. This work1 aims to study the impact of the main Zika researcher and the repercussion of their research on population. For this purpose, the main researcher were identified in co-authorship network and, through altmetric indexes (alternative metrics), the repercussion of these researcher were analyzed in news and social media."
5317;en_US;"The educational game Disease Extermination presents how the vaccines act in the organism and how they prevent viruses and bacteria from parasite in the human organism. The game is based on mechanical shooter game, whose game simulates as a scenario the human body internally and the player uses strategics to protect the organism against invaders represented by viruses or bacterias. The game has the role of raising awareness about the importance of Vaccination. Usually many user do not adopt the vaccine, and so, disease are not prevented."
5318;en_US;"With the growing video game industry, new markets and technologies are emerging. Electronic game of the new generation are increasingly requiring more processing and powerful video cards. The solution that is gaining more prominence is Cloud Gaming, which the player performs a command, the information is sent and processed remotely on a cloud, then the image return as a video stream back to the player using the Internet. To improve the Quality of Experience (QoE), it is proposed a model that reduces the response time between the player command and the stream of the resulting game scenes through a framework called Cloud Manager. The game must be encoded in different layers so that the Cloud Manager can use layer caching technique, in the background, and future state prediction using a prediction matrix, in the character layer, in order to reduce the network bandwidth usage, bitrate transmission and network latencies. To validate the result, an action game with god-view as point of view is used in a Cloud Gaming system called Uniquitous."
5319;en_US;"DJ Khaled is a popular musician that is known for having many collaborators in his songs. Hence, in this paper, we model the evolution of DJ Khaled’s collaboration network as nine different network that incrementally consider the albums of his discography. The network of each album includes the collaborations from previous ones and adds the collaborations from the new album. The artists are represented as node and the edges are the number of songs they appear together. Our focus is to answer whether or not: (i) we can identify meaningful communities in this network; and (2) there is an artist who has greater influence as network emerges. By using the network average clustering coefficient, we found that the artists in the the network tend to naturally cluster in a logical manner. As a result, we identified nine communities, six of them are meaningful, and we identified the rapper Rick Ross as the most influential artist of the network."
5320;en_US;"This paper discusses result from a quality evaluation experiment involving video on mobile device encoded with different configurations of H.264/AVC. The impact of not employing the Fractional Motion Estimation (FME) and the Deblocking Filter (DBF) during the encoding process was also analyzed in the experiment presented in this paper. In order to perform the quality assessment, the objective metrics Structural Similarity (SSIM) and Peak Signal-to-Noise Ratio (PSNR) were used. The subjective evaluation was conducted in two different mobile device by employing the Mean Opinion Score (MOS) with single stimulus. The obtained result have shown different levels of quality degradation for both modifications. In addition, they led to the conclusion that larger screen device present a more accentuated drop in subjective quality than small screen device."
5321;en_US;"This paper presents a framework for the creation of a knowledge database on QoE. The QoE Analyzer framework enables the simulation of degradations in video playout and also the application of a survey to evaluate the impact of degradations on the user Quality of Experience. In order to show the versatility of the framework, an instantiation of the framework and its application to a group of 62 user was carried out. The framework was implemented using the JavaScript language and, through it, it was possible to show the impacts of degradation pattern on the user experience. The framework was released under GNU GPLv3 license and is available in github (https://github.com/hugoschroterl/qoe-analyser)."
5322;en_US;"Mulsemedia application are shown to improve user experience by synchronizing sensory effects along with audiovisual content. An usual approach for specifying such synchronization is to mark the moments when a given effect has to be executed in the main media object. Multimedia authoring language provide a way to mark moments of a media object through anchors. An anchor indicates a temporal portion (video frames or audio sample) in relation to its parent media object. However, to synchronize such portions with sensory content can be costly. When, for example, a scene component appear multiple times on the media content. This problem was tackled in previous work by providing an approach for creating abstract anchors in declarative multimedia document. An abstract anchor represents (possibly) several media anchors. By using a scene recognition software, the anchors where duplicated whenever the same component was identified on the main media. Such approach, was proven useful for creating automatic sensory effects based on video recognition. This paper extends the proposal of abstract anchors in order to enable the automatic generation of sensory effects using sound recognition. This paper also extends the Abstract Anchor Processor to implement media pre-processing and to adapt the sound recognition software response."
5323;en_US;"Online Social network (OSN) are virtual environments that allow user to exchange message, interact, and share content. The amount of information flowing through OSN promotes the competition for attention and influence among user who struggle to co-opt other user to share their message. The influence gained by user can be important to call the attention to target topic so that they eventually become Trend topic (most popular topic within a time frame). In this work, we illustrate how we can apply concepts of network science to analyze the network structure that represents a Trend Topic. As a consequence, we show how to identify important user that contributed significantly to the topic popularity. In addition, we show how we can detect naive artificial efforts, such as bot activity, to increase the popularity of a user and, consequently, the popularity of the topic."
5324;en_US;"Nowadays people can provide feedback on products and service on the web. Site owners can use this kind of information in order to understand more their public preferences. Sentiment Analysis can help in this task, providing method to infer the polarity of the review. In these method, the classifier can use hints about the polarity of the word and the subject being discussed in order to infer the polarity of the text. However, many of these text are short and, because of that, the classifier can have difficulties to infer these hints. We here propose a new sentiment analysis method that uses topic model to infer the polarity of short text. The intuition of this approach is that, by using topic, the classifier is able to better understand the context and improve the performance in this task. In this approach, we first use method to infer topic such as LDA, BTM and MedLDA in order to represent the review and, then, we apply a classifier (e.g. Linear SVM, Random Forest or Logistic Regression). In this method, we combine the result of classifier and text representations in two ways: (1) by using single topic representation and multiple classifier; (2) and using multiple topic representations and a single classifier. We also analyzed the impact of expanding these text since the topic model method can have difficulties to deal with the data sparsity present in these review. The proposed approach could achieve gains of up to 8.5% compared to our baseline. Moreover, we were able to determine the best classifier (Random Forest) and the best topic detection method (MedLDA)."
5325;en_US;"Cyber Terrorism is a real threat to the modern society. Many terrorist organization spread their ideas and recruit new supporters over Online Social network. Among all terrorist organization, ISIS can be considered as the biggest one, which is responsible for inspiring terrorist actions in more than 20 countries. As expected, ISIS uses Twitter for spreading its hatred, and an important issue is how to characterize these supporters in order to understand their motivation. Our work investigates and discusses the way ISIS organizes within Twitter. We base our analyses on two curated dataset. The first dataset, “How ISIS Uses Twitter” (HIUT), is provided by the Fifth Tribe digital agency. The second dataset, “Syria and ISIS Mentioners” (SIM), we collected ourselves and curated without participation of experts in the field. We made the SIM dataset publically available, helping new studies in the understanding of ISIS supporters’ profiles on Twitter. The main contribution of this work is a characterization of both HIUT and SIM dataset."
5326;en_US;"Understanding how user consume mobile service during large events is a key factor in the improvement of the provided service. In 2014, Brazil hosted the FIFA World Cup, one of the biggest events in the world. The objective of this work is to exploit mobile data to discover important insights on how Brazilians accessed mobile application during this event. The dataset studied here is composed of mobile application usage records collected during 2014 by a software agent installed on smartphone of 5,342 Brazilians. The result reveal interesting findings regarding how mobile accesses differ during the matches in comparison with ordinary days."
5327;en_US;"The dynamics of society are constantly changing by social media. Twitter has been standing out as one of the main platforms for information discovery and its political use have been growing since 2008. In this work we collected the public deputies tweets between 2013 and 2015 for topic extraction by means of computational model. However, due to the large number of irrelevant word from the data dictionary, we used tf-idf and Shannon’s entropy to identify and select relevant political word."
5328;en_US;"Social network provide mechanism to represent and investigate different kinds of system like biological and social. In this work, our aim is to explore the characteristics of complex network extracted from the books and movies of The Lord Of The Rings’ Trilogy. We use centrality measures (e.g., PageRank, Betweenness, Weighted Degree) to identify influential characters and the Louvain’s algorithm to identify social nuclei. The result show that the communities identified reflect the story’s main nuclei, and that in the different source media the characters identified as more influential remain the same. In addition, we make a parallel between the differences and similarities of books (in Portuguese and English) and movies."
5329;en_US;"Deaf people face a number of difficulties in accessing information, primarily in dynamic, high-volume environments such as the Web. One of the major obstacles is due to the fact that this information is available almost entirely in the oral language only, while the deaf communicate naturally using signals. ere are some solutions available in the literature for automatic translation of oral language content into sign language, but they are usually restricted to translating content into a single input oral language. The objective of this work is to investigate the feasibility of generalization of a translation strategy with syntactic-semantic treatment, originally directioned from Brazilian Portuguese for LIBRAS, to define a flexible architecture for the construction of automatic translators of several oral language for associated sign language. The hypothesis we wish to evaluate is that an extensible and configurable translation core, based on the interpretation of formally defined rule and grammars acting at the morphological, syntactic or semantic levels, can be used to implement new machine translation initiatives for sign language or as a way to improve the quality of translation in existing tool."
5330;en_US;"Deaf people communicate naturally through visual-gesture language, called sign language (LS). As a result, they have a great deal of difficulty absorbing oral content, either in written or spoken form, even in the oral language (LO) of their native country. In addition, if it is already difficult to a deaf to access information in the oral language of your country, obstacles to accessing information in foreign language become almost insurmountable, reducing the level of access to information. Among the approaches to the problem, one of the most promising ones involves the use of automatic translators to translate written or spoken content into sign language through an avatar. However, the vast majority of these machine translation platforms are focused on translating a single oral language into a single associated sign language. In order to expand the range of oral language that Brazilian deaf people could have access to, this article investigates the use of ”text-to-text”machine translation mechanism before the ”text-to-gloss”machine translation. The idea is to evaluate the offer of a service for automatic translation of digital content (text, audio or video, for example) in any oral language for the Brazilian Language of Signals (LIBRAS). As a way of validating the proposal a prototype based on the Suite VLibras was constructed. A serie of computational and user evaluations were carried out to verify if the proposed flow of chained translations allows the suitable understanding of the content in foreign language."
5331;en_US;"With the wide variety of available mobile device, of different types, capabilities and technologies, associated with the profusion of wireless communication network, enables to offer mobile and ubiquitous application that can be designed to serve blind persons (PCDVs). In this sense, this article has as its principal contribution the approach, called HELIX, proposed to provide accessibility to the visually impaired through the use of concepts of Internet of Things (IoT) in indoor and outdoor environments. The functional architecture of the HELIX is integrated into the adaptation and context recognition subsystem of middleware EXEHDA, which provides support for the acquisition, storage and processing of context information used by the mobile HELIX application. The application prototyped were evaluated by the Technology Acceptance Model, and the result were promising."
5332;en_US;"Mobile device , such as smartphone and tablets, have become almost indispensable item in peoples daily lives. The interaction via touches on screen has been consolidated in these device, being quite efficient, for the majority of the cases. However, this type of interaction can be limiting, or even make impossible the use of the device, for a person with busy hands or some kind of motor difficulty. In such cases, the possibility of using voice commands to control the device may be a more attractive solution. Although some device already offer this kind of feature, it is restricted to some feature pre-determined by the system. The main goal of this work was to develop an application that allows full interaction with the device via voice commands using the speech recognition API of the Android operating system. Recognition tests were performed with the developed application, whose result demonstrated a 95% efficiency, making possible a full interaction with any application installed in the device."
5333;en_US;"This article describes a gestural interaction case study conducted with 36 blind and visually impaired user. Task-based user evaluations were undertaken on three phases to answer the question: Can gesture interaction improve the experience of blind or visually impaired user for Web video accessibility? After the study case analysis, 97% of the user would use a gestural interface and 92% preferred gesture interaction compared to the usual interaction. To obtain the conclusions, the variables were analyzed by comparisons of percentages and chi-square test."
5334;en_US;"Mobile device, such as smarthphones, became a common tool in our daily routine. Mobile application (a.k.a. apps) are demanding access to contextual information increasingly. For instance, apps require user’s environment data as well as their profiles in order to adapt themselves (interface, service, content) according to this context data. Mobile apps with this behavior are known as context-aware application (CAS). Several software infrastructures have been created to help the development of CAS. However, most of them do not store the contextual data, once mobile device are resource constrained. They are not built taking into account the privacy of contextual data either, due the fact that apps may expose contextual data, without user consent. This paper addresses these topic by extending an existing middleware platform that help the development of mobile context-aware application. Our extension aims at store and process the contextual data generated from several mobile device, using the computational power of the cloud, and the definition of privacy policies, which avoid dissemination of unauthorized contextual data."
5335;en_US;"Quality of context (QoC) is any information that describes the quality of the context information itself. The qualification process evaluates if the level of QoC computed meets context consumers’ expectations in face of ambiguities, imprecisions or errors in a particular context information. A context management system should deal with those imperfections on a broad sense, including QoC representation, quantification, qualification and dissemination. This paper presents our Hermes Quality (HQ) approach, which combines an ontology, QoC metrics and fuzzy logic-based QoC policies. Experienced nursing professionals helped evaluate the HQ capability to accept and discard irrelevant vital signs of ICU patient. result show that HQ properly qualifies vital sign measurements in conformance with fuzzy rule representing Nursing knowledge"
5336;en_US;"Recent advances in technologies for speech, touch and gesture recognition have given rise to a new class of user interface that does not only explore multiple modalities but also allows for multiple interacting user. Even so, current declarative multimedia language—e.g. HTML, SMIL, and NCL—support only limited forms of user input (mainly keyboard and mouse) for a single user. In this paper, we aim at studying how the NCL multimedia language could take advantage of those new recognition technologies. To do so, we revisit the model behind NCL, named NCM (Nested Context Model), and extend it with first-class concepts supporting multiuser and multimodal feature. To evaluate our approach, we instantiate the proposal and discuss some usage scenarios, developed as NCL application with our extended feature."
5337;en_US;"Nested Context Language (NCL) is the standard declarative language used for the development of interactive digital TV application in SBTVD (Brazilian Digital TV System) and ITU-T. Some previous researches show that NCL is more appropriate for content producers, whereas imperative language are better for application developers. However, the size of NCL application codes can reach levels that may affect even the legibility, which does not attract developers. The aim of this paper is to propose a framework, named Lua2NCL, to provide a set of textual feature that enable the creation of application for Digital TV without the same effort dispensed to the textual NCL authoring. These feature offered by Lua2NCL have as their central focus the reduction in the verbosity of document. This paper also presents two case studies performed with programmers showing that Lua2NCL can considerably reduce source codes, as well as, time spent in the authoring."
5339;en_US;"Interactive multimedia application are available in many platforms such as smartphone, computer and digital TVs. In addition, the production of multimedia content has been growing increasingly and facilitated due to easier access to these device. In this scenario, the creation of multimedia application has gained importance. There are several commercial tool that allow building multimedia presentations using the timeline paradigm for user with no programming knowledge. However, these tool inherit the timeline authoring paradigm limitations. In order to facilitate hypermedia document authoring for user with no knowledge of programming and avoid the timeline paradigm limitations, this paper proposes an event-based hypermedia document model and a graphical editor, which is based on this model, for spatiotemporal view editing of a document. The proposed tool is called STEVE, Spatio-Temporal View Editor, which supports the definition of viewer interaction. Besides, STEVE exports hypermedia application to NCL and HTML5 document to accomplish different execution platforms."
5340;en_US;"Template-based language can be used for arranging interface components in a layout model, like a grid. Declarative multimedia authoring language, such as NCL (Nested Context Language), may use those template for decreasing the authoring effort while specifying a presentation spatial layout. Although layout model are helpful for specifying presentation characteristics for media item, they usually do not consider the case where changes may happen at runtime. Moreover, presentations may lose tidiness when displayed on a device different then the one it was designed for or due to the viewer context or even due to viewer interaction. This paper proposes STyLe, a template language for dynamic spatial layout. STyLe is a constraint-based template language for providing dynamic and adaptive spatial layouts for hypermedia document. It also presents a framework capable of interpreting this language and performing the necessary changes in order to dynamically update NCL media object presentation characteristics at runtime."
5341;en_US;"The increasing number of smart spaces, fostered by the Internet of Things (IoT) and the Web of Things (WoT), as well as the user mobility in these spaces, can lead to smart spaces overlap, where a certain smart object may be used in different smart spaces. This paper presents the use of ModelDriven Engineering technique to propose: (i) a language to enable the definition of access rule for smart objects and ubiquitous application; and (ii) an algorithm to process model written in this language, enabling addressing smart objects’ concurrent access issues that might arise from smart spaces overlap. The proposal validation was performed by modeling a ubiquitous computing scenario’s access rule."
5342;en_US;"In this paper, we present a systematic literature review, whose object of study are the available feature in second screen application. The second screen is the ability to interact with the TV programming by using mobile device. The research was conducted in order to find out what the most common feature in second screen apps. The selected articles refer to 16 different feature, which were grouped into 5 categories. Interactivity was the category with more feature mentioned in the researched work. Therefore, we concluded the feature that provide interactivity between user and TV programming are the most common on the second screen."
5343;en_US;"Nowadays hypermedia content may be delivered over different platforms, such as Terrestrial DTV, IPTV and the Web. Therefore hypermedia presentation engines must be designed taking into consideration the specificity of their supported network to provide the expected QoE levels. Presentation engines employ some content analysis to help on the task of maintaining QoE. However, when the content includes pushed data, this analysis should be transferred to the server side for building the so-called Transmission Plan. The Transmission Plan is a data structure that predicts the time when media objects should be transmitted and for how long, in order to optimize end-to-end resource usage. This work proposes a framework for managing the push-mode delivery of hypermedia content. The framework is generic enough to be instantiated over different content delivery scenarios. Introductory instantiation scenarios and initial result are also discussed."
5345;en_US;"Given the growing demand for the development of mobile application, driven by use increasingly common in smartphone and tablets grew in society the need for remote data access in full in the use of mobile application without connectivity environments where there is no provision network access at all times. Given this reality, this work proposes a framework that present main functions are the provision of a persistence mechanism, replication and data synchronization, contemplating the creation, deletion, update and display persisted or requested data, even though the mobile device without connectivity with the network. From the point of view of the architecture and programming practices, it reflected in defining strategies for the main functions of the framework are met. Through a controlled study was to validate the solution proposal, being found as the gains in reducing the number of lines code and the amount of time required to perform the development of an application without there being significant increase for the operations."
5346;en_US;"In this work, we present a case study in which participant used a mobile application for collaborative record presentations. We developed an application for Android-enabled device to investigate the usability and design requirement of a mobile and collaborative capture system. Our main concern is to facilitate collaboration and create an enhanced result without adding complexity in relation to the individual capture task. In this way, we focused on problem related to the usability and to the awareness information that enables user to conduct an opportunistic recording. We report our case study result and discuss design requirement we identified for the collaborative recording of presentations by user in possession of smartphone and tablets."
5347;en_US;"The home care consists in a form of primary care performed by a lay caregiver, a specialist or a multidisciplinary team. This modality is applied in elderly people or patient in treatment of chronic disease who are not at risk of death. The aim of this work is to present a set of context-aware health application in a prototype of software and hardware that will assist caregivers and/or patient in home care situations. For this, a Set-Top Box (STB) connected to a TV with access to the Internet is used as a way of user interaction, which may enter information about its current state. Furthermore, health sensor can be used to capture data continuously to feed the system. The raw data and information provided by the user are later used, allowing, then, an inference about the patient condition."
5348;en_US;"This article uses the interaction of gestures and learning concept with mobility or mobile learning (M-Learning) to propose a mobile platform based on manipulation gestures focusing on benefit children in the literacy process in early childhood education to submit a learning disability. Based on ubiquitous computing and better usability, the objective is to make children can learn while playing through the manipulation of objects in touchscreen"
5349;en_US;"The MulSeMedia has been considered the great challenge of Multimedia for the next ten years. Aiming to stimulate other human sensory receptors such as mechanoreceptors, chemoreceptors and thermoceptors, the MulSeMedia increases the degree of immersion of user as well as improves the Quality of Experience and is standardized by MPEG-V. It is currently possible to identify a gap in the definition of process, method and tool to support the systematic development of multimedia /multisensory application in accordance with the MPEG-V standard. The main objective of this work is to propose a Modeldriven approach to integrate media, software and sensory effects project. In this research, the thesis is argued that MDD can increase the productivity of the development of MulSeMedia application, in particular those with such strong integration requirement with complex programming logic"
5350;en_US;"Technological advances in digital cinema have allowed people to encounter experiences that awaken their imagination and expose them to other realities. Experiencing these realties can be more difficult for the blind or visually impaired, however. In our cinema rooms, visual impairments create barriers that can restrict a person’s access to critical information. Therefore, we propose a solution that attempts to eliminate these barriers by using a computational system that is able to automatically generate and distribute accessible audio tracks that describe the digital cinema experience. Using mobile device to provide the content, visually impaired participant were given the opportunity to partake in an experiment to confirm or reject the viability of the solution presented in this article. The result of the experiment demonstrated that our computational system may be a feasible solution"
5351;en_US;"The presentation of information is a very important part of the comprehension of the whole. Therefore, the chosen visualization technique should be compatible with the content to be presented. An easy and fast visualization of the subjects developed by a research group, during certain periods, requires a dynamic visualization technique such as the Animated Word Cloud. With this technique, we were able to use the titles of bibliographic publications of researcher to present, in a clear and straightforward manner, information that is not easily evident just by reading its title. The synchronization of the video generated from the Animated Word Clouds allows a deeper analysis, a quick and intuitive observation, and the perception of information presented simultaneously."
5352;en_US;"The Auris system aims to improve music perception for deaf people. The system includes a set of tool for audio conversion into a new media (consisting of audio filtered synchronized with tactile impulses) to be played through loud speakers and special haptic interface, an improvement in musical experimentation by deaf people. The rating system is performed through the use of EEG interface, from the analysis of the recorded signals during cognitive testing. This article includes the presentation of the Auris system architecture and the result of its first stages of evaluation."
5353;en_US;"The semantics of current multimedia language is informal and may lead to the development of ambiguous application. In this paper we investigate the use of the synchronous language Ceu´ for programming local multimedia application, in particular, those application that can be described as a set of synchronized media objects. Ceu´ has a deterministic, concise and accurate semantics which, along with high-level programming constructs, makes the language an attractive alternative for developing multimedia application. We also present Ceu´ -Media, a library for programming multimedia in Ceu´ . Ceu´ -Media implementation guarantees that the properties of the Ceu´ synchronous semantics are reflected in the multimedia presentation, ensuring inter-media synchronization. We compare the synchronization paradigm of Ceu´ with those of NCL and SMIL, and examine the implementation of representative use cases."
5354;en_US;"In spite of recent advances in the so called 3D technology, the related literature reveals that, on the one hand, there is still a need for compression in order to reduce data volume. On the other hand, there is a lack of encoding method capable to produce reusable 3D content, easily interchangeable between different visualization modes. In this scenario, a possible approach, but yet poorly explored, is to use the anaglyphic encoding method as a means to get both: higher compression and independence of visualization modes. That way, this work proposes the HaaRGlyph, a new technique for stereoscopic video coding based on anaglyphic method. HaaRGlyph uses spatial coding, lossless and lossy, in order to achieve better compression ratios minimally interfering with the depth perception quality. At the same time, the technique preserves enough information to allow an anaglyphic image to be reverted into the related stereo pair. This helps content interchange since different visualization modes use stereo pairs as input. The conduced experiment used objective metrics (PSNR - Peak Signal-to-Noise Ratio) and subjective metrics (DSCQS - Double Stimulus Continuous Quality Scale) applied to a stereoscopic image database. The result were compared to related technique, pointing out that HaaRGlyph achieves better result."
5355;en_US;"Synchronization is about providing coherent orchestration of events or resource involved in a multimedia application. In a synchronized application, the user has the notion that his device content is directly connected with others. In this paper we discuss the existing synchronization technique, their advantages and disadvantages, and the current implementations and usage. We also present our open source solution for local synchronization of Web application, the Audio Markings API, detailing its usage, components and functionalities. The focus of this paper is on smart device such as smartphone, tablets and laptops since they often have built-in microphones and speakers - resource that we intend to explore. In addition to that, those device are perfectly capable of running full-featured web browsers, something that we also need to take advantage of. Our goal is to give developers an alternative for synchronization of Web application, using the Web browser as a platform and the sound as a bridge."
5356;en_US;"In this paper, we present the result obtained trough a per-flow routing resource with Quality of Service (QoS) support, provided by a multimedia gateway, to enhance multimedia delivery in OpenFlow Software-Defined network (SDN). We use the multimedia gateway to identify and classify multiple multimedia traffic flows on the network and to forward each traffic flow to the destination system according to specific flow rule, with different configurations of bandwidth allocation and priority of transmissions. In the SDN environment, the multimedia gateway acts as complementary component of the OpenFlow controller and as a network gateway of the endsystem. The interaction with the OpenFlow controller occur through a RESTful API, as an extension to the OpenFlow controller API Northbound. Through these interaction, with global information of the network, multimedia traffic flows can be routed and delivered differently from the other flows. These feature are important to improve the multimedia distribution and to increase the user-perceived Quality of Experience (QoE)."
5357;en_US;"Learning Objects (LOs) are entities, digital or not, that can be used, reused or referenced during the teaching process. According to Multimedia system area, they are specified by document that establish several spatiotemporal synchronization relationships of their contents. LOs allow student to individualize the learning experience with non-linear navigation mechanism and content adaptation. The paper presents a survey of requirement for the set of document representing such LOs as well as desirable aspects for expressing during authoring phase. In addition, this paper presents a multimedia conceptual model that answers such requirement gathered. The model is implemented by SceneSync, a domain specific language focused on the temporal synchronism of LOs. As a result of the work, it is presented the SceneSync modeling of a nonlinear LO illustrating all initially identified requirement, attesting the expressiveness and applicability of the language."
5358;en_US;"Mobile technologies have created a lot of challenges for distributed system over the last decade. Intermitent connections and weak network signals can induce unnexpected behaviour in some application. One kind of application that suffer from these difficulties is video streaming. This paper investigates the use of SDDL, a publish/subscribe middleware based on DDS, for live video streaming. Since SDDL is designed for scalable communications in a dynamic environment, we believe the proposed solution is fit for use in mobile network."
5360;en_US;"We present a Semantic Web based approach that meets the requirement for image retrieval based on low-level feature. For that, we developed a prototypical implementation using a Semantic Web framework, linking open data ontology and image processing libraries. We created an ontology to support the low-level feature data of image. Furthermore, we created semantic rule to define concepts based on lowlevel feature. We show how the different mechanism of the Semantic Web may help multimedia management, both for storage and in retrieval tasks."
5361;en_US;"Shot segmentation is a fundamental task in video system, being a prior step to scene detection and summarization. Although the literature provides large number of automatic shot segmentation technique, most of them cannot be easily used by researcher simply because they aren’t available to download, use legacy technology or are paid. This paper provide an evaluation of easily obtained video shot segmentation software in a benchmark composed by a set of movies and documentaries. result, although may not be comparable to state-of-the-art, have significant meaning because these method could be actually used by anyone."
5362;en_US;"Image retargeting has seen many application in area such as content adaptation for small displays and thumbnailing for image database browsing. Most retargeting method, however, are too expensive computationally to achieve fast performance on common desktop system. This work addresses the problem of fast automatic thumbnailing for image browsing. A simple approach of automatic thresholding saliency maps and cropping using bounding box extraction is presented. Eight of the fastest saliency detectors in the literature and three automatic thresholding method are assessed using precision, recall, F-score and execution time on the MSRA1K dataset. The result show that the approach is computationally efficient and adequate for fast automatic image thumbnailing. In particular, saliency detection with difference to random color sample (RS) thresholded by Rosin’s method achieved the best trade-off between execution time and F-score."
5363;en_US;"Interactive narratives are multimedia application that makes use of digital resource in order to enrich the reading experience. These application are more complex to produce than digital books because they require the specification of spatial and temporal synchronization among media. They can also define non-linear stories in contrast to linear books. The authoring of interactive narratives establishes an application domain that is defined by a set of functional and non-functional requirement. This paper presents F´abulas, a multimedia conceptual model created for the declarative development of non-linear interactive narratives. F´abulas model is small and designed for content producers like teachers, parents or writers. This paper illustrates the expressiveness and applicability of this model by describing a sample application that shows some of the F´abulas feature."
5364;en_US;"Mobile and portable technologies frequently adopt heterogeneous multimedia network. In this context it was designed scalable video encoders where a scalable video stream is transmitted containing a base layer (responsible by the minimum video requirement) and additional enhancement layers (each one improving the video characteristics). Recently MPEG and ITU-T groups published the scalable HEVC standard specification. However, the whole implementation of this encoder demands large computational resource and memory size. The current work presents a detailed analysis of this technology and its internal modules, indicating a simplified configuration that reach a tradeoff among low latency time and encoding quality. Comparison result indicate it as a fast and low complexity solution with small video quality loss."
5365;en_US;"People may lose motor skills for different reasons, due to accidents or illnesses. Very serious disease, such as Amyotrophic Lateral Sclerosis (ALS), evolve to the point of imposing severe motor restrictions, reaching situations where the patient is unable even to speak or perform movements, besides moving the eyes. An additional consequence for the sick person, besides needing support for all her necessities that require any movement, is the difficulty in communicating. It becomes essential, in such cases, the use of alternative communication facilities. Motivated for helping a sick person at advanced stage of ALS, unable to control even the act of blinking, we proceeded with studies and implementation of another device (camera + software) for eye tracking. The novelties of the proposed solution, compared to others that are based on the same principle, are: the independence of high precision eye-tracking device, usually very expensive; it does not require patient accuracy to select symbols on virtual keyboards, or memorization of specific eye movements to express themselves. We present in this paper the rationale that guided the design decisions, some details of the development and some achieved result which suggest the proposal feasibility."
5366;en_US;"With the growing video game industry, new markets and technologies are emerging. Electronic game of the new generation are increasingly requiring more processing and powerful video cards. The solution that is gaining more prominence is Cloud Gaming, where the player performs a command, the information is sent and processed remotely on a cloud, then the image return as a video stream back to the player using the Internet. To improve the Quality of Experience (QoE), it is proposed a model that reduces the response time between the player command and the stream of the resulting game scenes through a game manager called Cloud Manager. The Cloud Manager uses layer caching technique, in the background, and future state prediction, in the character, to reduce the network bandwidth usage, bitrate transmission and network latencies. The game is encoded in different layers, if a layer is the same in the following frame, it will not be re-encoded by the server. To speculate the next frames, the game manager renders all future possible outcomes based on the commands performed by the player."
5367;en_US;"There are several efforts that seek to provide abstractions to represent the behavior of multimedia application, each with its limitations and complexity. In this scenario, it is common to provide abstractions based on state machine, because they adequately define the behavioral transitions of these application. However, it is not trivial to identify the real state machine from application. In this context, reliability is quite critical, given the applicability of these abstractions in many activity. In this work, we present a controlled experiment to evaluate the reliability of the state-based representation of multimedia application, applying an approach in evaluating a real solution that extracts the behavioral model from the source code of NCL application. Our approach uses a finite representative set of sequences defined by a test-cases generation technique in the evaluation process."
5368;en_US;"In e-commerce scenario, identify in advance the category of a product is fundamental to improving the quality of the returned ranking for a query. In this article, we propose an alternative to the task of categorization of apparel products which explores the combination of representation generated by Bag of Visual word (BoVW) method with feature extracted by a traditional content-based image descriptor, the Color and Edge Directivity Descriptor (CEDD). Our experiment show that the proposed combination strategy is viable, competitive and statistically higher compared to baselines"
5369;en_US;"For the vision of the Semantic Web to become a reality and its benefits harnessed, data available on the Web must also be published in the form of linked data. Moreover, the quality of the abstract conceptual model behind this data, i.e., their ontology, can also have a big influence in the adoption of linked data sets and their vocabularies. In this paper, we propose FrameWeb-LD, an approach for the integration of Web-based Information system on the Semantic Web, which uses well-founded language and method for the modeling of ontology and aids developers in publishing their application’s data and service on the Web of Data."
5370;en_US;"Online Social network emerged at the beginning of 21st century and give us evidence that they are going to have a long life. Almost two-thirds of overall social media user affirm an everyday usage of a social media website and, therefore, the data volume across this platforms is huge. Natural language processing of social media text is an attractive topic among researcher of this area. While there are many studies about natural language processing of social media text for some language (e.g., English), the researches for Brazilian Portuguese language are still limited. Then, in this paper, a methodology is proposed to deal with peculiarities of the Brazilian Portuguese language in informal, short and noisy text, where the lack of context poses obstacles in text mining. The proposed methodology has been evaluated in two tasks (Text Categorization and Opinion Mining) and experiment showed that the preprocessing mechanism included in this methodology were important to achieve better result."
5371;en_US;"It has been broadly discussed over the last years about the growth and popularity of the Internet and, more specifically, about the World Wide Web and its service and application. Despite being common sense, acquiring indicators about this growth and characteristics of the whole Web, or event parts of it, is a big challenge, which can be explained by some factors: (1) the constant and dynamical evolution of the Web in many dimensions, that is, any analysis becomes obsolete instantly as soon as it’s ready; (2) the great volume of data that is necessary to generate indicators, which is usually disruptive in terms of bandwidth and storage. There are also problem related to ethics and network viability of the crawl; and (3) the coverage and newness to generate indicators, whether indicators about domains or Web pages. This paper presents a new methodology for generating dynamic Web indicators, which consider Web pages changes, both in terms of its modifications and its creation or deletion. This methodology provides a rational crawling and offers a measure of the quality of the indicators. In order to validate it, we run a simulation that uses a dataset with 8.690 Web pages that were downloaded daily for 134 days. The result show that it’s possible to crawl a greater universe of Web pages and still keep indicators between acceptable levels of confidence, turning it possible to have a snapshot of this universe as close to reality as possible."
5372;en_US;"This paper presents a model to integrate CMS contents and a intelligent. The proposed model acts on the problem of creating structured content to Semantic Web by the content publishers. The model also contemplate the use of Semantic Content through a Conversational Agent. For evaluation purposes will be dynamically integrated the contents of a Content Management System with a Communicational Intelligent Agent. The evaluation will be done in two parts: first checking if the agent can generate the knowledge base for dialogue, accessing Web pages and representing their content in RDFa and AIML format. In a second step, interaction tests will be carried out with user for usability evaluation in order to get their opinion on the use of Conversational Agent."
5373;en_US;"The Internet deeply changed the way people share their knowledge. Almost all content that people produces is now available in digital formats, like e-books, apps, newspaper, and magazines. That content has commonly some metadata available that can be used to generate complex recommendation system that track content similarity. Since there is some effort in the literature to explore this direction, almost all use classical recommendation approaches, like collaborative filter data and information present on websites that sells books. While most efforts in the literature use feature derived from the text syntax to create a recommendation model, our approach aims to trace an emotional fingerprint of authors extracted from their text. This approach, known as psychometry, consists of the study of behavioral characteristics like positivity, negativity, sadness, fear, religiosity, sexuality, which are able to disguise individuals. Using two sentiment analysis lexicons and a collection of 641 books from the English literature written by 56 authors, we show the effectiveness of these psychometric feature in order to trace those authors emotional fingerprint."
5374;en_US;"Recommender system help dealing with the information overload problem since they provide personalized content for user. There are two major paradigms in recommendation: content-based and collaborative filtering. Regardless of the paradigm, there has been a great effort into finding additional information to better describe item and/or user, which in turn helps to increase the personalization power of the system. User’s review turn out to be a great source of information, since they provide information about the characteristics of the item as well as insights about the opinion of the user towards them. In previous work, we explored some technique for extracting information from review in order to generate item’ representations and applied them into an item k-NN algorithm. In this work, we explore the impact that those representations, alongside with rating and genre-based representations, can cause into a soft clusteringbased recommender system. We compare our findings with the item k-NN algorithm and observe that they are better in some cases, but the soft clustering recommender has lower computational cost."
5375;en_US;"Recommender system were created to represent user preferences for the purpose of suggesting item to purchase or examine. However, there are several optimizations to be made in these system mainly with respect to modeling the user profile and remove the noise information. This paper proposes a collaborative filtering approach based on preferences of groups of user to improve the accuracy of recommendation, where the distance among user is computed using multiple types of user’ feedback. The advantage of this approach is that relevant item will be suggested based only on the subjects of interest of each group of user. Using this technique, we use a state-of-art collaborative filtering algorithm to generate a personalized ranking of item according to the preferences of an individual within each cluster. The experimental result show that the proposed technique has a higher precision than the traditional model without clustering."
5376;en_US;"Online consumer review are currently available in most eCommerce websites. By discussing products feature, review help consumers during the search stage of the buying process. However, from thousands of review published daily, it is not always clear which ones consumers should read. To help with that, consumers can vote user review as helpful or not helpful. This paper proposes an automatic method to analyze the helpfulness of online consumer review. This analysis was made on review collected from Steam using Multilayer Perceptron Artificial Neural Network. We found out indication that certain feature of review affect the perception of helpfulness and we discuss application and future researches."
5377;en_US;"Traditional method for obtaining data to conduct gender studies may be cumbersome because, usually, data are obtained manually through questionnaires. However, this poses challenges in conducting such studies on a large scale. Thus, available studies using traditional method often provide analysis only at country level. In this paper, we explore the use of check-ins data collected from Foursquare to estimate the cultural gender preferences for locations in the physical world. Our result suggest that gender preferences can be captured for locations at different spatial granularity – not just for countries. This indicates that our proposed methodology could inspire a complementary approach to conduct studies of gender preferences for locations."
5378;en_US;"Urban computing is a recent area of study that helps us to understand the nature of urban phenomena. In this sense, an important aspect to study is the dynamics of commercial establishments popularity in the city. Recently, Google launched a new service that provides popularity time serie of some commercial establishments in several city. This is a valuable source of data that allow us to better understand the dynamics of establishments popularity, helping to change our perceived physical limits about the city, which can enable the development of new application and urban service. The result of this study are: (1) characterization of Google popularity time serie for bars and restaurants in the city of Curitiba/Brazil and Chicago/USA. Among the result, we find cultural characteristics of these city, as well as a favorable clustering of similar venues based on the temporal pattern of popularity; (2) evaluation of reproduction of Google popularity time serie using Foursquare data. In this evaluation, we found evidence that Foursquare data might be used for this purpose. This means that for places where Google does not offer this service data from Foursquare, or other source, could be used. This enables the exploration of a greater number of establishments in, for example, a new venue recommendation engine."
5379;en_US;"Trajectories of moving objects have been an active research topic for over a decade. Classical approaches to analyze the trajectories of these objects are mainly based on large amounts of data acquired from positioning device, such GPS receivers. GPS data has the advantage of describing the trajectory of an object with a great level of detail and high accuracy, but the data do not carry any kind of semantic information. On the other hand, nowadays it is growing the number of interaction in social network with some kind of information about the location of the user. Georeferenced social interaction are an important source of semantic about user’s trajectories and activity. This work proposes a solution for reconstructing travel histories using heterogeneous social track source posts in social network, GPS positioning data, location history data generated by cloud service or any digital footprint with an associated geographic position. The solution encompasses a conceptual model; a methodology to reconstruct travel histories based on heterogeneous social tracks source; and an application to present the reconstructed travel itinerary in a graphical and interactive fashion. An experiment conducted with real travel experiences showed that the proposed solution is a reasonable way to reconstruct travels histories, geographically and semantically, in an automatic fashion."
5380;en_US;"In this paper we propose to use implicit ratings of multiple criteria to mitigate the data sparsity problem. The intuition is to predict the overall relevance of an item for a given user, based on her/his own implicit feedback instead of using similar user ratings (commonly used in collaborative filtering). Furthermore, since we believe one criterion may be more important than others, we propose a weighting schema, in which we estimate how interesting is each criterion for a given user, in order to generate a personalized ranking. The weighting schema do not suppose the generation of predicted explicit ratings. Instead, we reorganize the weights in such a way that just the criterion that has rating are weighted. For predicting the weight of each criterion to each user, we propose a genetic programming to predict how interesting is each criterion for a user, in which the initial weight values are randomly generated. In our experiment, we show that when having a sufficient corpus of historical user implicit feedback we can obtain higher precision for ranking item to a user, considering a predicted set of weight."
5381;en_US;"Linked Data promotes the publication of structured data on the Web, easing the development of an homogeneized-view over heterogeneous source, called Linked Data Mashup view (LDM view). But the development of this homogeneizedview still is a challenging task. This article proposes a framework Ontology-based that aims to ease the process of creation of LDM views. This framework allow user without specifics knowledge to create their own application, based on their needs. We also present a case study in which we use our approach to develop an integrated view over two heterogeneous source from Brazilian Public Health System."
5382;en_US;"In Brazil there are about 9.6 million people who have some kind of hearing impairment. The Brazilian deaf own mother tongue the Brazilian Sign Language - Libras. Because it is a visual language, a deaf person has great difficulty in social interaction, particularly with hearing people. One way to work around this limitation is by supporting tool, such as Falibras Messenger, presented in this paper. It is an integrated Portuguese-Libras translator to Telegram Web application that aims to facilitate communication between deaf and hearing people. However, to enable the use of Falibras Messenger, it was necessary to refactor its architecture to adapt it to new scalability requirement, given the increasing demand of requests for instant messaging application. In this work, the development of a new distributed translation architecture based on volunteer grid computing and a new tool for communication of deaf and hearing on the Web Telegram is addressed. The developed architecture was evaluated in a heterogeneous experimental environment presenting gains in scalability and increased performance of the median time translation."
5383;en_US;"Social network define a major media for user to express their opinion regarding different matters. As a consequence, these network naturally provide information that allow us to detect user behaviors, opinions, and sentiments about diverse events around the world. One event that called attention in Brazil is the impeachment process of the Brazillian President. The goal of this paper is to infer and characterize the opinion (polarity) of the Brazilians about the impeachment process in Brazil. We used a supervised learning approach and compared three classifier: Max Entropy, Support Vector Machine (SVM), and Multinomial Naive Bayes. The SVM presented the best performance for detecting the comment’ polarity about the impeachment process. In some cases, the SVM presented an F-score at least 1.03% higher than the others."
5384;en_US;"This work aims at highlighting gender differences in the use of Brazilian Portuguese by user of a Brazilian social network. We perform this study by using a dictionary of a text analysis program named LIWC. Experimental result indicate that males and females differ with respect to the most used word classes. Our result are consistent with studies performed in other language."
5385;en_US;"Recently the interest in video content sharing platforms, such Youtube and Netflix, has increased considerably attracting user with different profiles, including visually impaired. Although initiatives such as WCAG 2.0 (Web Content Acessibility Guidelines) set guidelines for video players development, there is still a need for investigation about how to improve the level of accessibility of visually impaired throughout the process of video media interaction, from browsing to the use of the player interface. The aim of this paper is to present an analysis conducted with 18 visually impaired user to access Web-video players through gestures. The analysis was carried out to check if there is improvement in the level of accessibility to access Web-video players through gestures if compared the usual access interface (keyboard, mouse and screen readers)."
5386;en_US;"The analysis of the organization of knowledge is an important tool for the management and evaluation of development agencies. Decisions are made in public politics, investment in research and innovation from the academic production of researcher and educational institutions in different area of science. In many cases this organization is composed of a rigid structure that does not follow the development of their area, this affects the progress of science, an example of organization is the taxonomy. With the analysis of the study of social network, we use the collaboration between researcher in a co-authors network can demonstrate new links among knowledge area. This article describes a method which analyzes a co-authorship network, infers how area are related and suggests new links and area for a taxonomy. We applied our method in the IEEE taxonomy, and in our experiment we obtained good update suggestions to this taxonomy, according to the experts."
5387;en_US;"With the explosion of text content made available in the internet Sentiment Analysis (SA) started to attract more of people’s attention by offering alternatives to automatically extract opinion information from text. As the internet extended its reach throughout the globe, the need for tool to enable information exchange between people who do not speak the same language emerged, to this need the most common response has been the use of Machine Translation. Some researcher have also evaluated the use of machine translation in SA and some interesting result were obtained. This work introduces Opinion-meter, a system for AspectBased Sentiment Analysis that enable user to analyze text in several language with the use of Machine Translation and using various method based on PMI, Lexicon and Machine Learning. An evaluation of the method available in the system was made in four different language and the result suggest that although Machine Translation can yield reasonable result, Machine Learning may still be a better alternative."
5388;en_US;"Sentiment Analysis is an emerging research area applied to social media to find useful information from specific topic, such as service or product quality, or even general context as marketing, politics and economy. Although there are numerous studies using Sentiment Analysis, few of them address the Portuguese language, because of the language complexity. This study aims to evaluate the performance of three method of machine learning (Support Vector Machine, Multinomial Naive Bayes, and Maximum Entropy) to detect polarities in two different scenarios. The first scenario is characterized as a three-class problem (positive, negative, and neutral). The second scenario consists of only two classes (positive and negative). Our dataset consists of comment from the Foursquare social network. The result show that Support Vector Machine presents an F-score at least 1.9% higher than the others for the three-class scenario, while Multinomial Naive Bayes presents an F-score at least 2.6% higher than the others for two-class scenario."
5389;en_US;"Affective Computing is a promising research area with many open challenges. This area expects to develop computational system that can monitor and respond to the affective states of an interacting user (IU). These affective states can be observed in terms of emotional responses, which demands continuous monitoring of IU. However, emotional responses can vary according to differences in personality traits. Due to that, we propose a novel model for personality-based agent to produce different emotional responses. This model suggests that distinct personality-based agent could have particular emotional responses. To evaluate our model, we collected data from an on-line social network in which entries have personality expressed by user and emotional information associated. We produced two personality-based agent: one extroverted and another introverted. Experimental result indicate that our model can be promising in providing distinct personality-based agent. The extroverted agent performed better on text written by extroverted individuals just as the introverted agent performed better on text written by introverted individuals. Our achieved result point out that personality traits are relevant to produce emotional agent."
5390;en_US;"ABSTRACT Recommender system are used by many sites and service, and are important tool to help the user to find what is most relevant in the immense amount of information available. One way to build a Recommendation System is contentbased filtering, which recommends item to the user based on a profile that contains information about the content, such as genre, keyword, etc. For this to happen effectively, the system must take into account the preferences and needs of user in order to generate useful recommendation. This work proposes the modeling of user profiles with integration of multiple domains and automatically. Then, through a transfer of knowledge of a domain to another, increase the performance of the recomendation. The result of the evaluation showed that information sharing between the domains increased the performance of the recommendation, as in the test with the metric prec@5, where obtained an improvement of more than 90%."
5391;en_US;"The Web of Things (WoT) is a new paradigm regarding the integration of the real world objects to the virtual world through the Web. This paradigm enables the development of powerful application and service. In this context, security of data user and device, and system reliability are important aspects. OpenId Connect is the identity layer designed to provide access authentication and identification to service by application. Designed to be an extensible protocol and based on a Web REST architecture, it is able to serve different types of application. This paper proposes the use of OpenId Connect protocol into the WoT context, in order to provide multiple mechanism for user authentication. The proposed model is implemented into an infrastructure that provides access to physical device on the Web through an Enterprise Service Bus (ESB). In this ESB, the MultiAuthWoT service should perform the authentication by intermediating the communication between the application and the OpenId Connect provider. As a case study, we used a Smart Room application, which controls device like security cameras, air-conditioning, lightning and sensor. Finally, we analyze the extension of the OpenId Connect protocol into the WoT context as technology capable to fulfill the multimodality authentication requirement."
5392;en_US;"The Web of Things is a proposal to make physical and connected device available to be used as resource in the development of Web application through the Web protocol and standards. On the one hand, the current Web has virtual content, which is accessed by client application that are hosted on Web servers, but on the other hand, the physical device are real objects that are geographically distributed and have several different ways of communication. As a result of these two before-mentioned characteristics, the physical device would demand a larger number of Web servers. In this context, this work proposes that device with limited memory capacity and processing power can be used as Web of Things gateways through Web protocol. Then, performance evaluation of such limited device is presented in this paper with two evaluation objectives: to evaluate the feasibility of a limited device as a Web of Things gateway; to establish the capacity of the gateway in management the access to the physical device."
5393;en_US;"Web pages are composed of elements, such as menus that are responsible for assisting navigation on the website. However, many of the menus are not developed properly, which creates accessibility barriers and hinders access to the contents. This paper aims to present a method for creating accessible menus. Initially, we studied the different types of menus and the accessibility guidelines involving the creation of accessible menus. From the studies, we developed a meta-model that gave rise to AMenu language, where we included all the technical details regarding to accessibility. Then, we developed the AMeG tool to facilitate the use of language. Finally, we conducted a case study with developers, in order to verify the feasibility of the approach, arguing its efficiency and limitations. The result indicate a reduction in efforts to develop accessible web menus, since developers do not have to deal with technical details of accessibility"
5394;en_US;"In the field of Web Engineering, many method have been proposed. FrameWeb is a method that targets the development of system that use certain kinds of framework in their architecture, proposing the use of model that incorporate concepts from these framework during design. However, in its original proposal, FrameWeb’s model do not fit well different framework instances, its language is not formally defined and no tool support is offered to aid software architects in creating the model. In this paper, we propose to address these issues using model-driven technique."
5395;en_US;"In this paper we conceptualize and define the QD Framework, a generic solution to manage a set of mirror servers, enabling a specific online service to be offered on the web with a better availability and success rate for requests. The framework includes all the components needed to deal with such service: registration, cataloging, monitoring, distribution and access for the end user. For validation, a case study was done with an implementation of the proposed framework to support a large scale service that provides machine translation of digital content in portuguese language to LIBRAS (Brazilian Sign Language)."
5396;en_US;"This paper proposes a new method to compute the semantic distance among item in collaborative filtering based on k-nearest neighbors. This approach predicts the rating that a user u would give to an item i calculating the similarity between i and other item rated by u. This item’ similarity is obtained using a semantic distance metric proposed in this paper. The technique exploits ontology available on the Web through the Linked Open Data. This is possible because they have semantic descriptions, structured by links, that define a knowledge domain. The equation to calculate the semantic distance is an extension of a related work. We propose to assign weight to links to show the specificity of item’s categories. Our proposal was evaluated with a movies dataset and it was shown that significant improvements can be achieved when compared to the baseline without weighted links."
5397;en_US;"In a cloud computing environment, company can allocate and de-allocate computing resource according to demand. However, this task does not happen instantaneously. There is a delay, which may take minutes, between the request for a new resource and it be ready for use. To resolve this problem we need forecast the future demand for then allocate the required amount of resource. As there is no forecasting model which is appropriate in all cases, we propose in this paper, the combination of different forecasting model by means of weighted multi-objective linear programming. In this way, we intend to create a generic method, able to optimize the resource allocation for different web application, with different demand types. The result obtained by means of simulation show that our proposal achieves this goal."
5398;en_US;"Digital Repositories (DRs) offer functionalities for managing, storing and accessing digital contents. DRs may make available a wide range of content types, including theses, dissertations, paper, video, work of art and literacy work. Some DRs have used recommendation system to offer user suggestions about digital contents that they might be interested. In this paper, we propose a multi-domain Recommender Web Service supporting multiple types of recommendation audience. The flexibility of domain and audience is provided by the use of ontology to represent domainspecific knowledge. In order to test the feasibility of our proposal, the paper presents two use cases of our Recommending Web Service."
5399;en_US;"The emergency response process is quite complex since there is a wide variety of elements to be evaluated for taking decisions. Uncertainties generated by subjectivity and imprecision affect the safety and effectiveness of actions. The aim of this paper is to develop an ontology for emergency response protocol, in particular, to fires in buildings. This developed ontology supports the knowledge sharing, evaluation and review of the protocol used, contributing to the tactical and strategic planning of organization. The construction of the ontology was based on the methodology Methontology. The domain specification and conceptualization were based in qualitative research, in which were extracted 131 terms with definitions, of which 85 were assessed by specialists. From there, in the Prot´eg´e tool, the domain’s taxonomy and the axioms were created. The specialists validated the ontology using the assessment by human approach (taxonomy, application and structure). Thus, a sustainable ontology model to the rescue tactical phase was ensured."
5400;en_US;"Web Service composition is a complex and error-prone process that requires the support of software tool in order to become feasible. Composition tool can help a developer to select compatible service from vast service repositories, taking into account characteristics such as port compatibility, availability, cost, and so on. This paper describes S3M, a service suggestion mechanism that, coupled with the CVFlow workflow editor, helps developers to select service and to build compositions. Service suggestions are given to the user taking into account the semantic description of Web service in SAWSDL format."
5401;en_US;"With the emergence of Information Extraction system driven by ontology, boosted by the Semantic Web, there is a need for the development of scoring schemas that enable the automatic classification of information. These schemas, even so little explored in the Portuguese language, provide measures used in the stage of classification of relevant instances to ontological classes. In this way, this paper presents: (i) a brief discussion about existing scoring measures based on PMI (Pointwise Mutual Information); (ii) new scoring measures based on PMI and Standard Deviation Calculation; and (iii) an evaluation of all discussed measures in the context of Brazilian Portuguese text from the web."
5402;en_US;"Currently available data about people whose left their home country to live in a foreign country does not adequately capture the standards of contemporary global migration flows. A new trend for migration studies is to study the data from the Internet, either by Social network or other data in the WEB. In this study, we collected user data from the social network Google+ to investigate which feature of Brazilian user are relevant to classify them as a possible emigrant. Our study uses machine learning technique, SVM. We selected some feature to compose our dataset. Our result show that the network feature were the ones that had greater capacity for discrimination. The most relevant for the prediction of Brazilian emigrants user are, in order: reciprocity, PageRank, in-degree, clustering coefficient and ratio of incoming foreigners."
5403;en_US;"The ever-increasing usage of Social media, like Twitter, have enabled company and public personalities to communicate and to influence their public. However, how to analyze and measure something as subjective as interpersonal influences? This paper presents a methodology for measuring and to analyze how Twitter’s posts (tweets) can influence their readers. In our work, the interpersonal influence of user is given by the capacity of tweets on influencing or affecting positively or negatively his/her mood or state of mind. Hence, the influence of one user A on another user B is the fluctuation of B’s mood when he/she reads and retweets a message posted by A. We measured the user’s mood using the Subjective Well-Being (SWB) that evaluates the mood of a person based on the positive and negative sentiment pointed on their collection of authored document, e.g. on his/her thread of tweets. We applied the proposed methodology to analyze the influence of an important Twitter account, Your Holiness the Pope Francis, on the mood of his followers. The result show the existence of the Pope’s influence on his followers’ mood in a short-term period: from 1 to 2 hours after he/she retweets a Pope’s message."
5404;en_US;"A central issue in the context of smart city is for one to be able to acquire timely information about city events for purposes ranging from being able to act promptly in response to events to just monitoring and collecting statistics about them. This paper describes an initial framework focused on processing message posted in the Twitter social network. Key issues are the high throughput – a large volume of data per second that needs to be processed, and the need to process ill formed natural language text. With these in mind the framework has pipelined modules for robust, fast, real time tweet acquisition and storage, filtering of several kinds, natural language processing and sentiment analysis, that feed a final analysis and visualization module. A case study of sentiment analysis during the FIFA World Cup 2014 in Brazil is used to validate the effort made so far."
5405;en_US;"Sentiment analysis has been applied in many context, including user review analysis on products and service, trends and financial market moods. Established method for sentiment analysis present a behavior that varies according to the application and its lexical base, generating different result among them. In this paper, a new sentiment analysis technique called SentiPipe will be presented, which takes the best of a set of method, generating a less sensitive analysis based context. For such, it was used a real Web database of financial market news in Portuguese to which was applied the new sentiment detection proposal. The result were promising, showing improvement in al"
5406;en_US;"The use of social network and the Web is growing every day, generating a lot of data that can aggregate value to different application. In financial market, there is a need to better understand the situations that occur in the capital market, through negotiation strategies and technical indicators that can assist in analysis and envertment decisions. This article presents a study of the time serie data of historical quotations on assets of BM&FBOVESPA 1 and Web data about investments (e.g., social network, forums, blogs, and news), with the objective of seeking subsidies that can assist in a better understanding of financial market behavior. Based on the theory of Elliott Wave, we propose several trading strategies, evaluating them in a realistic simulator of the financial market. The result show how the use of distinct indicators, such as the ones that are based on Web data, can help minimizing losses and maximizing the triggers that generate profit"
5407;en_US;"According to the efficient market hypothesis, financial prices are unpredictable. However, meaningful advances have been achieved on anticipating market movements using machine learning technique. In this work, we propose a novel method to represent the input for a stock price forecaster. The forecaster is able to predict stock prices from time serie and additional information from web pages. Such information is extracted as structured events and represented in a compressed concept space. By using such representation with scalable forecasters, we reduced prediction error by about 10%, when compared to the traditional auto regressive model."
5408;en_US;"The speed of information publishing in WWW is unprecedented. The individuals and organization struggle to be up to date and find relevant knowledge from a tsunami of news, video, posts, and comment. In the other hand, these contents (mostly bound to HTML pages) are unstructured and not explicitly classified. In this context, machine-learning technique can be very handy to automatic separate useful information from irrelevant noise. The present paper describes a novel approach for Web Pages crawling. The Smart Crawler employs two technique for improving the information classification: massive Web page crawling and continuous classification through committee machine. These ideas are implemented using Big Data and cloud-ready technologies, whose the cornerstone is a framework that enables memory-intensive processing, high scalability, and streaming processing. The result indicates a significant classification capability and that the classification rate can scale linearly according to the size of the dataset."
5409;en_US;"In scientific literature, there are some solutions that address the machine automatic of sign language contents. These solutions aim to reduce the communication and access to information barriers of deaf people in Information and Communication Technologies (ICTs). However, the most of these solutions do not explore syntactic and semantic aspects in the machine translation process, especially when they are designed to be general area. As a result, there is a limitation on the quality of the accessible generated contents, and a consequent resistance of deaf user for using these solutions. To reduce this problem, in this paper, we propose a solution that incorporates syntactic and semantic aspects in the translation of VLibras, a service of machine generation of Brazilian Sign Language (LIBRAS) content in for ICT (Digital TV, Web, Digital Cinema and mobile device). This solution involves a formal rule description language modeled to create translation rule; the definition of a grammar exploiting these feature; and their integration with the VLibras service. To evaluate the solution, some computational tests were performed using WER and BLEU metrics to assess the quality of the output generated by the solution. The result show that the proposed approach could improve the result of the current version of VLibras translator."
5410;en_US;"Ginga, the middleware of the Brazilian Digital TV System, can also work in the context of the Brazilian Digital Radio System. This paper presents a solution for the transmission of NCL application for both digital radio system in consideration by adoption in Brazil. An emphasis is placed on the support to advanced feature of Ginga, like fine synchronization between the main audio stream and other media content, and live edition of NCL presentations."
5412;en_US;"Nowadays, the amount of customers using clothing sites for shopping is greatly increasing, mainly due to the easiness and rapidity of this way of consumption. In this context, Recommender system (RS) have become indispensable to help consumers to find products that may possibly pleasant or be useful to them. These system often use technique of Collaborating Filtering (CF). When there are item that do not have ratings or that possess quite few ratings available, the recommender system performs poorly. This problem is known as new item cold-start. In this paper, we propose to investigate in what extent information on visual attention can help to produce more accurate clothing recommendation model. We present a new collaborative filtering strategy that uses visual attention to characterize image and alleviate the new item cold-start problem. In order to validate this strategy, we created a clothing database and we use three algorithm well known for the extraction of visual attention these clothes. An extensive set of experiment shows that our approach is efficient and outperforms state-of-the-art CF RS."
5413;en_US;"This paper presents a multimodal approach to perform contentbased sentiment analysis in TV newscasts video in order to assist in the automatic estimation of polarity tension of TV news. The proposed approach aims to contribute to the semiodiscoursive study relative to the construction of ethos of those TV shows. In order to achieve this goal, it is proposed the application of computational method of state-of-the-art that, through the processing of newscasts’ video of interest, perform the automatic emotion recognition in facial expressions. Moreover, they extract modulations in the participant’ speech (e.g., news anchors, reporters, among others) and apply sentiment analysis technique in their text obtained from closed caption, therefore making possible to estimate the emotional tension level in the enunciation of the TV news. In order to evaluate the accuracy and the applicability of the system, we use an actual dataset composed by 358 video from three Brazilian newscasts. The experimental result are promising, which indicate the potential of the approach to support the analysis of TV newscasts discourse."
5414;en_US;"Video encoder motion estimation algorithm allow a great level of parallelism exploitation, since the same arithmetic operations are repeated over near amounts of pixel data. This paper analyses the use of modern general purpose graphical processing units (GPGPU), such as the NVIDIA CUDA® as an effective acceleration engine to improve motion estimation algorithm overall performance. The result of our analysis include practical evaluations performed on different ME method using CUDA platform. The evaluations show the impacts of the method, window search size, and ME thread mapping onto the GPGPU in the speed up that can be achieved in such parallel platform."
5415;en_US;"The medical area has benefitted from several technological innovations over the years. A good example of this is the development of video game with natural interaction that can aid in physical and occupational therapy treatments. This article introduces a new alternative in this area with an infrastructure that contains: (i) an environment that facilitates the development of game; (ii) an inexpensive video game console, and (iii) an innovative wearable control. Preliminary usability experiment were done with user and professionals from the medical field. Promising result were obtained for both parties."
5416;en_US;"In this paper we present the concept of a VLibras-Box, a building box for distributed sign-language translation infrastructures. A VLibras-Box encapsulates a Portuguese to Brazilian Sign Language translation service and additional components needed to combine multiple VLibras-Boxes in order to assembly a fault-tolerant and scalable translation infrastructure. We present three different application scenarios, hanging from a single VLibras-Box, where the translation endpoint is defined in an static way to multiple translation servers scenarios with dynamic selection and a two-way load balancing strategy to compose public, private and hybrid fault-tolerant distributed translation infrastructures."
5417;en_US;"This paper presents a platform for multimedia traffic forwarding in OpenFlow Software Defined network (SDN). Its functional structure, developed as an extension to OpenFlow controller, uses a selective packet forwarding mechanism, QoS mechanism and multimedia cache mechanism to enable its operation. Preliminary result demonstrate that the proposed platform can be used in SDN environments, enabling selective packet forwarding and providing QoS and cache resource for multimedia traffic flows."
5418;en_US;"This paper proposes an approach to integrate multimodal events— both user-generated, e.g., audio recognizer, motion sensor; and user-consumed, e.g., speech synthesizer, haptic synthesizer—into programming language for the declarative specification of multimedia application. More precisely, it presents extensions to the NCL (Nested Context Language) multimedia language. NCL is the standard declarative language for the development of interactive application for Brazilian Digital TV and an ITU-T Recommendation for IPTV service. NCL application extended with the multimodal feature are presented as result. Historically, Human-Computer Interaction research community has been focusing on user-generated modalities, through studies on the user interaction. On the other hand, Multimedia community has been focusing on output modalities, through studies on timing and multimedia processing. The proposals in this paper is an attempt to integrate concepts of both research communities in a unique high-level programming framework, which aims to assist the authoring of multimedia/multimodal application."
5419;en_US;"Arranging interface components in a layout model, like a grid, is frequently supported in programming language. However, in multimedia authoring declarative language, those facilities are not provided and authors should declare presentation characteristics for each media item separately. Moreover, in hypermedia document template authoring language, where generic media components can be defined, layout model would be very helpful for specifying presentation characteristics of media item. This paper proposes the use of Adaptive Layouts for hypermedia document template. Adaptive Layouts allow the definition of generic layout model, such as grid or flow, to automatically place media item on the presentation device screen. This work presents the XTemplate 4.0 authoring language for specifying hypermedia composite template including the adaptive layout facility. Another contribution of this work is related to template nesting. When defining new document template, reusing previously-defined ones can be very helpful. As a hypermedia composite template specifies semantics for a document composite node, when nested compositions are supported in the document authoring model, nested template can facilitate template definition and reuse. This work also includes the facility of nesting template in XTemplate 4.0, specifying a well-defined interface for nesting template, which satisfies the compositionality property."
5421;en_US;"The urban environment has a lot of device that use different technologies, which makes the integration of data generated in them a difficult process due to their heterogeneity. However, it is important to manage these data in an integrated way, enabling the exchange of information between existing fields and assisting in the decision-making process. Moreover, there’s no way to tell how this data will need to be processed since each application may require it to be available obeying specific process. Thus, this paper describes the design and implementation of a platform that aims to integrate, process and make available data streams from heterogeneous source. It also defines an extensible data processing flow, which makes the creation of new process for existing data and the inclusion of new types of data easier. Finally, a case study was conducted, which used a parking lot as scenario and assessed some important aspects related to platform implementation."
5422;en_US;"Currently, several advances are taking place in the area of residential environments, providing convenience and pleasure to different profiles of people. With the increased use of smartphone, people will be able to use them to control their existing home appliances. In this scenario, we propose a platform structured into three layers: (i) Interaction, using a mobile application with the function of a universal remote; (ii) Connectivity, middleware responsible for managing the communication between the Interaction Layer and the Actuator Layer; and (iii) Actuators, microprocessors connected to home appliances so that they can be controlled. Some tests were conducted to validate the platform and identify its potential. The preliminary result indicated that the platform functions properly and efficiently."
5423;en_US;"The first 15 years of the twenty-first century are marked by the significant evolution of a new area known as Ubiquitous and Pervasive Computing. The introduced concepts are materializing in significant technological advances in different scenarios of humans’ daily life, especially the so-called Ambient Intelligence (AmIs). In this context, one of the relevant research points is to enable human-computer interaction to become transparent and preserve the natural shape of existing communication between humans. Thus, this work contributes to the studies in this area, with the specification of a new model for voice interaction in AmI. To validate the proposed model, an infrastructure was built, based on the specified components. The potential of infrastructure and its possible large-scale adoption are evaluated by the execution of a preliminary experiment."
5424;en_US;"Commonly, programmers who have no knowledge in electronics, and engineers, who have no programming experience, are involved in project that aims to build ubiquitous system. To create such system, they often face the problem of not having the specific knowledge to deal with activity like: implement system’s abstractions, configure logic connections between sensor and a computer device, capture, understand and process data from sensor in order to make them understandable, etc. To fill this gap, this paper presents a library named LibsensorPy, an extensible library which allows to abstract much of the complexity of these activity and more easily interact with an environment through sensor and actuators coupled to a Raspberry Pi computer."
5425;en_US;"The tourism sector in Brazil has grown considerably in recent years. Despite this growth, the sector still presents several problem such as the lack of information in Portuguese and in other language for Brazilian and foreign tourists. The absence of information about tourist sites and ordinary service also affects individuals when settling in a new city, as it is the case when freshman student move to a new city to start their studies in a college or university. In this work, we propose an innovative vision of a context-aware platform for recommending points of interest in Brazilian city, designed with mechanism for collecting data from the web, for extracting points of interest and background information, and for learning context-aware recommendation model. The platform is accessed by a mobile application. To validate our proposal, we ran a case study where freshman student used the platform during their first months in a new city."
5426;en_US;"The growth of tourism associated with the development of information and communication technologies have changed the way people do tourism, because tourists now have several support tool at all stages of tourism. However, most of them do not consider important aspects. For example, the generation of tourist guides dynamically from information available on the Web. In addition, the guides often lack information about small towns, regarding number of population and economic aspects. Considering this scenario, the objective of this work is to propose a ubiquitous tourism model, based on mobile device, called Ataîru. The main contribution is to perform a dynamic search for tourist contents in open databases available on the Web, presenting the result based on concepts of ubiquitous computing such as context awareness and transparency to the user. We performed an evaluation based on scenarios to assess the model."
5427;en_US;"This paper presents an evaluation of the quality of experience of use and the resource provided by the Mobile Fitness application (MFAs) Nike+Running and RunKeeper (MFAs). In this study, we used analytic and empirical evaluation method, exploring usability, and user experience to verify if they supply the user’ needs. Initial result show the relation between motivational and emotional aspects and MFAs resource, as well as the quality of its resource. We present the first part of a research whose final objective is to identify what characteristics are necessary for designing MFAs capable of motivating user to engage and evolve on physical activity."
5428;en_US;"Annotations enable us to highlight key points or add information to content presented, for instance, on paper or digital media. Even though smartphone and tablets facilitate video capturing, currently only few application allow limited video annotations using the mobile device itself. Given that video annotations can assist many tasks that depend or can be enhanced by video capturing, in previous work we have contributed with a tool for allowing multimodal video annotation using mobile device. Upon experimenting with the tool, we identified that reviewing rehabilitation exercise video can be especially enhanced with video annotations. Professionals in the field of physiotherapy and occupational therapy can add relevant annotations for their patient to improve performance of their exercises. After an evaluation with a specialist in occupational therapy, we identified new requirement associated with the monitoring of patient. We then identified the opportunity to develop a monitoring system with the collaboration of two rehabilitation specialists. Since these two specialists work with mirror therapy, we defined requirement that are relevant for this type of therapy. The system was developed to support the monitoring of exercises combined with video recording and annotation capabilities. The system aims to support rehabilitation therapy by distance: therapists can monitor patient as they record video that are sent for evaluation. We identified requirement that may be applied in many scenarios, however mirror therapy demanded many specific requirement related to the recording of video."
5429;en_US;"The exponential growth in the use of web service and application has increased the amount of personal information registered on websites and databases worldwide. Consequently, user are more exposed to vulnerability flaws and more subject to the impact of leaking this information. This article investigates how personal information is handled by three popular browsers: Internet Explorer, Mozilla Firefox and Google Chrome, by analyzing data collected in shared research laboratories. Through the analysis of data stored by browsers on a shared computer laboratory, we found a large number of cookies with important personal information, showing that these browsers can reveal more than the user would like."
5430;en_US;"This paper presents an authoring tool focused on the design of interactive narratives, named ISB Designer. Based on technique used by film and animation producers, the tool does not rule out paradigms they are used to. One of its main advantages is to allow the design of audiovisual content together with its points of adaptation and intervention, thus helping in the detection and correction of narrative inconsistencies. Another ISB Designer differential is the possibility of designing application for presentations on multiple screens. Unlike other tool, the ISB Designer focuses on the design and prototyping phase of application, as a means of producing higher quality interactive narratives, for then automatically generate the final application, in a post-project stage."
5431;en_US;"This paper contributes with a knowledge representation model of the human vital sign monitoring activity based on Semantic Web specifications for ontology and Horn-like rule. The proposed model is founded in interviews with intensive care units professionals, medical and nursing literature, and the reuse of existing ontology. As a result, this work contributes with an ontology describing vital signs, actors and temporal information involved in monitoring, a set of requirement underlying to that model, and dozens of Horn-like rule describing alarms and the respective abnormal values for each vital sign."
5432;en_US;"Currently, it has been observed an increasing popularization of e-commerce. Thus, in area such as tourism, online retailers are dealing with different challenges such as performance, scalability and personalization. In this context, it is fundamental to understand the characteristics of the user requests, and the access pattern of user on these system. In this work we analyze the workload of a tourism Web system, which has on average six thousand unique daily access. We present a characterization of user sessions, their requests, and their navigation profile. As result we identify the distinct user profiles and we understand the navigation and access pattern of these user and we define a methodology of profiles and workload characterization that can be used in any other type of system, not only in tourism application."
5433;en_US;"With the advent of Web 2.0 and the behavior change which it brought, there are millions of user worldwide contributing to different databases with various forms of data, such as movie ratings, for example. Moreover, the same real-world object (a song, a band or a movie) can be modeled using different ontology or represented in different ways within the same ontology. Thus, the same film is often described by different attributes in different databases, making it difficult to perform an automatic mapping between those databases. We propose MovieMatcher, which is a heuristic that matches films across different databases using their metadata. After performing 2 experiment with the attempt to match 500 films to IMDb and Rotten Tomatoes databases, MovieMatcher had a success rate of 97.4% and 94.1%, in contrast to an alternative, simpler approach (title exact matching), which had a success rate of 80.8% and 81.9%, respectively."
5434;en_US;"This paper describes an application for full-reference stereoscopic image quality assessment called ImQET. The application was developed using Mono framework and C# programming language. ImQET is independent of platform and provides a friendly Graphical User Interface (GUI). The stereoscopic image signals used in the application are based in a two-view model. ImQET has objective image quality algorithm such as PSNR, SSIM, and PW-SSIM and also incorporates a recently published technique for stereoscopic image quality assessment called Disparity Weighting (DW). Numerical result corresponding to the performance of the objective measurements, which were obtained using the proposed application, are presented. ImQET can be used by academia and industry for standardization and development of objective algorithm and evaluation of impairments in stereoscopic image signals caused by processing technique."
5435;en_US;"Wireless visual sensor network provide valuable information for many monitoring and control application. Sometimes, a set of targets needs to be monitored by deployed visual sensor. For those network, however, some active visual source may fail, potentially degrading the application monitoring quality when targets become uncovered. Moreover, some application may need different perspectives of the same target. As visual sensor will be used to monitor a set of targets, a high level of monitoring redundancy may be required and an effective way to achieve it is assuring that targets are being concurrently viewed by more than one visual sensor. We propose a centralized greedy algorithm to enhance redundancy in wireless visual sensor network when visual sensor with adjustable orientations are deployed. Additionally, as some targets may be more critical for the application, we propose a priority-based configuration of the sensor poses in order to achieve an optimized configuration for the visual sensor."
5436;en_US;"Two actors are identified in template-oriented authoring: the template author and the application author. Classifying hypermedia template, aiming to support application authors in searching for suitable template, in inferring on their semantic and in knowing how to fill them to generate application is the focus of this paper. In doing so, it can be said that the proposed catalog somehow mediates the communication between template and application authors, favoring reuse and reducing the cognitive load; thereby facilitating application authoring. As an example of use, an indexing and storage apparatus, associated with a template authoring tool, and a search plug-in coupled with an application authoring tool are presented."
5437;en_US;"In this paper, we propose a technique that uses multimodal interaction of user to generate a more accurate list of recommendation optimized for the user . Our approach is a response to the actual scenario on the Web which allows user to interact with the content in different ways, and thus, more information about his preferences can be obtained to improve recommendation. The proposal consists of an ensemble learning technique that combines rankings generated by unimodal recommenders based on particular interaction types. By using a combination of different types of feedback from user, we are able to provide better recommendation, as shown by our experimental evaluation."
5438;en_US;"In this paper, we propose a technique to automatically describe item based on user review in order to be used by recommender system. For that, we extract item feature using a robust term extraction method that applies transductive semi-supervised learning to automatically identify aspects that represent the different subjects of the review. Then, we apply sentiment analysis in a sentence level to indicate the polarities, yielding a consensus of user regarding the feature of item. Our approach is evaluated using a collaborative filtering method, and comparisons using structured metadata as baselines show promising result."
5439;en_US;"The application of multimedia resource during classes is becoming increasingly usual, making the learning process more participatory and interactive. Learning Objects (LOs) are entities, digital or not, that can be used, reused or referenced during teaching process. The multimedia authoring of LOs is still a complex and time-consuming process. The purpose of this paper is to present the process of participatory design used in the development of Cacuriá, a tool that allows teachers and tutors to create and share video enriched with interactive multimedia contents. Cacuriá interface was developed using Participatory Design technique, including focus group, Card Sorting and Paper Prototyping followed by an enhancement of the interface design. This paper also describes implementation architecture of Cacuriá. Finally, a case study was conducted to present a possibility of OAs creation using the Cacuriá Tool without requiring the user to previously knowing programming concepts."
5440;en_US;"The Web of Things proposes to make device available by using Web standards and protocol. Several different device, which can be connected to the Web of Things, demand efforts to implement specific service to deploy each of such device. For that reason, this paper presents an approach to automatically publish and configure device as Web of Things resource. Our approach presents model that implement device functionalities and uses such model to automatically generate Web service for device. This paper also presents: i) dynamic discovery and configuration of device when connecting to a local network by using Zeroconf protocol; ii) automatic generation of application for publishing device on the Web of Things."
5441;en_US;"KW-GPS is a system to assist user intent on enjoying Web resource related to a domain-restricted collection of stories. In this system, each story is referenced in a virtual library in terms of the following data: (1) the URLs of resource associated with the story, which include but are not limited to plot-summaries, narrative text, and video; and (2) keyword of different classes, which serve as a multi-aspect index mechanism. Library item also include story template, representing narrative motifs. Furthermore, a reduced version of the tool runs the basic rank-and-show process on mobile device."
5443;en_US;"In this paper we analyze the scientific articles published in 18 previous WebMedia editions, from 1995 to 2012, in order to provide a birds eye view over the Brazilian Multimedia Community and to show how the research topic addressed in the WebMedia serie of events have evolved over the time. We used Social Network Analysis technique to identify research groups, cluster and topic on paper presented in the WebMedia events over the last two decades. The result showed that WebMedia has a multidisciplinary nature with a connected component of core authors that is evolving to include an increasing number of new authors every year, showing that the community is still evolving."
5444;en_US;"With the advances in mobile device and ubiquitous computing, mobile and context-aware application is becoming increasingly emerging. However, the development process of these application still faces some challenges (e.g, heterogeneity of device, complexity of the sensor access code, etc). The adoption of middleware platforms for context-aware system is a well-known solution used to overcome such problem. An example of middleware developed for this purpose is LoCCAM, which allows adaptive acquisition of contextual information on Android based device. But LoCCAM still presents issues concerning middleware configuration of contextual information. One approach to mitigate these existing problem is the usage of MDE (Model-Driven Engineering) paradigm. This paper shows a Visual Domain-Specific Language for modeling contextual information that is used in the development of application using the LoCCAM. This language aims at generating skeletons of Android project. These project are properly configured for the use of middleware, including a transparent access to the contextual information. The main benefit of our solution it to provide a better abstraction to software developers concerning the configuration of LoCCAM middleware."
5446;en_US;"The number of people who need special care and are living alone has increased significantly in recent years. To help and assist them, different kinds of system have been developed, for example, to detect and alert falls. However, the acceptance of such system requires on the user part the belief that the system uses the collected data properly and not cause any harm. Specifically, trust for ubiquitous system, which represent computing everywhere, anytime, and transparent for the final user, is a relevant issue. Thus, this paper evaluates, using measures of software quality, trust in a ubiquitous system, called fAlert, for detecting and warning falls. fAlert is an Android system that makes use of sensor to detect anomalies in everyday user activity."
5447;en_US;"The amount of information available in the Internet does not allow performing manual content analysis to identify information of interest. Thus automated analyses are used to identify information of interest, and one increasingly important approach is the polarity analysis. Polarity analysis is the classification of a text document in positive, negative, and neutral, according to a certain topic. This classification of information is particularly useful in the finance domain, where news about a company can affect the performance of its stocks. Although most of the method in financial domain consider that the whole document is associated with a particular entity, this is not always the case. In fact, it is common that authors cite several entities in a single document and these entities are cited with different polarity. Accordingly, the objective of this paper was to study strategies for polarity detection in financial document with multiple entities. Specifically, we studied method based on learning of multiple model, one for each observed entity, using SVM classifier. We evaluated model based on the partition of document into fragments according to the entities they cite. We used several heuristics to segment document based on shallow and deep natural language processing (NLP). We found that entity-specific model created by partitioning the document collection into segments outperformed the strategy based on the use of entire document. We also observed that more complex segmentation using anaphora resolution was not able to outperform a low-cost approach, based on simple string matching."
5448;en_US;"The widespread of social communication media on the Web has made available a large volume of opinionated textual data stored in digital format. These media constitute a rich source for sentiment analysis and understanding of the opinions spontaneously expressed. Traditional technique for sentiment analysis are based on POS Tagger. Considering the Portuguese language, the use of POS Tagging ends up being too costly, due to the complex grammatical structure of this language. Faced with this problem, a case study is carried out in order to compare two technique for sentiment analysis: a SVM versus Naive-Bayes classifier. Our study focused on tweets written in Portuguese during the 2013 FIFA Confederations Cup, although our technique could be applied to any other language. The achieved result indicated that the SVM technique surpassed the Naive-Bayes one, concerning performance issues."
5449;en_US;"The OSNs (On-line Social network) have reached an incredible popularity in modern Internet. Those system have been present in the daily lives of countless people helping them to share personal experiences, expectations and opinions. So high popularity has made of such network complex system. To understand the operation and phenomena that occur in such network, there are metrics and model that capture aspects of their structures. The purpose of this work is to understand the complex reality of eBay ecommerce network, their connections and the dynamics of its user. Data were collected using a script developed in this work, and it resulted in a database of approximately 87 million transactions and 15 million different dealer user. From these data, the characterization was made estimating network metrics, like dealer user degree distribution, that gave us key insights about the eBay negotiation network. We found that there are user who bought/sold for more than 100.000 different persons. We also found that a user A interacted over 4.000 times with another user B in just 3 months. Those and other interesting result, such as average distance and feedbacks ratings, were obtained, analyzed and discussed in this work."
5450;en_US;"The generation of a television program schedule is a daily challenge. Broadcasting company need to broadcast the best content according to the audiences preference. This paper proposes a novel take on collaborative filtering technique to automate the selection of content based on viewer rating through an interactive digital TV application. In order to overcome the fact that a television channel can broadcast only one schedule at a time, we group all ratings on Time interval in order to generalize viewer preference and present the most appropriate content using a collaborative filtering technique."
5451;en_US;"Computer graphics and virtual reality technologies allow audiovisual experiences with high level of realism, as the ones achieved in video game and movies. The synthetization of media with high degree of audiovisual realism demands specialized system with high performance computing capacity. The profusion in the last decade of personal computing consumer electronics such as mobile and portable device, encourages the interest in making possible, also in these device, application with high level of visual realism. However, due to the intrinsic limitations of the computing capability of mobile and portable device, regarding to the physical characteristics of these device, such as dimensions, electrical consume and heat dissipation, it’s not possible directly process media with the same level of visual realism that is found in specialized system. This research suggests the exploration of a traditional solution: the remote interaction with these application. Challenges resulting from this approach are identified and studied. Solutions are proposed, analyzed and formalized in a architecture for reference. As a proof of concept the architecture is used in the development of application on two scenarios: one in a local network with a media characterized by its low tolerance in delay of interaction response and another with a high tolerance media through the Internet. Also is showed the flexibility of the proposed architecture by integrating one of the application developed with a multimedia context."
5452;en_US;"In this paper we report on our efforts to define a set of document extensions to Cascading Style Sheets (CSS) that allow for structured timing and synchronization of elements within a Web page. Our work considers the scenario in which the temporal structure can be decoupled from the content of the Web page in a similar way that CSS does with the layout, colors and fonts. Based on the SMIL (Synchronized Multimedia Integration Language) temporal model we propose CSS document extensions and discuss the design and implementation of a proof of concept that realizes our contributions. As HTML5 seems to move away from technologies like Flash and XML (eXtensible Markup Language), we believe our approach provides a flexible declarative solution to specify rich media experiences that is more aligned with current Web practices."
5453;en_US;"In order to deal with the complexity of context-aware application development, the literature has reported an increasing demand for intelligent infrastructures which process heterogeneous context information and also provide real-time distributed communication. This paper outlines the Hermes software infrastructure to supporting the development of real-time, semantic context-aware application. The main contribution is the anatomy of the Hermes Interpreter component in which the semantics of context is kept decoupled and context changes are notified in real-time. Benefits for application developers include a reference architecture for context interpreters as well as the reuse of a complex infrastructure providing real-time distributed context notification. We have been working on a scenario of vital signs monitoring towards validating both the infrastructure and the interpreter component."
5454;en_US;"Holography is a technique that uses the properties of light as a way of registering and representing three-dimensional scenes and objects. However, holography is not the only technique that makes it possible to visualize in three dimensions. In this work will be detailed another form of three-dimensional visualization based on an invention of the late 19th century. Different application that use this approach will be presented, as well as their result that are quite similar to those of holography. A solution involving hardware/software for 3D visualization through optical illusion is proposed. Using a prism with specific geometric proportions, is possible project the generated content with the developed tool to visualize objects and even 3D point clouds relating to faces captured with the Microsoft Kinect sensor."
5455;en_US;"With the rise of Web 2.0 application, most people started consuming information and sharing opinions and ideas about most aspects of their lives on a variety of social media platforms, creating massive and continuous streams of valuable data. While this opened the door for information extraction and mining technique that can help us understand different aspects of society, extracting useful information from such streams of Web data is far from trivial. In this setting, sentiment analysis technique can be convenient as they are capable of summarizing general feeling about entities people care about, such as products and company. Therefore, they can be quite applicable in scenarios like the stock market, which also has tremendous impact on society. This paper describes and evaluates two different technique for sentiment analysis applied to the Brazilian stock market data: lexicon-based and machine learning based, considering a wide range of text pre-processing and feature selection approaches."
5456;en_US;"This paper presents a metadata-based framework for software architecture evaluation of quality attributes. It implements a scenario-based approach that uses dynamic analysis and code repository mining to provide an automated way to reveal degradations of scenarios on releases of web-based system. The evaluation process has three phases: (i) dynamic analysis that collects information of scenarios in terms of measurable quality attributes; (ii) degradation analysis that process and compares the result of the dynamic analysis in term of quality attributes for two or more existing releases of a web-based system to identify degraded scenarios considering the desired quality attributes; (iii) repository mining that looks for development issues and commits associated to code assets of the degraded scenarios. The paper also presents and discusses the obtained result of the framework instantiation for the library module of a large-scale web system."
5457;en_US;"The volume of electronic transactions has raised a lot in last years, mainly due to the popularization of e-commerce. We also observe a significant increase in the number of fraud cases, resulting in billions of dollars losses each year worldwide. Therefore, it is essential to develop and apply technique that can assist in fraud detection. In this direction, we propose an evolutionary algorithm to automatically build Bayesian Network classifier (BNCs) tailored to solve the problem of detecting fraudulent transactions. BNCs are powerful classification model that can deal well with data feature, missing data and uncertainty. In order to evaluate the technique, we adopt an economic efficiency metric and apply them to our real dataset. Our result show good performance in fraud detection, presenting gains up to 17%, compared to the actual scenario of the company."
5458;en_US;"The use of social network has shown great potential for information diffusion and formation of public opinion. One key problem that has attracted researcher interest is Topic-based Influence Maximization, that refers to finding a small set of user on a social network that have the ability to influence a substantial portion of user on a given topic. The proposed solutions, however, are not suitable for large-scale social network and must incorporate mechanism for determining social influence among user on each topic of interest. Consequently, for these approaches, it becomes difficult or even unfeasible to deal quickly and efficiently with constant changes in the structure of social network. This problem is particularly relevant as the topic of interest of user and the social influence they exert on each other for every topic are considered together. In this work, it is proposed a scalable solution, that makes use of data mining over an information propagation log, in order to directly select the initial set of influential user on a particular topic without the need to incorporate a previous step for learning user social influence with regard to that topic. As an additional benefit, the targeted seed set also offers an approximation guarantee of the optimal solution. Finally, it is presented a design of experiment over a data set containing information propagation data from a real social network. As main result, we have found some evidences that the proposed solution maintains a trade-off between scalability and accuracy."
5459;en_US;"The concept of Viewer usually specifies someone who watches, listens and receives information available on his TV. However, the addition of the ability to run application and access the Internet into TVs changes this concept, since the content shown in TV receivers are no longer under the total control of the TV stations and a viewer can access and view on the screen of your TV (or on a second screen) extra contents related to the program that they are watching. In fact, each viewer decides how to integrate these multiple contents generating unique and individual experiences. However, as these experiences are based on the access to different content source, it becomes necessary to synchronize this content locally on each user’s reception platform. This paper proposes a generic model to synchronize content from different source with a TV show on each client, independently of middleware and platform used. The model foresees the generation of sync points from the (main) content of a program, which are sent to customers and used locally to synchronize the different extra content accessed by the viewer with the main content. A proof-of-concept application is presented to evaluate the model. In the application, different audio streams and text related to a TV show are aggregated, reaching a high accuracy when synchronized."
5460;en_US;"A recent kind of Web application incorporates three-dimensional image content, which allows interactivity and new visual experiences to the user. However, rendering 3D video content has been a research challenge due to modeling complexity and visual content definition. This paper proposes an interactive Web application that shows 3D modeled human faces that were captured by depth cameras, and using HTML5 and JavaScript resource for 3D reconstruction and interactivity. The 3D modeling process is realized with a triangulation algorithm called Convex Hull. We propose a method that divides the model into four parts in order to achieve improvements on visual details around the concave area. The final model mesh is saved into an XML file, which is readable by any Web browser. The implemented viewer resulted in image visual enhancements, simple synchronized integration of video and audio content, and friendly interactivity capabilities."
5461;en_US;"The automatic generation of hypermedia document is a subject that still little explored. This paper deals with authoring of dynamic hypermedia document based on template. A framework to support the automatic generation of these document at runtime is proposed and detailed. As an example of use, the framework is instantiated for the automatic development of NCL dynamic application, also bringing a discussion of the available resource and the native support provided by the Ginga middleware for managing such application types."
5462;en_US;"This paper presents the result obtained from a systematic literature review that aimed at mapping current research studies that use contextual information to improve the TV watching experience or propose some interesting approach using the TV environment. We followed the orientations of literature for elaboration of three Research Questions: What contextual elements are used IPTV/DTV service? How contextual information used by IPTV/DTV service is acquired? Which types of solutions are being proposed in those approaches? We end the paper presenting our conclusions and opportunities for further work."
5463;en_US;"One of the central aspects of Ubiquitous Computing (Ubicomp) is associated with tight integration between computer system and the environment. In this sense, one of the main research challenges in the area is to provide mechanism for context awareness that promote the development of application that respond itself according to the dynamics of the physical environment of user interest. This paper presents the EXEHDA-SN, a software architecture managed by rule that provides the interaction of UbiComp system with the physical environment by sensor network and actuators. This work is being developed as part of research efforts related to EXEHDA Middleware. To assess the functionality of the EXEHDA-SN, we present a case study in agricultural area, highlighting the prototypes and tests performed."
5464;en_US;"In this paper, we analyze the application of ensemble algorithm to improve the ranking recommendation problem with multiple metadata. We propose three generic ensemble strategies that do not require modification of the recommender algorithm. They combine predictions from a recommender trained with distinct metadata into a unified rank of recommended item. The proposed strategies are Most Pleasure, Best of All and Genetic Algorithm Weighting. The evaluation using the HetRec 2011 MovieLens 2k dataset with five different metadata (genres, tags, directors, actors and countries) shows that our proposed ensemble algorithm achieve a considerable 7% improvement in the Mean Average Precision even with state-of-art collaborative filtering algorithm."
5465;en_US;"IP telephony is a consolidated service that has been growing steadily, driven by its various advantages. However, maintaining the quality of this service is still a challenge. As the telephony is an essential service for various organization, the IP telephony must maintain reasonable call qualities. Therefore, the quality offered by the IP telephony service must be constantly monitored to guide maintenance actions. This paper proposes an end-to-end quality monitoring system for IP telephony service based on the reporting package RTCP-XR and using the SIP signaling protocol. A use case of the proposed system on an IP telephony production service of a university shows its effectiveness and versatility."
5466;en_US;"Recent advances in technology have increased the availability of video data, creating a strong requirement for efficient system to manage those materials. To make efficient use of video information, first, the data has to be automatic segmented into smaller, manageable and understandable units, like scenes. This paper presents a new, multimodal video scene segmentation technique. The proposed approach is to combine Bag of feature based technique (visual and aural) in order to explore the latent semantic obtained by them in complementary way, improving scene segmentation. The result achieved showed to be promising."
5467;en_US;"Nowadays, there a increasing interest in video scene segmentation due huge amount of video available through service like YouTube. Although there are some technique which obtain relatively good precision and recall values when segmenting the video in scenes, they are somewhat limited because the high computational cost. A well know technique to accomplish video scene segmentation is the shot coherence model, which presents lower precision and recall than state of art method, like machine learning and multimodality, but stands out for being simple. The improvement of the technique based on shot coherence model could be beneficial to these state of the art segmentation method. That way, this paper presents a new technique for scene segmentation using shot coherence and optical flow feature. The technique is presented and evaluated through a serie of precision, recall and F1 values, obtaining result close or even better of those obtained by related work."
5468;en_US;"Efficient and effective handling of video document depends on the availability of indexes. Manual indexing is unfeasible for large video collections. Video combines different types of data from different modalities. Using information from multiple modalities may result in a more robust and accurate video retrieval. Therefore, effective indexing for video retrieval requires a multimodal approach in which either the most appropriate modality is selected or the different modalities are used in collaborative fashion. This paper presents a new metric access method -- Slim2-tree -- which combines information from multiple modalities within a single index structure for video retrieval. Experimental studies on a large real dataset show the video similarity search performance of the proposed technique. Additionally, we present experiment comparing our method against state-of-the-art of multimodal solutions. Comparative test result demonstrate that our technique improves the performance of video similarity query."
5469;en_US;"The portable digital device’s market has grown in recent years. The device’ interaction possibilities have become more sophisticated with the multitouch capacitive screens. The touch used to control the narrative flow of those device poses challenges to communicators, programmers, designers, and developers in general. Products and current concepts cannot meet all the possible and incessant demand that portable interactive media, especially tablets, cause. Thus, the main purpose of this paper is to present the development of the Interactive Language Gestures (LIG) and its playback system designed to be used in digital video interaction in order to expand videographic hypertext narratives for tablets. The LIG system encompasses the application (AppLIG), the language for creating hypertext video (XLIG), the audio stream transition language to keep video uninterrupted (XSLIG), and finally, the production and assembly diagram (DLIG). The LIG system allows to store and display navigation between video without the need for graphical interface"
5470;en_US;"The application in Ubiquitous Computing (UbiComp) environments must be aware of their context of interest and adapt to changes in them. Thus, a major research challenge in the area of UbiComp is related to context awareness. Considering the high distribution, heterogeneity, dynamism, and mobility of ubiquitous environments, this paper presents an architectural model for context awareness, called EXEHDA-UC (Execution Environment for Highly Distributed application - Ubiquitous Context awareness). The proposal includes elements to support contextual data acquisition, actuation on the environment, and processing of contextual information. We consider that the main contribution of this work is an architecture that supports the managing of the acquisition, storage, and processing of context data, in a distributed way, independently of the application, in an autonomic and rule-based perspective. To assess the functionalities of the EXEHDA-UC, we present a case study, highlighting the prototypes developed, technologies employed, and tests realized."
5473;en_US;"company spend too much money on advertising in order to improve their sales. However, the ratio between investment and effective sales is low. Increasing the usefulness of provided ads and discount coupons is an ongoing challenge in advertising, in order to enhance return on investments, reducing wastage and increasing revenue. Ubiquitous computing offers many feature that are considered compliant to advertising needs. A key aspect in ubiquitous computing is the use of context information to provide information more relevant to user, according to their current situation and environment. This paper introduces CSCoupons, a mobile context-sensitive system to deliver discount coupons. We conduct an experiment with a developed prototype of CSCoupons to assess the ideas about fast food coupons in shopping malls. To measure the utility rate of delivered discount coupons, we compared two versions of the prototype: with and without considering context information. The preliminary result show context-sensitivity highly increases advertising usefulness."
5474;en_US;"Since the advent of Kinect, there has been an outbreak of application that go beyond mouse and keyboard interface. application developers aim to enrich and re-imagine these interface using gesture and voice commands recognition for controlling some virtual and real world objects using a natural interaction mechanism. Aligned to this, there are problem to set a standard for these interface, plus a huge effort in performing simple tasks such as connecting sensor, processing data, recognizing gestures and running actions in real or virtual world. This paper proposes an extendable event-driven framework that improves the life cycle of designing and building interactive environments, making it possible to interact with both real and virtual environments."
5475;en_US;"The development of methodologies and technique to evaluate smartphone usability is an emerging topic in the scientific community and triggers discussions about which methodology is most appropriate. The lack of consensus is due to the inherent difficulty on capturing context data in the scenarios where the experiment take place and on relating them to the found result. This work aims to correlate potential usability problem in mobile application with contextual factors that may occur during user interaction on different device, such as: environment luminosity, device screen resolution, and the user activity while interacting with the application. The following methodology was applied to carry out a field experiment: (1) identification of contextual factors that may influence user interaction; (2) use of UXEProject Infrastructure to support the automatic capture of application context data, by monitoring and storing quantitative, subjective and contextual data from application use; (3) implementation of experiment with real user, which have different profiles, on using three different mobile application over an one year period. In this paper, we present and discuss the result obtained during this study."
5476;en_US;"Modern mobile device are natural multimedia device that enable one to access, manage and transmit multiple types of media such as video, photo, audio and maps. Video playing on these device is becoming part of everyday life for many user. Aiming to enhance the video playback activity, we built a tool that allows temporal video annotation on mobile device: text, audio and digital ink annotations can be added to the video using Android-based tablets and smartphone. Annotations can be passed along user through the sharing options available on the device. We conducted a heuristic evaluation with ten experts and the result are discussed in this paper. Two different sets of heuristics were used to find a wider collection of issues. One of them is proposed by us and was developed especially for mobile device. With this work, we expect to contribute with the theme of authoring on mobile device in terms of user interface and evaluation."
5477;en_US;"Although usability heuristics are a useful tool for the evaluation of interactive user interface, the traditional Nielsens heuristics were created without mobile computing in mind. Other heuristics proposed for mobile application, usually derived solely from the traditional heuristics, consider aspects that are not directly related to the software visualization layer to which user interface belong. In this study, we extended Nielsens heuristics to derive other heuristics specifically for the usability evaluation of mobile user interface. Two separate sets of specialists evaluated an Android application using Nielsens heuristics and the heuristics we derived: the latter allowed the identification of more usability problem."
5478;en_US;"Sentiment analysis has being used in several application including the analysis of the repercussion of events in online social network (OSNs), as well as to summarize public perception about products and brands on discussions on those system. There are multiple method to measure sentiments, varying from lexical-based approaches to machine learning method. Despite the wide use and popularity of some those method, it is unclear which method is better for identifying the polarity (i.e. positive or negative) of a message, as the current literature does not provide a comparison among existing method. This comparison is crucial to allow us to understand the potential limitations, advantages, and disadvantages of popular method in the context of OSNs message. This work aims at filling this gap by presenting a comparison between 8 popular sentiment analysis method. Our analysis compares these method in terms of coverage and in terms of correct sentiment identification. We also develop a new method that combines existing approaches in order to provide the best coverage result with competitive accuracy. Finally, we present iFeel, a Web service which provides an open API for accessing and comparing result across different sentiment method for a given text."
5479;en_US;"Many links between Web pages can be viewed as indicative of the quality and importance of the pages they pointed to. Accordingly, several studies have proposed metrics based on links to infer web page content quality. However, as far as we know, the only work that has examined the correlation between such metrics and content quality consisted of a limited study that left many open questions. In spite of these metrics having been shown successful in the task of ranking pages which were provided as answers to query submitted to search engines, it is not possible to determine the specific contribution of factors such as quality, popularity, and importance to the result. This difficulty is partially due to the fact that such information is hard to obtain for Web pages in general. Unlike ordinary Web pages, the quality, importance and popularity of Wikipedia articles are evaluated by human experts or might be easily estimated. Thus, it is feasible to verify the relation between link analysis metrics and such factors in Wikipedia articles, our goal in this work. To accomplish that, we implemented several link analysis algorithm and compared their resulting rankings with the ones created by human evaluators regarding factors such as quality, popularity and importance. We found that the metrics are more correlated to quality and popularity than to importance, and the correlation is moderate."
5480;en_US;"On Foursquare, one of the currently most popular location-based social network, user can not only share which places (venues) they visit but also leave short comment (tips) about their previous experiences at specific venues. Tips may provide a valuable feedback for business owners as well as for potential new customers. Sentiment or polarity classification provides useful tool for opinion summarization, which can help both parties to quickly obtain a predominant view of the opinions posted by user at a specific venue. We here present what, to our knowledge, is the first study of polarity of Foursquare tips. We start by characterizing two dataset of collected tips with respect to their textual content. Some inherent characteristics of tips, such as short sizes as well as informal and often noisy content, pose great challenges to polarity detection. We then investigate the effectiveness of four alternative polarity classification strategies on subsets of our dataset. Three of the considered strategies are based on supervised machine learning technique and the fourth one is an unsupervised lexicon-based approach. Our evaluation indicates that effective polarity classification can be achieved even if the simpler lexicon-based approach, which does not require costly manual tip labeling, is adopted."
5481;en_US;"Given the intense attention that environmental topic such as climate change attract in news and social media coverage, key questions for large science agencies such as the National Oceanic and Atmospheric Administration (NOAA) are how different stakeholders perceive the observable threats and policy options, how public media react to new scientific insights, and how journalists present climate science knowledge to the public. This paper investigates the potential of semantic technologies to address these questions. It introduces the NOAA Media Watch and presents a detailed case study of how the metrics and visualizations of the webLyzard Web intelligence platform are used to track information flows across online media channels. Building upon this platform, we present a novel framework to measure the impact of science communication and public outreach campaigns – through a combination of quantitative and visual method that go beyond sentiment analysis and related opinion mining approaches."
5482;en_US;"Complex objects (COs) have surged as a way to integrate different digital resource under a same logical unit in order to facilitate aggregation and reuse. However, there is still a lack of consensus on precise theoretical foundations for COs, especially regarding design and specification, which compromise their utility and integration with existing software tool. Moreover, there has been little investigation on aspects related to the modeling of COs by the end user, much due to the lack of appropriate tool for this goal. In this work, we present a new Digital Library (DL) metamodel specially designed for the CO modeling which is grounded in formal theoretical specification for COs. More specifically, our goal is two-fold: (i) to indirectly validate our CO formalization by instantiating it within a DL modeling tool -- 5SGraph; and (ii) to investigate the difficulties of CO modeling and specification by real user using the specified metamodel. experiment with real user indicate that the use of the metamodel and the graphical tool facilitates the understanding of the COs structure and the modeling process."
5483;en_US;"With new sensor that can capture hand and body movements in 3D, novel interaction technique gain importance. But development of new forms of interaction is highly iterative, depends on extensive user testing and therefore is expensive. We propose a model-based notation using statecharts and mappings to ease multimodal interaction technique design. This model-based specification can be used to communicate designs, for evaluation and to enable re-use. Our contribution continues previous research on model-based interaction technique design considers multimodal interaction and addresses problem like the state explosion, error management and consideration of output modalities mentioned by earlier research. We evaluate our notation by comparing it with NiMMiT referring to the same use case to identify similarities, strength and problem."
5484;en_US;"Several efforts in research and development of technologies have been spent to publish data in open standard formats. The main project in this regard is the Linked Open Data, which goal is to create an open and semantic Web of Data, enabling processing and understanding the data by software agent. However, not only the machine can take advantage of the explicit semantics of data. People can take advantage from the semantic of the data to explore unknown concepts, new relationships and to obtain personalized access to relevant resource and service. However, it is not trivial for a user without experience with Web of Data, to satisfactorily explore and use these data. This paper presents the jRDFa, an approach to support the web developer interested in presenting to non-technical user, semantic data embedded in HTML pages in RDFa format. This paper also presents two ways of presenting data in RDFa that were created using the jRDFa: tooltips visualization and facets navigation. To evaluate the proposed approach, this paper presents result of experiment on HTML pages with embedded jRDFa."
5485;en_US;"Designing interactive system for multiple context of use becomes a burden when the end user interaction takes place in distinct scenarios whose specific characteristics and constraints vary and must be carefully considered. Stakeholders face then two main challenges: they are not aware of what among several context information is significantly relevant to consider, or how to appropriately adapt the user interface according to the information considered. Furthermore, stakeholders cannot simply rely on existing UI editors once they usually do not provide enough support for adaptation. Thus, adaptation is often ignored, resulting in user interface that are only suitable for static and conventional context of use. To support the design of user interface that are properly adapted to their target context, this paper proposes a novel methodology to enhance sketching activity by proposing to the end user context-aware adaptation guidelines. This work aims at raising awareness about context-aware adaptation since the early stages of the UI design."
5486;en_US;"XML SCHEMA is a standard defined by W3C widely used in the specification of XML elements. Another standard by W3C is XML Linking Language (XLink), a language that specifies how elements should be declared in XML document in order to define links between two or more resource. XLink and XML Schema are emerging Internet standards applied in varying context such as XBRL Language. Similarity evaluation is an important process in data management and serves as support for one of its core activity: duplicate detection. Thus, the classification of XML elements according to the similarity between them is becoming increasingly useful in the area of XML data management. This paper presents a process for similarity evaluation between XML elements defined with the use of XML Schema and XLink and an experiment. The experiment applies the proposed process to the context of the XBRL concepts, an example of XML elements created with extensive use of XML Schema and XLink."
5487;en_US;"Wireless sensor network have been employed as an effective tool for a large set of monitoring application, directly supporting application not addressed by conventional Internet-based technologies. Camera-enabled sensor enhance the applicability of those network allowing innovative visual monitoring functions. Sometimes, source node will perform real-time monitoring of an area of interest, where visual data packets will need to be transmitted with minimum delay. However, energy depletion of the node that compose the transmission paths may hamper the network capability to deliver packets with time constraints. In such context, we propose a delay-aware image transmission mechanism where the relevancies of DWT subbands are considered when forwarding packets to the next hop toward the sink. In fact, parts of DWT-based encoded visual data may have different relevancies for the reconstruction of the original visual information and those relevancies may be exploited when forwarding packets. In the proposed approach, high-relevant packets are forwarded through paths with lower average end-to-end delay, while the remaining packets flow through paths high higher delay, allowing that low-quality versions of the transmitted image reach the sink as soon as possible. Moreover, the best paths will need to relay fewer packets, potentially reducing energy consumption and enlarging their lifetime. We present simulation result to attest the benefits of the proposed mechanism."
5488;en_US;"Video telephony is the real time exchange of voice and video between end-user, and is the basis of a wide range of application. Quality of service (QoS) enables a level of network performance control which makes it possible to meet specific application and/or end-user requirement. This paper proposes an architecture for QoS-enabled video telephony in a 3GPP 4G Evolved Packet Core (EPC) environment. The architecture uses EPC as enabler to provide a refined differentiated QoS scheme that does not exist in the state of the art. The scheme allows prioritization between different sessions of the same video telephony application running in the same network. End-user can therefore use one application for different purposes (e.g. for business video calls and for private video calls) by assigning the appropriate priorities. We have built a proof of concept prototype using the Fraunhofer Fokus OpenEPC as the 3GPP 4G EPC infrastructure and have made some preliminary performance measurements. The architecture and the operational procedures are presented, along with the prototype and the performance measurements. Related work is also reviewed."
5489;en_US;"This paper describes a software-based approach for transmitting, and displaying ultra high definition (UHD) video (ex: 4K) in raw format (2D or 3D).The viability of using lossless compression algorithm for transmission, and exhibition of UHD raw video was investigated. This approach allows the transmission of raw video for supporting the development of distributed edition tool for UHD video, and high quality visualization using a lower bandwidth. We conducted performance studies of eight lossless compression algorithm, aiming at analyze the compression ratio for 4K video, and the latency in video encoding and decoding. Finally, a multi-thread version of the LZ4HC was integrated with the Fogo Player, which is a software-based 4K player developed in a previous work. We obtained a reduction of about 38% in bandwidth requirement, and a decoding latency that allowed the exhibition in real time of 4K video."
5490;en_US;"Currently the high computational complexity makes it very difficult to produce a whole high definition real-time H.264 encoder solution, for conventional personal computer platform, based only on single-threaded software implementation. Considering that, the current paper analyses the potential of using modern general purpose graphical processing technologies, such as NVIDIA CUDA ® platform, as acceleration engines to improve the overall performance of a computer based H.264 intra video encoder. Performed experiment allowed discriminating the real gains when replacing a CPU based only solution by a GPU solution identifying some practical bottlenecks related with that technology. The most efficient proposal was finally compared with the original H.264/AVC reference code and the optimized x264 open source library codec, registering significant performance gains (in same cases higher than 7.6x)."
5491;en_US;"In this paper we propose a blurring image quality assessment (IQA) based on histogram of oriented gradients (HOG). The image quality can be determined by the slope value of the HOG of the target image. The representative line of HOG is approximated by a random sample consensus set (RANSAC). Simulation result performed on the LIVE image quality assessment database show that the proposed method aligns better with how the human visual system perceives image quality than several state-of-the-art IQAs."
5492;en_US;"The availability of 3D-enabled displays, both stereoscopic and autostereoscopic ones, is growing in the market. However, most of the current multimedia digital TV standard for describing interactive application does not take advantage of these technologies. A useful and flexible way to codify 3D-video to work with both stereoscopic and autoestereoscopic displays is using video plus depth-per-pixel information. In order to improve authoring of interactive digital TV application written in NCL (Nested Context Language), the Latin-American standard for digital TV, this paper proposes some extensions to this language to allow multimedia authors to be aware of depth information. Among the new feature provided it is the control and animation of depth information for synthetic and non-synthetic media objects. As it is based on 2D+depth information, the proposed extensions will enable multimedia authors to take advantage of stereo and autostereoscopic displays, and also are compatible with previous versions of NCL players."
5493;en_US;"This paper presents a model-driven approach for the analysis of NCL document. Structural and behavioral properties of NCL document are verified guaranteeing its well-formedness and conformance with respect to the NCL language semantics. Document structural properties are verified using invariant validation and document behavioral properties are verified through model checking. The model-driven approach proposed is based on a formal and simplified model for representing the NCL document presentation behavior called Simple Hypermedia Model (SHM), used for the verification of document properties. In addition, this paper presents a prototype implementation of the proposed approach."
5494;en_US;"In this paper, we investigate the problem of normal forms for links and connectors in NCL 3.0. We identify two such forms, called the First and Second Normal Forms (NF1 and NF2), in which links and connectors appear in simple terms. We also present normalization procedures (proofs), which show that for every NCL 3.0 program, there is an equivalent program in each of the forms. The mere existence of NF1 and NF2 makes the semantic analysis of programs simpler. Moreover, the symmetry exhibited by these forms suggests that the same principle of arbitrarily ordered evaluation underlies both the evaluation of link conditions and the execution of nonsequential compound actions."
5495;en_US;"This paper presents a layout module that incorporates the facility of specifying adaptive spatial layouts, providing automatic creation of regions and descriptors for NCL document. Two types of adaptive spatial layouts are provided: flowLayout and gridLayout. Adaptive layouts are very useful for defining generic template for hypermedia document, where the number of components will be specified by the final NCL application. Therefore this proposal facilitates the authoring of hypermedia document used for interactive content creation in the Brazilian Digital TV System."
5496;en_US;"In recent years, computer network have been characterized by heterogeneous traffic and dynamic management of different kinds of service. The web and network requirement have increased within time and, since bandwidth is limited, it becomes necessary to employ optimization procedures in order to make the network able to operate in its full capacity. Traffic shaping mechanism implement Quality of Service (QoS) concepts to ensure acceptable service levels. This paper describes an approach for traffic shaping optimization. It is proposed a methodology based on throughput and packet loss optimization using genetic algorithm. This method was validated using actual data from a network infrastructure of a Public Educational Institution."
5497;en_US;"In this paper three optimization algorithm were used in order to solve the problem of dynamic composition of Web service with Quality of Service (QoS). This combinatorial optimization problem arises when multiple service, which provide subfunctions for a complete function, are aggregated in an execution flow and presented to the user as a single service. This problem has been modeled in the context of two deterministic and one stochastic algorithm, aiming to determine the best flow in terms of QoS. Besides, a performance evaluation was executed considering the composition algorithm in some scenarios and comparing them in terms of response time and quality of the obtained solution. The stochastic algorithm proved to be more advantageous for these scenarios due the deadline exploitation on the search for an optimal solution, although it does not provide guarantees of optimality."
5498;en_US;"Traditional scenario-based architectural analysis method rely on manual review-based evaluation that requires advanced skills from architects and developers. They are usually applied when the architecture is under development, but before its implementation has begun. The system implementation is one additional and fundamental element that should be used and considered during the software architecture evaluation. In this paper, we propose an approach to add information, which ideally should come from traditional evaluation method, about scenarios and quality attributes to the source code of web-based system using metadata. The main aim is to enable the automatic architecture analysis by producing a report with information about scenarios, quality attributes and source code assets, such as: (i) the potential tradeoff points among quality attributes, (ii) the execution time for scenarios and if it has failed or not. Up to now, the approach has been applied mainly to web-based system, but it can be adapted to other software domains. The paper also presents the tool used to perform static and dynamic analysis, and the result of its application to an e-commerce web system and an enterprise information web system."
5499;en_US;"The Web of Things (WoT) is a new trend related to the Internet that have yet to scale to mass usage. Consumer and in-vehicle context can promote WoT to mass usage. For these context, ad-hoc operation and complexity abstraction is very important. This paper suggests the creation of an ad-hoc service bus for the WoT. The solution uses Bonjour and Link-Local technologies to provide the main needed functions for a WoT RESTFul service bus operation. A proof of concept was executed to demonstrate this propositions viability in a ah-hoc network without any infrastructure."
5500;en_US;"This paper presents a framework system, called ProcessSearch, which is used to search and identify business process descriptions stored on the web. Some metrics were proposed in order to identify the web document describing a business process. Identifying descriptions of business process is a difficult task because the web stores bag-of-word document. Hence, the ProcessSearch framework has been constructed and implemented, using known technologies in information retrieval and computational linguistics. The result was a satisfactory list of web document ranked (top-k) by relevance for some given keyword. For validation, a precision at k analysis was used to confirm the accuracy of the proposed metrics."
5501;en_US;"The amount of video content that is available on the web grows at each instant. This fact implicates in an important issue -- video content overload. One way to treat such problem consists on the use of recommender system. In this sense, this paper proposes a method to enhance the accuracy of the predictions given by video recommender system by the use of Segments of Interest (SOI). Based on the premise that user tend to like particular segments of a video more than the entire video, and that they are able to mark these segments, these can be used to identify similar people, i.e. the ones who have similar interests about video. This similarity can be used to enhance the accuracy of the ratings predictions of traditional collaborative video recommender system. To evaluate this approach, an experimental evaluation was performed. The result showed that the accuracy improvement is directly related with the level of participation of people marking SOI. Thus, as more people collaborate and interact, better will be the recommendation result."
5502;en_US;"Recommendation system are a subclass of information filtering system that aims at helping user in retrieving information. Recently, contextual information proved to be effective in improving the quality of result of Recommender system. However, Context-aware Recommender system still suffer performance issues for real-time recommendation, mainly due to the amount of item that should be considered for recommendation. In this paper, we present an evaluation of using MapReduce and its integration with a mobile system for implementing a knowledge-based algorithm for context-aware recommendation. To be effective, this photo recommendation algorithm should work with a large set of image annotated with contextual information. The MapReduce algorithm parallelizes the processing required to generate the recommendation result and so improved the system performance. The result of performance analysis showed, for instance, that cloud-based version of the reccomendation reaches a speedup of 7x with a image base with more than 41 million photos."
5503;en_US;"Creating compelling multimedia productions is a non-trivial problem. The problem is compounded when authors want to integrate community media assets: media fragments contributed by a potentially wide and anonymous recording community. In this paper, we report on a hybrid authoring approach that provides mixed support for automated creation and manual enhancement of personalized multimedia presentations. We target small-scale events (such as a high school music concert), where lightly annotated media assets are provided. Our assumption is that enthusiastic, but less experienced, editors (e.g., parents and family members) will want to highlight personal aspects of each event: a particular child, a particular instrument or a particular solo. This places a requirement on a system that helps user to select appropriate content of personal interest, and that helps building compelling presentations with minimum user effort. Based on a 4-years user-centered evaluation process, this paper provides useful insights into how a multimedia authoring system should be designed and architected for helping user in creating personalized video stories they care about."
5504;en_US;"Web content has gained much importance lately. One of the most important content types is online video, as demonstrated by the success of platforms such as YouTube. The growth in the volume of available online video is also observed in corporate scenarios, such as TV network. This paper evaluates a set of corporate online video hosted by Sambatech, a company that holds the largest platform for online multimedia content distribution in Latin America. We propose a novel analytical approach for video recommendation, focusing on video objects being consumed, and not on consumer profile data. After modeling this service, we characterize the contents from multiple source, and propose technique for video recommendation. Experimental result indicate that the proposed method obtains a gain of about 42% in precision for a set of five recommendation, as compared to a baseline that is based only on video metadata."
5506;en_US;"The progress of information technology has made objects continuously acquire new resource and communication skills, therefore we have to change the way we interact with them. As the mainstream media of the twentieth century, television has also followed this trend. TV is changing from a passive medium, from which the viewer only receives information, into an active media, with which there is interaction facilitated by the option of choice, participation and even creating new content. However, the experience of interactive television is often barred by the problem inherent to dealing with the remote control. Especially, when it comes to a task, that is too complex to be done with a standard remote control: the task of putting data in text format into the TV. This paper presents an ongoing research that addresses the input of text data in digital television proposing an attention-aware system."
5507;en_US;"The growth of distance education has been enhanced by Massive Open Online Course and by the production of content broadcasted on television. The type of learning undertaken by Interactive Digital Television (iDTV) is also called Television-Learning (T- learning). Due to the possibilities of interactivity emerged with the creation of middleware Ginga, the T-Learning can cover a large number of learners. The marking video is a set of technique used to insert additional interactive content in a video. As the development of application for iDTV is still a costly process, because it requires a multidisciplinary team of developers to create tool for producing interactive application for iDTV is a promising solution. The need for specific knowledge of technology or programming language should not be a prerequisite for this team. This paper presents a tool, called MARKER, for building interactive application for iDTV whose main actors are the teacher (content creator) and student (interactive video user)."
5508;en_US;"It is recommendable that Interactive Digital TV application development should be oriented by user interface structure and interaction design. Better interactivity experiences can be obtained with the return channel usage, contributing to the offering of more convergent application and addressing their integration to remote businesses logics and service. Many solutions enable construction of interactive application with textual/visual programming support, but a few of them considers the disposal between the service operated over a return channel, the underlying data and the application widgets. Usually, these solutions require the direct manipulation of intermediary model whose their structures and notations demand an additional learning effort and, in some cases, they only focus on the achievement of a specific domain application template, instead of the final application instance itself. An alternative for application authoring will be presented aiming to abstract both the visual programming interface structure domain and its behavior/responsiveness when it requires the usage of the return channel based on service over IP and meeting the expectances for agility and quality in digital interactive television conception."
5509;en_US;"Interactive Digital TV (iDTV) exists within a digital ecosystem that interconnects a variety of media, viewer and electronic device, and it reaches new proportions as computer and hyper-connectivity are being incorporated into objects and also into everyday environments, in both public and private spheres. Every emergent technology suffers from a lack of references, process and artifacts for developers and as they assess and design new solutions. In light of this context, this study sought to map out the main research focuses that have been addressed in the iDTV field in recent years. Data was collected and an analysis was conducted on research source based on the frequency of word from paper titles and their abstracts; result reveal individual characteristics of one of the most relevant conferences in the field (EuroITV) and other publications found in the ACM-DL. Similarities and differences on these vehicles, allow an overview of contributions and gaps in the field. Moreover, this study presents detailed information about conferences, journals, affiliations and countries where work in the field is registered."
5510;en_US;"In this paper, we present an approach for reducing the complexity of NCL player implementations. This approach consists, basically, in introducing in the players architecture an initial conversion step that removes all syntactic sugar and reuse feature from the source language. The output of this step, a redundancy-free version of the original input, is then fed to the player that interprets it and creates a corresponding multimedia presentation. In particular, we propose the use of the NCL Raw profile as this intermediate language. The Raw profile is an (almost) redundancy-free profile that is compatible with the NCL 3.0 EDTV (Enhanced Digital TV) profile, a property that guarantees a seamless integration with current EDTV profile implementations. The main targets of the proposed approach are NCL players running on HTML browsers. We discuss how the solutions presented by NCL4Web, WebNCL, and Ginga Plug-in can be tuned to overcome some problem pointed their authors. The same problem arise in similar context for other declarative language, e.g., SMIL, and the solutions presented here can also be extended to those system."
5511;en_US;"Advances in interactive digital TV have enabled the introduction of application scenarios that explore Internet content and multiple device interaction. However, the authorship and interoperability for such scenarios is hampered by the diversity of technologies and device involved. This paper presents a software architecture for a portable application store based on the H.761 ITU recommendation for IPTV service. The application store concept is implemented as a Ginga-NCL application, which retrieves and executes other Ginga-NCL application. The description of the proposed software architecture, the execution of system and usability tests on a software prototype are presented as result."
5512;en_US;"System performance appraisal needed at the development of new large scale distributed system are faced with the challenge of correct estimated load that is imposed on them. When dealing with Digital Tv, including terrestrial, cable, satellite and IPTV obtaining such load characterization from real deployment scenarios has proved very difficult, due to the impediment of experimental access to these operational broadcast network. Thus, the researcher usually uses simulation that impose grossly approximate workloads, oversized or fictitious to his system, bringing uncertainty to potential service provider as to optimized design of the necessary equipment. We present at this paper a mathematical model of simple implementation, able to represent the behavior of user of Digital TV. The model can be parameterized to represent different behavior states of the simulated system and thus adapt to various interest scenarios."
5513;en_US;"Nowadays, more and more computing device arise with different applicabilities. Software application peculiarities for Digital TV (DTV), for example, require special attention in its development process, such as multimedia content gathering requirement (size, display time, location and timing) and development time (limited by the production time of the TV program). This work presents an agile and hybrid development method, instantiated for DTV environment and named eXtreme Digital Television (XDTv). The goal is to contribute with the handling of such peculiarities. Experimental result provide outcomes that XDTv contributes to improve the performance of software application development for DTV."
5514;en_US;"This paper proposes a hybrid recommender algorithm which integrates a set of different user inputs into a unified and generic latent factor model to improve prediction accuracy. The technique can exploit user demographics, such as age, gender and occupation, along with implicit feedback and item metadata. Depending on the personal information from user, the recommender selects content whose subject is semantically related to their interests. The method was evaluated in the MovieLens dataset and compared against other approaches reported in the literature. The result show the effectiveness of incorporating metadata awareness into a latent factor model."
5515;en_US;"Tag recommendation method that exploit co-occurrence pattern of tags have consistently produced state of the art result. However, tags are not present in significant portions of Web 2.0 objects, which may impact the effectiveness of such method. This problem, known as cold start, is the focus of this paper. We here evaluate the impact of the cold start on a family of method for recommending tags. Our result show that the effectiveness of these method suffer greatly when they cannot rely on previously assigned tags in the target object and that the use of automatic filtering strategies to alleviate the problem yields limited gains. We then propose a new strategy that exploits both positive and negative relevance feedback (RF) from the user to iteratively select input tags to these method. The result show that the proposed strategy generates significant gains (up to 45%) over the best considered baseline. It is also shown that the proposed method is robust to the lack of user cooperation."
5516;en_US;"Wikipedia, a web-based collaboratively maintained free encyclopedia, is emerging as one of the most important websites on the internet. However, its openness raises many concerns about the quality of the articles and how to assess it automatically. In the Portuguese-speaking Wikipedia, articles can be rated by bots and by the community. In this paper, we investigate the correlation between these ratings and the count of media item (namely image and sounds) through a serie of experiment. Our result show that article ratings and the count of media item are correlated."
5517;en_US;"The volume of online transactions has raised a lot in last years, mainly due to the popularization of e-commerce, such as Web retailers. We also observe a significant increase in the number of fraud cases, resulting in billions of dollars losses each year worldwide. Therefore it is important and necessary to developed and apply technique that can assist in fraud detection, which motivates our research. This work proposes the use of Genetic Programming (GP), an Evolutionary Computation approach, to model and detect fraud (charge back) in electronic transactions, more specifically in credit card operations. In order to evaluate the technique, we perform a case study using an actual dataset of the most popular Brazilian electronic payment service, called UOL PagSeguro. Our result show good performance in fraud detection, presenting gains up to 17.72% percent compared to the baseline, which is the actual scenario of the corporation."
5518;en_US;"line sales, mainly due to agility to buy and attractive prices that are offered on the Web. However, fraud has also been increased on the same rate or more. In order to address this problem it is very important to understand the characteristics of fraudsters and their typical behavior. On the tourism e-market it is not different, thus millions of frauds occur each year. In this work we analyze a representative amount (thousands) of online transactions of a tourism Web system. We try to understand the characteristics of fraudsters with the main goal to support decision of e-payment evaluation of transactions. Our result are promising, achieving up to 64% of increase in accuracy in comparison to the baseline."
5519;en_US;"Given a set of item, a Multidimensional Computer Adaptive Test (MCAT) selects those item from the bank according to the estimated abilities of the student, resulting in an individualized test. MCATs seek to maximize the test’s accuracy, based on multiple simultaneous examination abilities (unlike a Computer Adaptive Test - CAT - which evaluates a single ability) using the sequence of item previously answered. Although MCATs have been very well studied from a statistical point of view, there is no computational system that covers all the steps needed for its appropriated use such as: the use of a calibrated item bank, proposal of initial and stopping criteria for the test, criteria for estimating the ability of the examinee and criteria to select item. The purpose of this paper is twofold: (i) to present an innovative architecture of an MCAT for real user, as a Web application, and (ii) to discuss the theoretical and methodological development of such MCAT, through a new approach named here Computer-based Multidimensional Adaptive Testing (CBMAT). The proof of concept of CBMAT was an implementation called Multidimensional Adaptive Test System for Educational Purposes (MADEPT). In simulation, MADEPT proved to be a computer system suitable for application with real user, secure, accurate and portable."
5520;en_US;"Mobile computing and localization system recent diffusion enables the use of context and trails in several application, with the incorporation of resource for content adaptation and distribution. A trail represents a set of user context, historically organized. This article presents a proposal for managing multiple trails in mobile computing environments. Its differential is the representation of the data of each entity in several trails. This approach allows the multiple aspects of interest for the entity to be modeled and stored. In addition, facilitates its use in different application, which may need only part of the elements in this set of trails. In this way, this proposal extends the possibility of context composition for entities, providing greater flexibility to their use. This is demonstrated in two case studies of the application of this model"
5521;en_US;"Nowadays the web is an ubiquitously available source of information that can be accessed through a broad range of device, such as smart phones, tablets and notebooks. Although web application can be used through several device, they are controlled and designed for a one-to-one connection type of interaction, which prevents device-spanning multi-modal interaction. We propose a model-based run-time framework to design and execute multi-modal interface for the web. Different to a model-based design that implements reification, a process to derive concrete model from abstract ones by transformation, we design interactors that keep all design model alive at run-time. Interactors are based on finite state machine that can be inspected and manipulated at run-time and are synchronized over different device and modalities using mappings. We show the expressiveness of state charts for modeling interaction, interaction resource, and interaction paradigms. We proof our approach by checking its conformance against common requirement for multimodal framework, classify it based on characteristics identified by others, and present initial result of a performance analysis."
5522;en_US;"The wide availability of online video content in the Internet has changed the way user interact with TV. In fact, TV user often watch the news, movies and TV serie through the Web. Along with this change, new advertisement of products and service have emerged. The success of contextual advertising in the Web, mainly related to finding advertising keyword on page content, has motivated us to apply them to video. Textual evidence extracted from video may provide good contextualization source for advertising. In this work, we evaluate the usefulness of movies scripts as a source of information for contextual advertising in video. We adopted a machine learning-based strategy to finding keyword and advertising. We studied not only feature proven be useful in earlier studies, as well as novel feature proposed and derived from the ad collection. We evaluate the impact of using scripts both in finding keyword and in finding relevant ads. The result indicate that the studies feature were more useful for finding keyword than ads. feature derived from the ad collection performed consistently well in finding keyword. We also observed that the best keyword are found in the script section which describes the characters actions and scenarios than in the one which describes the dialogues."
5523;en_US;"The processing of business rule usually occurs through its encoding in software application, causing impacts that hinder their maintenance and reuse. In the financial area, the centralization of business rule represented in technology XBRL Formula promotes reuse by multiple application and reduces these impacts. However, its use is not widespread and solutions that enable the application reusing business rule with flexibility are restricted to proprietary solutions. This article proposes a framework for flexible processing of business rule defined with XBRL Formula from the use of service."
5524;en_US;"Currently one of the main feature of events such as birthday party, wedding, conferences, and trips is the amount of photos taken from different digital cameras. The plethora of photo device such as smartphone and tablets have contributed for this avalanche of photos. Social network such as Facebook, Orkut, Flickr, and Picasa store a large volume of photos. As a consequence, the retrieval of such photos demands new system. The automatic annotation of photo context metadata such as timestamp, and geographic coordinates, represents a challenge. In this paper, we propose a method for automatic event detection based on photos taken from different cameras in a same event. The proposed method aims to improve the retrieval of photos in a same event, to make cross tagging and to detect errors in the annotations."
5525;en_US;"Extract knowledge from a dataset is not trivial. Information visualization shows up to help on this task by trying to optimize the user information gathering by using suitable graphical representations. There are some tool for this, but they are often focused on desktop, require advanced knowledge or use proprietary technologies. The proposal of this work is to present OPENEDEYES, a JavaScript framework that uses web standards to implement interactive information visualization modules to be run in a web browser. From the framework core, a case study was built based on a real dataset for an empiric framework evaluation. Traditional and new technique were implemented confirming the flexibility and extensibility of the framework."
5526;en_US;"This paper applies Information Visualization and Adaptive Hypermedia technique to the development of a computational tool to adjust elements of hypermedia, based on the user profile."
5527;en_US;"Objective video quality assessment is important to validate the performance of application in video communications system. The research on visual attention and gradient-inspired metrics improves the performance of the video quality evaluation. This paper investigates the use of first and second order differential operators as visual attention estimators. The edge information, computed by differential operators, is an important factor of visual attention. The performance of the proposed model are compared with the objective metrics, PSNR, SSIM and GSSIM, by means of the Pearson correlation coefficient, considering the blurring, blocking, salt and pepper and Gaussian noise distortions. The result suggest that for blurring, blocking and salt and pepper, the combination of objective metrics with first order operators provides a significant improvement, especially for the Sobel operator."
5528;en_US;"The objective assessment of video quality is an important area of research for the validation of video system, and new algorithm are always in demand. experiment indicate that the inclusion of characteristics of the human visual system into the objective metric, such as visual attention, improves the evaluation. This paper presents a new approach to evaluate the video quality based on an estimate of the local visual attention, using the structural similarity index. This approach is compared with three classical objective metrics: PSNR, SSIM and MS-SSIM, by means of the Pearson linear and Spearman rank-order correlation coefficients. The video are submitted to several types of distortions, such as blocking, blurring and salt & pepper noise. The result indicate that the proposed approach presents good correlation with the subjective scores, for video that contain blurring and blocking degradations."
5529;en_US;"Understanding user behavior in user generated-contend system (UGCs) is a fundamental building block for maximizing usefulness of these system. For example, the importance of user connections and the degree of iteration is needed in order to build meaningful recommendation system. In this paper, we evaluate the impact of user network on marking photos as favorites in Flickr considering various levels of distance between user in the network topology. We have observed that user first-degree contacts are clearly the biggest contributors to the evaluation of hers/his photos (i.e., marking them as favorites). This result indicates that, in contrast to other UGCs such as Twitter and Digg, contact relations are a good indication of content interests in Flickr."
5530;en_US;"Designing Interactive Digital TV (iDTV) application is a challenging activity, due to the restrictions of having the remote control as the main and in most cases the only input device for those application. user of iDTV application are used to an environment where constant concentration and intervention is not needed, so application requiring much interaction are unfamiliar to them. Personalized application, which behave accordingly to the context of their execution, including user habits and preferences, tends to require less interaction. Developing such application is however burdensome, due to the lack of tool for designing and developing the personalized behavior using contextual information. ConnecTV fills this void by combining a component-based approach to develop such application and a runtime environment to run and give additional support to their execution."
5531;en_US;"This paper presents an approach for development Interactive Digital TV application. Methodology seeks to explore concepts and technique already established in the area of generative software development for rapid prototyping application source code from model. The main goal is to define a systematic method using notations of high level and platform-independent to allow integration of media objects and complex application logic in application, for example the use of Web service. In addition, the proposed solution takes care of generating a source compatible with existing authoring tool to allow a subsequent spatial and temporal design of application. The work also describes a case study for iTV domain for illustration purpose and an experimental pilot study to evaluate the impact of the approach usage."
5532;en_US;"This paper presents an approach to develop new instances of interactive digital TV -- DTV middleware based on reuse and port of existing implementations of these middlewares for other hardware platforms. Design characteristics of DTV middleware and software portability concepts are used to propose a reuse model. A proof of concept using an implementation of the Brazilian DTV middleware (Ginga) showed that the approach can be useful within specific portability context."
5533;en_US;"For developing application and service in the Knowledge TV platform there is a need in structuring, organising and standardising data according to consolidating academic and industry model, however inserted in the context of interactive Digital TV (iDTV). This work presents research carried on the implementation of the Conceptual Framework MDM-KTV, which means Multi Data model KTV, considering operational, analytical, semantic and Linked Data based data, in the context of the Knowledge TV project."
5534;en_US;"The Interactive TV (ITV) advances are enabling the development of modern application in this platform. However, several of such application could take advantages from a convergence environment, where they could access information and service from other platforms. The Web servers, in particular the knowledge servers, present interesting properties to the configuration of a convergence environment. This work explores such properties as a way to support convergence between the Web and ITV platforms."
5537;en_US;"Currently, even considering the recent advances in the microprocessor power computing, high definition multimedia application still require very complex demands to allow real-time video encoding. Particularly, modern video encoders (MPEG/ITU H.26x serie) depend of complex and computationally exhaustive motion estimation algorithm to identify and remove temporal redundancy among consecutive (or not) frames inside a video sequence, as strategy to reduce the final compressed bit rate. In fact, the mechanism of block matching can be considered the most critical encoder algorithm, in terms of computational demands, like it is responsible for searching, in distinct reference frames, for similar pixel blocks related with each one of the input image blocks. The number of required block comparisons for high definition video represents a clear and important restriction for real-time implementations. This paper introduces an improved strategy of block matching method, which was optimized for multiprocessing execution, mainly focusing in implementation over general purpose graphical processing unit technologies, as the NVidia CUDA® GPUs. The improved motion estimation solution was implemented in the JSVM reference code (scalable version of H.264 video encoder), when it was registered a speed up gain of more than 350% in average for 4CIF video."
5538;en_US;"Holoscopic imaging, also known as integral imaging, is a promising solution for glasses-free 3D technology since it allows a more natural and immersive 3D sensation with continuous full motion parallax. However, in order to provide 3D holoscopic content with convenient visual quality in terms of resolution and 3D perception, ultra-high resolution acquisition and display device are required. Consequently, efficient video coding tool become essential to deal with this large amount of data. However, current and emerging state-of-the-art video coding technologies do not yet address the specific characteristics of 3D holoscopic content. In this context, this paper presents and studies a coding scheme based on the concept of self-similarity compensated prediction, which is used to explore the particular arrangement of 3D holoscopic content through the introduction of new prediction modes. In order to profoundly analyze these new prediction modes, two different generations of video codecs, modified to handle 3D holoscopic content, are examined and compared: the first one is derived from the H.264/AVC video coding standard while the second one is based on the recent standardization project called High Efficient Video Coding (HEVC). Experimental result clearly show the advantages of using this coding scheme in both codecs, as well as the connection between the performance of the self-similarity compensation process and the characteristics of the 3D holoscopic content."
5539;en_US;"The increasing demand for application of videoconference over IP requires not only low bandwidth but also adequate performance on network. This paper presents the evaluation of a local network videoconferencing system based on open source codec for video and for voice signals. Specifically, these are the Theora codec and the Speex codec, which are developed under the Xiph Foundation. The satisfactory performance result we achieved indicate that both coders are potential candidates for future implementation of immersive system."
5540;en_US;"The Bag-of-feature is a popular approach to describe multimedia information by using visual word. The SIFT (Scale Invariant Feature Transform) is one of the most utilized descriptor to model multimedia information in Bag of-feature. The data is described as a set of keypoints and a feature vector is assigned for each of the keypoints. This feature vector is composed of 128 values, which represent the region around each keypoint. In general, some of the detected keypoints are not relevant and can be discarded without losing the local discriminative power. In this paper, we propose a technique to reduce the detected keypoints by SIFT, as well as a technique to reduce the feature vector dimensionality. experiment were made in order to analyze the performance of the proposed reduction technique using two different image databases. The result demonstrated that the proposed technique improve the performance of the image retrieval by reducing up to 50% the feature vector dimensionality of SIFT and at the same time providing a gain of computational time of modeling an image employing Bag-of-feature."
5541;en_US;"In mobile computing environments, the tracking of user allows application to adapt to the user’ context (Context Awareness). Context, in this sense, is any information that can be used to characterize the user’ situations and that is relevant to the interaction between the user and an application. In recent years, the use of context information and user’ profiles have been considered an opportunity for ubiquitous commerce. Furthermore, the improvement and the wide adoption of location system are stimulating the tracking of user, allowing the use of trails. A trail is the history of the context visited by a user during a certain period. In this article, we propose a model for trails management and its application in ubiquitous commerce. In this text, we consider that Trail Awareness is an advance of the simple use of context and profiles. We present a prototype and its application in a simulated commercial environment for discovery of deal opportunities using trail awareness."
5542;en_US;"The development of complex application is one of the major current challenges of Ubiquitous Computing. Such application are difficult to develop because they use service provided by different context-provision middleware, thus being necessary to know the model used for communication and representation of context information for each one. This paper presents the semantic composition and Web service selection mechanism provided by OpenCOPI, a platform designed to integrate context-provision middleware. In OpenCOPI: (i) the application are described in a high-level of abstraction by using semantic workflows; (ii) the semantic composition is responsible for composing concrete service from abstract descriptions of the application, and; (iii) the selection is based on service quality metadata and user preferences. This paper also presents an evaluation of the semantic composition and the Web service selection mechanism considering a ubiquitous application."
5543;en_US;"In this paper we present a view of EXEHDA middleware and a novel service created for dynamic adaptation. EXEHDA is service-oriented, adaptive and was conceived to support the execution of ubiquitous application. The main concept in the proposed design for the middleware and for the application is context awareness expressed in an adaptive behavior. The middleware manages and implements the follow-me semantics for ubiquitous application. This is also a key to provide functionality adapted to the constraints and unpredictability of the large-scale environment. EXEHDA provides service for distributed adaptive execution, context recognition, ubiquitous storage and access, and anonymous and asynchronous communications. To evaluate the proposed service we developed a case study, implementing an application in medical area. Analyzing the result we can see that the user found the application easy to use and usefulness for health workers at a hospital."
5544;en_US;"Ubiquitous computing (Ubicomp) environments are characterized by high distribution, heterogeneity and dynamism. In these environments, application must be aware of their context and adapt to changes in them. A major research challenge in the area of Ubicomp is related to context awareness. Considering the characteristics of ubiquitous environments, this paper presents a framework for context awareness, called DynamiCC (Dynamic Context Composition), which includes elements to support context modeling, contextual data collection, environment actuation, composition and interpretation of contextual information. We consider that the main contributions of this work are the use of a hybrid approach for context modeling, and the proposal of an architecture that supports interpretation and composition of dynamic context. DynamiCC enables the construction of complex context at runtime. To assess the functionality of the proposed model, we developed usage scenarios."
5545;en_US;"Given the importance of new media on traditional forms of civic mobilization, it is opportune to investigate how online civic mobilization can be described in terms of the actions performed by user. In earlier work we proposed the application of established data mining procedures to evaluate rule associated with social interaction, and developed a technique for codifying, mining and evaluating social interaction. In this paper we present a method which guides the iterative application of the technique. We used the method to analyze social interaction in two online civic mobilizations against corruption occurred in Brazil. After two iterations, the result include: in terms of generic social interaction, Facebook user are more likely to perform Likes and comment on Posts; in terms of media-based social interaction, user are more likely to choose the media text."
5546;en_US;"The emergence of online social network in the past few years has generated an enormous amount of valuable data containing user opinions and experiences about the most varied subjects. Aiming to identify the orientation of user postings, several sentiment analysis technique have been proposed - mainly based on text analysis. We propose here a different perspective to treat this problem, based on a user centric approach. We adopt a graph representation in which node represent user and connections represent their relationships in social network. When available, the user opinion orientation is used to tag the user node. Then, we apply link mining technique to infer opinions of user who have not posted their opinion about the subject under analysis. Preliminary experiment on a Twitter corpus of political preferences have shown promising result."
5547;en_US;"With more than 800 million monthly active user, Facebook bears significant potential for science project. Climate Quiz is an interactive Web application in the tradition of game with a purpose that leverages this potential to create metadata through a crowdsourcing-based approach. It presents participant with two types of challenges: (1) selecting the correct relation to connect two environmental concepts, and (2) answering climate-related multiple choice questions. Climate Quiz aims to create shared meaning through collaborative ontology building, a process that captures emergent semantics and elicits formal knowledge in the form of a domain model. As an innovative survey instrument, the application leverages social networking platforms to capture indicators of environmental attitudes, lifestyles and behaviors."
5548;en_US;"This paper presents a new methodology to classify Twitter user based on Artificial Neural network and Fuzzy Logic. simulation are carried out using a SOM (Self Organized Maps) neural network for classifying user into four distinct groups: (0)Unimpressive User; (1)Desired User: Follower; (2)Desired User: Follower and Publisher; (3)Desired User: Publisher. The proposed methodology was validated through an autonomous agent, whose interaction with others were modeled by means of Fuzzy Inference System. The result obtained show that neural network can be used for user classification in social network, and we observed that the interaction of the agent with other user occurred in a transparent way, i.e., showing typical behaviors of real user.This paper presents a new methodology to classify Twitter user based on Artificial Neural network and Fuzzy Logic. simulation are carried out using a SOM (Self Organized Maps) neural network for classifying user into four distinct groups: (0)Unimpressive User; (1)Desired User: Follower; (2)Desired User: Follower and Publisher; (3)Desired User: Publisher. The proposed methodology was validated through an autonomous agent, whose interaction with others were modeled by means of Fuzzy Inference System. The result obtained show that neural network can be used for user classification in social network, and we observed that the interaction of the agent with other user occurred in a transparent way, i.e., showing typical behaviors of real user."
5549;en_US;"service are being widely published over the Web and many service may be composed to attend a user need. A composition of service can demand complex requirement to get an executable composition. Temporal restrictions are one of these requirement. As compositions are dynamically composed, model checking can be applied to verify if compositions are correct in relation to the temporal restrictions required. In this work we propose an algorithm that creates semantic web service compositions and verifies the correctness of a composition checking the temporal restrictions of each iteration. experiment were carried out and the precision of retrieved service and their execution time were analyzed."
5550;en_US;"In last years have seen an increase in SaaS (Software as a Service) use. The development of multi-tenancy web application (one of the main ways to provide SaaS) increased considerably after the start of call “Web 2.0 Age”. This work presents an approach for implementation of a multitenancy SaaS application, and an architecture based on plugins and metaprogramming to achieve a high level software reuse. This approach is presented through an experience report described throughout the paper."
5551;en_US;"Semantic association requires an analysis on similarity in order to provide better combinations. Several semantic similarity measures have been proposed for the Word Sense Disambiguation (WSD) problem. Therefore, this work aims to evaluate the performance of five semantic similarity measures into a thesaurus by WSD approach so as to incorporate semantic similarities into association problem. experiment were conducted using two main algorithm of WSD domain. The result showed that the application of semantic similarity improves precision and recall on disambiguation domain. In order to complement the evaluation, we proposed a hybrid approach and we evaluated it over other measures presented. According to our result, it was possible to adapt a similarity measure for the problem of finding semantic associations in text."
5552;en_US;"This paper presents the concept of eventline as a visual representation proposal for the temporal behavior of multimedia application. The main difference of this proposal when compared to the timeline paradigm is the replacement of the temporal continuous axis to a temporal discrete axis based on the occurrence of events. Media synchronization in each eventline is based on the relative time of a main media. User interaction is expressed as the navigation between multiple eventlines. The objective of this work is to provide a simplified alternative for authoring of interactive multimedia application."
5553;en_US;"This paper describes a NCL 3.0 hypermedia application development toolchain which supports the verification of temporal and spatial consistency of NCL application. In this toolchain, the application is translated into a TSS code and temporal logic formulas are used for checking the desired properties. It is proposed an approach for incremental verification of live NCL application. The paper illustrates the proposed approach with a case study of a NCL-based interactive TV application."
5554;en_US;"Since the standard interactive Digital Television (DTV) has been defined, there is the expectation of creation of universal network of Distance Education. But there are limitations concerning the technique and profile of the Brazilian, however, one sees an improvement of the technology for use in educational settings and across many sectors. So this paper proposes recommendation for the production of such content, grouped into the categories of usability, communication and technology that were enriched from experiences with student of the public school system. The contribution of this research is a checklist to support in verification of production of content."
5555;en_US;"User tags are an important source of information that can be used to gather semantic data about the content, reducing the semantic gap and the restrictive domain of automatic indexing approaches. In this paper, we propose an automatic technique for semantic annotation of multimedia content based on collaborative user tags. Our technique faces some of the challenges of using user-generated terms, such as noise and incompleteness. Based on the actual context of a multimedia item and the co-occurrence of concepts and tags from the training set, we are able to predict semantic concepts for new item without the need of complex multimedia indexing technique. We describe the result of our approach with an evaluation of our algorithm using a large scale dataset composed of image and user tags."
5556;en_US;"The recording of multimedia sessions of small group activity, such as meetings, lectures and webconferences, is becoming increasingly popular following the improvements in recording technologies, the popularity of web-based media repositories, and the opportunity of reviewing or sharing the activity in a later moment. When reviewing a (potentially long) multimedia session, a user may not be interested in watching it linearly as a whole, but only on browsing or skimming specific fragments of interest. For tackling this requirement, the literature reports the opportunity of indexing interaction events that typically occur in these activity, such as slide transitions, speech turns and gestures. In this paper we investigate the issue of combining different types of interaction events as an aid to navigate in multimedia sessions. First, we define temporal interval-based composition operators so that the semantics of groups of annotations can be orchestrated in query. Second, we demonstrate the operators in a web-based multimedia player that enable user to browse a multimedia session with the aid of visualizations and filters over interaction-focused annotations. In order to experiment with the model, we report a case study with multimedia information recorded by a capture environment in use."
5557;en_US;"Long before the first transmission in color of a World Cup in 1970, people used to gather around the few existing radio and TV sets to watch together and talk about their favorite programs. Decades later, not only the technology has significantly changed but also peoples consumption and commenting habits. Nowadays, one can easily watch an online video on demand and share comment with others asynchronously. However, current video commenting facilities do not take into account the temporal nature of video. viewer can only add comment that will then appear statically underneath the video. Motivated by a survey research on current media watching and commenting practices, we report on our findings from the evaluation of an online video commenting system that allows user to add synchronized comment to third-party video. Our result indicate that user appreciate the functionalities of our system and find it better to comment when compared to existing tool. Ultimately, we hope that our work can bring insights to be considered in the design of next generation online video commenting tool."
5558;en_US;"The growing ease of capturing and playing back video using mobile device demands the investigation of alternatives for improving the user experience, for instance by taking advantage of the expanding culture of end-user content generation. Advances in terms of end-user media capture and media combination aim at enriching and facilitating the authoring experience. This work explores the generation of textual annotations on video played on mobile device: the approach is to offer an application that allows associating annotations to a navigation line decorated with frames that are representative of the points of interest. The aims is to improve the user experience of video annotation by allowing user to to find interesting points intuitively. experiment with user identified of new issues, even though the application was considered easy to use."
5559;en_US;"As a result of many real world demands, the literature abounds with result in the form of annotation-based system, as it is the case of system which allow the annotation of audio or video objects as well as digital ink, paper and web pages, to name a few. Among the many types of annotations which may be of interest, annotations in the form of additional content associated with audio or video objects are likely to result in enriched media useful for several application, including the promotion of accessibility. However, besides the highly demanding intellectual work of defining what additional content should be created for a particular segment of media, the author of that content faces the task of identifying the exact media interval in which the additional content should be inserted. That task is particularly arduous when the media has a long duration. In this paper we propose FIND, a reference model guiding the construction of system which aggregate software components for: 1) the specification and the recognition of pattern in audio or video; 2) the synchronized composition of the annotated media; 3) and the formatting of the annotated media into multimedia document for presentation. We also illustrate how the model was instantiated in a configuration which allows the association of additional content to movies resulting in a multimedia document with better accessibility."
5560;en_US;"There are several subjective test methodologies for assessing video quality, being that each of these method was developed by considering specific degradation factors in video quality. Therefore, for video streaming service that use TCP as transport protocol different evaluation criteria should be considered as compared to current method, because the impairment are only pauses. In this paper, the concepts of the mechanism that integrate perceptual and cognitive process are studied, relating them to a test environment for subjective evaluation of video, which is limited to streaming video service transmitted via HTTP / TCP. For this reason, some recommendation to perform subjective assessment of streaming video service are proposed, taking into account perceptual and cognitive criteria. In this work, subjective tests are conducted, evaluators with different content preferences assess 3 different video content. result show that the assessors QoE depends strongly on video content preferences. Thus, assessors who are interested in the video content are more drastic in the ratings. In the case of sport video, the Mean Opinion Score (MOS) value of assesors with explicit preference in sports reachs only 54% of the MOS obtained by assessors without interest in sports. Furthermore, the roll of the instructor during the test is also evaluated."
5561;en_US;"The volume of electronic transactions has raised a lot in last years, mainly due to the popularization of e-commerce. We also observe a significant increase in the number of fraud cases, resulting in billions of dollars losses each year worldwide. Therefore it is important and necessary to develop and apply technique that can assist in fraud detection, which motivates our research. This work aims to apply and evaluate computational intelligence technique to identify fraud in electronic transactions, more specifically in credit card operations, using Bayesian network and Logistic Regression. In order to evaluate the technique, we define a concept of economic efficiency and apply them in an actual dataset of the most popular Brazilian electronic payment service. Our result show good performance in fraud detection, presenting gains up to 35.61% compared to the actual scenario of the company."
5562;en_US;"Knowledge discovery in large online photographic repositories has been an active area of research in recent years. This is due to the great popularization of device equipped with image capture, such as digital cameras, smartphone and tablets. Moreover, the image files generated by those device are easily spread out on the Web through social networking sites. Typically, the photos stored in these repositories bear valuable metadata, such as, geographic coordinates, timestamp, and camera orientation. This information can be used for many interesting data mining tasks, such as detection of points-of-interest (POIs) and trip planning. This paper introduces Compass Clustering, a new clustering algorithm for detecting POIs in georeferenced and oriented photo repositories. Most of the state-of-the-art approaches for POI detection cluster photos based solely on their geographic proximity. However, in many cases, the POIs are within a certain distance from the point where the photo was taken, that is, not in the exact camera location but in the direction it is pointing to, and thus many photos would be erroneously classified by existing method. Therefore, we propose to exploit the camera orientation in order to identify more reliable POIs that reflect the real intention of people when taking photos. We evaluated our approach on a collection of more than 8,000 georeferenced and oriented photos collected from Flickr."
5563;en_US;"Due to the growing popularity of the Web, there is an increasing number of people who performs e-business transactions. On the other hand, this popularity has also attracted the attention of criminals, raising the number of fraud cases in Web and financial losses that reach billions of dollars per year. This paper proposes a methodology, based on the knowledge discovery process, to detect fraud in online payment system. In order to evaluate this methodology we define the concept of economical efficiency and applied it to an actual dataset of one of the largest Latin American electronic payment system. The result show a very good performance for our proposal, providing gains of up to 46.5% in comparison with the strategy currently employed."
5564;en_US;"A key challenge in mobile social media application is how to present personalized content that is both geographically and temporally relevant. In this paper, we propose a new and generic temporal weighting function for improving location recommendation. First, we identify area of interest to recommend by clustering geographic activity based on a trace of geotagged photos. Next, the cluster are temporally weighted using TF-IDF, in order to capture seasonality, and a decay scoring function to capture preference drift. Finally, these weights are combined with the cluster scores based on geographic relevance. We evaluate our recommender on a large dataset collected from Panoramio consisting of the top-100 most populated city in the world and show that incorporating the proposed temporal weighting function improves recommendation quality."
5565;en_US;"Tag recommendation method have mostly focused on maximizing relevance, but other aspects may be as important for recommendation usefulness. We here define novelty and diversity for tag recommendation, and propose two new recommendation strategies that consider these aspects jointly with relevance. We evaluate the proposed strategies using real dataset from 3 popular Web 2.0 application, achieving gains over the state-of-the-art of up to 21% in relevance, 45% in novelty and 2.5\% in diversity."
5566;en_US;"This paper presents the conception, design and implementation of an object-oriented framework for the development of recommendation user agent for Web-based application. The framework agent can be plugged or unplugged in a non-invasive way from existing Web application using aspect-oriented programming technique. The framework was assessed through its instantiation to three different Web-based system."
5567;en_US;"Research in Natural interface, sub-area of Ubiquitous Computing, investigates the use of non-traditional device to support user interaction with application in less intrusive ways (gestures, voice and writing based on electronic ink, for instance). With the increasing popularity of accelerometers, developers now have another tool that can be used to provide interaction between user and different application, such as interactive TV environments. However, application that make use of accelerometers are currently being developed for specific situations, and their implementations and handled document are also dependent on the domain for which they were designed. This paper aims to propose a model to formalize how the accelerometer data may be handled in a generic way. In addition, the model enables the description of rule to aggregate value to these data through the addition of meanings. This is done by proposing a layered architecture to structure and share data in a flexible way. An example of use and the description of a simple application that makes use of the proposed model are also presented."
5568;en_US;"The increasing use of social network via touch screen interface on smartphone and tablets has brought enormous benefits to the mobile application usability. However, access to information via these device represents a new challenge of interaction for user with visual impairments. In this context, this paper describes a study on the issue of visual accessibility in virtual social network, specifically on Twitter. Moreover, we have developed a mobile application to access Twitter via touch screen smartphone using the Android platform. This application provides access to blind people with audio feedback and a writing tool based on Braille. The mobile application presents itself as a solution to facilitate the interaction of the visually impaired user in this social network. In this paper, we also describe a study of use of the application with a group of blind people."
5569;en_US;"One of the most important challenges in Information system is information overload. Recommender system try to cope with this problem by helping people in retrieving information (ex: video, service, products, image, etc.) that may match their preferences and intentions. An issue of Recommender system is related to user context. The use of the system in a different context than usual may cause an unsatisfactory result for the recommendation, since preferences and intentions can be influenced by user context (location, trajectory, time of day, activity, etc.). This paper presents the MMedia2U, a mobile photo recommender system that exploits the user context and the context when photo was created as a means to improve the recommendation. Three context dimensions area exploited: spatial, social and temporal. We describe the similarity measures used for each dimension and the result of the system evaluation with 13 user following a Gold Standard approach."
5570;en_US;"The way people relate with technology nowadays requires more from human-computer interaction method: good usability is an essential condition, but user expect also a pleasant and funny experience, especially when entertainment is the purpose. This paper reports the usability evaluation of game and of an e-commerce application for interactive TV, which considered user affective state, and highlights this approach benefits to analyze the interaction design."
5571;en_US;"Facebook, the largest social network nowadays currently has 901 million active user, with 526 million of them accessing the system daily. With a very rapid growth, Facebook has become a potential site for the collection of personal information by unauthorized individuals, leaving its user vulnerable to actions of violation of privacy, spamming and phishing. This article discusses the vulnerability of Facebook user based on their exposure in the network. To this end, we propose a numerical indicator capable of estimating the degree of vulnerability of each user. This indicator is a function of both the amount of personal content published by the user and the size of her network. We demonstrate the use of the proposed indicator in real data collected from 75,000 Facebook user."
5572;en_US;"researcher and developers still replicate ideas with low reuse when developing Web 2.0 application. A domain engineering identify and document commonalities and variabilities of an application family fostering reuse. In this work, we used a domain engineering approach for content sharing feature of social network. We used as a method the FODA (Feature Oriented Domain Analysis) with pattern for computer-mediated interaction to describe the collaborative feature and the 3C collaboration model to classify them. To implement the commonalities, a component kit was defined and developed, based on an infrastructure named Groupware Workbench. We conducted an experiment to evaluate the artifacts generated by the domain engineering."
5573;en_US;"Based on the context in which social network and collaborative system are involved, this paper presents the process of conception, projection and implementation of a collaborative social network with the goal to promote actions related to social inclusion of people with genetic disorders with physical disabilities. Using an experimental and descriptive approach the creation and development of GenNet is described and reflections are made over the particularities of this process in the healthcare environment."
5574;en_US;"Driven by public policies, distance education course or EAD are now a reality in the Brazilian educational system. However, a major difficulty faced by professionals and institutions involved in this type of education refers to the effective monitoring of student. One alternative used by the scientific community to deal with this problem have been investigating technique for exploring the data stored by the technological system used, trying to turn them into useful information. This work demonstrated some possibilities of using social network analysis technique in order to obtain information from the interaction in discussion forums. In the experiment some potentially useful information was obtained, indicating the feasibility of this proposal."
5575;en_US;"This paper proposes and compares two approaches for data capture to support the analysis of user interaction and audience measurement in Interactive digital TV (IDTV) system. The first approach relies on the development of extensions to existent standards and the second one depends only on resource commonly available in IDTV system. tool for audience and interaction analysis are also presented, which, independently from the approach chosen, allow for the handling of data originated from the interaction between user and their digital receivers."
5576;en_US;"The significant increase of the audience of video-sharing websites has attracted large investments on contextual advertising. In this paper we investigate alternative technique for selecting ads to be placed in video during their exhibitions. In order to improve the effectiveness of these ads avoiding the high cost of image processing, we explore textual metadata created by the user and stored in the page that hosts the video. Our proposal consists in assigning weights to the metadata attributes, according to their relative importance. To estimate such an importance, we apply a block importance model. Our experimental result show that the metadata attributes which perform better in the task of selecting ads are the ones that provide the best descriptions of the video content. We also observed that the application of weights according to the studied block importance model obtained gains of about 7\% over the selection method without weights. Such a gain is relevant due to the possibility of increasing the profitability of ad selection system and avoiding the negative impact on advertiser brand and credibility of placing non-relevant ads."
5577;en_US;"In this paper we present three new method to extract keyword from web pages using Wikipedia as an external source of information. The information used from Wikipedia includes the titles of articles, co-occurrence of keyword and categories associated with each Wikipedia definition. We compare our method with three keyword extraction method used as baselines: (i) all the terms of a web page, (ii) a TF-IDF implementation that extracts single weighted word of a web page and (iii) a previously proposed Wikipediabased keyword extraction method presented in the literature. We compare our three keyword extraction method with the baseline method in three distinct scenarios, all related to our target application, which is the selection of ads in a context-based advertising system. In the first scenario, the target pages to place ads were extracted from Wikipedia articles, whereas the target pages in the other two scenarios were extracted from a news web site. Experimental result show that our method are quite competitive solutions for the task of selecting good keyword to represent target web pages, albeit being simple, effective and time efficient. For instance, in the first scenario our best method used to extract keyword from Wikipedia articles achieved an improvement of 33% when compared to the second best baseline, and a gain of 26% when considering all the terms."
5578;en_US;"The World Wide Web is the most popular application throughout the Internet and, since its creation, it has changed peoples lives in lots of ways, hence, it has become subject to several social, technological, economical and political researches. This paper presents both a project called ICT Web (Measuring Information and Communication Technologies for Development – Web) and the result it has obtained by studying the Brazilian Governmental Web. Some of the discussed topic are as follows: the importance of Open Standards, and how their conformity evaluation can be used to measure and classify the quality of Web sites. Also, more technical issues related to web crawler and web analysis tool are shown in order to reveal how all data were retrieved. Not only does this work point out some characteristics of the Brazilian governmental Web sites, which helps the creation of policies that improve this Web sites quality, but also it establishes a serie of feature to compare the perceived quality between Web domains."
5579;en_US;"Interactive multimedia application development can be facilitated and more attractive to non-expert authors through the use of graphical editors. In a graphical environment that permits creation and edition of multimedia document and offers different views of the document as a whole, it is possible to develop application with less difficulty. In addition, if the editor provides template, the development can be easier as, in that case, the author can use a pre-configured document and fulfill it with its own media content. This paper presents NEXT - NCL Editor supporting XTemplate, a graphical editor that allows development of NCL document using hypermedia composite template, which represent generic structures of NCL context node. Composite template can be created with the XTemplate 3.0 language. Besides supporting template, NEXT is based on a kernel and a set of plugins, which allow its extensibility and adaptability to different author skills."
5580;en_US;"In the application development described in NCL language, we have observed the reuse of some model and document structures, which is possible by repetition of common codes on application. Thus, we do visualize the need to generalize this kind of development described in NCL. This need has been observed by other developers who are aiming at the possibility of the reuse of structure from some document. This paper introduces Luar, an authoring language for NCL template. The Luar language has been conceived through analysis of the application behavior for iDTV. Luar has a template processor developed with the Lua language and library to maintain and to aggregating template collections, sharing them among developers. The entire template system aims to facilitate the design and development of interactive application described in NCL using the technique of reuse."
5581;en_US;"Presentation machine for multimedia declarative language especially the ones related with Interactive Digital TV (iDTV) and Internet Protocol TV (IPTV) are usually embedded in device and strongly coupled with the platforms when native code and API for the device platform are used. Since much of the complexity to implement presentation machine lies on presenting and controlling different types of media (video, audio, image, text), and given that most of the modern browsers natively support those requirement, it becomes interesting to implement presentation machine using Web technologies to reduce their coupling with platforms. In this paper we discuss the advantages of a presentation machine for declarative multimedia language implemented on top of Web technologies. As a proof of concept we implemented the WebNCL, a lightweight NCL presentation machine based on the web technologies stack (HTML 5/ JavaScript/ CSS). By using WebNCL, NCL document can be presented in any device that has a HTML5 compatible browser, such as tablets, smartphone, smart TVs and PCs."
5582;en_US;"This paper proposes a structural and contextual validation method for NCL (Nested Context Language) document. As part of the proposed method, we define a declarative metalanguage to ensure low coupling between NCL structure and the code of the validator, which easy the validation of new language profiles. requirement such as incremental processing and multilingual message are also covered by this work. An implementation of this method using component architecture is presented as a concept proof."
5583;en_US;"The GINGA middleware enables creating application that are usually known as interactive GINGA application. The development of these application shares some requirement that can be explored jointly, such as reusability, standardization, maintainability and extensibility. This work proposes a framework that addresses the shared requirement, beyond integrating other specific-purposes framework. The metadata-based framework approach is used to provide the declarative configuration. This framework extends functionality of some pre-existing components of GINGA and allows easier implementation of new components."
5584;en_US;"This paper describes the development of the compliance test suite for the Ginga-NCL, an ISDB-TB standard for digital terrestrial TV and ITU-T H.761 Recommendation for IPTV service. Both the test suite specification, i.e., the set of its test cases, as the several possibilities for its application are discussed. The peculiarities with regards the development of conformance tests for system designed for declarative language are argued, in particular those found in developing tests for middleware system aiming at XML-based declarative environments. In this respect, the paper points out what the proposed suite has brought as contributions to the state of the art. Because it is an extensible suite, the article also brings the rule, adopted by the ITU-T, for its extension."
5585;en_US;"Recently, there has been in Brazil a few number of device capable of receiving the digital television signal. However, a few number of device has the support of the Brazilian Digital Television System’s middleware, named Ginga, and usually there is no benchmark suite for validation tests, which affects the execution of interactive multimedia content. This paper reports a benchmark suite performed on the implementation of Ginga-NCL for Android based device, developed at UFES. The obtained result allow to quantify some aspects of the middleware’s performance, and particularly to sugest best practices for developing NCL application in mobile scenarios."
5586;en_US;"Significant development effort is dedicated to authoring spatiotemporal relationships, including user interactivity, in multimedia application. That effort is even higher when the language requires specification of relationships using links, as it happens with NCL, adopted in the Brazilian digital TV system. In an NCL program, the author must specify each type of relation to be used, as a causal hypermedia connector, and each relationship among media components as a link that uses a connector, which makes the authoring process very tiring. Connector specification requires knowledge about the event-based temporal model used by NCL, which is not trivial for beginners. This paper presents a graphical editor for NCL hypermedia connectors. Besides facilitating connector creation, the proposed editor can help user understanding how spatio-temporal relations are specified in an interactive digital TV program."
5587;en_US;"For many people television is still the main form of entertainment. However, due to the way some television programs are developed, in particular movies, and because of a lack of prior knowledge or cognitive difficulties, some viewer may not fully understand or enjoy the programs. With the advent of a new TV, digital and interactive, and possible to enrich media television with additional multimedia content, increasing the satisfaction of the viewer while watching TV programs. However, considering the collective audience, the additional content on TV can be intrusive. By combining the provision of additional content with the use of multiple device for interaction, is possible promote personalized support and in a non-intrusive way, thus maintaining the individuality of each viewer. This combination is evaluated in this paper, through a case study conducted with a group of viewer who watched a video enriched with additional content and interacted using the remote control and/or cell phone."
5588;en_US;"The Semantic Web renewed the interest in rule based software system. Semantic Web rule Language (SWRL) is a rule languagee that allows rule to be conbined with Web Ontology Language (OWL) knowledge bases to improve its expressivity. However developers face difficulties on managing large rule sets. A large rule set is difficult to understand and error prone, especially when used and maintained collaboratively. To minimize this problem, technique and tool are needed to organize, view and ceate large rule sets in SWRL. This paper discusses and presents two strategies in the diferection: the similarity analysis between rule and the detection of syntatic and lexicon errors. They can help us to understand, view and correct SWRL rule in large knowledge bases."
5589;en_US;"Context-aware and multimedia system emerge as a new application domain for smartphone thanks to the addition of sensor, user data and multimedia functionalities to these device. To illustrate this new application domain, we present CAPTAIN: a Context-Aware and Photo-based Tool for logbook generAtIoN. CAPTAIN merges three main mechanism: i) sensor data acquisition and multimedia creation on the mobile device, ii) a validation tool, iii) and an automatic Web-content generator. The paper also describes a user evaluation of CAPTAIN made by a real crew during the ZeroCO2 project."
5590;en_US;"The Interactive Digital TV enables the creation and dissemination of interesting multimedia application. It is natural to ask whether Interactive Animation and Virtual Reality application are contemplated. Initially one can say no. Due to the high computational power required by these application, it is not plausible run them at a set-top box or embedded processor on a TV set. This same question can be asked when mobile device are taken into account, since they have similar computational constraints to Digital TV. This paper presents a strategy that enables the use of Interactive Digital TV and Mobile device to provide multimodal interaction with some classes of Virtual Reality application."
5591;en_US;"The advent of Web 2.0 has brought the idea of “Web as platform”, i.e., the software would work through the Internet, no longer only when installed on the machine or user’s mobile device. Thus, the objective of this work is to propose a tool capable of running Web 2.0 service with context information retrieved from the user’s mobile device, enabling the expansion and customization of the feature present in this device, to assist the user in their daily tasks, without the need to change the way they carry out their activity."
5592;en_US;"The iDTV technology is new for the user and usability issues must be studied. This article presents the result and lessons learned from migrating an existing web application to iDTV. This research is important because the application must suit a new model of interaction, which goes from mouse and keyboard to a remote control and also must take into account the differences of processing power and screen distance between the device, and the variety of user the television has."
5593;en_US;"This work proposes a model-driven development approach, which integrates interactive multimedia application, and Web service. It is based on existing modeling language extended, which integrates modeling concepts for interactive application and ads support for web service. Three Digital TV application were modeled and developed. As we show, the evaluation of the approach brought benefits not supported by related work, like requirement structuring and reducing amount of work needed to finalize the code generated."
5594;en_US;"There is a gap concerning the production of courseware for deaf student. The objective of this article was through a case study; identify the moments and the approach in translation/interpretation process with the courseware design by the deaf student. The result revealed how complex is the translation/interpretation process, highlighting the necessity to define specific moments to work with the specificity of the program, leading to a deeper observation about accessibility of digital content."
5595;en_US;"This paper introduces a module named UDOnt-Q (Universal Discovery with Ontology and QoS) that uses the Semantic Web and an Ontology based on Service Level Agreements (SLA) and attributes of Quality of Service (QoS). In order to classify and select Web service without drastic changes in the standard Web Service architecture, two semantic algorithm were developed and included in the module. At the end, a performance evaluation was executed to compare their performance in different settings, trying to identify an efficient way to promote the selection of Web service."
5596;en_US;"The goal of this work is to make possible automatically creation of Interactive Digital Television journal application (voting, quiz, chats, etc.). Thus, we present the tool called iTVnews that offers a computer environment that abstracts the complexity of programming these application. The tool focuses on the language of the journalists’ domain."
5597;en_US;"The use of widgets is a very popular manner to make a website customization. From widget’s creation the content creator configures the website with functions that he/she consider adequate to the user. Typically, widgets relies on syndication (RSS) in which a website content is made available to other websites. Even though there is a huge popularity of this kind of widgets, they typically are constrained to what a data provider makes available. Linked Open Data (LOD) is an opportunity to cope with the today’s constraint in the process of widget creation and execution. We propose a platform, called SemWidgets (from Semantic Widgets), for the creation and execution of piece of programs able to access and reason over LOD. With SemWidgets, we provide to the content producer of a website a way to describe the concept(s) that best represent the content to be explored. Widgets created from SemWidgets have the power to perform inferences and access external source that constitute information that may be useful and appropriate to the context of the website."
5598;en_US;"In video encoding H.264/AVC is the state-of-the-art and provides efficient compression for video application. However, by using the rate control scheme of reference H.264/AVC software, high variations in the visual image quality will be experienced. This paper presents a novel rate control scheme for the H.264/AVC standard in order to ensure the output video quality and maintain a stable output bit-stream. First, an overview of the rate control module is presented. Then a neighbor-fast based model to predict the mean of absolute difference of basic unit layer is proposed. Finally, a comparison between compromise and visual quality with related work described in the literature will be performed."
5599;en_US;"This paper presents a system to support semantic annotation and semantic browsing of contents from repositories on the Web, by using domain specific knowledge and visualization technique. Empirical tests of this system, involving the annotation of multimedia learning objects from the health area, showed gains in annotation time, by using the proposed semantic support. These tests also indicated usability and viability of the proposal in the considered domain, and the user’ predilection for an interface based on lexical and semantic auto-complete, instead of navigation in trees, to choose metadata values from a knowledge base for annotation purposes."
5600;en_US;"The recent growth of high definition multimedia application imposes several restrictions to traditional ISO MPEG-x e ITU-T H.26x video encoders. Considering that, the most recent international standard, H.264 codec, includes several new algorithm in order to increase compression efficiency and application flexibility. Unfortunately this improved technology demands very high performance to support real-time video encoding. Considering this scenario, the current paper proposes the adoption of the GPU NVidia CUDA® technology as development platform to increase performance of a H.264 intra video encoder. Practical result comparing the proposed solution with the original H.264/AVC reference code points to significant performance gains for high definition computing."
5602;en_US;"An ever-increasing number of web-based repositories aimed at sharing content, links or metadata rely on tags informed by user to describe, classify and organize their data. The term folksonomy has been used to define this “social taxonomy”, which emerges from tagging carried by user interacting in social environments. It contrasts with the formalism and systematic creation process applied to ontology. In our research we propose that ontology and folksonomies have complementary roles. The knowledge systematically organized and formalized in ontology can be enriched and contextualized by the implicit knowledge which emerges from folksonomies. This paper presents our approach to build a “folksonomized” ontology as a confluence of a formal ontology enriched with social knowledge extracted from folksonomies. The formal embodiment of folksonomies has been explored to empower content search and classification. On the other hand, ontology are supplied with contextual data, which can improve relationship weighting and inference operations. The paper shows a tool we have implemented to produce and use folksonomized ontology. It was used to attest that searching operations can be improved by this combination of ontology with folksonomies."
5603;en_US;"Proposals for standards, technologies and infrastructure for the Semantic Web must take into consideration the current Web infrastructure. In this direction, this paper presents an infrastructure for Semantic Web service deployment that uses the infrastructure of the current Web: iSWS. This infrastructure includes the implementation of tool and modules in order to achieve publication, discovery and composition of Semantic Web service. Some experiment were performed and result are presented."
5605;en_US;"It is increasingly common to use system capable of transmit- ting multimedia content such as audio and video, in real-time infrainstructured network, but it is not the same with Mobile Ad Hoc network (MANET). A MANET is characterized by the free movement of its vehicles making packet routing with time delivery restrictions a complex problem. To solve this problem some work they propose the use of routing protocol with support for multiple paths. In this paper, we describe an extension to the Protocol OLSR, which has the goal to make it possible to support multimedia data transmission by multipath and use the data transmission quality present in RTCP reports to determine how many paths and which of them should be used to perform a real-time transmission in the most appropriate way."
5606;en_US;"This paper proposes an Model-Driven Engineering approach for modeling and verificating of interactive multimedia application. The approach introduces a toolchain based on FIACRE language, that is used both as the target language of model transformation engines from NCL multimedia model, and as the source language of compilers into the targeted verification toolbox Tina. The paper illustrates the proposed approach with a case study of a NCL-based interactive TV application."
5607;en_US;"Although attractive, the large amount of TV programs creates information overload. One of the solutions is the use of recommender system, which aim is to suggest programs according to the viewer’s preferences. Several system have been proposed, but most have an inflexible architecture due to being embedded in receivers and consume their hardware resource. This article proposes a flexible architecture in a cloud to support the execution of programs recommendation algorithm. With the convergence between TV and Internet, Connected TV has emerged as a consume option of new interactive service. Thus, a system built over the proposed architecture is available as a service, where different algorithm can be run, disengaging them from the viewer receiver. In order to validate the flexibility of the architecture, two recommendation algorithm and a Connected TV client application were implemented."
5608;en_US;"Nowadays, the digital television system do not have specific standards for sign language (SL). The solution used in TV is to transmit a window with a SL interpreter into the video program. This solution is ineffective in several aspects: it has hight operational cost, is depedent of a interpreter, and distract nondeaf viewer. In addition, it does not respects the regional differences in SLs. To reduce these problem, the main objetive of this paper is to propose a protocol to encode and transmit Brazilian sign language (LIBRAS) windows into digital television system. In this propose, the frames of LIBRAS windows are not transmitted. Instead, a set of codes is transmitted, where each code is related to a visual representation of a sign in LIBRAS sotred in the TV receiver. Thus it is possible to respect the regional differences of SL and to reduce the used bandwith. Additionally, some strategies to represent sounds effects, voice intonation and emotion nuances are also being investigated."
5609;en_US;"Converging device, such as cell phones and Interactive Digital TV, are on the list of the most sold equipment nowadays. Besides the great search for those equipment, the diversity of user, differences on the form of interaction, dimension of equipment, aspects of mobility and diversified use scenarios, demand usability assessments for the investigation of possible improvement of the interaction involving user and the interface of the available application. In this paper we present a model to evaluate the usability of application for this kind of device. The proposed model is divided in three modules: (i) mapping of the intensions of the application’s designer, (ii) capture of the user’s interaction with the application’s interface, (iii) module of comparison between the intentions of the designer and the usability of the final user."
5610;en_US;"Social network are increasingly present on the Web, especially those supported by multimedia platforms, allowing social interaction, communication, sharing and collaboration among user. In social network analysis, some model for the representation of user interaction have been proposed in the literature. However, those model do not explain what actions were taken by user during social interaction. In particular, this also occurs when social interaction involve media. We present a technique for a human-readable representation of social interaction in the form of if-then rule, and for evaluation of the rule using data mining procedures. Our technique allows the representation and the evaluation of media-based social interaction by making explicit both the actions performed by user, and the media used in the interaction. We present the result of applying our technique to describe interaction among a group of Facebook user."
5611;en_US;"Online Social network (OSNs) such as Facebook and Twitter have experienced exponential growth in recent years. user are spending more time on OSNs than on any other sites and service on the Internet. user post and share a lot of personal information on these sites without being aware of privacy implications or simply not caring much about them, what turns to be a treasure for marketing company and cybercriminals. Characterizing the privacy awareness of user is important to design technologies and policy solutions. user expect the OSN to provide good privacy protection or controls so they can make informed decisions about their privacy. This paper investigates the privacy awareness of user on Facebook using real-world data (not self reported). The main findings are: only a low percentage of user change the default privacy settings; a large percentage of user expose their gender publicly; women are more concerned about disclosing personal information online; many user share their photo albums and links (content) to everyone; user exercise more control over content that are more potentially dangerous to their reputation. The present study is one of the first to characterize the privacy awareness on OSN through a real world experiment. Implications of the study are discussed."
5612;en_US;"Understanding social influence and its related phenomena is a major challenge in the study of the human collective behavior. In the recent years, the availability of internet-based communication and interactivity data has enabled studies on social influence at an unprecedented scale and time resolution. In this work, we study how individual behavior data may provide knowledge regarding influence relationships in a social network. We define what we call the influence network discovery problem, which consists of identifying influence relationships based on user behavior across time. Our objective is the design of accurate model that are able to exploit different types of behavior in order to discover how people influence each other. Several strategies for influence network discovery are proposed and discussed. Moreover, we present a case study on the application of such strategies using a follower-followee network and user activity data from Twitter, which is a popular microblogging and social networking service. We consider that a followerfollowee interaction defines a potential influence relationship between user and the act of posting a tweet, a URL or a hashtag represents an individual behavior on Twitter. The result show that, while tweets may be used effectively in the discovery of influence relationships, hashtags and URLs do not lead to good performance in such task. Moreover, strategies that consider the time when an individual behavior is observed outperform those that do not and by combining such information with the popularity of the behaviors, even better result may be achieved."
5613;en_US;"Volume rendering has several application that benefit many domains of knowledge, such as medicine, biology, geology, and virtual reality. One of the most widely used method for real-time visualization of data volumes is the marching cubes, which is part of a class of visualization technique called isosurface extraction. Due to the constant evolution of graphics processing units, it is possible to obtain considerable rendering rates and a high degree of realism. This work describes a methodology for accelerating the marching cubes algorithm on a graphics processing unit and presents some possible ways to improve its performance through auxiliary spatial data structures. experiment using several volumetric dataset show the effectiveness of the proposed method."
5614;en_US;"This paper presents a proposal for unified development of learning objects, for access by digital TV, Web and mobile phones, yonder a metadata extension that allow cataloguing and recovery them by the same platforms. First, the common formats and programming language available are described, such as the main metadata standards for each platform. As result, several recommendation for interoperability are presented. This proposal was validated and is part of OBAA brazilian standard [1], that researches interoperability using multiagent system."
5615;en_US;"The NCL language supports the creation of hypermedia presentations using resource from multiple connected device simultaneously, through a high-level declarative description. This paper proposes protection mechanism to address fundamental characteristics of the distributed presentation environment of the Ginga-NCL subsystem, which is seen as a failure-prone distributed system using asynchronous communication to orchestrate device with heterogeneous hardware and software specifications. As proof of concept the discussed mechanism were incorporated to the reference implementation of Ginga in order to make it capable of recovering from and adjusting to faults or configuration changes during the presentation of distributed hypermedia application."
5616;en_US;"This paper aims to propose an approach for the testing of web software product lines. The approach provides: (i) guidelines for the choice of testing strategies in the domain and application engineering; (ii) guidelines for the design, implementation and reuse of unit, integration and system automated test cases; and (iii) tooling support for management and customization of automated test cases using product line derivation technique. The approach feasibility is evaluated through its application to an ecommerce web-based product line."
5618;en_US;"In this paper we propose an evaluation and comparison of guidelines and technique that allow not only the creation of secure Web service, but also the validation of the service used to determine whether the application has the desired characteristics related to performance and security. In this sense it is crucial evaluating the cryptographic algorithm and key length used. The result obtained allow to determine, based on specified objectives, the impact of security mechanism used in application performance."
5619;en_US;"Inside a video encoder, the technique of motion estimation (or motion prediction) is one of the most relevant algorithm, which is particularly responsible by the consumption of most expensive portion of the global video encoder computational processing costs. The current paper explores the use of a Cell microprocessor as platform to the implementation of a dedicated parallel H.264 motion estimation solution. The proposed algorithm has been designed in order to operate simultaneously over six distinct regions of the same reference video frame. The obtained result points to significant improvements."
5620;en_US;"Around 90% of the total encoding time of raw video into H.264 is spent in block-matching, a stage of Motion Estimation. In this paper we combine two block-matching optimizations that yield significant performance improvements on Motion Estimation: 4:1 subsampling by macroblock and truncation of the two less significant bits per sample. When applied to the JM Reference Encoder, our strategy showed an average speedup of 2.64 times in total encoding time with a small loss of quality (less than 0.5 dB)."
5621;en_US;"There is a diversity of strategies for stereoscopic video coding, commonly known as 3D video. Each strategy focuses on one type of 3D visualization format, which may lead to incompatibility or depth perception problem if one strategy is applied to another format. A generic approach may be based on the proper coding of the stereo pair – every visualization format knows how to deal with stereo pairs – however, to keep the stereo pair, even a coded one, demands a high data volume. This paper proposes a method for reversing an anaglyph video back into a stereo pair. This way, a coder may convert a stereo pair into an anaglyph video, reducing the data volume by half, at least. Moreover, a correspondent decoder may use the proposed reversing method to restore the stereo pair, ensuring the visualization independence of the coding method. Tests showed that both conversion and posterior reversion resulted in video with good quality obtaining an average of 63.09% of compression and 34,52dB of PSNR."
5622;en_US;"The domain of Information and Communication Technology has been going through a notable transformation which is characterized by the global connectivity and the increasing use of multimedia device. These factors have afforded the development of new transmission network to handle large volumes of data and increasing power transmission. As the development of several multimedia technologies gets faster, even more data are generated and transmitted over the network. When applied to military, commercial and medical fields, for example, a major matter to be concerned about is security and privacy. Thus, this paper presents a secure scheme based on authentication and user authenticity verification as well as based on distribution of encrypted streams. This strategy was developed and integrated to Arthron, a tool for high definition multimedia stream transmission."
5623;en_US;"Content pollution is one of the challenges for deploying live streaming with P2P network in the Internet. As the peers themselves are responsible to retransmit data, there is no trivial solution to this problem. This work presents a new strategy to detect content pollution that employs comparison-based diagnosis to identify modifications on the data stream. A peer compares selected chunks with those of its neighbors. Based on the comparison result, peers that transmitted polluted content are identified. The proposed solution was implemented using Fireflies, a scalable and intrusion-tolerant overlay network. Experimental result show that the strategy represents a feasible solution to detect content pollution and adds a low overhead in terms of network bandwidth. Permission"
5624;en_US;"This work aims to develop a method for scene segmentation in digital video which deals with semantically complex segments. As proof of concept, we present a multimodal approach that uses a more general definition for TV news scenes, covering both: scenes where anchors appear on and scenes where no anchor appears. The result of the multimodal technique were significantly better when compared with the result from monomodal technique applied separately. The tests were performed in four groups of Brazilian news programs obtained from two different television stations, containing five editions each, totaling twenty newscasts."
5625;en_US;"Nowadays, the wikis have become popular platforms focused on communication and writing collaboratively and asynchronously. However, many people communicate in a synchronous manner, as the case of Instant Messengers (IM). So when we talk about web communication widely, we must consider both the synchronous and asynchronous collaborations, which so far the wikis are limited to asynchronous collaborative form. Thus, the objective of this paper is to discuss the aspects of the activity of synchronous and asynchronous communication between wikis and Instant Messengers in order to establish a notification process of editing through wikis, IMs. Therefore, the result of this study has helped developing a new alternative for notification of wiki edition, enhancing communication and collaboration on the web through wikis / IMs."
5626;en_US;"Sign language (SL) are natural language composed by their own grammar and vocabulary. Therefore, the different deaf communities need dictionaries to associate the signs to the word of the spoken language of their country. These dictionaries can be used, for instance, to support the teaching and dissemination of these language, to compose automatic translation system, etc. However, these SL have, in general, thousand of signals and new ones may appear constantly to express new concepts. As a result, the construction of these dictionaries is resource intensive and is not a trivial task. In order to minimize these problem, this paper proposes a web system to collaborative construction of a multimedia dictionary for Brazilian Sign Language (LIBRAS). The objective is that user, mainly deaf, automatically generate the signs of this dictionary by setting parameters of an animated 3D virtual agent (3D-avatar). A supervision step is applied after the generation of the signs by the user, preventing incorrect signs to be inserted in the dictionary. To enable the automatic generation of these signs, an additional contribution of this work is the definition of a formal language to represent the signs in LIBRAS."
5627;en_US;"This paper presents a model designed to provide ubiquitous accessibility. The project supports accessibility for People With Disability (PWD) and elderly in various situations of their everyday life. Offering context awareness, user profiles and trails management, the model is a base for applying assistive technologies that fulfills accessibility needs. Moreover, in the proposed model, we devised an ontology. Besides the benefits of intrinsic semantic representation, the use of an ontology fosters future integration with others solutions. We also present a case study based on a prototype, which was developed to evaluate the model. This assessment used a smart wheelchair, operated by a paraplegic person, which is under development at University of the Sinos Valley (Unisinos)."
5628;en_US;"This article proposes an architecture for the next generation network to provide both QoE and seamless handover for video application. The proposal considers framework used for traffic engineering (MPLS/RSVP-TE) and mobility management at the network layer (MIPv6), as well as, it adopts the new standard IEEE 802.21 to assist the integration of heterogeneous network. In addition, it uses a vertical handover decision policy based on fuzzy system and its optimization by a genetic algorithm for scenarios that integrate the WiMAX and Wi-Fi access technologies. The proposal is evaluated via simulation using the ns-2 (Network Simulator) and the performance result are shown through the QoS (throughput) and QoE (PSNR, SSIM and MSU VQM) metrics that demonstrated the effectiveness of the architecture to support seamless handover."
5629;en_US;"This work explores the technologies used to develop multimedia application for smartphone and evaluates, empirically, the multimedia communication capacity of multimedia data in smartphone over IEEE 802.11 wireless network."
5630;en_US;"Video Quality assessment is one of the most challenging problem in real time communications. Most of the quality assessment algorithm is based on pixels, so they are dependant of the original video as reference. This dependancy make complicated to apply these algorithm in a real time scenario. Besides, these algorithm do not consider Human Visual System characteristics. This paper introduces 3 algorithm that use HVS characteristics. The first two algorithm still use the original video as reference and the third uses only the received video as parameter."
5631;en_US;"The press newspaper is suffering a severe crisis that was established with the advent of the Internet, which brought the spread of free high quality news. Even their online versions are facing major problem to gather resource. Experts believe that the future of online newspaper is a greater interaction with the user and the use of personal advertising. This paper presents an architectural model for generating personalized content oriented for news sites. Therefore, this aims at increasing the flexibility of the structure of online newspaper in order to encourage all sides of this issue, increasing convenience to the user while generating a more robust revenue stream to the newspaper."
5632;en_US;"This article discusses ways to manage connections to enable interaction through handheld device such as mobile phones in educational environment, using technology to assist in communication between teachers and student. Communication between the mobile is done through Bluetooth connections and management of these connections is provided to enable a large number of active connections, since the Bluetooth allows only seven active connections."
5633;en_US;"With the widespread adoption of broadband Internet access, home user have started to consume several multimedia service, such as IP Telephony, radio and video on demand. Meanwhile, the main video service are on-demand and need buffering, while TV is live. They also require a server bandwidth that grows linearly with the number of clients. IP Multicast does not have this bandwidth problem, but is unavailable, so overlay network are used. Nonetheless, these network do not specify the packet loss handling: ignore or recover and how. After the analysis on the properties of the H.264 standard for digital video compression, this work presents clear criteria for retransmission based on the several different types of frame coding. It establishes priorities among these types and defines an algorithm for the selection of lost parts for recovery. The algorithm uses a movable target, lowering the target each time the retransmission of a segment is requested. To test it, an overlay network (SeRViSO) is used, comparing the algorithm to another where the target is fixed. The advantages of a clear loss handling are the greater adaptation to the network conditions and less important losses, which do not propagate error for many frames."
5634;en_US;"In most current commercial search engines, image and video are represented essentially based on textual information associated with them. Such an approach can only achieve limited result, which can be enhanced by the addition of content-based information. One of the most promising content-based approaches to classifying visual data in a semantic level are those based on Bags of Visual feature (BoVFs) representations. Nevertheless, extracting BoVFs have a high- computational cost, making those not scalable to large databases. In this work, we perform an experimental investigation in which we compare three strategies for visual vocabulary selection, a key step in the BoVF-building process. Our result indicate that it is possible to substitute the classical approach { based on k-means clustering algorithm { for a simple random selection, without statistically significant loss of information, but with a radical decrease in computational cost."
5635;en_US;"Many system have been developed to allow indexing, extraction of characteristics, processing and recovery of image based on their content. This work presents a content-based image retrieval method, using sketches drawn by the user using digital ink, to recognize geometric shapes in flowcharts."
5636;en_US;"Digital TV application are able to use the resource made available by the device connected to the Digital TV receiver through a Home Area Network (HAN). That brings advanced feature to the Digital TV environment, since such device may offer media display resource, multiple interaction mechanism, amongst other feature. NCL (Nested Context Language), which is the core language of Ginga-NCL Digital TV middleware, is provided with mechanism for the distributed reproduction of its application, so that multiuser application can be developed, redefining the single user/remote control relationship. Using a hierarchical model for the application distribution and an abstraction for grouping device (called device classes), it is possible to orchestrate the usage of the resource provided by the connected device. This work aims to extend the original model proposed for the Ginga-NCL middleware, so that it can be made compatible with the different technologies used for device integration, such as UPnP and OSGi."
5637;en_US;"This work presents an approach for image retrieval system based on its visual feature applied to World Wide Web scenario. The proposed approach presents technique for crawling, indexing and retrieving without visual redundance image copies. In order to achieve its goals, the present work uses a spider to capture web image from Google image and wavelets transform in order to extract the essence of image feature that well represents them. In the present work, it was indexed 310 thousand image, which were reduced to 225 thousand after image copies elimination. It represents a reduction in about 27% of redundancy and 20% faster."
5638;en_US;"WebQuests are used to create learning activity integrating web content to the classroom. This technology adoption requires the use of specific software or editing and publishing HTML pages. The WQE WebQuest Editor purposes the instructional activity creation obeying IMS Learning Design standard. In a realized testing was possible to create practical laboratory activity on Software Engineering, publishing them in a player and accessing them through TIDIA-Ae Learning Management System."
5639;en_US;"This paper aims to present a Ginga-J’s reference implementation. Although based on a particular platform, the implementation not only work as a proof of concept, but also raised several issues and difficulties on the software architecture project that should be taken into account to ease extensibility and porting to other platforms. Ginga is the standard middleware for the Brazilian DTV System and its imperative environment (Ginga-J) is mandatory for fixed terrestrial receptors."
5640;en_US;"This paper presents an image segmentation algorithm based on the ant colony optimization metaheuristic and on a local search. Clustering is used to group image pixels and determines the cluster centers. The local search is applied at the end of each ant solution to improve its quality. Once obtained the best centers the thresholding technique is applied to segment the image. Tests on image corroborate the performance of the metaheuristic with the local search proposed in terms of the segmentation quality."
5642;en_US;"Recently, there has been in Brazil a few number of device capable of receiving the digital television signal. However, these device lack the Brazilian Digital Television System’s middleware, named Ginga, and therefore they do not allow the execution of interactive multimedia content. This paper reports an implementation of Ginga-NCL for Google’s Android platform. In order to validate the implementation, experiment were conducted to analyze the execution of NCL application, as well as the usage of device resource. Moreover, the developed environment allows to evaluate the transmission and reception of NCL application through the standardized DSM-CC over IP protocol."
5643;en_US;"The Web 2.0 increases the possibilities of expression and socialization by means of tool for computer-supported interaction. This work presents a Domain Engineering based on the extension of the FODA method, using the 3C collaboration model to classify, and pattern for computer-mediated interaction to describe collaborative feature. An infrastructure named Groupware Workbench is used to implement components that address the identified feature."
5644;en_US;"In this paper we describe the use of personas in the interface of Web-based service. Since personas can closely mimic the user’ real world, their use as guiding artifacts in the UI facilitates navigation and makes the content more intelligible to individuals with poor computer skills or low literacy level. Furthermore, due to the use of audio narrations simulating oral communication, they are much friendlier to user uncomfortable with written language. We present herein the main aspects of the implementation and some qualitative field result obtained with target user."
5645;en_US;"This paper presents the architecture and implementation of MyPersonal-EPG, an Electronic Programming Guide (EPG) that supports customization and recommendation. It is based on Ginga middleware and it meets the following requirement: (i) creation of user’s personal programming guide using data sent by TV programs provider; (ii) automatic channel tuning that runs whenever a selected program is going to start; (iii) definition and selection of programs categories that can be user in recommendation; (iv) synchronous and asynchronous recommendation based on selected program categories; (v) personal configuration of several feature; (vi) login accounts that associates personal configurations and preferences to each user."
5646;en_US;"Due to the Web evolution, which currently offers a wide range of service that go beyond the limits of entertainment and communication, middle-aged adults and elderly people can enjoy several benefits, such as shopping, banking, government service and information in general. These benefits also help them to preserve their autonomy and functional independence in carrying out their daily tasks. Despite of all the benefits obtained through the Web, there is still considerable resistance from older adults to use it. Web Accessibility is intended to, in addition to provide means for people with special needs to use it in a natural and independent form, assist those people whose interaction constitutes an insurmountable barrier, either by insecurity, fear or a simple misconception that it is very difficult to learn something related to technology. This paper proposes an approach to the development of an accessible interface for an e-commerce application focused on the older audience, aiming to provide support in each step of the interaction to minimize the performance differences in relation to younger people."
5647;en_US;"The current available large volume of multimedia data, semantically annotated, from several different source, generates new issues about storing and retrieval of those data. In this scenario, it is common to use simple ontology to classify data, creating a relationship between them, that relationship may be measured by a similarity index. The contribution of this paper is to propose a way to organize multimedia data by its conceptual classification, using LSH (Locality Sensitive Hashing) functions, facilitating the conceptual search in P2P network."
5648;en_US;"In various operations related to Quality of Service (QoS) management is necessary to specify the levels of quality through QoS parameters. Most of the work on QoS adopt a fixed set of QoS parameters at the network level. In many situations where humans are the application/service end-user, ideally the quality of network service should be specified using Quality of Experience (QoE) parameters. However, the adoption of QoE parameters to specify the network QoS requires efficient mechanism on QoE mapping into network QoS parameters. This paper proposes a QoE and QoS mapping using an Ontology based approach that can be used during various operations related with QoS management. The use of our proposal is illustrated to support a Voice over IP service negotiation."
5649;en_US;"In this paper, we present a Domain Specific Language (DSL) to specify business and Web transactions in a systematic way, addressing both structural and behavioral perspectives. Our metamodel is based on the reification of transactions, where transactions are modeled as first-class types, supporting attributes, associations, operations and state machine. Treating transactions as domain type instances facilitates the interplay with other model, such as the navigational model, which is a view of the domain type model."
5650;en_US;"Distributed multimedia system have a high-variability of requirement and the most of them can be dynamically changed. So, these system should provide support for dynamic adaptations in order to adjust their structures and behaviors at runtime. This paper proposes a meta-model for description of self-adaptive distributed multimedia application, which allows describing model at runtime used to define new structures consistent with the requirement and other involved elements of the system, keeping a system self-representation. The meta-model can represent the system components and their relationships, policies for quality of service and adaptation actions. Further, this paper presents an architecture for the proposal implementation and an ADL defined to model a case study."
5651;en_US;"The blogosphere is a highly dynamic and interconnected subset of the Web that has triggered a lot of interest due to its social and personal nature. In this paper, we present a study of an important social aspect of blogs, namely popularity. This study, based on the most popular blogs from four important blog domains in Brazil, shows that, despite the blogosphere being a social network, popularity has been underexploited by at least the most popular search engines in the context of blog search. In our experiment, query specifically formulated for retrieving these popular blogs were not capable of ranking them at the top positions (top 100) by the most popular search engines. Besides, their PageRank values are very low. We also provide evidence that explicitly incorporating popularity into the search engine algorithm has the potential to significantly improve the final rankings."
5652;en_US;"Several popular Web 2.0 application allow user to assign keyword (tags) to their objects, in order to provide a better description and organization of the shared content. Tag recommendation service may assist user in that task, improving the quality of the available content and, thus, the effectiveness of tag-based Information Retrieval (IR) service, such as searching and classification. This work addresses the task of recommending high quality tags by exploiting not only previously assigned tags, but also terms extracted from other textual feature (e.g., title and description) associated with the target object. These source are exploited to generate candidate terms for recommendation and to compute heuristic metrics that estimate the quality of a candidate. In particular, we propose a heuristic function that combines multiple metrics to produce a final ranking of the recommended tags. We also investigate the use of Genetic Programming (GP) as a tool to generate and evolve ranking functions. We evaluate both the heuristic and GP-based functions in various scenarios, for three popular Web 2.0 application, namely, LastFM, YahooVideo and YouTube. Our experiment show that our heuristic and GP-based functions significantly outperform state-of-the-art tag recommendation algorithm."
5653;en_US;"Social networking websites provide a suitable environment for interaction and topic discussion. With the growing popularity of online communities, estimulated by the easiness with which content can be created and consumed, some of this content became strategical for company interested in obtaining population feedback for products, personalities, etc. One of the most important of such websites is Twitter: recent statistics report 50 million of new tweets each day. However, processing this amount of data is very costly and a big part of it is simply not useful for strategic analysis. In this paper, we propose a new technique for ranking the most influential user in Twitter based on a combination of the user position in the network topology, the polarity of her opinions and the textual quality of her tweets. In addition, we develop and compare two method for calculating the network influence. We also performed experiment with a real dataset containing one month of posts regarding soda brands. Our experimental evaluation shows that our approach can successfully identify some of the most influential user and that interaction between user are the best evidence to determine user influence."
5655;en_US;"In this paper we revisit the concept of session applied to collaborative work and define a set of operators to manipulate session information related to workpaces and tool scheduling in collaborative environments. By means of a proof-of-concept implementation which uses web service and context-aware tool, we show an example of how session information provided by the operators can be used to leverage the ubiquitous capabilities of collaborative application."
5656;en_US;"The computational power and support for communication with other device in home network, incorporated by digital TV, create new possibilities and opportunities for research and promote the development of new types of service and application. Currently, a significant amount of computational device is part of human environment, however, the interaction with these device, depends frequently on some process of learning due to differences found in interface and ways to configure and operate each one. Potential application may use the TV set for interaction with domestic appliances, as the TV has a central role in many peoples daily entertainment. This paper presents an architecture whose aim is to facilitate the implementation of ubiquitous application in home network that has the TV as a central element of interaction with other device. The proposal is evaluated with implementations undertaken as service extensions of common core of middleware for the Brazilian system of digital TV."
5657;en_US;"Subsequence identification consists in identifying real positions of a specific video clip in a video stream together with the operations that may be used to transform the former into a subsequence from the latter. To cope with this problem, we propose a new approach considering a bipartite graph matching to measure video clip similarity with a target video stream which has not been preprocessed. We show that our approach locates edited video clips allowing insertion, removal and replacement operations. Experimental result demonstrate that our method performance achieve 93% recall with 93% precision, though it has a low computational cost since its classifications step is extremely simple."
5658;en_US;"This paper presents TAL (Template Authoring Language), an authoring language for hypermedia document template. template describe document families that are structurally or semantically similar among them. TAL enables the description of a template independently of the target hypermedia authoring language. The paper also presents a TAL processor that generates complete hypermedia document taking as input the template specification in TAL and a data file with the information that makes that document unique in its family."
5659;en_US;"Live presentations can be captured in instrumented places generating document with the talk. A presentation is normally related to others as well as to document. Therefore, linking of the related document, before and after a live presentation takes place, can be useful when lecturers are interesting in knowing more about his talk. Moreover, the availability of linking during the presentation provides a unique opportunity for linking in the live context itself. On the one hand, it is interesting that the creation of links occurs automatically given the amount and diversity of information. On the other hand, the evaluation of the possibilities of links identified by algorithm can be a burden when the user does not have the focus of attention on the associated task. We propose that well-known Web interacting operations be used to identify links. The operations should be made available before, during and after live presentation and in any case the user should attach relevant result as annotations. We present the model and associated implementation. The activation of the operations can be done automatically by multimodal interaction, typing and browsing."
5661;en_US;"This paper proposes a hybrid solution of hardware/software cooperation aiming efficient scalable H.264/SVC encoder implementation. Scalable solutions generate complex multi-layer streams, resulting in additional computational demands and latency delays when compared to single-layer alternatives, due to increased amount of resource needed to handle inherent interlayer data dependency. In the proposal, a hardware FPGA board executes the high-demanding computational algorithm, while the software is responsible for external interface management and overall system control. Besides that, the paper suggests optimized hardware modules specially designed to improve the performance of critical algorithm, like DCT and Hadamard."
5662;en_US;"This paper presents an analysis on how the chrominance subsampling affects the three-dimensional perception in stereoscopic anaglyph video. The analysis used objectives and subjectives measures of video quality, encoded by color matching red/cyan and green/magenta method. The chrominance subsampling 4:2:2 and 4:2:0 (at color space YCbCr) was applied for each method of color combination and the result have shown that the method green/magenta is less sensitive than red/cyan method for chrominance subsampling. The analysis also demonstrates that subsampling 4:2:0 is prohibitive for both method."
5663;en_US;"The popularization of Web application has given rise to new service every day, demanding mechanism to ensure the credibility of these service. Since now, little has been done to measure and understand the credibility of service on this complex Web environment, which itself is a major research challenge. From the challenges related to the task of assigning a credibility value to an online service in Web 2.0 application, we propose a framework for the design, implementation and evaluation of credibility model. We call a credibility model a function capable of assigning a credibility value to any transaction of a service on the Web, considering different criteria of this service and its supplier. To validate the framework, we perform experiment using an actual dataset, from which we evaluated different credibility model using distinct types of information source, and it allows to compare and evaluate these credibility model. The result show that the credibility framework has applicability and is capable to support decision of user of Web service."
5664;en_US;"Recently, there has been a huge growth in popularity of online social networking, which has facilitated the interaction between Internet user. The characterization of the user access pattern of these application is an important task to support the otimization project and new system that best t the user needs. This paper presents a characterization of user access pattern of Orkut, the more popular social networking in Brazil. The characterization was done with real data traffic from a residential broadband provider, was presented from two perspectives: the intra-Orkut analysis, which emphasizes the pattern of user navigation through various feature of Orkut, and the inter-social network analysis, which covers the access from Orkut to other social network such as YouTube, Fotolog, MySpace, Last.fm and Facebook. The result show the presence of three distinct profiles of navigation through the feature of Orkut, and a predominance of sessions using the Orkut and Fotolog together with YouTube to share video and photos."
5665;en_US;"DTV application (with their related media objects) and live editing commands (with their associated parameters) are transmitted embedded in data structures supported by asynchronous transport service that must be defined by each particular DTV system. This paper proposes several transport alternatives to Ginga-NCL middleware, stressing their data structures that allow for not only controlling the application life cycle and mapping the authoring syntax to the transfer syntax without the author’s intervention and knowledge, but also for improving the transmission and processing performance of DTV application. Although focusing on the Ginga-NCL middleware for terrestrial TV and IPTV system, the proposed alternatives can be extended to other middlewares."
5666;en_US;"This paper presents EDITEC, a graphical editor for hypermedia composite template based on the XTemplate 3.0 language. EDITEC was designed for the creation of template using a user-friendly visual graphical approach. It provides several options for representing iteration structures and a graphical interface for creating basic XPath expressions. The system provides a friendly environment with multiple views, giving the user a complete control of the composite template during the authoring process. Composite template can be used in NCL programs for embedding spatio-temporal semantics into NCL context and making the production of interactive content easier for the Brazilian Digital TV System."
5667;en_US;"The use of textual authoring tool to NCL hypermedia application development brings the author closer to the source code produced. However, those tool tend to create an environment more subject to programming errors requiring an author with an intermediate knowledge of the language and capable of identifying possible solutions for those errors. This work presents technique to suggest semi-automatic code correction in order to minimize the time spent in this task and consequently reduce application development time, thus encouraging less experienced authors to utilize textual authoring tool. Finally, the implementation of those technique in the NCL Eclipse environment is also discussed."
5668;en_US;"Vocal access to TVDi content can promote social and digital inclusion. Actually, vocal interface enhances accessibility since it enables TVDi usage by physical-impaired people and blind community. In the scientific literature, however, TVDi voice-driven interactivity is not often considered. There are just few work concerning architecture proposals, but none of them is actually properly validated. We consider the integration of VoiceXML voice gateways and the middleware Ginga a promising hypothesis for architecture definition. In this paper, we describe such an integration proposal and perform validation by means of two different case studies, two different TVDi application. The proposal key element is the syntax extension we provide to NCL in order to incorporate some native VoiceXML elements. result show that the vocal interactivity mechanism has achieved similar functionality to that of the remote control."
5669;en_US;"The Internet is an important mean of information transmission, of interaction between people, accomplishment business-oriented, education and government service. However, problem related to accessibility content have been a factor for exclusion of user, mainly those with some type of disability. Such process of exclusion has motivated research for method, technique and tool to offer to the Web professional sustentation for development of accessible Web application. In this context, this work presents a Accessibility Tasks Model (MTA) inserted in ISO/IEC 12207 Development Process (Standard for Information Technology – Process of Software Life Cicle) to assist analyze, design, implementation, and evaluation of accessible software. Pantaneiro framework is presented to support sub process in MTA. It was modified to produce Web pages with standard of Web accessibility. To test, evaluate and validate the MTA and accessible Pantaneiro, and to evaluate the strategy to promote the accessibility, one case study was elaborated with groups of developers."
5670;en_US;"The diversification of the information dissemination channels as well as the user available bandwidth, contributed to the increasing availability of audio-visual notices in various formats and media. Despite of the large volume of news, deaf people tend to be uninformed, because they do not have a complete understanding of the news on the tradition way of publications. Thus, accessibility becomes an important point of study, because it allows the information socialization, contributing to social and digital inclusion, and allowing the different people integration. This paper presents how to use Digital TV resource to provide a solution for deaf people to read TV Closed Caption in Brazilian Deaf Sign Language (LIBRAS). The main objective of this paper is to allow the automatic translation of the closed captions used in Digital TV to Libras, and present the experiment result."
5672;en_US;"
            The issue ofuser interaction for query formulation and execution has been investigated for distributed and dynamic environments, such as Peer Data Management System (PDMS). Many of these PDMS are semantic based and composed ofdata peers which exported schemas are represented by ontology. In the literature we can find some proposed PDMS interface, but none ofthem addresses, in a general way, the needs of a PDMS for user interaction. In this work we propose a visual user query interface for ontology-based PDMS, which provides a simple and straightforward interaction with this type of system. It aims not only providing a natural visual query interface but also supporting precise direct manipulation ofthe data schemas for query generation.
       "
5673;en_US;"
            The ontology alignment process is a necessary step to reduce the semantic heterogeneity among ontology. This paper presents a machine learning approach to generate ontology alignment classifier, based on data alignments found through different similarity functions
       "
5674;en_US;"
               Adaptability is an important requirement that aims to reconfigure bu- siness process through contextual information. Non-functional requirement (NFRs) are also important for organization, as they are related to restriction and quality aspects. However, in the business process modeling, NFR and con- text are hard to be captured and represented. How will be represented the con- text information and NFR in BPM, if they are? To answer these questions, we conducted a systematic review, the result ofwhich are presented in this article. 1883 paper were initially identified ofwhich only 24 approaches were identified and analyzed
          "
5675;en_US;"
                  In supervised learning, it is very usual the ocurrence ofdataset con- taining irrelevant attributes. Under such circumstances, it is crucial to apply some feature selection criterion, mainly in learning problem where data ac- quisition costs are proportional to the number of attributes. In this paper, we introduce two attribute selection criteria designed for Random Forests, named Incidence Factor (IF) and Depth Factor (DF). Comparative tests indicate that DF is a robust criterion, outperforming the Error-Based Importance (EI) and performing similarly to the Gini Importance (GI), the two main criteria for Ran- dom Forests currently in use.
             "
5676;en_US;"
                     To achieve reliable levels of safety, the focus of many company has been to invest primarily in technology and process, forgetting the human resource that necessarily work with these technologies and will be part of the process. Thinking about this gap, particularly in people as internal threats (insiders), the present study analyzed through theoretical and field research, aspects of information security at 34 public and private company in Greater Recife where, in general, it was established that information security has a low level of maturity and active participation of insiders, these points that the paper proposes improvements
                "
5677;en_US;"
                        Mobile device as smartphone and tablet PC have become an important platform for communication and information access. This implies the emergence of new forms of interaction with these technologies, which include the use of mobile device as a resource in support of decision making. Take into account the user context while the same search information to maximize their level of satisfaction with the system since the information space/time may provide further details on the process of information filtering. In this perspective, this work presents a recommender system able to customize products and service based on geographic location, as well as in estimated consumption pattern ofmobile user
                   "
5678;en_US;"
                        In this work, we propose a method for analyzing and processing textual news from the Legislative Assembly of Sergipe State website, by means of a text mining process which can be applied to legislative chambers from different states. The main goal is to facilitate to the voter the documentation of such news, and provide decision support on which candidate to vote for state representative. The analysis consists mainly in the automatic categorization of news on predetermined labels that, aligned with other data, measure the performance of parliament during its mandate by generating an index, the QoP (Quality of Parlamentarian). Different technique have been used to categorization and Multinomial Naive Bayes algorithm with a minimum cutoff frequency equal to 0 (zero) has obtained the highest success rate, in the order of 84%. The QoP index was effective for the dynamic ranking of deputies according to the assessment of their quality in both quantitative and qualitative terms. A Web application was developed and allows the voters to view the default ranking as well as generate alternative rankings through a custom interface where they can modify weights used to calculate the index
                   "
5679;en_US;"
           This article presents a comparative analysis of the performance of one algorithm of the classification tree family (J48) and one of the support vector machine (SMO), when combined as ensembles bagging and boosting. The two main questions are: a) For a certain algorithm, which ensemble setting (between Bagging and Boosting) achieves higher accuracy? b) Is there any evidence that a particular classifier performs consistently better than the other under the ensemble setting? result suggest that J48 tends to achieve a higher accuracy under the Boosting configuration, while SMO seems less sensitive to the ensemble adopted. Nonetheless, both algorithm attained similar numbers of victories among the used dataset
      "
5680;en_US;"
           Data mining method have been widely applied in financial markets, for trend forecasting, buy/sell decision support and automatic trading. This pa- per describes the application ofa supervised learning approach, using Random Forests, for decision support in stock markets. Among the 68 stocks that com- pose the Bovespa Index, in 40 stocks our approach achieved a rate ofsuccessful operations above 75%, in 38 stocks, the rate ofyielded opportunities was higher than 50%; and in 30 stocks the average net return per operation was higher than 4%. These preliminary result provide a strong motivation for further studies and extensions.
      "
5681;en_US;"
           This paper is an exploratory study of how privacy is handled by Facebook user. To achieve this goal a few method were used, providing different perspectives on the issue – an online survey, the Semiotic Inspection Method (SIM) and the Communicability Evaluation Method combined with interviews about privacy issues. The conclusion is that user say they are worried about Facebook privacy regarding the disclosure of their personal information, especially photos; however, there were also major disruptions of communication related to the privacy of photograph
      "
5682;en_US;"
           Over the years, people suffer changes caused by the aging of the body and might develop some kind of visual, hearing, motor, among others dysfunctions. These limitations may represent difficulties to access service provided by the Internet, which are growing increasingly. This work is an assessment of accessibility of Internet banking service of the Banco do Brasil using the Method Barrier Walkthrough. The application of this technique made it possible to identify, evaluate and suggest improvements to diminish the obstacles that hinder and/or make it impossible for the elderly user to perform tasks on this website.
      "
5683;en_US;"
           The usage of mobile device is growing rapidly. Actually, it is incre- asingly common to use digital forms for mobile data acquisition using mobile device (smartphone and tablets). This paper presents the project Maritaca, an open solution for create mobile application to data gathering using Android mobile device. By using the platform, no programming skill is needed to cre- ate the mobile application. Moreover, the platform facilitates the sharing ofthe collected data in the cloud, thus allowing the formation of social network for gathering and information sharing. The project was designed to support a he- avy volume of user and data acquisition. It is based on free software and can be accessed at: maritaca.unifesp.br.
      "
5684;en_US;"
           This work outlines current research issues concerning the implemen- tation of a platform, called OpenMuseum, for collaboration and knowledge sharing between cultural heritage institutions. Most of the work developed for this domain is oriented towards the use of global model for integration. Con- trastingly, OpenMuseum has been designed using a loosely coupled approach in which institutions collaborate through a lightweight interoperability platform, called JamSession, which effectively deals with the heterogeneity of service- oriented system. In order to manage the complex nature of cultural heritage information, some extensions to JamSession must be implemented. The extended platform will serve for cooperative interactive system in general.
      "
5685;en_US;"
           With most of the population living in urban area, the preoccupation of the authorities and the population is increasing aiming to reduce the negative impacts caused by this urban agglomeration. One of the biggest challenges is to improve efficiency of the public transportation. Smart city application and User Information System (UIS) have been increasingly used to optimize these transportation service. This paper presents the Busão, a mobile UIS that uses geoprocessing technique based on user´ location, point of interests and bus routes to present real time information about buses available in city.
      "
5686;en_US;"
           In the information system development, software engineers seek to improve the system’ functionality and usability, which may require a review of their requirement. Considering a teaching-learning process scenario, guaran- teeing such goals demands to comply with pedagogical rule and satisfy stu- dent desires and needs. This paper reports on an experiment in requirement refinement for a Learning Management System, involving the system’s user through the application of the Design Thinking methodology. Design Thinking is a human-centered set of technique and tool that supports an iterative pro- cess to produce, analytically and creatively, solutions for real challenges. Also, the authors present a set ofrefined requirement as a result ofthe experiment.
      "
5687;en_US;"
           This paper presents a case study regarding the use of the ThreadControl Testing Framework to test asynchronous information system. This framework is intended to help test developers to avoid false positives in the execution of their automatic tests for asynchronous system. Some of these false positives occur because the tests fail in some executions due to early or late verifications (assertions). In this paper, we have used ThreadControl in the automatic tests of a simple CRM information system that is asynchronous and discuss the main challenges and lessons learned from this use.
      "
5688;en_US;"
           This article presents an experience report ofmodeling and implemen- ting a business process using the free software Bonita Open Solution (BOS). The process refers to a support activity in undergraduate course: the assessment and validation of complementary, extra-curricular activity developed by stu- dents. Its implementation in a Bachelor Course in Information system brought improvements over the original process and demonstrated some strenghts and limitations of BOS. All artifacts generated in the development of this work are available in a public repository, serving as a pedagogical resource for teaching Business Process Management, as well as a technological solution that can be used in other cases with similar requirement.
      "
5689;en_US;"<p>The traffic in major city has led public transportation to become inefficient, having as one of its characteristics the absence of information to user. In this scenario, Public Transportation User Information system emerge as a possible solution, aiming to provide information to passengers and support their decision-making. This work describes our proposal for a system that considers contextual information of both user and traffic to recommend bus routes and support passengers in their decision-making. Thus it is expected to provide information of great relevance for the user of urban public transportation, improving the quality of public transportation by bus.</p>"
5690;en_US;"
           The set covering problem (SCP) is one of the most important problem in combinatorial optimization. The aim of this paper is to show the application of a Parallel Genetic Algorithm to the SCP. The parallelization of the genetic algorithm was based on the island model with migration unilateral. The preliminary computational result show that the proposed algorithm produces good quality solutions at a reduced computational time.
      "
5691;en_US;"
           In this paper, we describe a Ginga middleware extension, developed in the context of the Knowledge TV (KTV) platform, a new layer to provide semantic service to the convergent TV environment (iDTV and Web), which aim is to share and reuse data, resource and service application. We describe the Semantic Integration, an API of the Knowledge TV platform, that does the communication between the KTV server and the Ginga middleware. This is responsible for collecting metadata of TV schedule and send via return channel to the KTV server.
      "
5692;en_US;"
           Innovation is a strategic differential in a world of strong business competitiveness. An innovation is not just an idea but an elaborated process that result in the implementation of a new or significantly improved product or organizational process. Innovation comprises steps of generating ideas, resource allocation, implementation and acceptance by a consumer market. Software tool have an important role, supporting activity that enable or facilitate information sharing, acquisition and classification of ideas, research and data collection on a scientific basis and trends forecast. In this context, this work presents a comparison among main software tool applied to Innovation Management.
      "
5693;en_US;"
           The risk management (RM) process comprises a set of coordinated activity to identify, analyze, assess, treat, monitor and communicate project risks. organization that wish to implement these set of activity on their software development process (SDP), in its turn, should implement a serie of activity to adhere to existing standards and regulamentations. However, there are no references to model that enable the evaluation of the SDP through a questionnaire and enables managers have a clear view of the deficiencies of this process. In this way, this study aims to present the diagnostic assessment questionnaire that is part of the GAIA Risks framework as well as the methodology for calculation and display of result.
      "
5694;en_US;"
           This paper, based on theoretical and applied research in company in Greater Recife, Pernambuco State, Brazil, aims to measure the efficiency achieved through the ongoing process of awareness and training of employees of private company in area outside of the IT on the subject of Social Engineering and Phishing. Research shows that social engineering and phishing continue to be an efficient way to get data from employees in the corporate environment. Thus, we demonstrated a strategy, without the cost of acquiring tool, so user often categorized as a weak link in the chain, are transformed into a more efficient enterprise-class protection layer.
      "
5695;en_US;"
           organization use service to support the implementation of their business process. Service requirement are identified at design time. However, due to changes in the business process, a service might no longer comply with those requirement. Hence it is needed to adapt the application that implements the process to consume other service which best fit its needs. This paper describes an approach for automatic and flexible identification of service that are more appropriate to meet the context of a specific process instance. An example of application of the proposal is conducted in order to demonstrate its applicability.
      "
5696;en_US;"
           This paper presents the result of a systematic literature review on work published in the Service-oriented requirement Engineering (SORE) area. Due to the dynamism that service-oriented environments have, because of their feature of interoperability among heterogeneous environments, it is necessary the creation of new technique in order to elicit, analyze, specify, negotiate, manage and verify requirement. The methodology of this systematic review classified the primary studies according to three main concepts: aspects related to electronic service, aspects related to traditional requirement engineering and emerging aspects related to SORE. The review identified 52 primary studies and classified them in these three concepts. The result point up the growth of the number of published work on SORE in recent years as well as evidences some research gaps and tendencies.
      "
5697;en_US;"
           Several organization have used Service-Oriented Architecture to achieve cost and schedule gains. However, the success of this kind of strategy depends on the implementation of governance mechanism that allows an architectural evolution aligned with the organization’s objectives. To reach this goal, compliance with corporate policies must be ensured. This work proposes an approach for using ontology and semantic rule to support the compliance evaluation in the SOA context. A proof of concept in a real scenario was executed demonstrating the proposal applicability.
      "
5698;en_US;"
           Many company choose for Distributed Software Development (DSD), once it brings benefits like cost reduction and productivity increase. Together with the benefits, come also challenges regarding coordination, communication and control. Model Driven Development (MDD) has model as main artifacts. Although it’s adoption increases development productivity, to take advantage from it, working with model, adjustments in software development are requireds. This paper presents a Continuous Integration Server (CIS) for model. It aims to mitigate the challenges of DSD and also offer support to MDD.
      "
5699;en_US;"
           This paper presents a MDA methodology for MAS development that uses model in different abstraction levels, going from system specification, and after a transformation set between model, get to the specific platform JASON/Moise+ codification. The methodology uses the FAML as platform independent model, which is a metamodel that englobes the concepts of several agent-oriented methodologies for MAS development into a single model. As platform specific model, the JaCaMo model was chosen. The transformations between platform independent model and platform specific model are programmed in QVT language and transformations between platform specific model and the execution platform are programmed in M2T language. This paper also presents a MAS development environment, which is a set of Eclipse plug-ins and the Gold Miners system that was modeled using Prometheus..
      "
5700;en_US;"
           The Software Engineering Research Group of the Institute of Infor- matics in Federal University of Goiás has invested in an Application Frame- work (AF) for Information system (IS) development using Model-Driven En- gineering (MDE) concepts to support the automatic generation of IS software. However, new requirement revealed troubles to evolve the first AF architecture version due to problem such as replication and spreading code, low flexibility of the architecture, and especially the lack of theoretical framework on AF as- sociated with MDE. This led to the following research question: How to design an architecture for a model-driven AF for IS? To answer this question, we con- ducted a survey and we designed an AF architecture that uses MDE to synthesize IS components. This proposal is an architectural evolution ofthe first and pro- vides a comprehensive solution to foster the generation and reuse ofcode in the IS software development.
      "
5701;en_US;"
           It is well known that the use of technology has brought numerous benefits in treating disease, autism is not out of this reality. Because it is a syndrome characterized by failures in specific area and on different levels, it ends up requiring adequacy of mechanism used for the treatment of individuals who have, in this universe activity including literacy, critical step in treatment. The project itself aims to develop the initial modules of a tool that assists autistic children in literacy, seeking to boost the use of TEACCH methodology currently applied manually, and internalized by children already receiving some type of monitoring.
      "
5702;en_US;"
           Stored procedures are commonly used to provide access and manipu- lation ofdatabase data for information system and other application. If pro- cedures present inefficient programming logic or data manipulation, excessive delays are provided to the client application. Such delays can cause, among other problem, expressive financial losses to enterprises. In additon, if proce- dures are developed using bad programming practices, they may become com- plex to maintain and evolve. In general, attempts to minimize these problem using manual analysis of source code are labor- and time-consuming. In this work, we present PL/SQL Advisor, a static analysis-based tool, which automat- ically detects potential improvements on database stored procedures written in PL/SQL. The result ofa case study, using real open source project, show that our tool is able to suggest a reasonable amount ofcode improvements with low cost.
      "
5703;en_US;"
           Changes in teams always represent a challenge for organization and societies. In the governmental domain, this is also critical. In the Brazilian Govern case, the teams have a short time (120 days) to accomplish the political transition and they usually have distinct points of view. This way, information system have become important pieces to aid the knowledge management applied to different governmental system as well as their integration. This paper presents a system that work as a central piece for joining information from many levels of Brazilian Govern’s federal sphere. This system extracts and organizes governmental transition reports in order to contribute to programs and initiatives continuity.
      "
5704;en_US;"
           The purpose of this paper is to propose a framework which main focus is to improve the development of Android Database-Enabled application inside Brazilian Federal Government. AlienDroid provides a simplified architecture, with only few negative impacts in the architecture and performance of the application that extends it. The main focus is to facilitate the development of Android application that uses relational databases as storage.
      "
5705;en_US;"
           Product Line (PL) is a Software Engineerings approach that seeks to increase quality and to reduce cost and time-to-market of information system development. However, due to its particularities, this approach requires specific technique and tool for software testing. This paper proposes a tool to support the management of functional tests for PL, based on Feature Modeling, developed as an extension of the SPLOT tool.
      "
5706;en_US;"
           Since the creation of the particle swarm optimization algorithm, it is remarkable the increasing number of publications proposing different parameter settings or implementation strategies. However there is a big difficulty of representing the effects of such proposals during the optimization process. This difficulty is due the few existing tool are not flexible enough and require the installation of additional resource to run. This paper presents the development of a web simulator for the global optimization algorithm particle swarm optimization. With the simulator it is possible to follow the behavior of the algorithm in the main optimization problem or in any function defined by the user.
      "
5707;en_US;"
           The search in the source code is gaining more and more space because of the increasing complexity of current software system and also the need for improvements in source code. Although the paradigms of object- oriented programming and aspect-oriented programming have several feature to improve code reuse and clarity when maintenance of code is required, developers tend to reduce productivity because of problem on locating the parts to be corrected or improved. Aiming maintenance activity, this paper presents a search code process that can be applied to source code repositories.
      "
5709;en_US;"
           Tailoring process of software is a very complex task, involving many factors, including experience of process engineer, understanding the context of the project, among others. Such factors may cause not optimized and inconsistent result. This work proposes to optimize and add consistency to process tailoring using concepts of Search-base Software Engineering and Situational Method Engineering approach. The strategy used for recovery and validation of the fragments is the use of Octopus Model context, with fragments from the RUP, evolving proposal OSPTA.
      "
5711;en_US;"Software engineering disciplines need to be taught in context as diverse as undergraduate course and large corporations training programs. A primary challenge in teaching such disciplines, in any context, is to quickly and effectively evaluate the student learning and measure their strengths and weaknesses. Another challenge is to make student of different instances of a discipline end up with the same basic foundations, turning knowledge independent of the instructor. To overcome these challenges we propose an approach for software engineering teaching based on adapted PDCA cycles and checklists as instruments of evaluation. We also report a case study which shows the implementation of this approach in teaching a first year undergraduate software engineering course. With a careful definition of checklists, the use of the adapted version of PDCA as a methodology for software engineering teaching is promising, allowing an efficient form of evaluation."
5712;en_US;"Currently, the majority of Virtual Environments for Learning (VLEs) lack of efficient mechanism that can identify affective phenomena throughout the student interaction with the environment, since these phenomena deeply interfere in mental process such as reasoning and, especially, motivation. To fill this gap, this paper proposes a system for recognizing facial expressions based on System Facial Action Coding System (FACS) and a method of classification rule based on emotion. This system, by means of a camera, investigates their performance in the recognition of emotion (happiness, sadness, anger and disgust) student, verifying his facial expression during the entire course in a VLE."
5713;en_US;"Understanding the importance of education in software quality for integration between academy and industry, this paper reports the use of a proposal for teaching and learning aspects related to software quality. The practical side of the study was based on the instantiation of real project of a Junior Enterprise (JE), implemented through a specific environment in the classroom. The environment allowed the student to understand the relation between quality and software process, through the roles and activity, template, procedures and tool used in project development. Other contributions were the increase of JE’s project quality and the value added to student, through the use of best industry practices."
5714;en_US;"Learning Management system (LMS) are application that allow interaction between student and tutors, either dynamically or statically for attendance and semi-attendance course. In the LMS, it is possible to use various learning mechanism such as visualization of classes, chat tool, message exchange, forums etc. However, the use of these mechanism does not imply real learning, and this requires the development of an evaluation tool to provide a better understanding of both classes and tutors’ efficiency real scenarios. The article presents MAAT system, which allows generation and application of questionnaires in a LMS, and consequent consolidation of result to assist in the evaluation and decision making."
5715;en_US;"The difficulty in teaching Algebra and Relational Calculus has been proven through the GPA in Database course. The abstraction of these language makes difficult the understanding and culminates with the demotivation in the sequence of the course. However, Algebra and Calculus are the foundations that support the SQL language and especially the foundations to optimize a DBMS. Thus, in order to facilitate and motivate learning, we developed a tool called ProgramAR which has as its main objective the description of expressions in Algebra and Relational Calculus which are converted to the SQL language. These expressions are executed over a DBMS, allowing student to view the result. In order to validate the tool, some tests were conducted with student of the Information system and Computer Science course from the Federal University of Bahia."
5716;en_US;"<p>The Smart city are emerging ahead of the needs of the new society and information technology that has emerged in this century. Currently there is a maturity model that can measure how intelligent a society can be based on social or technological indicators. Create a maturity model assumes establish requirement, analyze them and determine which will be transformed into indicators. This paper presents the initial level of a maturity model applied to intelligent city.</p>"
5717;en_US;"<p>Social network are now a global communication medium with a huge number of user. The Facebook, for example, has more than 1 billion active user per month, and these user share a myriad of information, including opinions about many subjects. This big quantity of public information accessible has attracted the attention of company and institutions that want to know better what people on the Internet are thinking about them. In this paper, we present a sentiment analysis tool for social network message using the SenticNet knowledge base. The early tests to evaluate the tool have shown that our approach properly classifies the sentiment in message,and it supports the large quantity and speed of the sharings in a social network.</p>"
5718;en_US;"<p>The Brazilian Law of Information Access determines the spontaneous publicity (active transparency) of diverse information by public institutions. The law has filled a social political, historic gap in the presence of international initiatives and agreements, but it exposes the lack of technical maturity in open government data. In fact, the execution of the law is being done amid very recent R&amp;D efforts around themes from open formats and interoperability standards to linked data in the context of the Semantic Web. This position paper presents research perspectives and technological challenges in the area of open government data and transparency.</p>"
5719;en_US;"In this article is presented a computer simulation model, since their development until its validation, which aims to support environmental managers in their decisions regarding the definition and / or maintenance of solid waste policies recycling, as well as evaluating the benefits of process in the environment (in this article we evaluated the energy savings). For the model development was considered: the rate of natural population growth, percentage of solid waste recycled, gravimetric composition of the material in the total waste generated, the amount of waste generated per inhabitant and energy savings caused by each distinct type of material. Through the model result generated, end user (environmental managers) thereof may, for example, set incentives to reduce the total generation of solid waste and to assess the relative benefits of electrical energy savings caused by recycling."
5720;en_US;"The Markowitz’s quadratic model played a key role in the investments’ portfolio selection problem, however, no longer meets the needs of the complexity of the current market. The addition of constraints to approximate the model to the real situation faced by investors, makes the problem NP-Complete. Thus, this paper presents a genetic algorithm that seeks to maximize the investment’s return, given an acceptable risk level. After portfolio optimization based on historical data, there is a forecast for the subsequent year. The result improves the Bovespa index performance, highlighting the effects of diversification according to the number of assets and the capital available for investment"
5721;en_US;"Mobile device have become popular, and along with them, the Mobile Information system (MIS). Due to some device constraints, the development of these system becomes complex. Software testing is one of the activity aiming MIS quality assurance. Nevertheless, this activity is very costly. Aiming cost reduce, it is necessary make use testing tool. However, there are many commercial options, making difficult choose the greater tool. This paper presents a comparison between the main testing tool for MIS, using a DMADV-based method, defined by the Six Sigma methodology. The observed result should help to guide the choice of testing tool, as well as identify unsupported feature."
5722;en_US;"Monitoring and planning are interesting activity to help transit operator and to provide quality in public transportation. In fact, some computational tool and simulators play this role and assist humans in tasks and improving transportation. However, existing solutions are typically proprietary and, therefore, have prohibitive cost to be adopted by small and medium size city. In addition many of them are not easy to be operated by non-specialists. In this paper, we describe the implementation and evaluation of a simulation using the support of a multi-agent system to represent dynamic components (flow, roads, vehicles, pedestrians, bus stops, etc.) in the urban transport. Our simulation can be easily operated by non-specialists and was experimentally evaluated using as scenario a medium city, considering the variations of two given journeys."
5723;en_US;"To achieve the objectives proposed by the Green Computing it is necessary to consider technique to reduce consumption, both on aspects of hardware and software. A major challenge is to develop method that optimize components of all levels of abstraction. This includes the optimization of software components. In this context, this paper conducts a study dedicated to evaluating the energy expenditure of software application through monitoring, analysis and testing, in order to examine how programming technique may contribute to the development of more sustainable system."
5724;en_US;"In view of the importance that Medical Informatics has acquired through the use of Artificial Intelligence technique in their application, especially concerning to Knowledge Engineering and ontology, it is necessary to map the evolution of this area thoroughly, impartially and systematically. Therefore, we built a Systematic Mapping that aims documenting about the use of ontology in Medical Informatics. By the fact that we don’t find a general taxonomy that defines the subfields of Medical Informatics and that allows sorting the selected studies for Systematic Mapping, this paper presents a study about the construction of a taxonomy that characterizes all subarea of Medical Informatics."
5725;en_US;"Dynamic Circuit network have been adopted by the foremost Research and Education network around the world. However, some management aspects of this kind of network remain unclear to the scientific community, characterizing it as a challenge to be overcome in the pursuit of providing a robust and reliable virtual circuit provisioning service. To address this issue, we propose the adoption of a business process management approach. The process were adapted from conventional IP network management process, in which specific activity for dynamic virtual circuits were included. A case study was conducted and preliminary result evidenced that the adapted process are applicable in a real Network Operation Center."
5726;en_US;"Dynamic adaptation aims to make a business process applicable to a particular situation during its life cycle. Adapting requires experience, and involves knowledge about various aspects of business. We argue for the application of adaptation rule, considering the context of a particular process instance. However, a context-based adaptation environment should go beyond, and learn from its decisions, as well as continuously identify new unforeseen situations. The goal of this paper is to present a methodology to infer the need to update situations and adaptation rule, suggesting changes to them. An application scenario is presented to discuss the proposal."
5727;en_US;"Software process improvement model can contribute significantly in product quality and evolution of organization. However, implement these model is a major challenge. This process generates an increase in cognitive load to project manager that must manage project following the recommendation of model. This paper proposes a multi-agent web system to assist in knowledge management and automation tasks recommended by CMMI (Capability Maturity Model Integration) Level 2."
5728;en_US;"Distributed software development (DSD) has been an approach increasingly adopted by company. Hence, managing the distribution of steps in a development process among distributed teams is quite challenging. Therefore, defining strategies that consider socio technical aspects involving people, technology, and process metrics can provide the necessary support. This paper presents the experimental validation using GQM to evaluate a strategy that considers the estimated effort as an intrinsic element. The result show that these metrics are indicators to allocate requirement step in DSD - offshore outsourcing model."
5729;en_US;"The use of mobile and ubiquitous computing has been stimulated by the widespread diffusion of mobile device, wireless network and location system. In this context, numerous application are emerging in different area such as education, entertainment, commerce and transport. This paper proposes the MD-UTS, a model for development of ubiquitous transport system. The model allows management of different types of vehicles, making a historical record of their movement. The model provides information through web service that can be used by different application. The article also describes two application integrated into an urban transport simulator. The result demonstrate the feasibility of the model, facilitating the construction of application directed to the transport system."
5730;en_US;"Cloud Computing (CC) is one of the most discussed topic among IT professionals today. With a strong economic appeal, CC makes possible the idea of computing as a utility, in which computing resource (processing power and storage, for example) can be consumed and paid with the same convenience as electricity. This research analyzes CC adoption by Brazilian company of all sizes and sectors that have adopted at least one IT service in CC model. This paper used a not randomly picked sample with 96 cases. This research identified the major cloud computing service used in Brazil as well as their characteristics, motivations for contracting the service provider and the impact of those service in the organization."
5731;en_US;"This article proposes the transformation of UML Activity Diagrams that model workflow process into WF-nets (WorkFlow nets). The transformation is automated using the ATL transformation language, well-known in the model-driven development context. This transformation enables the verification of the soundness property for workflows using linear logic proofs in WF-net specifications. The generated proof trees also help finding possible causes for unsound diagrams. An illustrative case study is presented to demonstrate the approach effectiveness. The result from this paper could motivate the typical software company to introduce the rigor of formal verification using Petri Nets associated with linear logic without sacrificing the common practice of developers who can continue using UML notation integrated with industrial tool such as ATL."
5732;en_US;"Most trajectory mining approaches consider a very small set of properties to extract pattern from trajectories. Besides, a lot of them consider those properties separately. In this paper we present a method to find co-location pattern based on different properties of trajectories along time. The proposal allows to identify a sequence of co-locations composed by different properties (distance, acceleration, speed, time etc) that represents the behavior of a set of trajectories. The sequences of co-locations pattern present the evolution of an event, for example traffic jam. By using this knowledge is possible to anticipate the phenomenon occurrence, and to take actions to solve problem regarding to the event."
5733;en_US;"pattern of use of a web site can be used to personalize service, identify consumer profiles and customize navigation. To identify these pattern using chains of navigation contained in access log files of web servers is necessary to segment the records in user sessions. As the HTTP protocol does not store this information, some strategy must be traced to join records into sessions. This article describes a method for identifying association rule between pages of a web site that uses as a source data, only the contents of access log files of web server."
5734;en_US;"Monitoring Science, Technology and Innovation project require control of their lifecycle through reports or management and operational activity. The goal of this work is to build a classification model that automatically discovers the lifecycle stage of a project based on a set of characteristics that describes it. Data Mining was used to achieve this classification model. Moreover, analyses in the model suggest that they can also be used to identify problem in data or failures in the process."
5735;en_US;"Among the data mining tool embedded in decision support system and Business Intelligence environments, classification trees have the advantages of being conpeptually simple and easily interpreted. However, many classification problem involve unbalanced dataset and, in such cases, low frequent classes tend to be negleted by algorithm driven to global error rates minimization. This work introduces a new algorithm for induction of decision trees for unbalanced dataset, with minimal user parameterization needs. Preliminary result show good mean within group error rates for the proposed algorithm in comparison to other competitors."
5737;en_US;"Information system are used to collect, store and disseminate information generated by user. Moreover, these system help in decision making process as well as the Information Visualization (InfoVis) technique. Experts recommend the use of heuristics to facilitate the selection process of InfoVis technique to be applied in any context. The goal of this work was analyze the literature on InfoVis and transparency of public data in order to identify a heuristic set which could be used to verify the suitability of application of visualization technique in the government context."
5738;en_US;"With the increasing generation of structured and unstructured data, internally and externally to the enterprises, approaches have been proposed to process and present this information, enriching their analytical capabilities. But few have addressed it in an integrated way, joint exploration and taking advantage from the analytical processing facilities offered by OLAP tool. Thus, this paper proposes JointOLAP, an integrated architecture for joint exploration of structure and unstructured data applied in a real scenario with the development of an analytical information system, called PowerOLAP. It allows the enrichment of the analyses of disturbances on the Brazilian integrated electrical system with their impact reflected in the news. Examples of analyses illustrate its analytical potential."
5739;en_US;"The Brazilian Army produces a summarized report about each military member’s activity during a semester. This requires that the references to a specific member are searched through a set of document produced during the period of six months. This work proposes ways of performing this classification task automatically by using the Naive Bayes learning method. It is also necessary to identify which sentences inside a document refer to the military member in question, such that only these sentences are used for training the classifier. We propose two technique for sentence selection that choose portions of text that surrounds the target names. The experiment show that it is possible to achieve an f-measure of 76.7% in retrieving relevant document, and that sentence selection and training data size play important roles in the task."
5740;en_US;"In Brazil, the use of mobile internet and mobile device, such as tablets and smartphone, has been growing in a higher pace than global mean in recent years. The use of those device has modified the way people interact with each other and with company around, and has also potential to reach government-government, government-company and government-citizen relationships. In this way, this paper presents challenges for building mobile application in the context of the federal government, discussing and comparing possible existing application architectures and presenting 2 case studies built at SERPRO for the Brazilian Internal Revenue Service and for the National Department of Transport Infrastructure."
5741;en_US;"This paper discusses the main law project in Brazil about Internet and their rule of use, and also about crime practiced through the network; from the perspective of privacy and individual freedom. Contextualizes it with the actions taken internationally, especially in the United States and European Union, world exponents in this matter."
5742;en_US;"This paper presents a Electronic Checking Process to perform an automated comparison between records databases and qualitative assignment of categories, based on five conditions. The described methodology uses only information from civil identification (full name and birthdate) to simulate simple cognitive responses through the use of logical operations, heuristics and indicators, in order to establish and to describe the links between records of personal information. The proposed procedure assists in decision-making by allowing the manager to establish the acceptance limits for qualified information."
5744;en_US;"Project management has become a common subject in Software Engineering and an everyday task in software organization. In this task, the effective use of technologies can determine the success of any business; affect quality and ability to provide products and service on time. According to some authors, success in project execution can be associated with organization maturity. organization search for project management maturity in order to improve their management process and increase client satisfaction. Maturity is related to cost, time and quality, and can determine the success of project. In the context of project management, we have two important indicators: Schedule Performance Indicator (SPI) and Cost Performance Indicator (CPI). SPI indicates whether the budgeted costs for work scheduled to date exceed the budgeted costs for the work performed to date. CPI indicates whether the actual costs for the work performed to date exceed the budgeted costs for the work performed to date. These indicators give information about whether or not the project is on track, so they are important factors which represent success in project management. This paper discusses how Cost/Schedule Performance Indicators are related to project management maturity and presents the result based on IT professionals’ opinion analysis."
5745;en_US;"In complex system development is evident a significant difficulty resulting by semantic gap, which is characterized by semantic and conceptual distinction between two descriptions generated and their representations. This difference has a negative impact on the developer productivity and probably, the quality of the generated code. This work aims to bring the concepts of modeling and implementation, especially for normative multi-agent system, through the extension of JAMDER framework, including the norm concepts and its properties. The main benefit of the proposed mapping is to reduce the semantic gap between the modeling project and its implementation. To illustrate the result of this approach a case study is presented that involves a normative multi-agent system to paper submission."
5746;en_US;"Collaborative risk management is a fundamental task in project management. This paper discusses a new collaborative approach to risk management which is grounded on the integration of dialogue game and argument schemes from argumentation research. In particular, we propose a new dialogue game to organize risk discussions, and the exploitation of typical argument schemes for risk management on the collection of more complete arguments. A new collaborative Risk Discussion System is discussed and evaluated, where its environment is capable of structuring and recording risk discussions in a project management memory."
5747;en_US;"New government regulations, business volatility and changes on stakeholders needs are examples of process change inductors. This dynamic scenario promotes a phenomenon called business process variability. This is an emergent topic in Business Process Management (BPM) that uses Software Product Line (SPL) theoretical basis to investigate the variability of process model. This paper explores the adoption of variability concepts and theories by the BPM community, with a mapping to analyse how the variability body of knowledge has been used from SPL to the BPM field. In addition, we position current research challenges within business process variability, and discuss how concepts and theories from SPL could be used to treat these questions."
5748;en_US;"Control system integration (IS) information is, to the electronic government, a challenging, interesting and little explored issue in Brazil. This case study explores this environment in a public agency of Brazil that is reference in information technology. Key contributions of this paper are: (1) presenting a model of IS control process that promotes standardization, systematic communication, knowledge management, division of responsibilities, continuous improvement and; (2) identification that changing requirement is the most problematic issue for physical design phases of integrations."
5749;en_US;"This work presents a requirement catalog for data migration tool. It captures the needs, desire and expectations related to user of migration tool, based on our experience dealing with migration project. The catalog can be used to facilitate the development of new tool. Besides, the catalog can be used as basis for comparison among tool, facilitating the identification of suitable tool for specific project. In this work is still presented a comparison of six tool using the catalog."
5750;en_US;"Management Information system (MIS) usually demand product customizations for each client, frequently involving the creation of new components and changes to existing ones. As a result, MISs usually face maintenance and evolution problem. One of the major challenges is to identify the variations present on the current version and reapply them to newer versions of the system. This might demand rework if these variations are not properly separated from the base code. This paper presents a catalog of variations types found in a real MIS, which is being deployed at Federal University of Sergipe (UFS), and discuss how most common variations that occur in a MIS can be addressed by Aspect-Oriented Programming in a modular fashion."
5768;en_US;"<p>Nowadays, heart failure is the second most diagnosed cardiovascular disease in Brazil, costing over 14 billion reais to the public safes. Besides, the lack of an ideal structure for the patient’s care generates an overload of the public system care, making the close monitoring impossible. This project’s objective is to develop a computer system in order to help monitoring public health system’s patient diagnosed with heart failure.</p>"
5769;en_US;"<p>Advances in the treatment of cystic fibrosis have allowed patient to reach adulthood. As an alternative, the Forced Oscillations Technique (FOT) is being used in the respiratory system analysis and must prove its efficiency. Thus, this work proposes the use of machine learning algorithm to aid the investigation and diagnosis of respiratory changes in cystic fibrosis through the data provided by FOT. During the experiment, the used model presented an AUC value varying from 0.87 to 0.89, showing that the use of machine learning algorithm increased accuracy in diagnosis of respiratory changes in patient who suffer from cystic fibrosis.</p>"
5770;en_US;"<p>Peripartum Cardiomyopathy (PPCM) is a rare disorder characterized by left ventricular dysfunction and heart failure symptoms. Immediate prevention and treatment reduce the rate of maternal mortality and increase the rate of live births. The CardioMPP project aims at offering a solution that help the diagnosis of CMPP with accuracy, bringing efficiency to the clinical routine of clinical care. For this, goals and stages of Human-Computer Interaction are used to promote efficiency, ease of use and learning of the system proposed for medical specialists.</p>"
5772;en_US;"<p>This paper shows a survey carried out with undergraduate student of the ICT (Information, Communication and Technology) course on the reasons that motivate them to take part of research and development project.</p>"
5773;en_US;"<p>In this paper, we aim to analyze the changes in the mobility pattern in relation to the main motives for travel (Work and Education) in the Metropolitan Region of São Paulo (RMSP), through the Decision Tree technique. For this purpose, we used the Databases of the Origin-Destination Survey of 2007 and the Mobility Survey of 2012, with the purpose of building two decision trees, containing the attributes Age, Income and Reason of the Trip (attribute class: House-Work-House and House-Education-House). The result indicate that there were significant changes in the mobility pattern and that the attributes of age and income explain of the adequate form the motives of trips of work and education.</p>"
5774;en_US;"<p>In this work we consider the problem of finding a set of vertices S minimum of a graph P4-tidy G, such that the subgraph induced by G n S is a tree and S is a stable set. It was showed that this problem is NP-complete for general graph in Brandstädt et al. 1998. We present an algorithm for finding a minimum set S in P4-tidy graph based on a characterization by minimal forbidden subgraph. Through the analysis of the algorithm, we prove that this optimization problem can be solved in linear time.</p>"
5775;en_US;"<p>Critical system are system which require high reliability and are present in a wide variety of domains. Should they fail, serious problem can occur, resulting in financial loss and even deaths. Standard software engineering technique does not suffice in guaranteeing the required level of reliability. Reo is a graphical modelling language based in coordination which focuses on model system interaction by means of common primitives in distributed system. Constraint Automata are defined as primitive formal semantics for Reo, providing means to reason about and prove properties of Reo model. The present work describes a formalization of Constraint Automata in Coq proof assistant, regarding its main formalisms, including a compositional operation.</p>"
5776;en_US;"<p>With the advent of critical system in the modern world, the necessity to validate them also increased. That necessity comes from the fact that a system fail can cause catastrophic damages, therefore it’s necessary to guarantee that those programs won’t fail. Reo is a graphical modelling coordination language that takes advantage of the natural properties in distributed system, such as data transfer and remote function calls to model such system. Model checkers are tool used to verify and validate properties and characteristics about a model. This article proposes a compiler to generate a nuXmv (a symbolic model checker) model from a Reo model.</p>"
5777;en_US;"<p>This paper evaluates security mechanism of IEEE 802.11 network. This standard, also called Wi-Fi, is widely used as a device connectivity infrastructure, providing Internet access and creating local area network. For the evaluation of security mechanism, dictionary and brute-force attacks are performed to obtain network password. The Krack Attack vulnerability is also exploited in order to verify vulnerabilities of Wi-Fi device. result show vulnerable device and network because of outdated security patches and the use of trivial password.</p>"
5778;en_US;"Mobile device, especially smartphone, are part of peoples daily lives. In these device, application are virtual environments that user use to chat, take pictures, play, and other activity. One way to make user-application interaction more real and interesting is to use augmented reality, which is characterized by adding virtual add-ins in real-time real-world environments. Thus, the user has not only the virtual environment of the mobile device, but also virtual inserts in the real environment in which it is. Therefore, the objective of this work is to present an approach to the creation of information system using mobile device and augmented reality. In addition, to show the feasibility of the proposed approach, an application was developed as a case study that demonstrates how this interaction can be made and its benefits."
5779;en_US;"Validation of business process model is usually performed by business analysts. These can easily read the model, however do not hold in-depth knowledge of the business. In contrast, domain experts know the business domain, but do not have knowledge about modeling. For these, it is easier to read a text in natural language. For this reason, both the process model and the descriptive text are artifacts necessary to allow natural communication between specialists and business analysts. This research proposes a methodology for generating text from model and vice versa. The result will be evaluated in real scenarios, through company and case studies."
5780;en_US;"The amount of resource provided by the computational clouds on the Internet has generated complex challenges to solve problem related to the allocation of these resource. Quality of experience emerges as a differentiated paradigm as a potentially important factor in solving these challenges. The quality of experience takes into account context parameters. Thus, the MAROQ resource allocation model is proposed, which is a model oriented to the quality of experience, which uses context information to allocate resource in clouds and computational grids. Experimental result show that using context information improves performance in task submission."
5781;en_US;"More and more farmers are realizing that the decision-making and use of intelligent system in agriculture is more than a trend, it becomes a matter of survival and necessity due to the globalization of the economy and the competitiveness of agricultural products. This work presents an approach focused on improving the quality of tomato crops. We developed low-cost computational strategies aimed at supporting family farmers in the early detection of firewood. Our approach uses technique from the field of Precision Agriculture, being applied in tomato cultivars of an experimental field where field observations, image and annotations collected by farmers and used in neural network for the detection of the disease were processed."
5782;en_US;"Nowadays, it is quite common for people to assemble their playlists for a variety of context in their day to day lives. This work aims to present an application on Android platform to recommend songs, according to user speed, through a mobile device. The purpose of the application is to motivate people to perform physical activity."
5783;en_US;"SOA is fundamental for organization to be able to adapt to the constant changes. Service development is not a simple task. A systematic process should be used to guide the work. This work presents the practical application of method for the development of service for identification, analysis, design and implementation, as well as the use of an Enterprise Service Bus (ESB) to support their implementation. Oracle Service Bus was chosen after analysis between commercial and open source tool. Although specific method have been used, this work brings new insights and practical experiences useful for SOA Analysts and SOA Developers to apply in their environments."
5784;en_US;"Service Oriented Architecture (SOA) supports interoperability between heterogeneous system. However, even using SOA, integration between system is a challenge. In practice, the service contract is typically generated automatically from the code (code-first approach), which leads to long-term maintenance and service difficulties. A better approach is to build the service contract first and then implement the code adhering to this contract. This work makes an exploratory study of contract-first development through an example of use in order to demonstrate that this approach brings high level of interoperability, facilitates governance and reduces technology coupling."
5785;en_US;"This article presents an account of experiences about the use of WebSockets as a technology capable of meeting a new type of trend generated by the demands of information system that require real-time answers. Also discussed in this article is how WebSocket can be integrated into a RESTful architecture, creating a means of communication in modules that are used to provide service to user. Thus, in this article, we discuss the advantages and disadvantages of using this technology in relation to the current architecture standard for Web application development."
5786;en_US;"The web, at present, is a platform used by many application. An application with problem in its structure can not provide accurate information and makes it difficult to communicate and share information between system. At the Federal Institute of Education, Science and Technology Southeast of Minas Gerais - Câmpus Rio Pomba there are several system that do not communicate. The information is decentralized, which causes the Islands of Information. Therefore, the purpose of this article is to show the use of the Service Oriented Architecture (SOA) technology to integrate existing system in the institution. Thus, system developed in different programming language can communicate by providing a sharing and reuse of information."
5787;en_US;"This paper proposes a methodology for selection of parameters to classify short-circuit type faults in transmission lines. Since most of the work in classifying events in power system is concerned with classifying an event according to the morphology of the corresponding waveform. An important and even more difficult problem is the classification of the cause of the event. For this, this article uses different technique of pre-processing (front-ends), selection of parameters and machine learning technique to classify short-circuit type faults."
5788;en_US;"Business process model present various information on how process are performed in company. In a Service Oriented Architecture, these model are important source of information for identifying service with subsequent automation. This work implements the automatic identification of candidate service from process modeled using BPMN notation. The algorithm were developed from heuristics of identification and consolidation of candidate service proposed in another work. The tool was applied in a process model. The information generated on candidate service reduces SOA Analyst time in service analysis."
5789;en_US;"Currently several technique and tool are proposed to allow the end user to interpret large volumes of data stored in organizational databases for a particular decision making. In this work, we discuss ways of interacting with cluster analysis tool, taking into account both clustering and interpretation steps. We investigate how usability and user experience in such tool can improve understanding of discovered knowledge and thus improve decision making over a database. Four different cluster analysis tool were evaluated: Knime, Orange Canvas, Rapidminer Studio and Weka data mining tool."
5790;en_US;"The PET-SI is a Tutorial Education program that aims to train student in a situation of financial fragility to work as a team, raising interest in the adoption of good IT practices and development of actions aimed at technological innovation in computing. This paper presents the FSMA methodology developed by the PET-SI group and discusses its importance for the Information system course at UFRRJ. The paper also presents the main products and benefits generated by the program and the relation of the student academic performance gain during the first months of operation."
5791;en_US;"This article discusses a project that seeks the interaction between the area of education and computing, proposing the realization of a network of knowledge building mediated by technology. Through the cooperation of undergraduates, employees and teachers, Project Interagir aims to transform any existing difficulties and limitations in access to digital media and technological tool into factors of mutual interest, with a view to building knowledge that can contribute to academic and personal training."
5792;en_US;"Considering the applicability limitations of commercial software development methodologies in the academic field, this work proposes guidelines for the development of a new methodology based on XP, RUP and Scrum methodologies that seeks to add to academic teaching and practice an approach based on what happens outside the university environment."
5793;en_US;"We propose a computational model based on the use of Bayesian network, in order to identify factors that lead to evasion in the undergraduate course in Information system of UFRRJ. The proposed model was able to identify the non-correlation of the school source as an avoidance factor. The sensitivity obtained in the prediction of avoidance in the validation set was 93.3%. The result obtained are promising regarding the use of Bayesian network, in the identification of factors and prediction of student evasion."
5795;en_US;"<p>The Vehicle Routing Problem (VRP) is one of the combinatorial optimization problem most studied in Computer Science and of great relevance to the area of logistics and transport. This paper presents a new algorithm for solving the Capacitated Vehicle Routing Problem (CVRP) using Monte Carlo method. Monte Carlo method are statistical method that use random sampling to solve probabilistic and deterministic problem. The proposed algorithm was developed based on Monte Carlo simulation and Clarke and Wright Savings heuristic and demonstrated result comparable to the best existing algorithm in the literature, it overcomes previous work with Monte Carlo method. The comparison, analysis and evaluation of the algorithm were based on existing benchmarks in the literature.</p>"
5796;en_US;"<p>Agile Governance in the Information and Communication Technology (ICT) is an area on the rise and has been suggested as an innovative proposal based on the use of principles and values of the Manifesto for Agile Software Development on Governance in ICT conventional context. However, the adoption of practices to good Agile Governance in ICT is still considered a challenging task due mainly multidisciplinary and relative paucity of the area. On the one hand, there is a set of principles, practices and values of the underlying area this domain, on the other hand, this set is not presented yet organized in a broader context in order to promote a systematic and gradual way to an increase of maturity in Agile Governance in ICT. Given this gap, this article proposes a maturity model for Agile Governance in ICT constructed from a wide bibliographic study involving the area of Governance in ICT, agility and maturity. During construction of the proposed model, it started with a qualitative approach, with inductive method and comparative-structuralist procedures. Finally, this paper presents an evaluation of the model proposed by focus group. As a result, a number of improvements identified during the study is subsidizing the construction of a new version of the model.</p>"
5797;en_US;"<p>This paper presents a methodology to optimize the execution of the commercial service of electric power distribution company. This activity represents a significant portion of the operational costs of these company. How to distribute the service to the teams and define efficient routes is a complex problem due to the great number of possible combinations. The set of geographical positions of the service can be seen as an instance of the multiple traveling salesmen problem. We created a variation of the ant colony optimization algorithm to obtain optimized solutions for the distribution of the service and the route of each team. Our methodology was applied to 17 real word instances obtained from an electric power distribution company from the city of Cornélio Procópio, Brazil. Our method obtained an improvement of 42,23% on average when compared to the solutions that were performed in the real world. To allow the reproduction of our result, the source-code of our system and the dataset are freely available at https://github.com/denilsonfag/STACS.</p>"
5798;en_US;"<p>Learning difficulties in computing course is a situation perceived in diverse universities from different countries, cultures and backgrounds. These difficulties directly affect achievement rates and increase course evasion. We believe in the existence of a foundation of cognitive process, that without it, even the most motivated student would have trouble to transform the received information into knowledge. This work has focused mainly on the research of candidate method for cognitive process assessment with a strong background theory. With this kind of information would be possible to devise cognitive interventions, in order to evolve student cognitive level, and consequently, raise their success rates. A systematic review was conducted and among the many researched method we selected Lawson Classroom Test of Scientific Reasoning – LCTSR. Authorized by its author, we conducted the first translation of LCTSR to Brazilian Portuguese and administered to student of three undergraduate computing course: Information system, Computer Science and Software Engineering. We also present result of its administration that we consider important to reinforce the above suggested strategy.</p>"
5799;en_US;"<p>With the increasing size of information system and their complexity and the limitations that currently have available the IDEs for more complex searches in source code, tool that can help software developers in the retrieval of relevant information becomes very useful . In this context, this paper presents a tool that enables the retrieval, informations in AspectJ code in an unstructured way. This tool allows you to search the structures using only the syntactic value of the query or adding semantic value and thereby improving their result.</p>"
5800;en_US;"<p>In studies that use metaheuristics although the input parameters directly influence the performance of the algorithm its definition is mostly done manually raising questions about the quality of the result. This paper aims to apply the F/I-Race in the self parameterization of GRASP with Path-Relinking in the data clustering in order to obtain better result than the manually tuned algorithm. experiment performed with five data sets showed that the use of I/F-race contributed to achievement best result than manual tuning.</p>"
5801;en_US;"<p>This paper presents Give Me Views tool that can indicate possible modules and components that may be impacted when a corrective maintenance, adaptive or evolutionary is performed. Provides views that allow user to obtain information about the relationships between modules and components based on statistical analyzes performed by an SAE (Statistical Analysis Engine) on historical software data. A proof of concept was performed in order to verify the feasibility of the tool in software development activity in a real context of use. The tool deployment result in a software development company are presented.</p>"
5802;en_US;"<p>This work aims to present an architecture for Android Mobile Augmented Reality (MAR) application which has to be extensible, flexible and adaptable. Extensible to allow the addition of new functionalities in the application; flexible to allow the change of content/data generating custom application; and adaptable to the many mobile device screen sizes. For this reason, we considered an architecture based on the MVC pattern adapted to the context of Android mobile platform, in this adaptation the business logic get out the controller layer and reaches the view layer, in so doing, the controller layer becomes responsible only for managing the request between the model and view layers, ensuring the application modularization. Also, the Fragments user interface pattern was utilized, aiming to a better adaptation to the many mobile device screen sizes. Furthermore, we applied the Remote Proxy design pattern, for abstraction of data source (local or remote), and the Facade design pattern to facilitate the use of query and filters in data. Finally, we present usage scenarios with different data and screen size device to validate the proposed architecture.</p>"
5804;en_US;"<p>Due to the problem caused by population growth in large city, there is a need for solutions that point to the initiative of Smart city, that is, using the technology to offer resource that can help solve or minimize urban problem. This solutions seeks the integration of several source of Information Technology(ICTs), however, those source of Information Technology form complex structures and generate a large volume of data, that represents big challenges and opportunities, impeding the possibility of to make available, system that integrate informations of sensor and capture data from the physical space, getting sample of what is going on in the city in real time. With the intention of offer a reference architecture, to compare issues related with those challenges and opportunities, this paper presents an approach that employs components off-the-shelves for the construction of a crowdsensing platform for solution in Smart city. We performed an experiment to determine the performance and stability of the system. Thus, this proposal opens the way for to broaden the integration of data source of various types of sensor and device.</p>"
5805;en_US;"<p>The construction of rankings consists of ordering retrieved result according to certain criteria. Rankings can provide relevant information to analysts from different sectors of industry. For the music industry, rankings enable understanding how musical genres and popularity of artists and their songs evolve over time, allowing analyses of history data and trends. Due to the importance of building rankings in the musical scope, data mining technique have been used to predict rankings by using information from social media. This work evaluates regression model for prediction of artists’ rankings using historical data (daily rankings of artists) extracted from website Vagalume. Three regression technique (k-Nearest Neighbors - k-NN, Multiple Linear Regression - MLR and Random Forests - RF) were evaluated in this study considering different scenarios. result obtained from experiment showed that predictions with low error rates can be obtained, indicating that data mining technique can be used to obtain information to assist the music industry in decision making.</p>"
5806;en_US;"<p>The emerging scenario of interactive Digital TV (iDTV) is promoting the increase of interactivity in the communication process and also in audiovisual production, thus raising the number of channels and resource available to the user. This reality makes the task of find the desired content becoming a costly and possibly ineffective action. The incorporation of recommender system in the iDTV environment is emerging as a possible solution to this problem. This work aims to propose a hybrid approach to content recommendation in iDTV, based on data mining technique, integrated to the semantic web concepts, allowing structuring and standardization of data and consequently making possible sharing of information, provinding semantics and automated reasoning. For the proposed service it is considered the Brazilian Digital TV System (SBTVD) and the middleware Ginga. A prototype has been developed and experiment carried out with a NetFlix database, As result, it was obtained an average acciracy of 30% using only the data mining technique. On the other hand, the evaluation including semantic rule obtained an average accuracy of 35%.</p>"
5807;en_US;"<p>The technological development in recent years has experienced the exponentially growth of the digital universe, part of this digital universe lies stored in cloud storage system. With each day, more of these system come out, offering datatorage in a distributed manner with the proposal to provide high availability rate, what has driven more and more user who have migrated your data to the cloud. However, the large amount of files stored in these system makes it difficult to filter relevant content, requiring time and labor by the user in searching for files with similar content to your preferences. Face of this scenario, this study proposes a model for recommendation of files in cloud storage system, which aims to use cloud feature associated with the technique of content-based recommendation.</p>"
5808;en_US;"<p>Intelligent Transportation system are application of information and communication technologies aimed at improving the transportation area. Providing information about bus arrival time on the bus stop is very important and useful to passengers and transit managers. This paper presents a proposed bus arrival time prediction system at the bus stop where user is located. For this, an experimental study on bus route named Campina do Barreto No. 722 in Recife-PE, was performed by comparing the regression model for Support Vector Machine (SVR) and the neural network Extreme Learning Machine (ELM) to estimate the time it takes to go through adjacent bus stops. The experiment were performed using the bus GPS log data in the metropolitan region of Recife, and the result showed that for this application the SVR significantly outperforms ELM.</p>"
5809;en_US;"<p>This paper intends to anlyze why e-commerce is more popular than mobile commerce among internet user, despite the growth of mobile market. Through survey research carried out among 130 user, it was possible to infer that people use mobile device along the day and prefer using computer than mobile device in all phases of their purchases. The possible reasons of that behavior is related to safety conditions of m-commerce and errors that occur on eletronic transactions. Mobile device are used auxialiry tool to check available products on market and to follow the track of requests already done.</p>"
5811;en_US;"<p>This paper presents the application of a methodology for evaluation of usefulness of opinions with the aim of identifying which characteristics have more influence on the amount of votes: basic utility (e.g. ratings about the product and/or service, date of publication), textual (e.g. size of word, paragraph) and semantics (e.g., the meaning of the word of the text). The evaluation was performed in a database extracted from TripAdvisor with opinions about hotels written in Portuguese. result show that user give more attention to recent opinions with higher scores for value and location of the hotel and with lowest scores for cleanliness and quality of rooms. text with small values for intelligibility (more difficult) receive more votes than text with large values of intelligibility.</p>"
5813;en_US;"<p>The increasing in the production and availability of unstructured information on the Web grows daily. This abundance of unstructured information is a great challenge for acquisition of structured knowledge. Many approaches have been proposed for extracting information from text written in natural language. However, only a few studies have investigated the extraction of information from text written in Portuguese. Thus, this work aims to propose and evaluate an unsupervised method for ontology population using the Web as a big source of information in the context of the Portuguese language. The result of the experiment are encouraging and demonstrated that the proposed approach reached a precision rate of 67% in the instances of ontological classes extraction.</p>"
5814;en_US;"<p>In this paper, we discuss the architectural project and construction of a framework called Outer-Tuning, which supports (semi) automatic tuning of database system through a specific ontology. The architectural aspects componentbased, interface design, and especially the approach taken to include both a domain ontology and an ontology tasks in an integrative information system. We also discuss aspects of machine inference rule and issues related to the use of logical language. Finally, some experimental result allow an assessment of the expected framework contributions.</p>"
5815;en_US;"<p>With the growing volume of data in various area such as Hydrology, there is a need for using information system to aid in handling such data. This article is a report of an experiment that used knowledge discovery technique to estimate an important component of the hydrological cycle: evapotranspiration. The experiment reported in this article was done with weather data and showed that some algorithm, such as M5P, present good result when compared to historical data of the estimated evapotranspiration.</p>"
5816;en_US;"<p>Business Intelligence technique aim to extract strategic knowledge from great data volumes in organization. With the need do manage and handle timely this data, a Business Intelligence Platform becomes necessary. This paper presents a methodology for generation of platforms for automation of organizational process from University Evaluation Committees, which automate part of the process and support strategic knowledge generation. The proposed methodology comprehends from specification to evaluation of the platform prototype, made according to ISO/IEC 9126 standard. A case study in an University Evaluation Committee was made, and the developed platform had an 88,9% approval rate, considered ready for deplyoment.</p>"
5817;en_US;"<p>Association rule mining has shown great potential to extract knowledge from multidimensional data sets. However, existing method in the literature are not effectively applicable to quantitative temporal data. This article extends the concepts of association rule mining from the literature. Based on the extended concepts is presented a method to mine rule from multidimensional temporal quantitative data sets using genetic algorithm, called GTARGA, in reference to Quantitative Temporal Association Rule Mining by Genetic Algorithm. experiment with QTARGA in four real data sets show that it allows to mine several high-confidence rule in a single execution of the method.</p>"
5818;en_US;"<p>Content-based Recommendation system (CbRS) is a research area in which Machine Learning (ML) strategies can be applied with success. However, specifically in textual CbRS, the use of ML has not been expressive in recent years. To contribute to the evolution of the intersection of such area, we present a Systematic Review to identify, interpret and evaluate how the ML strategies have been applied to CbRS.</p>"
5819;en_US;"<p>This paper presents a method based on Artificial Neural Network that evaluates the rotational bad-positioning of fingers on touchless multiview fingerprinting device. The objective is to determine whether the finger is rotated or not, since a proper positioning of the finger is mandatory for high fingerprint matching rates. A test set of 9000 acquired image has being used to train, validate and test the proposed multilayer Artificial Neural Network classifier. To our knowledge, there is no definitive method that addressed the problem of fingerprint quality on touchless multiview scanners. The proposed finger rotation detection here presented is one of the steps that must be taken into account if a future automatic image quality assessment method is to be considered. Average result show that: (a) our classifier correctly identifies bad-positioning in approximately 94% of cases; and (b) if bad-positioning is detected, the rotation angle is correctly estimated in 90% evaluations.</p>"
5820;en_US;"<p>With the technology advances, new approaches for automatic recognition of a person’s identity have been proposed and such a fact has encouraged the use of Biometrics system. This approach uses physical or behavioural characteristics of the user in order to recognize or authenticate their identity. The Biometric system can be classified as Unimodal or Multimodal. The Unimodal system use a single biometric modality to perform the recognition, while the Multimodal ones use two or more modalities. A Multimodal Biometric System can be constructed in different ways, according to its architecture, fusion level and fusion strategies. The main of this work is to investigate and compare different feature level fusion strategies, in order to design a Multimodal Biometric System with high performance. In this paper, we used the discrete wavelet transform to extract the feature sets from iris and face image. Experimental result show that Multimodal Biometric system outperform Unimodal Biometric system according to recognition rate computed over the outputs produced by the induced Support Vector Machine classifier.</p>"
5821;en_US;"<p>Information system (IS) industry has been pressured to deliver software products under reduced time-to-market and restrict budget. Agile Methodologies (AM) have been adopted to meet those aforementioned needs by the adoption of self-managing teams, iterative development cycles, fast delivery, and focus on functional software. Adoption of AM requires a suitable organizational environment, with significant changes in the employees’ behavior and in the working process, impacting, and suffering the impact of Organizational Culture (OC). In this direction, method, actions, and policies must be thought to align the company’s OC to the use of AM, in such a way that both can benefit each other. However, there is a lack of proposals that systematically investigate how to align both OC and AM. In this sense, a systematic mapping study (SMS) was conducted to identify studies that associate OC in initiatives of AM adoption. This paper presents the state-of-the-art about the influence of OC in the adoption of AM. The main contribution of this paper is bringing up an overview of the area, indicating perspectives of research, and exposing (i) a list of actions which have been reported to align OC and AM; (ii) OC factors recognized as essential to the successful adoption of AM; and (iii) the perceptions on a lack of awareness about the influence of OC in IT organization.</p>"
5823;en_US;"<p>Business and IT system are facing increasingly complex environments characterized by collaboration, change and variety of customers, suppliers and products. Group storytelling technique can contribute to the business knowledge management. The stories count brings benefits from capture to securing information, through communication and understanding of the concepts. American company (3M and Apple), Japanese (Sony and Toshiba) and European (ClubMed and Océ) already use this approach in practice. Ontology Engineering can contribute towards improving the quality of information and offer a solution to address knowledge management systematically. However, the specification and manually made of ontology management can be expensive, tedious, biased and prone to error. Automatic learning ontology is an approach that extracts ontology from the data, both structured and unstructured (text). This work presents, at the exploratory stage, a proposal able to specify, automatically, elements of an ontology, from the tacit knowledge of those involved in the field. An exploratory study was able to get the concepts of an ontology, automatically, from stories told by a group storytelling tool on the business process of one department of the University.</p>"
5824;en_US;"<p>Indoor location data are critical in emergency situations. Command centers need to monitor their operational forces. Rescuers need to find potential victims to carry proper care and the building’s occupants need to find the way for fast evacuation. Despite the growing body of research in indoor location, no technique is considered appropriate for different situations. Furthermore, few studies have analyzed the applicability of these technique in an emergency setting, which has particular characteristics. This survey review work in indoor location applied to emergency scenarios, analyzing their applicability in relation to existing requirement in these types of situations.</p>"
5825;en_US;"<p>When making judgments, people rely on heuristics or shortcuts that can lead them to good solutions. In certain situations, however, these technique can cause inconsistencies and promote cognitive biases. Referring to software process improvement initiatives, it is important that the practices, technique, method and tool suggested for the process provide mechanism to support decision-making, thus minimizing the negative effects of such biases. This paper, based on a qualitative research applied in two IT company in Brazil and Portugal, aims to examine eight biases: anchoring bias, exposure effect, hindsight bias, halo effect, planning fallacy, sunk-cost fallacy, availability-related bias, and Parkinsons law effect. Through semi-structured interviews with project managers (PMs), roots causes were identified for each bias, as well as method and tool used to minimize its negative effects, which were consolidated into a concepts map. Agile practices and knowledge management activity were cited as essential in software process focusing on decision-making improvement.</p>"
5826;en_US;"<p>organization are increasingly looking for data integrity and quality to assist in strategic making decision and value creation. In this context Data Governance (DG) provide process and practices that assist in the management and maintenance data. There are many framework to implementation DG process and benefits they may provide, however there are few implementation reported in the literature. This study aims to identify the DG process and framework implemented in Brazilian organization and compare the benefits in implementation with those proposed by literature. For this will be carried out case studies in Brazilian organization that implemented or are implementing DG framework.</p>"
5827;en_US;"<p>The performance of a graduate program is assessed by CAPES partly by their level of publication. Therefore, it is necessary that the program chair has instruments to analyze the quality of publication produced by the associated researcher. In the context of co-authoring relationships in publications, network analysis has been proved to be an appropriate tool to evaluate the relationships already formed, and to stimulate the formation of new relationships. This paper presents a network analysis tool applied to real data of a graduate program from a Brazilian Federal University. The data was modeled in a NoSQL graph oriented database including all associated researcher’ publication. We emphasize the usefulness of the partners’ recomendation module to the program chair, as well as associated researcher. The development of this research work used the Design Science Research methodology to guide both the construction of the artefact and the associated documentation. Preliminary, using data from a graduate program, we can note the recomendation potential to integrate new partners to the scientific network already formed.</p>"
5828;en_US;"<p>The advent of virtual and dispersed organization increases the demand for collaborative system and encourages research in the area of Computer Supported Cooperative Work (CSCW). Conflicts are inherent to collaborative work and can motivate reflection and interaction among stakeholders. However, current approaches to conflict management does not provide mechanism to stimulate these process. Moreover, only few use the context in supporting the resolution of the conflict. The aim of this work is to present a Context Sensitive Metacognitive Conflict Management (GCSC) approach for collaborative planning system that promote reflection and interaction among stakeholders in order to improve collaboration. The approach evaluation was performed by using a prototype implementation of an ontology and an experimental study.</p>"
5829;en_US;"<p>In this paper an approach to support Sprint Planning in Scrum project is discussed. This approach allows the automatic determination of the optimal set of tasks for a given sprint, as well as its execution flow, considering the a priori information concerning the current state of the project, tasks’s difficulty and importance, and the relations between tasks. The proposed solution is based on the representation of the project decision space, defined by this information, as workflow model. To evaluate the approach, a prototype has been developed and is being assessed in the context of the Cornea Notification and Collecting Information System (Sincap) project. The result suggest that the use of the approach provides greater determinism for the sprint planning process, easies the viewing and evaluation of project scenarios and decreases planning time.</p>"
5830;en_US;"<p>The adoption of information security model, implementation of policies and fitness for any information security standard is rare for Small and Medium Enterprises (SMEs) because, often, the complexity of the rule. As these organization contribute to much of the national economy, being the largest employers in Brazil, it was necessary to research ways to try to fill the gap. For this purpose the present study analyzed with real sample of 48 SMEs, through a questionnaire, which the vision of information security for SMEs and proposed a model simplifying controls 133 of ISO / IEC 27002 for just 22. This simplified model was , later also validated via questionnaire with ICT professionals in SMEs.</p>"
5831;en_US;"<p>The ISO 27001 adoption grows worldwide motivated primarily by the need for compliance and as a way of improving the management of assets and risks of organization. Many are the challenges to establish and maintain a Information Security Management System (ISMS) effective and adds value. However, the Brazilian organization studies about these challenges are scarce. This article identifies and analyzes some of the challenges faced in establishing and maintaining an ISMS on the national scene using the multiple case study method. Obstacles such as lack of management support, lack of training of information security area, influence of local culture, failures in risk analysis and resistance to change were systematically identified.</p>"
5832;en_US;"<p>To understand the actions that lead to successful attacks and also how they can be mitigated, researcher should identify and measure the factors that influence both attackers and victims. Quantifying security is particularly important to construct relevant metrics that support the decisions that need to be made to protect system and network. In this work, we aimed at investigating the lack of validation in security quantification method. Different approaches to security quantification were examined and 57 paper are classified. The result show that most of paper seek to measure generic and complex targets like measuring network security or the security of an entire organization, however, the incidence of validation attempts is higher in work that propose the quantification of specific targets.</p>"
5833;en_US;"<p>requirement engineering is concerned with the identification of service (functional requirement) and restrictions (non-functional requirement) that a system must meet to satisfy the needs of its user. requirement, in turn, are increasingly influenced by the context in which the system are used. In the search for system that are adaptable to the needs of user and to changes in the operating environment, context-sensitive system arise. There is a need for a process to systematically elicit context to such system. Given this scenario, we propose a process to elicit requirement and contextual information to be used during the requirement elicitation phase. The process is based on the Storytelling Group technique and also includes mind maps, the 5W1H dimensions (who, what, when, where, why and how) and the conditional dimension that are used to structure and organize the information collected; heuristics were defined to guide the identification of context from the information captured in the mind map structured with 5W1H + conditional. Moreover, the contextual information is analyzed and modeled using a specific framework for context. To illustrate the use of the process, a Smart Home system was used. The process was also applied in the context of an information technology company for evaluation and posterior refinemnt. Then, the effectiveness and easiness of use of the process were evaluated in an empirical study in an academic environment. The result obtained indicate that the process is useful and easy to use, bringing benefits to the development of context sensitive system.</p>"
5834;en_US;"<p>Software Product Line (SPL) Engineering is a software development paradigm that fosters systematic reuse. It is focused on improving software practices, leading company to experience benefits, such as reduced time-to-market and effort, and higher quality for the products delivered to customers. However, establishing a SPL is neither a simple nor a cheap task, and may affect several aspects of a software company. Besides, it involves a range of risks that may hinder project success. These have to be managed accordingly, so as to minimize the likelihood of project failure. Despite the importance of Risk Management (RM) for SPL Engineering, little has been published in terms of suitable and structured practices to cope with that. This present paper reports an approach for RM in SPL Engineering, named RiPLERM (Rise Product Line Engineering – Risk Management). The approach presents activity to structure RM in SPL project, The design of the RiPLE-RM approach elaborated on result from empirical investigations, and was proposed to facilitate the management and provide significant insights that can be used to avoid and solve risks.</p>"
5835;en_US;"<p>Information security is an important concern for information system development. Managing and executing authorization rule (which constrain who is allowed to execute some action over which information) are crucial issues. This work presents a tool for managing authorization rule part of a role-based framework for access control. Business user may use this module to specify authorization rule using an ERM (entity-relationship model). The module was implemented using open-source technologies, in a real organization that is responsible for controlling the access of several information system to a corporate database. An example of its use is presented, illustrating its viability and efficacy.</p>"
5836;en_US;"<p>A design pattern is a general reusable solution to a recurring problem in software design. Bad smells are symptoms that may indicate something wrong in the system design or code. Therefore, design pattern and bad smells represent antagonistic structures. They are subject of recurring research and typically appear in software system. Although design pattern represent good design, their use is often inadequate because their implementation is not always trivial or they may be unnecessarily employed. The inadequate use of design pattern may lead to a bad smell. Therefore, this paper performs an exploratory study in order to identify instances of co-occurrence of design pattern and bad smells. This study is performed over five system and discovers some co-occurrence between design pattern and bad smells. For instance, we observed the co-occurrence of Command with God Class and Template Method with Duplicated Code. The result of this study make it possible to understand in which situations design pattern are misused or overused and establish guidelines for their better use.</p>"
5837;en_US;"<p>The access to information, in the public sphere, is considered a fundamental right and it is advocated in declarations, conventions and laws. This study is inserted in this context and uses a checklist to identify and explore problem of transparency in existing websites. This checklist is based on checkTrans, where some actions were excluded and some were customized. 30 websites were evaluated through the execution of predefined tasks, observing if they work as the actions suggested by the checklist. The quantitative analysis of the result exhibited evidences of a relation between the quality of the institutions and how their websites complied with checklist suggestions. This analysis also indicates transparency problem in all of the analyzed websites and suggests some corrective actions.</p>"
5838;en_US;"<p>Opportunistic network are one of the most interesting developments of MANETs, which allow various application, such as downloading the mobile traffic, communications in emergency situations and contour censorship. The increasing number of mobile device should, in theory, promote opportunistic network. However, in practice, current technologies for opportunistic network, such as Wi-Fi ad-hoc, Bluetooth and Wi-fi Direct, or arer not available in current device, or unwanted require user interaction to establish connectivity. To overcome these shortcomings, we propose an architecture that uses the Wi-fi infrastructure mode in order to promote communcation between device, allowing the transparent exchange without user interaction content. Two application that employ the use of this architecture are presented. The first, from personal device, proved to be scalable in tests with up to nine device. The second, vehicles, proved to be feasible when applied in scenarios with low speed, generating a low packet loss and high transmission rates.</p>"
5839;en_US;"<p>Although the use of open-source software (OSS) is a reality for information-technology company, there has been little academic research on the factors impacting the process by which OSS is adopted, the way OSS is adopted, and the business model as employed. The TOE (Technology, Organization and Environment) framework has been used to study the influence of technological, organizational, and environmental factors considered by company when adopting OSS. In this work, we collected data through online surveys answered by workers in IT company in the state of Minas Gerais, Brazil. The proposed model for determining the impact of each factor on the adoption of OSS and on the business model practiced by IT company was evaluated by using structural equations. The result show that three groups of factors impact the way of OSS adoption. Organizational and technological factors are the most relevant, whereas for business model only environmental factors are relevant. The most relevant technological factor identified is reduced hardware and software costs; the most relevant organizational factor is flexibility of IT structure; and the most relevant environmental factor is reports of successful use of OSS. We verified that IT company in Minas Gerais use OSS in software development, either by incorporating OSS components into their software products or by employing OSS tool for software development.</p>"
5840;en_US;"<p>Small farmers realize that the adoption of information system and wireless communications in the field is more than a trend it becomes a necessity. Despite having access to mobile telephony, they do not usually use mobile application to improve their operations. this work presents a novel computational approach focused on improving the quality of Brazilian tomato crops. Wr present a low cost and ubiquitous computing environment based on precision agriculture principles to support small farmers to inspect tomato crops and to help them to early detect late blight, one of majos disease affecting tomato plants in Brazil. Our initia result have shown that the approach is capable of handling field observations, retrospective provenance descriptors and process image with neural network to assist small farmers in automated detection of the foliage disease.</p>"
5842;en_US;"<p>In this paper, we report a case study carried out in order to analyze the potential of applying knowledge discovery as a strategy to support decision making in public administration. The discovery of knowledge was implemented by using a binary classifier to predict the success of failure concerning cost and deadline plans. The prediction was made analyzing descriptive data of the plans. The dataset was obtained from a project management system that was built based on the practices of the PMBOK guide. The strategies used in this case study, the difficultiesfaced during the classifier modeling process and the result are discussed herein.</p>"
5843;en_US;"<p>Context. The assessment of maturity of the testing process, although it is consensual in organization and universities also requires affordable tool for informal assessment in small businesses according to a maturity model, as TMMi. Purpose. Identify and evaluate instruments to measure adherence to Level 2 of maturity, according to the TMMi, the testing process in small businesses. Methodology. It is an applied qualitative exploratory study which includes conducting a case study in small businesses. Involves: identifying assessment tool, featuring company, application and analysis of the instruments and their result. result. Two instruments, were applied in the process of two enterprises. The instruments have different level of detail, and the result obtained differ at various area of the process. Conclusions. The creation of an instrument with details on the practices and work products of the testing process, are not sufficient for understanding the practice, it requires more support for the domain of feature. There is still need for preparing the companys evaluators to better assessment of the practicals.</p>"
5844;en_US;"<p>More than 50% of the Brazilian company do not survive to its second year due to the lack of a proper business strategy plan. The Balanced Scorecard(BSC) methodology was proposed to help company create simple strategy plans that can be explained to all employees within all company levels. The core of this methodology is the strategy map that shows a collection of strategic objectives that a company needs to achieve to reach its mission. Small and medium company find it difficult to create their own strategies without the help of a management consultant, which is not always affordable. We proposed the Mistral Solutions, a system that helps managers to build strategy maps according to the BSC methodology. To easy the numeric knowledge acquisition process, a manager can answer a question using a verbal anchor scale instead of a number. This system is based on fuzzy logic. Fuzzy rule are instantiated from the answers given and indicate the most adequate strategic objectives. This paper presents three study cases based on the use of the Mistral Solutions. The Regional Labor Court of the 10a Region, a company in the civil construction industry, and a Real Estate Registry Office are focused as case of study. The strategy maps proposed by Mistral Solutions were empirically validated by a BSC specialist and by managers in charge of strategic planning of these institutions. These institutions represent the public sector, the private sector, and a public concession. Mistral Solutions selected the eight more appropriate strategic objectives from a set of forty five, two for each classic BSC perspectives. In the empirical evaluation, the system performed better when applied to private sector institutions when all the eight strategic objectives were considered adequate by the manager in charge of strategic planning of this institution.</p>"
5845;en_US;"<p>Software testing is an important component that leads to quality software production. This paper presents the result of a framework for assessing the level of maturity in Software Testing application in the context of Small and Medium-Sized Enterprises (SMEs) based on TMMi model. Our framework includes an evaluation questionnaire based on TMMi sub-practices, support tool with examples of artifacts required to ensure that the questionnaire is thoroughly completed, as well as an automated tool support for its application, enabling SMEs to carry out self-assessment. The framework was applied in ten company and before the result presented, it can be concluded that the company maturity in software testing is low and that the company positively assessed the adequacy of the framework developed for the context of SMEs.</p>"
5846;en_US;"<p>Although digital computerization is already quite common, the use of health information system is still very poor in most of the places. From a regional demand for support of health professionals working in basic health units (BHU) in the city of São João del Rei/MG, a research was conceived for development of an information system for sharing electronic health records among various BHU. In this article we present a review of the use of SANA, a standard-focused open-source platform to facilitate the creation and sharing electronic health records, for the development of an information system. For this, we developed and evaluated a prototype representing electronic records as requested by health experts. Finally, lessons learned are presented as well as solutions to problem encountered during development, including a reflection on the utility and convenience of the prototype generated by SANA platform considering the application context, and recommendation for future development.</p>"
5847;en_US;"<p>Ecosystem are an important aspect of today’s software business. Different company aim to create an ecosystem around their products so that they can benefit from this. Unfortunately, creating such ecosystem is not an easy task. One of the few tool that can be used to facilitate this process is Adner’s Value Blueprint. This tool allows a company to identify the different types of risks that it faces during the establishment of an ecosystem. Adner presents several examples of blueprints he has built and provides some guidelines to create new ones. Given the potential of the approach in addressing some of the issues faced by ecosystem designers, we decided to assess the usage of the Value Blueprint through a case study using data from the Apple Watch ecosystem. We report our result from the Apple ecosystem, and more importantly, our evaluation of the value blueprint tool. We conclude by providing recommendation for practitioners interested in establishing their own ecosystem and researcher interested in the design of ecosystem.</p>"
5848;en_US;"<p>The maintenance management aims to estimate the equipment conditions over time or to make predictions or diagnosis of failures. With the growing of Information system, like a Factory Information system, Process Mining technics could be used to support maintenance decisions making. To ensure the quality and reliability of the information obtained, improvements must be made in events acquisitions. This paper proposes recommendation for structuring the records of Factory Information system events, aiming to facilitate the application of Process Mining algorithm. We use as case study of a parts manufacturing process for the automotive sector, using a CNC machine. It is concluded that the main cause for the reduction of quality of information is due to lack of delimiters events and incorrect input events by the operator. With the application of the proposed improvements, we try to extract information to optimize costs, increase equipment availability and guide the implementation of improvements in production process.</p>"
5849;en_US;"<p>Business Intelligence (BI) relies on Data Warehouse (DW), a historical data repository designed to support the decision making process. Without an effective Data Warehouse, organization cannot extract the data required for information analysis in time to enable more effective strategic, tactical, and operational insights. This paper presents an approach and a Rapid Application Development (RAD) tool to increase efficiency and effectiveness of ETL (Extract, Transform and Load) programs development. An experimental evaluation of the approach is carried out in a controlled experiment that carefully evaluated the efficiency and effectiveness of the tool in an industrial setting. The result indicate that our approach can indeed be used as method aimed at improving ETL process development.</p>"
5850;en_US;"<p>System developers often face problem in the maintenance and evolution of software system when they need to customize products to meet different customers needs, by creating new components and modifying existing source code. In this work, it is presented a comparative analysis of existing approaches that deal with variations in Software Product Lines (LPS) through a rigorous study of the state of the art, observing their applicability to handle customizations.</p>"
5851;en_US;"<p>One of the biggest challenges for an organization IT area is to provide support so effective and efficient that the finalistics area can achieve their missions, goals, indicators and compliance with legal requirement. The key to this problem is associated to information system which are based on business model, being properly analyzed and specified, originating products that are close to business objectives and strategies. This article presents the experience with a complete restructuring proposal of the IT area, which includes changing internal process, customization and deployment of software tool, involving organizational cultural changes. The proposal was implemented with the help of a framework, being used in many IT project at the Ministry of Science, Technology and Innovation. When Complete the first execution cycle some organization benefits were verified, such as IT service quality, customer satisfaction and engagement, as well as transparency on IT project.</p>"
5852;en_US;"<p>As the volume of data on the web continue to increase, it is getting more challenging for the search mechanism to find with a high precision rate what the user want to find. As a solution to improve these result, the development of a recommender engine, based on the content of the document, would prove itself very useful. In this context, this research has the objective to show how the current search and indexing tool could be improved with recommendation, Machine Learning and textual analysis algorithm. The idea behind these project would be to, based on the content of the document recovered in the search, find similar document using most of the Open Source technology we have available right now.</p>"
5853;en_US;"<p>This paper presents an approach based on ontology and Semantic Web specifications for information management of intelligent transport system. The methodology includes the creation of an ontology-based model for representing spatiotemporal information as well as the model validation by means of the development of an urban transportation management system for a Brazilian metropolis. The authors argue that the combined use of ontology and Semantic Web standard specifications for interchange and query makes it easier the development of intelligent transport system concerning homogeneous and shared semantic representation among application.</p>"
5854;en_US;"<p>The study of new approaches that seek to improve the diagnosis of pathologies in the vocal folds process, is one of the main motivators for health research based on voice. Not only by the creation of new technique, but in the use of already existing technologies using new approachs, such as the mobile technologies in fields they were never fully explored, or barely explored at all. This article is intended to further increase the development of the m-health’s field, specifically the early diagnosis of the vocal fold’s disease through analysis of the fundamental frequency of the speaker’s vocalization improving the support in medical decision. The result shows 95% with a minimum of 10hz difference.</p>"
5855;en_US;"<p>This paper presents a novel information system to assist in psychological treatments through pictures taken by the camera of smartphone or tablets, creating a new communication channel between patient and therapist by the use of the proposed application Fotossenti. The purpose of this application is to help in the generation and management of information to be considered on the patient’s therapy sessions, which could go unnoticed in the traditional way. This paper presents a brief theoretical foundation on Information and Communication Technologies (ICTs) applied to Health, especially those focused on psychology and considered in the development of this work, as well as unique characteristics of Fotossenti, with an assessment by specialist in psychology, and, finally, the challenges and opportunities found along the research. The conclusion recaps the importance of the development and use of new ICTs, particularly new information system in the field of psychological health, and places the Fotossenti application as a tool to contribute to the generation of information for psychological treatment, and consequently the decisions taken by the therapist, increasing the benefits of treatment.</p>"
5856;en_US;"<p>The Brazilian Ministry of Health and other related organization are concerned with the issue of self-medication. Although these organization warn about the risks of concomitantly using different drugs, they do not provide any tool to facilitate this process. ANVISA offers a collection of 6.076 medication guides in PDF file format. However, the information available in this guides are in an unstructured format. One of challenges of this work consisted in the automatic retrieval of information from ANVISAS’s medication guides. This paper presents a semiautomatic procedure that maps ANVISAS’s medication guides to DrugBank and SNOMEDCT. The medications, the disease, the drugs, and their relations were structured and stored on a graph database using the Neo4j technology.</p>"
5857;en_US;"<p>The use of digital game for educational support can motivate student, but this use should be well exploited for pedagogical success, behaving as allies in the conventional process, addressing the concepts seen in the classroom. Thus, this paper presents considerations and result on the creation and testing of Ludo Educational Atlantis, which is an educational digital game system, in which student of elementary school can participate in an electronic board game. It challenges are presented in the form of questions and answers defined by a responsible teacher who can monitor the result of their student. For initial validation, the game was used in a State School of São Carlos-SP, in a Science discipline, being reported in this paper the considerations and result from this experience.</p>"
5858;en_US;"<p>Investors in the stock market employ various technique of graphical analysis to assist in decision making about their investments. To facilitate the use of these technique are developed tool able to process large volumes of data in order to present consolidated information to investors. However, most of these tool is complex to use for those who are beginners in this kind of market and therefore needs help to make more informed decisions to minimize the damage and maximize profits at the same time. In this context, this work presents the Chronos Ações, a tool developed to support investors in making decision to purchasing or sale of assets on the BM&amp;FBOVESPA, which is the main stock exchange of Brazil.</p>"
5859;en_US;"<p>The advance of the Internet, mobile device and their application are providing a new range of data and habits that can help achieve our goals everyday and still provide us a better quality of life. In this context, we present the RateMyDay, which is a tool for mobile device. This tool aims to support people in adapting and monitoring daily routines. People will be able to record and analyze, in a simple, private and personal, their day to day and thus form and monitor your routine life. In a second step, they can analyze your progress through a historical, indexes and statistics.</p>"
5860;en_US;"<p>The Balanced Scorecard (BSC) methodology was proposed to help company create simple strategy plans that can be explained to all employees. The core of this tool is the strategy map that shows a collection of strategic objectives a company needs to achieve its mission. Small and medium company find it difficult to create their own strategies without the help of a management consultant, which is not always affordable. This paper presents the Mistral Solutions, a system that supports entrepreneurs and their teams to create their own BSC initial strategy maps. The system proposed is based on fuzzy logic. Initially the user takes a online survey about his/her enterprise. During the knowledge acquisition a verbal anchor scale can be used to represent numeric information if the entrepreneur does not know the exact values for each question answer. The Mistral Solutions uses the answers to ground fuzzy rule for creating business strategies in the shape of BSC strategy maps. The system proposes eight strategic objectives, two for each of the four classic BSC perspectives. These strategic objectives are chosen from a set of forty-five possibilities. The knowledge base has one-hundred-eleven variables and onehundred-twenty-six fuzzy rule. This system was applied to institutions representing the public sector, the private sector and a public concession. In the empirical evaluation, the system performed better when applied to private sector institution when all the eight strategic objectives were considered adequate by the manager in charge of the strategic planning of this institution.</p>"
5861;en_US;"<p>This paper presents the result of a research that has the objective to provide information about the Brazilian Information system Community. The study used data from the articles published on the main track of the Information system Brazilian Symposium (SBSI) from 2005 to 2014. The data were stored in two databases (DB), using different approaches database (relational and NoSQL).A study about efficiency aspects of both database approaches was conducted in order to investigate which alternative is better to store and retrieve information about the community.</p>"
5862;en_US;"<p>The Experimental Software Engineering is one of the sub-area of Software Engineering (SE) and the aim is to improve method, technique and tool ES, from experimental method. An experimental project involves several steps and activity that must be carried out by the researcher and participant, generating large amounts document. This paper deals with experimentation in software engineering, presenting a tool for management of experimental project, called TESE (Tool for Experimental Software Engineering), the main difference is the provision of aid to its members in relation to the concepts of Experimental Software Engineering. Evaluation one tool with student and former student of Bachelor of Computer Science at the Federal University of Goiás (Regional Jataí) was performed. For this, we used a questionnaire built on the model TAM (Technology Acceptance Model), in order to find out what the reviewer think about the usefulness with ease of use of TESE tool. The result was considered positive, as on average 80% of the evaluators agreed that the tool has good utility and ease of use.</p>"
5863;en_US;"<p>This systematic review aims to consolidate the understanding of the term Computer Literacy, which corresponds to the classification of the first stage of learning skills and knowledge about the aspects of information and communication technology (ICT). In addition to this concept, the study also aims to assess the range of knowledge and skills related to computer literacy. This review was based on ACM and ERIC research bases, comprising the period of the last 10 years, and adding some extra articles that were deemed relevant. The conclusion indicates that Computer Literacy has a dynamic nature – exhibiting evolution over time – and an inherent need to upgrade constanly in order to keep up with information and communication technology’s evolutionary curve.</p>"
5864;en_US;"<p>Teaching Information system (IS) for computer student, with course very related to Information and Communications Technology (ICT) requires adapting the subject with a different approach. To achieve this goal, this paper presents a methodology that exemplifies the application of IS knowledge inside ICT organization or ICT departments. The content used and its importance were evaluated applying a questionnaire to the student. Responses showed that this method increased student’ IS subject understanding and the desire to apply IS knowledge in their professional activity.</p>"
5865;en_US;"<p>The ERP system usage for the teaching/learning process to business administration student is an important tool in the acquisition of knowledge about business process integration view. Several authors have stated that the learning of ERP system could be favored by the application of the hands on methodology, on which the student build your knowledge through tool provided by educator. The objective of this paper is describe an experience with a 68 student about the ERP system usage according to hands-on approach as a tool to facilitate the teaching/learning process in bachelors on business administration course. The analysis of this approach was made through a methodology based on comparison of a student’s knowledge related to a general sales process before and after of hands-on exercise application. It was possible to observe an improvement of knowledge about the sales process, highlighted through the comprehension of the involved actors as well as the relationship between them and the executed tasks.</p>"
5867;en_US;"<p>This paper discusses qualification and acknowledgement of IT (Information technology) professionals in conceptual terms originated on psychology and sociology of work, and empirical ones originated from tree researches: one run among IT Brazilian professionals about acknowledgement; another among graduated in Information system, about acknowledgement and qualification; a case study in an IT organization. It is concluded that social professional acknowledgement are not substantial as perceived by that professionals (social status and wages counts on that perception), despite the acknowledgement of work done by them on organization might be good. On the other hand, required qualifications are not obtained only through regular or technological undergraduate course, but also through personal effort and technology certifications.</p>"
5868;en_US;"<p>This study aims to verify the existence of significant differences in propensity to technology adoption, considering user and not user of the Nota legal. To achieve the goal, among several other methodologies, we opted for the employment of the Technology Adoption Propensity Index (TAP-I). The study was carried out from a quantitative approach, through survey with convenience sampling, obtaining the return of 201 valid questionnaires, and at the end, we used the nonparametric method Mann-Whitney U test for the comparison between groups. At the end of the study it can be concluded that there are statistically significant differences between user and non-user of the program Nota Legal, when searched for the technology adoption propensity.</p>"
5869;en_US;"<p>The social media use has been diffusing since they are enabling information sharing and the creation of virtual communities and interaction mechanism. Due to its characteristics, public agencies have used social media for mobilizing, inform and call their public to take part of social participation. However, if this kind of tool is capable to promote engagement in the public, is still a matter to be worried of. Thus, this study aims to analyze how a governmental social media functionalities influence the engagement of user. Then a netnography study was accomplished. In this study we observed and analyzed interaction from a community in a social media platform that was released by the Brazilian federal government. Finally, we verified that some of its resource were not well explored by user. Even if they got through the process of engagement, their use experience was not so satisfactory to make them keep their access frequency</p>"
5870;en_US;"<p>Online communication and collaboration tool are widely employed by user in order to express their opinions on a vast amount of subjects. These tool were not designed to accurately identify topic, nor to point out relationships between topic elements related to a given discussion. As it turns out, there is a staggering amount of user-contributed information generally available, and conversely, a huge challenge related to accurately pointing out featured topic and their intertwining relationships and source. The main purpose of Argument Web is to define a rich, full-featured annotation model capable of storing relationships between topic and their source. Given the availability of rich, interlinked data about a number of related subjects, Argument Web can potentially increase the quality of online discussions and the analysis of its components. However, there is still a reduced number of real-world application based on these concepts. Even in well-known project, theres still a lack of exploration efforts related to the use of open and linked data. This paper presents an application model based on Argument Interchange Format (AIF) and state-of-the-art semantic Web technology. Its main contribution lies in the integration of external source information, linked data formats and data visualization aspects. The solution is then evaluated through a case-study related to the use of open and linked data on the field of public administration.</p>"
5872;en_US;"<p>Governments make use of internet to be closer with their governed nowadays. Therefore, government sites must be able to be used by anyone who wanted to. The present paper exposes an analysis of three known usability inspection method (Cognitive Walkthrough, Heuristics Evaluation, g-Quality) and exposes theirs differences and similarities. This paper makes a comparison between them willing to suggest a better usage of them also.</p>"
5873;en_US;"<p>This paper aims at demonstrating the effectiveness of a support tool for the social control of public management, the so-called SICM—Educação (Integrated System of Municipal Costs — Education), which has been developed at the University of Londrina in a joint effort of the Department of Computing and the Department of Administration. The purpose of such a tool is to allow visualizing and comparing costs of school, e.g. within a city. The paper shows a case study using the proposed tool over data obtained from one of the conducted surveys, regarding the city of Assaí/PR. It is also shown how the tool can be used to visualize the collected data and how it can be used to aid decision-making in public power, which enforces transparency and citizens control over the public administration.</p>"
5874;en_US;"<p>Information system that support public sector daily activity generate large data sets. As a large proportion of the data in these data sets are text, Text Mining can play an important role in deriving potentially useful and previously unknown information. The overall goal of this paper is evaluate the performance and quality of three text mining classification algorithm applied to detect irregularities in public sector records. To evaluate the algorithm, a tool was designed and a case study was carried out at the Court of Accounts of Sergipe. Performance and Quality metrics were evaluated: mean execution time, accuracy, precision, coverage and F-measure. The result show that the multinomial naive bayes algorithm using inverse document frequency was the best approach to find evidences of travel reimbursement irregularities.</p>"
5875;en_US;"<p>This paper proposes a recommendation system facing virtual communities seeking to analyze the proposal impacts presented in a dedicated virtual community for debate and discussion of matters of public interest. To conduct the evaluation, there was an experiment used the virtual community described after the implementation of the proposal. The analysis of data collected during the experiment showed relevant evidence related to implementation of the proposed.</p>"
5876;en_US;"<p>A Business Intelligence (BI) System employs tool from several area of knowledge for the collection, integration and analysis of data to improve business decision making. The Brazilian Ministry of Planning, Budget and Management (MP) uses a BI System designed with the University of Brasília to ascertain irregularities on the payroll of the Brazilian federal government, performing audit trails on selected item and fields of the payroll database. This current auditing approach is entirely deterministic, since the audit trails look for previously known signatures of irregularities which are composed by means of an ontological method used to represent auditors concept maps. In this work, we propose to incorporate a statistical filter in this existing BI system in order to increase its performance in terms of processing speed and overall system responsiveness. The proposed statistical filter is based on a generative Gaussian Mixture Model (GMM) whose goal is to provide a complete stochastic model of the process, specially the latent probability density function of the generative mixture, and use that model to filter the most probable payrolls. Inserting this statistical filter as a pre-processing stage preceding the deterministic auditing showed to be effective in reducing the amount of data to be analyzed by the audit trails, despite the penalty fee intrinsically associated with stochastic model due to the false negative outcomes that are not further processed. In our approach, gains obtained with the proposed pre-processing stage overcome impacts from false negative outcomes.</p>"
5877;en_US;"<p>In Brazil, the use of e-government is a relatively new. It first started in 2000, and since then, the web platform, through the web sites, has been widely used to strengthen the relationship with the Brazilian citizen, to provide service and to enhance transparency and access to information. Among the main pattern of e-government, the e-MAG and e-PWG model stand out. The first model is responsible for digital accessibility guidelines, and the second model is a set of technical guidelines for the development of sites and managing digital content. The Brazilian government is also implementing, since 2013, the Government Digital Identity, a project that aims to standardize the navigation logic and the structure of government sites from the federal level. This article aims to show that key government sites, despite all efforts, still do not implement the standards set by the Brazilian Electronic Government properly. We used code validators to evaluate and to analyze thirty-nine sites related to the ministries of the federal government. During our analysis, we found errors that compromise the access to digital information guaranteed by specific legislation to any Brazilian citizen.</p>"
5878;en_US;"<p>A graph-based method is proposed for inferring similarities among company from their affiliations in the context of expenditure financial transactions in the Brazilian Federal Government. There are trusted and untrusted company. We performed a basic cluster analysis in the company network to verify whether cluster (connected components) are discriminative concerning company trustworthiness. result show evidences that this is true, reinforcing the following hypotheses: (1) there are suppliers associations, which evidences the formation of cartels; and (2) public agencies and agent play an important role in the legality of financial transactions.</p>"
5879;en_US;"<p>In Business Process Management understanding the profile and the role of the Business Analyst is important, because that professional helps an organization to identify risks and opportunities, avoids costs and realizes benefits in the business and its process. But what are the skills required to work as a Business Analyst and the responsibilities of that role in an organization? This paper contributes to the debate on this issue, identifying and analyzing skills required, the key responsibilities of this role, through a survey carried out with Business Analysts, in the national context. From the perception of these professionals we obtained a set of the main competencies and responsibilities to act as Business Analyst and a mapping of the presence level of these skills and responsibilities in the current scenario.</p>"
5881;en_US;"<p>This paper is part of a major research in Business Process Management (BPM). There are international publications that identify the evolution of this area and practical challenges in several perspectives. This paper contributes with a comprehensive survey that identifies, from a Brazilian perspective, the evolution of the academic interest and the practical challenges of the national organization. The expected result are, first, that this work can provide evidences to answer our research question: What are the issues BPM in Brazil? In addition, we expect to contribute with an approach and instruments that can be applied in the future in a new evaluation, following the same process of this research. This first part presents the result of a key concerns classification of all the paper presented in a Brazilian´s Conference: the workhop of Business Process Management. With this first part, we aim to contribute by showing and discussing what are the academy keys concern and compare it with the BPM International Conference.</p>"
5882;en_US;"<p>Business Process Management (BPM) has become a powerful tool to increase the efficiency and effectiveness of service provided in public and private organization. However, there is growing awareness that BPM requires a holistic view of the organization where the organizational culture is a critical success factor for the implementation of a BPM initiative. This article presents a case study that explores the values and cultural aspects of an organization that contribute as facilitators and barriers to the development of a BPM initiative.</p>"
5883;en_US;"<p>In business process model, elements can be scattered (repeated) within different process, making it difficult to handle changes, analyze process for improvements, or check crosscutting impacts. These scattered elements are named as Aspects. Similar to the aspect-oriented paradigm in programming language, in BPM, aspect handling has the goal to modularize the crosscutting concerns spread across the model. This process modularization facilitates the management of the process (reuse, maintenance and understanding). The current approaches for aspect identification are made manually; thus, resulting in the problem of subjectivity and lack of systematization. This paper proposes a method to automatically identify aspects in business process from its event logs. The method is based on mining technique and it aims to solve the problem of the subjectivity identification made by specialists. The initial result from a preliminary evaluation showed evidences that the method identified correctly the aspects present in the process model.</p>"
5884;en_US;"<p>One of the most important feature of an Knowledge Intensive Process (KIP) is the variability: different activity can be performed by certain factors, i.e., certain behaviors lead to different directions at runtime. Despite the variability to be a key point in PIC, the various existing proposals in the literature are not treated satisfactorily aspects of reasons why the behavior of process to be modified. This article aims to present the KIPOrganon method, designed to identify the elements that can cause variability in Knowledge Intensive process.</p>"
5885;en_US;"<p>In this work, we propose an approach for recognition of compromised Twitter accounts based on Authorship Verification. Our solution can detect accounts that became compromised by analysing their user writing styles. This way, when an account content does not match its user writing style, we affirm that the account has been compromised, similar to Authorship Verification. Our approach follows the profile-based paradigm and uses N-grams as its kernel. Then, a threshold is found to represent the boundary of an account writing style. experiment were performed using a subsampled dataset from Twitter. Experimental result showed that the developed model is very suitable for compromised recognition of Online Social network accounts due to the capability of recognize user styles over 95% accuracy.</p>"
5886;en_US;"<p>In this paper, we describe a Reference Software Architecture for a Brazilian Public Entity based on a software design paradigm, called Convention over Configuration, which tries to decrease the decisions made by developers, gaining simplicity, but not necessarily losing flexibility or productivity. Moreover, the proposed architecture deals with auditing, tracing, logging, monitoring and other relevant issues for information system in the Brazilian government scope. Our Reference Software Architecture has been applying into two information system’ development at a Brazilian Public Entity. One of them is the most important information system at this Entity, nowadays.</p>"
5887;en_US;"<p>The overall goal of our research is to produce a characterization of the software startup ecosystem in the state of Pará, Brazil. This characterization will describe the various actors involved in this ecosystem, as well as the relationships among them. This paper presents our initial result based on a set of interviews conducted with entrepreneurs located in the city of Belém, Pará. We report different aspects faced by those involved in startup ecosystem, which can be used to suggest actions to strengthen the ecosystem. We plan to collect additional data in other city of the state as well as to compare our result with other software startup ecosystem.</p>"
5888;en_US;"<p>The electrical distribution is a critical activity since many people depend of this service. Faults in distribution system occur from several factors that can damage the system and therefore interrupt the supply of energy. Among the various factors that may cause problem this work proposes a automatic detection of trees near or even in the distribution network. In order to avaoid that the trees to force or even rupture of the distribution cables, are made the pruning of the trees that have kind of risk to the network. However, this activity is usually manual and teams must sift through all the network for problem. The main objective of this work is to propose a process, based on computer vision, which allows the automated identification of nearby trees or under the power distribution network from aerial image provided by Google Earth.</p>"
5889;en_US;"<p>This paper presents an ongoing research on the difficulties in treatment adherence and the use of gamification in health. A system is proposed to adapt and apply gamification technique to the specific case of hypertension, focusing in inspiring motivation.</p>"
5890;en_US;"<p>Sustainability metrics are measures and indicators that are intended to serve as management tool, both at the macro level, to public policy, for example, as in the micro, in the efficient management of a company. With its use one can measure the impacts of sustainable practices, through the correlation, for example, from increased revenue and market share, with practices such as reducing energy costs, reducing expenses with waste reduction costs of materials and water. Or even the correlation between an environment where Sustainability is promoted and the increased employee productivity and reduced spending on hiring. Arguably a growing alignment is needed between the discourse and practice of sustainability values. In this context, this article aims to use the Analysis of Feelings in the development of a new metric. In the present stage was done a survey, to know about the opinion that the Superior Educational Institute FAMEC - PRs workers have about organizational sustentability. The answers passed by an analysis, done with the tool RapidMiner, where the workers feelings were qualified as positive, negative or neutral.</p>"
5891;en_US;"<p>Graph coloring is one of the most effectiveness approaches to perform register allocation. This work describes a new approach to flip colors in an interference graph to minimize the code insertion for accessing memory. To evaluate the impact of using this strategy in the graph coloring register allocator, a George and Appel allocator has been developed in two ways - flipping the colors and without flipping the colors in the interference graph. experiment with a set of 27,921 graph of real programs were performed. In some cases, our result showed over 12% of reduction in number of variables sent to memory.</p>"
5892;en_US;"<p>The use of game design elements in context unrelated to game is increasing in industrial and educational scenarios. The gamification applied to teach Information system can be seen as a relevant and powerful contemporary strategy to attract student attention. The present work proposes the use of gamification in the bachelor of Information system program in order to engage and motivate student. Also, this work presents the initial game design for the algorithm III and System Analysis and Design I course.</p>"
5893;en_US;"<p>This article discusses the open and collaborative government system such as digital ecosystem, building a conceptual framework to define, specify and develop computational solutions aimed at supporting the operating dynamics and expand relations of access to information, participation, knowledge management, innovation, and education in citizen-government relations.</p>"
5894;en_US;"<p>There are currently several domains and indicators around the world that serve to categorize Smart city, however, there are not enough studies on the comparison of these city in Brazil. The public databases have data on various indicators and domains, and these data need to be standardized and clustered to allow a comparison between the smart city. Make an analysis based on clustering similarity smart city indicators can bring to the municipal managers a better understanding of the strategic possibilities of resource optimization.</p>"
5895;en_US;"In the last few years, novel approaches for using blockchain to solve Internet of Things (IoT) security and dependability issues have been proposed. Currently, different solutions were applied to Smart Homes, Smart city, Smart Grids, Supply Chains, Industry, and Vehicular network scenarios. Despite of that, the main advantages on the adoption of different architectures, model and algorithm proposed in the state of art of blockchain in IoT scenarios are not yet clear. This paper presents some discussion about the usage of blockchain technology in IoT environments and proposes a layer model of blockchains for IoT. In addition, we present an overview of the latest research regarding network architectures, consensus algorithm, data management, and application. Finally, this paper presents open issues and future trends about blockchain in IoT."
5896;en_US;"The uncertainty propagation is to investigate the effect of errors in model input parameters on the system output measure in probability model. In this paper, we present a moment-based approach of the uncertainty propagation of model input parameters. The presented approach requires only the fist two moments of model parameters, and has an advantage in terms of computation over the closed-form, numerical and sampling-based approaches for uncertainty propagation. The paper presents the properties of moment-based approach by comparing the existing Bayes estimation for the uncertainty propagation in a simple reliability model. An availability model of a server with virtual machine is used to illustrate the applicability of our method in practical problem."
5897;en_US;"In the field of dependable computing, it is important to be able to quantitatively assess the availability and reliability of system. In many cases, these system are represented by graph and node centralities can be applied to obtain the required assessments. More recently, many complex system are being represented by time-varying and multilayer graph, In these cases, often an aggregated dependability result is required. Nevertheless, it is well-known that the aggregation process may create spurious paths on the aggregated view of such high-order network. These spurious paths may cause path-based centrality algorithm, such as betweenness and closeness, to produce incorrect result, thus undermining the dependability assessment. In this context, we propose a method able to avoid taking into account spurious paths when computing centralities based on shortest paths in time-varying, multilayer, and time-varying multilayer network. Our method is based on MultiAspect graph (MAG) and we show that well-known centrality algorithm can be adapted to the MAG environment in a straightforward way. Moreover, we show that, by using this MAG representation, pitfalls usually associated with spurious paths resulting from aggregation in time-varying and multilayer network can be avoided. As a result, path-based centralities are assured to be computed correctly without taking into account spurious paths that could lead to incorrect result."
5898;en_US;"Containers are a lighter solution to traditional virtualization, avoiding the overhead of starting and configuring the virtual machine. Docker is very popular due to its portability, ease of deployment and configuration. However, the security problem that it may have are still not completely understood. This paper aims at understanding Docker security vulnerabilities and what could have been done to avoid them. For this, we performed a detailed analysis of the security reports and respective vulnerabilities, systematizing them according to causes, effects, and consequences. Then, we analyzed the applicability of static code analyzers in Docker codebase, trying to understand, in hindsight, the usefulness of tool reports. For a deeper understanding, we analyzed concrete exploits for some vulnerabilities. The result show a prevalence of bypass and gain privileges, and that the used tool are rather ineffective, not helping to identify the analyzed vulnerabilities. We also observed that some vulnerabilities would be easy to find using robustness or penetration testing, while others would be really challenging. "
5899;en_US;"This work presents QMapper, an approach for modeling and managing Virtual machine (VMs) on virtualized web servers cluster. In addition to providing energy savings and maintenance of the QoS of the cluster application, our model has linear scalability and high adaptability, enhancing its use in scale-out data centers and cloud computing platforms, and defines a standard VM, known as VAS (Virtual Application Server). A VAS operates in a flexible manner adapting its performance and power consumption at runtime according to the workload. Concepts of VAS agile clone, co-allocation of VAS in the same core, and dynamic voltage and frequency scaling (DVFS) of the processor are used in the model in order to manage the trade-off between power and performance. The experiment evaluate the effectiveness of our model by means of power consumption reduction and QoS violation as compared to the Linux governors and a state-of-the-art approach based on optimization. The result show that our model conserves up to 51.8% of the power required by a web servers cluster designed for peak workload scenarios, with a negligible impact on the application performance."
5900;en_US;"Mobile OS security relies heavily on cryptography. feature like file or device encryption and secure keystores are essential to protect user data from intrusions. As smartphone increasingly gain popularity, mobile platforms keep evolving their hardware and software modules that work as cryptographic provider for the rest of the system. These solutions are usually designed to resist software attacks by introducing a Trusted Execution Environment (TEE). This kind of protection is not enough when physical control over the device is lost. Secure elements such as smart cards, on the other hand, include a set of protections that make them physically tamper resistant device. In this paper we propose the use of the SIM card, the only universally present secure element in mobile phones, as a cryptographic provider and put forward a proof-of-concept prototype developed under Android OS. We also present the result of a performance evaluation that was conducted and study the impact on battery consumption, comparing our solution to the default implementation of an Android mobile phone. Despite some performance limitations our approach proves to be a valid alternative to provide enhanced security feature on any smartphone."
5901;en_US;"Chemical process plants are subject to risk caused by the handling and storage of hazardous substances. Major accidents may occur, particularly in those unfortunate circumstances when a triggering event produces a cascading accident that propagates to other units, a failure propagation scenario known as domino effect. An important aspect of designing such industrial plants is to properly arrange hazardous equipment such that, in the event of failures, cascading effects are minimized. In this work, we present a modeling approach to perform a probabilistic analysis of the likelihood of domino effects caused by propagating vapor cloud explosions. The approach combines the modeling of accident propagation based on physical properties of gas clouds, such as released mass and explosion distance, with the probabilistic modeling of cascading effects based on Stochastic Petri Nets. The proposed methodology is subsequently applied to a case study where different layouts of atmospheric gasoline tanks are analyzed, in order to evaluate the likelihood of domino effect occurrence."
5902;en_US;"Limitations of the CAP theorem imply that if availability is desired in the presence of faults – especially that create network partitions (or substantial delays), one must sacrifice sequential consistency, a consistency model that is more natural for system design. We focus on the problem of what a designer should do if he/she has an algorithm that work correctly with sequential consistency but is faced with an underlying key-value store that provides a weaker (e.g., eventual or causal) consistency. We propose a detect-rollback based approach: The designer identifies a correctness predicate, say P, and continues to run the protocol, as our system monitors P. If P is violated (because the underlying key-value store provides a weaker consistency), the system rolls back and resumes the computation at a state where P holds. We evaluate this approach with practical graph application running on the Voldemort key-value store. Our experiment, deployed on Amazon AWS EC2 instances, show that using eventual consistency with monitoring can provide a 50 – 80% increase in throughput when compared with sequential consistency. We also show that the overhead of the monitoring itself is low (typically less than 4%) and the latency of detecting violations is small. In particular, more than 99.9% of violations are detected in less than 50 milliseconds in regional AWS network, and in less than 5 seconds in global AWS network. In turn, this makes it possible to provide efficient recovery from such faults with a minimal amount of work wasted due to rollbacks."
5903;en_US;"State machine replication is a fundamental technique to render service fault tolerant. One of the key assumptions of state machine replication is that replicas must execute operations deterministically. Deterministic execution often translates into sequential execution of requests at replicas. With the increasing demand for dependable service and widespread use of multi-core servers, several proposals for enabling concurrent execution in state machine replication have appeared in the literature. Invariably, these technique exploit the fact that independent operations, those that do not share any common state or do not update shared state, can execute concurrently. Existing protocol differ in several important ways. In this paper, we survey this field of research and discuss the main aspects of the different protocol. Central aspects include conflict detection, representation and enforcing; tradeoffs involving existing architectures and level of allowed parallelism; workload-driven adaptation schemes; and implications of parallel state machine replication to recovery. Moreover, we discuss ongoing and future work directions for high-throughput state machine replication."
5904;en_US;"Recently, blockchain has attracted a great interest, and today it is considered not only as an innovative technology, but as a potential revolution for the world of business. The motivation of this enthusiasm is due to its capability of enabling new forms of records-keeping, transactions, and interaction between decentralized and mistrusting entities. Indeed, blockchain is driving company to huge investments and strategic acquisitions, and it is raising innovation and research across industries and academia. However, besides the opportunities offered, this technology may expose institutions and interacting parties to new risks that have to be discovered, understood, and, where possible, eliminated or at least reduced. In this paper we identify the main threats of blockchain and assess their related impact. Then, applying a NIST-compliant approach, we perform a qualitative risk assessment. Finally, we review the possible countermeasures, where existing, for each threat analyzed, and discuss open challenges and future directions. "
5905;en_US;"Simulation-based fault injection is an indispensable technique to assess the robustness of hardware components defined by means of hardware description language (HDL). However, the high complexity of modern hardware and its strict verification accuracy requirement lead to an unfeasible number of fault injection experiment, even when following statistical (instead of exhaustive) approaches, as accurate implementation-level model are up to three orders of magnitude slower than (inaccurate) behavioural ones. This paper proposes the combined use of multi-level fault injection in sequential logic and the profiling of the use of combinational logic to guarantee result accuracy while keeping experimentation duration within reasonable time-bounds. First, the sequential logic generated at the implementation-level model is matched with associated structures at its related behavioural-level model. In such a way, most fault injection experiment targeting sequential logic could be executed at the much faster behavioural level, while maintaining the accuracy of result. Second, by profiling the implementation-level model, run-time statistics (inactive macrocells, switching activity, etc.) can be exploited to keep result precision while reducing the number of experiment targeting combinational logic. The case study of three embedded processor model illustrates both approaches and quantifies the experimental speed-up derived from their combined use."
5906;en_US;"The continuous growth of the integration scale in CMOS circuits has derived in an increase in the memory system capacity, but also in their fault rate. In this way, the probabilities of suffering Single Cell Upsets (SCUs) or Multiple Cell Upsets (MCUs) has thus raised. Traditionally, Error Correction Codes (ECCs) are used in memory system to correct errors. However, when using ECCs, it is necessary to find a good balance between the redundancy of the code; the area, power consumption and delay overheads of the encoding and decoding circuits; and the error coverage achieved. In this work, we present two new low-redundant matrix ECCs that are able to correct different types of adjacent errors. Both codes have the same error coverage, but different levels of redundancy. In this way, we have been able to study the influence of these different levels of low redundancy in the area, power consumption and delay overheads. We have also compared our proposals to a well-known matrix code, in terms of overhead vs. coverage using a recently introduced metric. In all cases, our proposals get better scores."
5907;en_US;"Hierarchical broadcast strategies based on trees are scalable since they distribute the workload among process and disseminate message in parallel. In this work we propose an efficient best-effort broadcast algorithm that employs multiple spanning trees to propagate message that are bundled on tree intersections. The algorithm is autonomic in the sense that it employs dynamic trees rooted at the source process and which rebuild themselves after process crash. Experimental result obtained with simulation are presented showing the performance to the algorithm in terms of the latency and the number and sizes of message employed."
5908;en_US;"Airborne critical system that use real numbers in their algorithm can be considerably affected by the floating-point discretized representation. This limitation in the representation is the cause of many problem already known while running software with floating-point variables such as loss of precision in arithmetic operations. This work presents a method for detecting floating-point absorption and cancellation phenomena using static analysis in software design model. Our method uses a range analysis tool that operates over SCADE model to propagate the range of the internal variables and, then, each addition and subtraction operation in the model is analyzed to check the occurrence of the floating-point absorption and cancellation phenomena. The result are presented in an HTML report containing absorption alerts and cancellations charts providing the number of canceled bits for each sub-range in order to permit better assessment of the impact of each detected cancellation. In order to validate the proposed method, we compare the result of our proposed method with the result obtained by an alternative validation method developed using the source code as input and the Frama-C EVA to propagate internal ranges. The method can be used as an early design analysis enabling the cheaper detection and treatment of floating-point anomalies."
5909;en_US;"A Cyber-Physical System-of-system (CPSoS) can be defined as a System-of-system (SoS), where its Constituent system (CSs) are Cyber-Physical system (CPSs). A main challenge in integrating CPSoS to function as a single integrated system is the autonomy of its components, which may result in conflicts due to the lack of coordination among its CPSs. In this paper, we advocate that in order to facilitate the integration of CPSs within the overall context of their CPSoS, we may need to adjust their level of autonomy in a way that enables them to coordinate their activity to avoid any conflict among one another. Reducing such conflicts surely contributes to the dependability of the CPSoS. In particular, we propose a novel model-based approach for modeling and analyzing the autonomy levels of CPSs based on their awareness concerning their operational environment as well as their capability to safely perform their activity. We illustrate the utility of the approach with an example concerning a cooperative driver overtaking assistance system."
5910;en_US;"Wireless Sensor network are becoming the communication base for many Cyber-Physical system, which rely on sensed data to make sensitive decisions. Faulty data can lead such system to unpredictable behavior. It can result from sensor hardware failures and also from the intentional interference of an intruder. Gateways connecting such CPS with the Internet usually run conventional operating system and communication protocol and therefore are natural candidates to be overtaken by intruders. This work proposes the use of a confidence attribution scheme, based on lightweight predictors, capable of detecting wrong sensor data caused either by sensor failures or by malicious data forging. simulation show that its possible to achieve high detection rates with a very low communication overhead."
5911;en_US;"We revisit Byzantine-tolerant reliable broadcast algorithm in multi-hop network. To tolerate up to f Byzantine node, previous solutions require an exponential number of message to be sent over the network. We propose optimizations that preserve the safety and liveness properties of the original algorithm, while highly decreasing their observed message complexity when simulated on two families of random graph."
5912;en_US;"Virtualization provides many benefits as server consolidation and cost reduction, but it also introduces new challenges like security and isolation. Thus, trust is still one of the roadblocks in their adoption in critical system. Virtualized system are governed by a hypervisor and resource are shared amongst virtual machine. Paravirtualization improves the performance of the costly I/O operations, by providing an hypercall interface to the guests kernel. Hypercalls must be robust and secure, as their abuse leads to harmful effects. This paper presents an assessment of the applicability of robustness testing to the Xen hypercall interface. For this, we devised a testing campaign by mutating valid hypercall invocations with invalid values. The campaign was then executed from a compromised machine inserted in a representative virtualization environment. The result revealed the compromised machine being crashed frequently, in some cases without notification, and also lead into inconsistent states. result also show the inadequacy of the approach: new failure mode scales are necessary, as well as new mechanism for failure detection. "
5913;en_US;"This paper investigates the Raft consensus algorithm in the presence of failures. We are especially interested in how the single failures - link failures, isolation and partition-affect the running time of the leader election, which is an important building block of Raft. Our tests show that such failures are non-negligible. We therefore propose new timeout policies which can improve the performance of Raft."
5914;en_US;"In this paper, we introduce Crane, a new software tool for reliability analysis of system subject to perfect and imperfect fault coverage. Crane supports qualitative and quantitative analysis of traditional fault trees, imperfect fault coverage model (IFCM), and irrelevancy coverage model (ICM). ICM is a new coverage model which can detect and isolate irrelevant components in addition to faulty components, such that the not-covered faults of the irrelevant components will not affect the system anymore. The analysis of ICM is not available in the third-party tool. A generalized multiple-valued decision diagram algorithm is implemented in Crane, and it can be used to analyze both IFCM and ICM. Crane supports graphic and text input modes. Experimental result on some benchmark fault trees show that Crane outperforms some existing tool in terms of the efficiency for evaluation of minimal cut sets, and it can also be used to analyze the reliability of IFCM and ICM in an efficient way."
5916;en_US;"Computational tool, including educational software products and hypertext document, enable the teaching of mathematics in an innovative way, reinforcing the role of graphic language. Thus, it is another way of seeking and making feasible the construction of knowledge, in a more autonomous and independent way and, when using the computer, mainly with exploratory tool, a certain approximation of the concrete materials is possible. This work proposes an educational software, TBC-GAAL / WEB (Computer Based Training for Analytical Geometry and Linear Algebra via Web) to be used in disciplines of Analytical Geometry and Linear Algebra; because it is possible to use it via the Web, its diffusion is high, not being restricted to the place of its development."
5917;en_US;"This paper proposes a methodology that integrates the requirement of role-based access control (RBAC), obtained through role-modeling, to the eXtreme Programming (XP) development process. Integration is accomplished through an extension of the XP planning game to include the role-engineering steps that will result in new masses called Role-related User Stories, test cards related to Role-related User Stories, and the particular RBAC model."
5918;en_US;"This paper presents a branch and bound architecture that allows project managers to determine the best order for developing a network of interdependent software modules that has value for customers. In many cases, the method allows the development of complex and expensive software from relatively small investments, favoring the development of software as a means to obtain competitive advantage."
5919;en_US;"This paper proposes a Multi-Agent system to solve the problem of composition of work groups for project using the JADE framework. Its operation is inspired by the contract-net interaction protocol. The agent must negotiate between themselves the vacancies in the project and the winning agent of this negotiation will be part of the final result. The argumentation used in this process of negotiation between agent is based on the criterion of brevity for the conclusion of each activity of a given project."
5920;en_US;"Software organization are constantly looking for well-defined software process for the development of their products and service. However, many existing software development process are lacking in project management. This research proposes the definition of a model that integrates the concepts of project management and the software development process, forming a basis for the automation of the planning of the activity belonging to these two area of knowledge. A prototype was developed to demonstrate the proposed concepts."
5921;en_US;"In this paper we are interested in discussing the possibility of theusage of Data Mining tasks in order to reveal knowledge resident in Trajectory Data Warehouses (TDW). We consider a data stream environment where a set of mobile objects send the data about its location in a irregular and unbounded way. The data volume is stored in a centralized and traditional DW with precomputed aggregations values (preserving the trajectories privacy). Through of analysis of the TDW measures (pre-computed aggregation values) we can reveal some characteristics about trajectories in a given spatio-temporal area. The revealed knowledge can be useful in order to describe or show the occurrence of a real phenomenon. We present a review of a proposed structure of a TDW and discuss the use of Data Mining tasks to improve the analysis of the trajectory data warehouse environment."
5922;en_US;"The scenario of the data explosion was already predicted since 1970 by Alvin Toffler in Future Shock. The information overload considers a polluted information space, that is, it contains a lot of information of low quality or low relevance as to the task that we propose. If the current situation seems to us critical, the increasing and uncontrolled increase in the amount of information project that problem of this type will increase in the short term. To assist in the treatment of these problem, this work proposes a modeling framework for process based on high-level petri nets and active rule. The process modeled here in the form of standards exemplify the use of this framework and are aimed at eliminating non-relevant and unnecessary data. The proposed patternintegrate the perspectives of control and data flows in a single description model."
5923;en_US;"The paper describes FlowSpy, an environment that employs a sequence mining technique to discover and analyze actual process execution paths from business process, for both process comparison and process discovery. FlowSpy focuses on exploratory analysis of the different execution flows, enabling a detailed analysis of business behavior, quantification of different execution flows, and abstraction mechanism (log pre-processing and visualization abstraction) that deal with process complexity and different process views. Log pre-processing aims at improving the data mining phase, with a more restricted aggregate tree. Visualization abstraction facilitates pattern interpretation by producing trees that represent the obtained pattern."
5924;en_US;"This article presents a proposal of the use of the Contextual Analysis of Tasks for the development of information flow within computational system. This technique can be used to aid in the collection of software requirement, helping to reorganize the user daily tasks, so as to eliminate administrative defects prior to the implementation of the information system. A case study is presented in a real system, where the flow of information developed and the flow desired by the user presents important disagreements."
5925;en_US;"This article describes an environment for generating composite application, called SINS, that is able to combine service that are known to the environment and that have been developed as Web service in application without coding."
5926;en_US;"In this paper we present a collection of high level workflow activity pattern based on the semantic of specific business functions (e.g., notification, task execution request, approval). In particular we discuss three pattern sample (approval, unidirectional and decision pattern). Moreover we gather the result of an analysis of their adoption on a wide set of real process model. The analyses showed that the pattern are not only enough but also necessary to model all the 190 process model which were subject of the investigation. We also show and discuss specific sequences or combination ofactivity pattern which were more often in the process model analyzed. In larger research we apply these pattern as well as the analyses result in the development of a suite for process modeling and normalization."
5927;en_US;"This paper proposes a KDD process to aid in the reconfiguration of Xen virtualized machine. Xen allows simultaneous execution of several virtual machine (VMs) on the same hardware. Initially, performance data from each VM are compiled from benchmark runs on each. This data, once stored in the data warehouse, can be prepared for use by mining technique. The predictive model generated can then be enriched with reconfiguration instructions. These model seek to suggest, given a current configuration, the best set of configuration parameters to modify the environment, and achieve a global performance gain."
5928;en_US;"This article presents the development of a Mobile Geographic Information System (GIS) that allows the performance of personalized query to a geographic database through the use of a mobile device such as a PDA or Smartphone. This customization was implemented through a mechanism that uses ontology to define a query in the SQL language. In addition, a set of Webservice has been developed to minimize the limitations of mobile device in terms of processing and memory."
5929;en_US;"CMMI is a worldwide benchmark for software quality. However, it has been little adopted by small development company, mainly due to the restrictions of personnel, the cost with the implementation and maintenance of the process, and the delay in the return of invested capital. This article proposes an alternative for the implementation of the requirement engineering process present in the CMMI, together with the strategic planning. This alternative would allow an eventual observation of improvements in a short time, perhaps, motivating the incremental definition of the process of the model, including by small company. In order to support the proposed reflections empirically, we present initial data from a case study carried out."
5930;en_US;"The importance acquired by Information Technology (IT) for todays company, requires a better management of IT in the organizational environment, seeking the strategic alignment between IT and the organization business. ITIL is a library of best practices for managing IT service that has been used by a number of public and private company that aim to improve the quality of IT service by bringing them into line with the organization objectives. However, there are still many difficulties for the adoption of these practices and how to introduce them into the day-to-day of organization. The objective of this article is to discuss the implementation of good practices for IT service management and to present a horizontal approach to implementation of practices of ITIL based on the organization service catalog."
5931;en_US;"Active rule define actions on an active database and are typically used to maintain database consistency and implement information system (SI) functionalities. A tool was built to test SIs based on active rule written in SQL - ART-TOOL (Active Rule Testing TOOL). Structural software testing technique were extended to support the application of test criteria based on data flow analysis to the test of active rule. The tool was used to test 15 active rule and the result are promising: all defects were revealed; and the tool supported the application and evaluation of coverage of the criteria."
5932;en_US;"The difficulty in choosing automation tool is a problem that entails a high level of complexity and costs. Choosing and relating the tool most appropriate for certain types of testing requires a great deal of time, experience and knowledge from test engineers. This makes your job more difficult, since there is no descriptive and comparative analysis of the tool available in the market. Lack of information about these tool reduces productivity and increases test routines. This work aims to evaluate automation tool for test engineers, helping them to choose the best or most suitable tool."
5933;en_US;"This work presents a method for extracting, organizing and presenting metrics for the Software Development Process (PDS), taking into account the evolution of the PDS itself and the corresponding set of metrics. The solution, based on a Data Warehousing environment, is intended to retrieve measurements made on past project under different PDS model and metrics programs and form a solid foundation of information from these project. In order to enable the retrieval of these measurements, procedures are proposed to adequately address the creation, alteration and exclusion of metrics. These requirement were identified in an Information Technology company, certified CMMI level 2, whose main characteristic is that the majority of developed application is focused on the Automation of Business process. The main contribution of this work is to allow present and past measurements to be kept in a single repository of metrics of the organization and that they are comparable, allowing a better control of software project and the quality of their products."
5934;en_US;"This document describes an architecture for Semantic Web-based Adaptive Hypermedia application. The main objective of the proposal is to evaluate experimentally the advantages that can be obtained from the description of the application with semantic resource and with greater possibilities of interaction. Some of these are the great flexibility for the generation of adaptations and facilities for the semantic annotation of contents."
5935;en_US;"In Brazil, the classification of the fat finishing of bovine carcasses is regulated by Portaria of n.º 612 of 05/12/1989 of the Ministry of Agriculture. This process is carried out by means of visual and subjective observation through the analysis of predefined regions by an authorized professional during the slaughtering process in the cold storage industries. This paper proposes the use of artificial neural network to automatically segment and classify the fat finishing of bovine carcases into digital image."
5936;en_US;"This work presents the Statistical Criminal System (SIECRIM), whose objective is to automate the generation of statistical reports that aid criminal analysis and strategic actions. Another peculiar feature of this system is the possibility of integrating the different databases of the Secretariat of Public Security of the State of Pará."
5937;en_US;"This paper proposes a groupware development process. The process is the result of the best practices learned in the ten years of experience with the development of the collaborative service of the AulaNet project, and more specifically with the seven years of research and development of Mediated Chat versions. The proposed process, RUP-3C-groupware, is an extension of the Rational Unified Process (RUP) that incorporates the best practices learned in the project. A case study was conducted with student of Software Engineering to investigate RUP-3C-Groupware. Evidence was obtained on the repeatability and adequacy of the proposed process."
5938;en_US;"Reuse is one of the concerns of software developers and can be obtained using software standards or framework. This work proposes the reuse of graphical user interface, developed using the Model-View-Controller standard, with adaptations, to enable the separation of layers of information system. To exemplify this reuse, two versions of an information system developed with different technique are presented: with the Standard Language for Business Resource Management (GRN) and with the Java Business Resource Management (GRENJ) framework."
5939;en_US;"<p>This study describes the implementation of the COBIT framework in a private organization from the healthcare industry and analyse the level of maturity of IT Governance before and after its implementation. This is an exploratory and qualitative study. It was used a single case study strategy in order to describe the implementation of the COBIT framework. Data were collected through interviews in the second half of 2015. The main contribution of the research was the identification that GTI framework are becoming increasingly complex and difficult to implement. organization can achieve great result focusing on critical process, instead of implementing all the procedures provided by the framework. This opens an opportunity to review the implementation process of this framework, suiting them to specific needs of each organization.</p>"
5940;en_US;"<p>While considering transparency as a rule and secrecy as an exception, the Access to Information Act (AIA) provides for the protection of citizens personal data when the publication of data related to the public sector on the Internet (Art. 31). Existing systematic method for anonymization can be applied to meet this need. Thus, this article aims to develop a domain ontology for privacy preservation area in published data in order to comply with the provisions of AIA and initiatives of the Brazilian government, besides enabling the semantic unification of terms of anonymisation area and interoperability between tool for this purpose.</p>"
5941;en_US;"<p>This paper discusses the need for the study of government transparency from the perspective of information technology. So, is presented the building of an Evaluation Methodology of Municipal Transparency Websites, in light of the Standards serie ISO/IEC 25000, and the Brazilian law. The proposed model contains 443 appraisal item, divided into a specific indicator to measure the level of transparency the Legislative Power, and another to the municipal Executive Power. The built methodology was based on objective criteria for the allocation of weights to each indicator and had focus on reducing the degree of subjectivity of the process of execution of the evaluation. The work also includes the development of an operational supporting software for the evaluation process, speeding up the fieldwork. The methodology was applied in the execution the measurement of transparency of city of the Espírito Santo State, Brazil, and the result showed a low degree of achievement of established criteria.</p>"
5943;en_US;"<p>Nowadays, social network have become huge source of studies, since with them it is possible to find out a range of information related to tastes, interests, desires and opinions of its members. Identification of reputation dimensions is a task of online reputation management that aims to separate opinions about an entity in reputation dimensions, these dimensions reflect the affective and cognitive perceptions about the entity by different stakeholder groups. Supervised technique have been applied to this task. However, these technique are impracticable in real application, since they need a set of training examples that are usually manually labeled. This work presents a new unsupervised topic-based method for detecting reputation dimensions in microblogs. As the topic modeling algorithm do not work properly in identifying such dimensions in short text, our proposal aims to improve such a performance. We evaluate our proposal using the dataset provided by the RepLab 2014 challenge and our method outperforms the winner of such a challenge that is a supervised method. But, our method performs without the boring of manually labeling the examples.</p>"
5944;en_US;"<p>The measurement of energy consumption by smart device is growing rapidly. Studies of such measures is in the interest of governments and company around the world. With the identification of user profiles by energy consumption, there are plenty of opportunities that arise every time. This article presents an approach to the electric energy consumption in a home, and seeks to identify pattern. This is done on a database with many device that have had their power consumption measured regularly. Through a clustering algorithm used on these data, we tried to establish consumer profiles that contribute to a better use of energy. They yielded result that identified energy consumption pattern on conditions such as temperature and time.</p>"
5945;en_US;"<p>The healthcare process are complex and require a certain level of interdisciplinary cooperation among the various specialists and sectors involved in the process. Besides this complexity, the Brazilian healthcare area has a notorious problem in its public and private health assistance. These problem are structural, organizational and financial, reflecting in the low valuation of quality and service. The goal of this work is propose an adaptation of Process Mining to healthcare process in order to contribute in improve the healthcare area in Brazil. In order to achieve this goal a study case was carried out in the Erasto Gaertner hospital, situated in Curitiba – PR, Brazil, that is a national reference in treatment of cancer.</p>"
5946;en_US;"<p>Reputation information has become an important asset for the software development company. Such information depends on the context for which the reputation was established. In geographically distributed teams, each team may represent a different context. To allow the exchange of information between groups and context, one should use an interoperable reputation model. Therefore, the ArchiRI architecture was specified. Through ontology and views, supports decision making in software maintenance project. A scenario of evaluation was detailed, presenting evidence that ArchiRI can help managers in analyzing the members’ reputation, compare this information and make decisions.</p>"
5947;en_US;"<p>One of the great challenges of knowledge management is the externalization of knowledge (the conversion of tacit in explicit knowledge) effectively. Tacit knowledge is associated with personal experiences and represents the subjective knowledge that is often difficult to be formalized or explained. Group Storytelling is an important approach to tacit knowledge retrieval, which through the collaborative construction of stories it helps in externalization. This paper presents an exploratory case study with tutors of an online course, whose result showed that it is possible to capture the tacit knowledge through this technique with computer system support.</p>"
5948;en_US;"<p>The software development process usually changes between the various organization, while some have formal and institutionalized process, others do not have standards in development process, do not specifying in formal document and tend to change very often. Thus, is believed that there any direct relationship between the how to work of software development teams and the motivation of their members. This study aims to analyze the influence of the software development process in the motivation of development teams. For this, interviews with software developers from different organization using different software development process were compared. With this, was possible to verify the influence of software process in motivation the members of the organization and which characteristics of these process influence in motivation of these members.</p>"
5949;en_US;"<p>Communication is a critical factor that directly influences on the project success, no matter its type or the industry type it is within. However, many IT professionals end up ignoring its importance and focusing on technical skills. Taking in consideration the lack of material and its dissemination amongst the various other scientific work, the main goal was, through a systematic literature review, to compile the many source regarding the Communication Practices in Software Project Management. As result, main technique, tool and challenges were discussed, quantitatively and qualitatively, in a way that project management professionals will be able either to use this work as a guide to future researches or to help on decision-making in subjects concerning the communication on software project.</p>"
5950;en_US;"<p>This paper presents the modeling and the implementation of an agent-based simulation tool, here called Demiourgos, that allows the obervation of the camuflage evolution in virtual organisms that are put together with their predators. The case study developed was inspired by John A. Endler’s research, in which he observed how natural selection induces color pattern changes in the lebistes fishes (Poecilia reticulata). The agent behavior model was defined through observation research. The preliminary result show that the proposed agent-based model achieves satisfactory levels in relation to the original work used as reference. The simulation tool can be mainly used by researcher that need to work with multiple variables to understand complex model of living beings interaction, helping the process of decision making about species conservation issues.</p>"
5951;en_US;"<p>This work describes an information system created to genetical enhancement of sheep and goats, with the goal to maximize weight gain and minimize the degree of kinship of the herd. The genetic enhancement was developed using animal science literature and implemented by using computational intelligence algorithm. The system was applied in a pilot project, with few animals, in order to evaluate the result. The observed result was considered a success, so, theinformation system is being used in an experimental purpose in a higher education institution. From its use is possible to predict the best couples to mate in order to generate better descendants in terms of weight gain minimizing the degree of kinship of the herd for future generations.</p>"
5952;en_US;"<p>In this paper is presented a systematic literature review (SLR) conducted in the field of multimodal biometrics, considering the fusion of biometric characteristics of face and gait. Biometric system based on fusion of face and gait are useful in non-controlled environments with non-cooperative user. This SLR includes 18 primary studies which allowed the conclusion that although the theme presents some trends, there are still important gaps that need to be investigated.</p>"
5953;en_US;"<p>This article presents the MASC, which is a computational model for accessibility in smart city. The use of ubiquitous computing in the area of accessibility provides solutions to support persons with disabilities (PwD). Unlike the proposed approaches, the MASC uses the interaction of PwD to compose trails which will be offered as a service. Moreover supports various disabilities, is intended for mass application. A prototype was developed to evaluate performance and functionality. This evaluation was conducted with data generated by a context simulator in São Leopoldo - RS. The result presented in the tests indicate that the service offered by the model can be applied in smart city to collaborate with accessibility, helping PwD, health professionals and public administration.</p>"
5954;en_US;"<p>Technological advances have influenced the relationship between government and citizen. In this scenario, the Digital Democracy theme that encourages the state to adopt strategies that enable the performance of the citizen not as a client of the information provided, but as a catalyst for democracy, arises. Parallel to this, changes can be observed with regard to the understanding of citizenship. However, digital democracy is a phenomenon that requires clarification both in relation to the various resource available as in the acceptance of these new possibilities for social participation. In this article, an exploratory study that sought to understand this phenomenon will be described. The study was conducted from three lines of action: literature review, analysis of resource available and survey research. In the survey, 220 people were interviewed via an online questionnaire. Research shows that there are different initiatives converge to similar degrees of digital democracy. Moreover, the survey showed a consistent level of acceptance of the use of technology in this context.</p>"
5955;en_US;"<p>Reduction in data center energy consumption is a constant motivation for IaaS provider. Among all components, CPU appears as a main energy consumer. Although there is a strong relationship between CPU load and its energy consumption, pricing model of popular IaaS provider do not consider this information as a primary and variable element. This paper quantifies the relationship by identifying the individual consumption of virtual CPUs, which form the basis for an allocation cost model. The proposed model, termed Virtual Power, is faced with Amazon EC2 pricing model pointing a cost reduction for IaaS provider and a proportional sharing between user.</p>"
5957;en_US;"<p>Information system with the objective to make forecasts for financial time serie and negotiate from these are subject to various risks, because the stock market is influenced by different source continuously. The study of quantitative finance addresses method for treating problem such as these, a fact which occurs mainly through the use of computational intelligence. This paper presents an automated strategy (investor robot) that combines predictions made by artificial neural network and econometric predictors in a second neural network, this acts like a ensemble. The predictions are used to generate purchase or sell signals through a negotiation model built into the algorithm. The experiment were conducted with real serie of three assets with high liquidity, a commodity and a market index. The financial result are compared against the individual application of each predictor and also the classical market technique.</p>"
5958;en_US;"<p>This paper presents a method that identifies duplicate contacts, i.e., records representing the same person or organization, automatically collected from multiple data source. Contacts are compared using several similarity functions, of which scores are combined by a classification model based on decision trees, which eliminates the need for an expert to manually configure similarity thresholds. The experiment show that the proposed method correctly identified up to 92% of duplicate contacts.</p>"
5959;en_US;"<p>The growing of criminality in Brazilian city is a common theme addressed by media as well as by the legal authorities. To effectively reduce the criminality, people and infrastructure must be carefully involved to not only punish who had committed crime, but also predict and prevent it. Since acquiring official data about crime is far from trivial, citizens have become important data source through Web-based collaborative system. These system provide a huge volume of data that has to be analyzed. How to analyze this volume of data and identify pattern in crime is an important, yet open, issue. Thus, this work presents a system called SiAPP. Its main objective is to support the analysis and prediction of crime pattern using a machine learning algorithm. SiAPP automatically acquires data from collaborative source, generate logical rule and visualizes the found pattern. Experimental analysis shows that SiAPP is a promising solution tool to assist crime prevention.</p>"
5960;en_US;"<p>Performing data mining tasks such as clustering can be very complex due to the high dimensionality and volume of data being mined. This paper proposes an approach for data clustering using the Symbiotic Organisms Search algorithm (SOS) developed in the MapReduce parallel architecture. Also, the cluster quality evolution is analysed using the purity measured considering four different fitness metrics. The cluster qualities obtained by the proposed approach not only shows to be competitive with other approaches but also increased its performance using the MapReduce architecture. Another contribution of this work is to bring to light the correlation between the cluster purity and the fitness value obtained during the optimization process. It was noticed that for some fitness metrics the final purity found by the optimization algorithm is less than the purity found in an earlier stage in the optimization process.</p>"
5961;en_US;"<p>Information system (IS) rely on software to model, simulate and execute business process. The complexity, size and diversity of these process is a challenge for requirement Engineering (RE). This paper presents an approach to deal with this challenge. In this approach the concept of Business Process is the basis for all RE activity and products. A proof of concept of the feasibility of this approach has been taken with its use in the specification of software that supports the RE process itself. The comparison of this software with others that represent the state of the art on RE tool shows that few tool meet the requirement related to the RE support for IS, especially in supporting the concepts of business process.</p>"
5962;en_US;"<p>Over the years, the gaps and challenges that occur during the construction and implementation of a software are related to problem at the stage of requirement analysis and management. This recurrence draws attention from researcher and industry, and some researches have been developed with the aim of proposing solutions to minimize these problem, particularly in requirement elicitation phase. However, these efforts are not always accessible to the common knowledge, which complicates its dissemination and consolidation in academic and industry area. The aim of this work is to present the characterization of requirement elicitation process proposed in recent years, through a Systematic Literature Review (SLR). This kind of characterization is important, once it can assist company wishing to adopt an elicitation process. Furthermore, the categorization of existing process will assist in their dissemination and consolidation.</p>"
5963;en_US;"<p>The requirement elicitation is a complexity phase of the Requirement Engineering, being necessary method and technique to execute it. Many researcher emphasized that the software system must fully meet the peculiarities of the company’s business. Then, with the intention to elicit rightly the requirement of the software, there are technique and method in the literature that perform the requirement extraction from business process model. Such model can be represented in different types of notations, being the Business Process Model and Notation (BPMN) the standard notation. In this context, this paper describes a systematic review to identify primary studies that perform the extraction of functional and non functional requirement from business process model represented in BPMN notation. From the result obtained through the systematic review, we observed that there are few studies about the subject and most of them take in account only the functional requirement extraction. Thus, it was possible to outline future research to contribute to the advancement in this research area.</p>"
5964;en_US;"<p>A large amount of data repositories became available due to the advances in information and communication technology. Those repositories, however, are highly semantically heterogeneous, which hinders their integration. Ontology alignment has been successfully applied to solve this problem, by discovering correspondences between two distinct ontology which, in turn, conceptually define the data stored in each repository. Among the various ontology alignment approaches that exist in the literature, interactive ontology alignment includes the participation of experts to improve the quality of the final alignment. An important issue for interactive ontology alignment proposals is to maximize the efficiency of the expert participation. According to OAEI (an evaluation initiative conducted annually), despite the advances in this field there are still recurrent errors in the final alignments obtained by the interactive ontology alignment proposals. In this paper we propose ALIN, an interactive ontology alignment approach that increases the efficiency of the expert participation through the use of alignment anti-pattern. ALIN was evaluated considering three anti-pattern available in the literature, and the result proved the potential of the approach.</p>"
5965;en_US;"<p>Managing scientific project is a complex task. The project may be associated with several different scientific experiment that in turn require implementations of different computer simulation (scientific workflows). This management becomes even more complex if we consider that the project tasks should be associated with the specification and execution of these simulation (which can take days or weeks to finish) and that the project’s team can be geographically dispersed. This paper presents the SciManager information system that aims at helping scientists managing scientific project. The SciManager is able to manage the project, its associated experiment and workflows in a single tool, making all information related. The SciManager is based on a cloud architecture, which means it is easily available for project members. An experimental evaluation was held out and approximately 88% of user agreed that SciManager is useful and easy to use in scientist’s daily duties.</p>"
5966;en_US;"<p>Information system that uses relational databases for data maintenance are increasingly migrating to cloud databases in order to minimize costs related to the management of huge data volumes. In this context, NoSQL databases are good options, in particular, the key-value databases, which present a simple data model and scalable solutions. Even that, the costs regarding the migration to a NoSQL data management may be high, mainly in terms of source code updating of the information system for adapting database access interface. This paper presents VoldemortSQL, a layer that maps SQL DML instructions to the access method of the NoSQL key-value database Voldemort with the purpose of avoiding the laborious work with data and access interface migrations from a relational database to Voldemort. The usage of this layer allows the manipulation of data in the cloud through the continuous usage of the SQL standard. An experimental evaluation had demonstrated that the overhead introduced with the layer is not prohibitive.</p>"
5967;en_US;"<p>The emergence of agile method in software development has brought many opportunities and challenges for researcher and professionals. A major challenge is the effort estimate for agile software development. When the estimation of effort is not well defined or is inaccurate, the result can directly reflect the software delivery, causing customer dissatisfaction or decrease the quality of the product, thus leading to the need for new mechanism that can assist in this process. Given this need, this paper presents a framework, called GiveMe Effort to support the effort estimation activity in the maintenance and evolution of software in agile method. The solution is based on historical data change requests associated with the maintenance and evolution of software.</p>"
5968;en_US;"<p>Software Product Line (SPL) relies on the development of a collection of information system from a shared set of software assets. In this context, the adoption of SPL in the industry relies heavily on tool support. This paper presents ViSPLatform, a visualization environment aimed at portraying data related to experiment focusing on SPL tool. We conducted a preliminary evaluation to analyze to which extent the platform is effective to support the understanding of characteristics of the SPL tool. The result of this study show that ViSPLatform can somehow indicate strengths and improvement opportunities in the analyzed SPL tool. For instance, they show that Automatic Analysis is a strength of the SPLOT tool and that Interface is an improvement opportunity. (Better if read in colors).</p>"
5969;en_US;"<p>Technical Debt is a term used to classify non-optimal solutions during software development. These solutions cause several maintenance problem and hence they should be avoided or at least documented. Although there are a considered number of studies that focus on the identification of Technical Debt, we focus on the identification of Technical Debt in pull requests. Specifically, we conduct an investigation to reveal the different types of Technical Debt that can lead to the rejection of pull requests. From the analysis of 1,722 pull requests, we classify Technical Debt in seven categories namely design, documentation, test, build, project convention, performance, or security debt. Our result indicate that the most common category of Technical Debt is design with 39.34%, followed by test with 23.70% and project convention with 15.64%. We also note that the type of Technical Debt influences on the size of push request discussions, e.g., security and project convention debts instigate more discussion than the other types.</p>"
5970;en_US;"<p>The evolution is necessary for information system do not become inadequate. However, this evolution has been identified as critical aspect in ensuring maintainability, because of the increased amount of dead code in these system. The identification and elimination of dead code decreases the code size and the complexity, facilitating the understanding. technique have been proposed in the literature for automating the detection of dead code. Thus, Systematic Literature Review was performed to find existing dead code detection technique. As result, two main technique were found: Accessibility Analysis and Data Flow Analysis. In addition, quantitative and qualitative analysis were performed and they are presented to help researcher on which technique to use.</p>"
5971;en_US;"<p>Accessibility is an essential condition for the full exercise of citizenship and a civic right that should not be denied to any citizen. Nevertheless, there are many architectural barriers found in urban area, such as broken and narrow sidewalks, slippery surfaces, stairs and ramps excessively steep, among others. People with locomotion difficulties, whether permanent or temporary, are the public who suffer most from lack of access to planned area, especially to public healthcare service, essential to the well-being of the population. In this context, this paper implemented a system to assess the risk of pregnant women to access Basic Health Units (UBS). The system was applied in two basic health units and we found that 35% of pregnant women are exposed to high or medium risk of health complications due to obstacles on the path to healthcare units.</p>"
5972;en_US;"<p>In a scenario where there is a huge amount of available data source, the Semantic Web has played a key role in sharing, retrieval, selection, and combination of data organized in various formats. The storage and retrieval of medical image manipulated by system that support breast cancer detection can take great advantage from the use of such technology. In this paper we present a comprehensive study on ontology-based system that support the manipulation of medical image related to breast cancer, identifying the main feature of each approach.</p>"
5973;en_US;"<p>The percentage of elderly population in society has grown on a large scale in the last years, and it is estimated that this grown will continue to occur. In face of this, rises up the demand for new products and service that come up with solutions for the necessities of this age group. In order to supply this demand, comes up Ambient Assisted Living, a field of Ambient Intelligence that uses ubiquitous or pervasive computing and aims to provide a safer and more comfortable home life to elderly or to people that need some assistance in daily activity. The goal of this study is to provide a web system for managing and accurate monitoring of the medication use for patient in Ambient Assisted Living environments. The system purpose is to alert the patient to use their medication at the right time preventing them from using the wrong medication, and, also, notify a responsible in case of errors and keep track of the treatment. Validation is done through a simulation with fictitious data performed on a simulator. The intention of this work is to provide this service to real user in order to assist them in their medical treatment.</p>"
5974;en_US;"<p>The purpose of this article is to understand how different personality profiles can be related to different academic performances and skill levels in management, computing and mathematics disciplines in graduation student in Information system. With an interdisciplinary methodological approach, the research uses the theory of psychological types of C. G. Jung to evaluate how personality predispositions can be connected to the various skills required of an academic in Information system.</p>"
5975;en_US;"<p>Business process modeling helps to understand and identify activity performed in an organization, which serve as a source of requirement for system modeling. It also can be used to discover candidate service to support these requirement. However, managing information between model of different levels of abstraction is not a trivial task. Several work have been proposed to solve this problem by deriving service from business model. This paper presents a method to assist service derivation from business process using the Model Driven Development approach and heuristics and in order to achieve service model that can be used to generate code. The method is divided into two phases. In the first phase, a business process, modeled in BPMN, is transformed into a UML activity diagram. In the second phase, UML model are transformed into a SoaML model.</p>"
5976;en_US;"<p>Software reuse is a development strategy in which existing software components, called reusable assets, are used in the development of new software system. There are many advantages of reuse in software development, such as minimization of development efforts and improvement of software quality. New method for reusable asset extraction are essential to achieve these advantages. Extraction method may be used in different context including software product lines derivation. However, few method have been proposed in literature for reusable asset extraction and recommendation of these reuse opportunities. In this paper, we propose a method for extraction of reuse opportunities based on naming similarity of two types of object-oriented entities: classes and method. Our method, called JReuse, computes a similarity function to identify similarly named classes and method from a set of software system from a domain. These classes and method compose a repository with reuse opportunities. We also present a prototype tool to support the extraction by applying our method. We evaluate the method with 38 e-commerce information system mined from GitHub. As a result, we observe that our method is able to identify classes and method that are relevant in the e-commerce domain.</p>"
5977;en_US;"<p>To support information security, organization deploy Intrusion Detection system (IDS) that monitor information system and network, generating alerts for every suspicious behavior. However, the huge amount of alerts that an IDS triggers and their low-level representation make the alerts analysis a challenging task. In this paper, we propose a new approach based on hierarchical clustering that supports intrusion alert analysis in two main steps. First, it correlates historical alerts to identify the most typical strategies attackers have used. Then, it associates upcoming alerts in real time according to the strategies discovered in the first step. The experiment were performed using a real data set from the University of Maryland. The result show that the proposed approach can provide useful information for security administrators and may reduce the time between a security event and the response.</p>"
5978;en_US;"<p>The increase of dynamic cloud computing environments introduces the need for new ways of access control in application. One access control model which adapts flexibly to such system on the Internet is the RAdAC (Risk-Adaptive Access Control). This model is based on the user confidence degree and the risk of releasing access to some information taking into account the context in which a request is performed. However, in practice, to use such model it is necessary to implement a technological support as, for example, extending the access control architecture present in the XACML (eXtensible Access Control Markup Language). This paper extends the XACML access control architecture to support the RAdAC model providing a quantitative, concrete and dynamic risk calculus in order to improve the access control in cloud environments. A prototype was developed in Amazon EC2 cloud environment to perform dynamic access control policies using the proposed XACML extension. Some risk calculus tests are described in the paper to exemplify the RAdAC decisions.</p>"
5979;en_US;"<p>One of the fundamental requirement for cloud computing consolidation for a robust and reliable solution is security. organization looking to adopt the cloud as a solution should be aware that this technology brings all the problem that exist within the information security combined with the complexity and heterogeneity of your settings to provide confidentiality, integrity and system availability. To impose uniform management practices for provider and the security control, with privacy policies agreed with its customers defined in Security Service Level Agreement (Security Service Level Agreements), or simply Sec-SLA, it is expected that the cloud be able to improve your control and security and achieve efficient incident response. It is proposed in this paper a model to calculate the trust provider from solution and mitigation measures to security incidents offered in their service catalogs.</p>"
5980;en_US;"<p>Music recommendation system such as Last.fm use collective knowledge bases containing ratings and historical use, in order to recommend item (such as artists and songs) considered similar to each other. With reference to the knowledge generated by Last.fm user, this work investigates the co-occurrence of item in radio station programs, that is, whether the radio playlists represent cohesive sets of related item. In this sense, we developed an analysis methodology in which frequent item sets containing artists, songs, and musical genres that co-occur within radio programs are extracted, in order to analyze the similarity among discovered item sets, using as reference the similarity lists from Last.fm. Experimental result show that the more strict the filters applied to define the set of frequent item are, the more item present in the Last.fm similarity lists are found. On the other hand, the study also reveals that new correlations between item, even though not classified by Last.fm, can be discovered, showing that even large-scale collaborative system as Last.fm are not complete regarding data characterization for extracting abstract similarity concepts.</p>"
5981;en_US;"<p>Extracting accurate information from the huge volumes of data, much of them unstructured, generated in social media is currently a big challenge. However, it has several relevant application, some of them latent yet. One of the first and most decisive steps in this information extraction process is the recognition of relevant word in text. This article presents a comparative study of method and tool for recognizing relevant word on microblog posts. Among several analyzed tool, five have been selected for experments with 100,000 tweets. These experiment showed high variability of the result generated by different tool, suggesting a need for improvements.</p>"
5982;en_US;"<p>Online Social network (OSNs) are the most used media nowadays, such as Twitter. The OSNs provide valuable information to marketing and competitiveness based on user posts and opinions stored inside huge volume of data from several themes, topic and subjects. In order to mining the topic discussed on an OSN we present a novel application of Louvain method for Topic Modeling based on communities detection in graph by modularity. The proposed approach succeeded in finding topic in five different dataset composed of textual content from Twitter and Youtube. Another important contribution achieved was about the presence of text posted by spammers. In this case, a particular behavior observed by graph architecture (density and degree) allows the classification of a topic as natural or artificial, this last created by the spammers on OSNs.</p>"
5983;en_US;"<p>This article presents the principles considered in the development of an electronic guide that aims to contribute to the dissemination and participation in the celebration of Holy Week in the city of São João del-Rei, MG. It is a scientific-technological study, which draws on exploratory research on the topic, analysis and application of taxonomy technique for organizing information, which culminated in the development of an application for smartphone in order to provide access to information available on the Internet (web). The presented result are a reference model for the development of e-guide application that allow access considering three ways organization (chronological, thematic and spatial), content with multimedia format and interactivity among its user promoted through other popular service social media (mashup). Despite the scientific findings, we believe that the application tends to promote regional tourism, improving the experience of user participation in the celebration of Holy Week, besides serving as a reference for developing similar initiatives involving the development of e-guide apps that rely on the use of multimedia information and service available online.</p>"
5984;en_US;"<p>The Stochastic Inventory Routing Problem (SIRP) is a combination of the inventory control problem with stochastic demands for goods in commercial centers and vehicle routing problem used in their supply from a single distribution center. This paper presents an alternative to the algorithm proposed by [8] for SIRP using Monte Carlo technique. The new algorithm was implemented and compared to the original one considering several policies, showing similar result in some cases and better result in others in terms of time efficiency and quality solution. The analysis, comparison and assessment of both algorithm were based on benchmark problem from the literature.</p>"
5985;en_US;"<p>With the advent of the social web, user contribute actively sharing their content instead of just navigate the Web. Such user have become truly human sensor through collaborative platforms such as the LBSNs (Location-Based Social network), bringing a collective intelligence for problem solving. Human sensor are in charge of producing VGI (Volunteered Geographic Information) and AGI (Ambient Geographic Information), very useful information in the most diverse application domains, such as the Smart city. These sensor assist on solving various problem of urban area and contributing to the citizens’ life quality improvement. Currently, the growing number of disease cases transmitted by the Aedes aegypti mosquito, such as Dengue, Zika and Chikungunya, has led both Brazil and other countries to an alert state. The most efficient combating method nowadays relies on the population taking preventive actions, posing a challenge to the local authorities. In this context, this paper presents the DeuZikaChico, a framework that makes use of GIS technologies, mobile platforms, crowdsourcing and social networking, with the purpose of providing public managers better monitoring of epidemics with the support from the society.</p>"
5986;en_US;"<p>There is a global interest in encouraging startups company because of the expected economic growth in the regions where these startups are located. However, startups are not individual company, they live in an ecosystem that includes other startups, universities, incubators, investors, among other elements. Thus, understanding the components and the relationships that exist among the elements of a startup ecosystem enables decision making about how best to encourage this ecosystem. This study describes, through a critical review of the literature, a holistic view of the elements that make up a technology startup ecosystem. This work was guided by a literature review of 20 selected work through a process of snowball sampling. The main result is a conceptual framework with the elements that make up a startup ecosystem and their relationships. These are the elements that influence the ecosystem, although, in some cases, there is no consensus in the literature about whether this influence is positive or negative. Thus, the proposed framework identifies factors that have been extensively studied in the literature and, more importantly, other factors that deserve further exploration.</p>"
5987;en_US;"<p>The remote monitoring and control of machine are essential in industrial environments. Emerging communication technologies such as Web of Things and Machine to Machine Communication can meet this demand for automation. This paper aims to introduce a solution, called Smart Meter, for continuous and remote monitoring of electrical quantities, in smart industrial environments with three-phase system. The proposed solution uses a resource-oriented architecture and makes use of a Smart Gateway for communication, RESTful web service and cloud computing. The solution was integrated with a real case study and evaluated by software testing. The result obtained demonstrate the feasibility of the solution, and the correctness of measurements persisted in the cloud.</p>"
5988;en_US;"<p>Software as a Service (SaaS) and Data as a Service (DaaS) proves to be two promising area of research in the cloud computing field, however interoperability among different cloud provider is yet poorly explored. Today, clients looking for content or service from different provider need extra time and resource to learn and implement the required adaptations from the other parties. In this paper we propose MIDAS, a novel middleware to interoperate SaaS and DaaS service seamlessly and independently from provider. That is, SaaS application will be able to get data from DaaS dataset by sending a query to our middleware and letting it mediate the communication and return the expected result. We evaluate our proposal by developing a prototype from two case studies and by analyzing the time effort to query through our middleware. Our result presented that no important overhead were required from provider nor to the final user.</p>"
5989;en_US;"<p>The reuse in Service Oriented Architecture (SOA) has been used strategically in organization to reduce development costs and increase the quality of application. This article reports a qualitative research realized with experts in order to identify goals, barriers, facilitators, strategies, metrics and benefits associated with reuse in SOA. The result were summarized in three dimensions (management, architecture, operation) and represented by a conceptual model that can serve as a preliminary roadmap to manage the reuse in SOA.</p>"
5990;en_US;"<p>Collaborative network (CN) has arisen as a prominent enterprise strategy for leveraging new sustainable model, to Small and Medium sized Enterprises (SME) in more particular. There are several types of CNs. This paper focuses on the Virtual Enterprise (VE) type, which can be defined as a dynamic and temporary network of SMEs that collaborate with each other towards achieving a common goal, sharing resource, knowledge, costs, risks and benefits. In a VE the diverse kinds of transactions among its members are performed pretty much via Internet, demanding a reasonable amount of investment on IT and human resource from the enterprises. However, SMEs usually have large technical and financial limitations. The underlying premise of this work is that VE members can also share IT resource so as to decrease their general costs. Cloud computing has become a sound approach nowadays and there are plenty of cloud-based tool already available. Therefore, it is important to SMEs knowing which ones fit the VE requirement best. This is the core goal of this paper, also identifying such requirement, the requirement to evaluate such cloud-based tool, and making a comparison among them. result are assessed and some reflections about the feasibility of a cloud approach for VEs are presented in the end.</p>"
5991;en_US;"<p>Internet has played nowadays an important role in society, being the means for service of diverse purposes to be delivered. One of the service that have gained attention on internet is the collaborative system, in which multiple user create content based on their own personal experiences. An emerging class of collaborative system is currently the gastronomical recipes sharing service. The area of Web Information Retrieval has grown interest in retrieving information in the recipes environment in order to discover new knowledge, such as the discovery of healthy recipes, which happens by employing textual data mining technique. In this scope, this work analyzes feature of gastronomic recipes present in specialized sites, taking into account characteristics of ingredients, comment, number of user, categories, among other information related to the recipes in the target sites.</p>"
5992;en_US;"<p>In this paper, we describe Hígia a model designed with the goal of constructing usual trails to identify possible depressive signals, similar to those lived by the user in other previous moments, and warn the related people as quickly as possible, so actions can be taken. This is done through constant evaluation of user characteristics on social network, e-mails and interaction with your smartphone, computer or other device, as well as its location. A prototype of the designed solution was implemented and the model was evaluated by the user who used the prototype, their opinions, as well as the opinions of experts in the field were collected. It was found that these data can be rather favorable to treatment depending on the situation and how they are used.</p>"
5993;en_US;"<p>Sentiment Analysis emerged from the need to treat and evaluate text, opinions and comment made by user on the Internet, in order to understand how they relate to a given entity. Several analytical method have been developed in an attempt to better translate the uncertain and the subjectivity of human feelings. This research used data from interaction in a social network to identify the sentiments involved in each student comment. From the collected text different method of sentiment analysis were used in order to identify which method had better result compared to the real ones. The comparison showed differences between these result and the real ones: while the used tool classified more than 40% of the comment as neutral, the analysis of the message’ author showed that 71% of the comment were positive. In the classification, the occurrence of outliers was identified as well as differences on the intensity of the sentiments acquired with each method. No approach, including the one performed by one of the researcher, was considered efficient enough as the highest level of accuracy obtained was less than 70%.</p>"
5994;en_US;"<p>The current scenario of Health Insurance provider (HIP) consists of a steady increase in operating expenses over revenues, growing at a slower pace. Among several factors that explain this scenario, this work was highlighted two important points, they are: (i) The requirement of regulation imposed on private health care sector with the creation of the ANS in 2000; and (ii) the increased use and costs of physician - hospital procedures resulting from population aging. The objective of this work was a study of the market for Health Insurance provider (HIP) to analyze the motivators and inhibitors of using system in SaaS format.Considering the context presented, it is believed that the rational use of information system, especially with the paradigm of cloud computing, and more specifically with the adoption of SaaS (type of software available in the cloud) could be a way for provider to optimize their health plan budgets technology. The methodology used in this work was the application of a survey to analyze the factors influencing adoption of SaaS technology, based on technology acceptance model (TAM). In this context, expected the influence of factors on the use of SaaS technology in organization,and through the application of the survey, the motivating factors and inhibitors of technology adoption SaaS in Health Plans Operators market.</p>"
5995;en_US;"<p>An Information Infrastructure (II) provides a space for information sharing and collaboration that allows the spontaneous association of people, organization and technological components located in different geographical context to develop some activity. II do not originate from project specified a priori, its formation occurs through the evolution of an installed base. The current teleradiology infrastructure does not yet constitute an II for radiological practice, as the inertia present in its installed base hampers its evolution. This paper presents DicomFlow, a decentralized architectural model, built on the email and PACS-DICOM infrastructures, which uses this very inertia to promote the formation of an II for radiological practice.</p>"
5996;en_US;"<p>The need for faster deliveries with maximum business value to the product has gained prominence in current software development scenario. One of the key roles is the ScrumMaster in the context of agile project management process based on Scrum. In this way, it is important to understand how this role has been perceived by practitioners in software development in order to identify elements that are beyond the proposed by Scrum. Hence, this paper presents a qualitative research, performed to identify attributions and competences inherent to the role of ScrumMaster under professionals viewpoint that work in the public sector. This work has identified 20 different ScrumMaster attributions in respect of Product Owner, Team and organization, as also 12 competences considered important to this role.</p>"
5997;en_US;"<p>Agile methodologies are increasingly present in the industry. Known as a methodology that adapts easily to changes, which reduces risk and provides product creation quickly and safely, it has feature such as: constant contact with the client, generation of releases at the end of each iteration, prioritizing what has more value to the client, in addition to embrace easily the changes requested. Being requirement traceability important when we think of changes as it facilitates activity such as impact analysis, it is possible to realize that it would be a very useful activity in the agile process. However, there are some challenges when trying to apply traceability in agile environments. This paper is aimed to perform an exploratory research to raise the main problem related to traceability in agile environments, thus collecting information to assist in raising requirement for a tool that supports traceability in agile environments, and perform pre-traceability inter-tracking and post-traceability.</p>"
5998;en_US;"<p>Pair Programming is a development technique in which two programmers collaborate to conduct the same development task. The use of this technique in information system development may support many activity, such as code inspection and software integration. Studies have investigated the advantages and drawbacks of pair programming in both industrial and academic context. However, with respect to academic research, the majority of studies investigate this technique in European or North American educational institutions. Considering that some social and geographic factors may impact on the application and efficiency of agile method such as pair programming, we lack an evaluation of this programming practice in the context of Brazilian student. In this paper, we discuss the findings of three one-hour quasi-experiment conducted with 55 undergraduate and graduate student to assess pair programming in the development of tasks to implement an information system. These participant are student enrolled in Information system and related course of two Brazilian institutions. For the experiment, we divided each class in two groups: one group for solo programming and the other for pair programming. As a result, we observed that participant developing tasks in pairs presented lower rates of time spent and difficulty faced to complete development tasks when compared with solo programming participant. However, we did not observe a significant increase on the correctness in tasks developed by both experiment groups: paired and solo programmers. Finally, we conducted an analysis of participant feedback regarding other advantages of using pair programming in system development.</p>"
5999;en_US;"<p>Due to the large volume of data available, researcher find it difficult to store and organize the relevant paper to their investigation. Reference management system optimize this process, assisting in editing of a new paper through standardization and proper formatting of citations and references. The purpose of this paper is to evaluate the usability of EndNote, Mendeley and Zotero system. Evaluation method were used with and without user participation. It was observed that EndNote user had the highest completion rate of the requested tasks while Mendeley user achieved the highest satisfaction rate.</p>"
6000;en_US;"<p>Gestures analysis system have been getting attention for their ability to contribute to the interaction between humans, humans and machine, and humans and environments. In such system, the establishment of an efficient data representation for gestures is a critical task. The chosen representation as well as its combination with technique for analysis can or can not favor the solution being developed. In this systematic review we identify and discuss the strategies of representation of gestures used in 21 studies published in the last five years in the context of syntactic gesture analysis.</p>"
6001;en_US;"<p>Crowdsourcing is a problem-solving model through the contribution of a large number of people and has a low cost among its main advantages. On the other hand, smart city today comprise a multidisciplinary challenge, where they have the objective of sustainable development and improving the quality of life of its inhabitants. Thus, we see in crowdsourcing a resource capable of contributing to building smart city. This paper investigates the existing intersection between the fields of smart city and crowdsourcing and discover the gaps and challenges that characterize this application context. As a result, we propose some strategies to facilitate the development of crowdsourcing application. These strategies are then applied to the construction of several application of this type, two of which are discussed at the end of the article.</p>"
6002;en_US;"<p>Human beings spend much time indoors, such as school, factories and businesses. The emergency management in such environments is useful and challenging. The location and visualization technologies in these environments are not as advanced as existing for open environments (e.g., location via GPS, visualization in maps). Currently, much effort is devoted to identify people in indoor environments. Despite the relevance of this activity, few studies investigate aspects related to the visualization of this information. This paper presents a new visualization for indoor environments aimed at supporting the emergency. The proposed visualization was based on the opinion of emergency professionals, developed as a prototype and validated with end user. The result show that the developed visualization is effective in transmitting information regarding a possible indoors-emergency scenario and can thus support the professionals in their rescue activity.</p>"
6003;en_US;"<p>The identification of requirement of a computer system, which satisfy the needs of user, has become a key factor for the success of this system over the years. It is important to ensure that the requirement are correctly identified with minimal effort in its elicitation process. For this, we propose the use of method that favor the choice of the most appropriate technique for elicitation of requirement in order to minimize the cases in which the requirement are incorrectly indicated. This paper presents an approach that uses a decision matrix composed of values, which represent the importance of the technique based on a set of criteria previously known. The matrix is submitted to the decision-making method Electre II and AHP Referenced that generate the most promising alternatives. In our studies, the procedures for calculating these method have been automated in the software named ATD (Assistant Decision Making), which we are developing for mobile device. A set of data generated from the literature and information provided by professionals of the area of information system development was submitted to ATD. The result obtained are promising and can help professionals from mentioned area in their activity of selection process of the most appropriate elicitation technique to be applied to the problem whose solution will be solved by a computer system.</p>"
6004;en_US;"<p>Business Intelligence (BI) and Data Analytics application depend on an effective ETL (Extract, Transform and Load) process . This paper presents an approach and a Rapid Application Development (RAD) tool to increase efficiency and effectiveness of ETL programs development and maintenance. Furthermore, it is also described a controlled experiment conducted in industry to carefully evaluated the efficiency and effectiveness of the tool. The result indicate that our approach can indeed be used as method aimed at improving and speed up ETL process maintenance.</p>"
6005;en_US;"<p>Bovine meat commercialization has an important role in the general food market scenario. The beef quality evaluation is realized through many ways, being one of the parameters the intramuscular fat amount (marbling). This evaluation is often made by a visual approach, so the process is subjective and susceptible to some errors source. The use of Computer Vision technique result in an automatized, non-subjective, fast and accurate method for evaluation. This paper presents the modeling and development of a Computer Vision System for Marbling evaluation, applied on a meat Boutique, localized in Londrina – PR. The proposed System uses a Computer Vision approach to control the feature of the marbling analysis tool, aiming to satisfy sanitary requirement for non-contamination of the analyzed sample. Besides that, multiples sample on the scene are supported by our application. The proposed Computer Vision System has proved to be suitable for implantation in a production environment, like a meat Boutique.</p>"
6006;en_US;"<p>The increased use of physical activity monitoring device has created possibilities and opportunities to help in health care, as well as encourage the practice of physical activity and help to promote a healthier lifestyle, has also facilitated the sharing of information between professionals and patient. Because of the increased demand for these device, several model have recently been developed and released by different manufacturers. In this context, this paper proposes the development of a physical activity monitoring system prototype aimed at health professionals, called FitData. In order to monitor the patient, the system uses commercially available wearables and mobile device, connected to a physical activity tracking platform. The purpose of the system is to assist health professionals in the conduct of treatment, through the monitoring and evaluation of the patient. In order to evaluate the prototype was performed a questionnaire and applied to experts. The result were considered promising and allowed to observe the interest of user in the system.</p>"
6007;en_US;"<p>The teach of sorting algorithm in data structure discipline of Computer course, typically is accomplished through lectures and implementation of algorithm by student. With the aim of support the teaching algorithm, this paper presents the SORTIA 2.0 game, which aims to teach the Heapsort sorting algorithm through simulation of its execution. It is an online game, single player and free. To evaluate the game we used the model for assessment educational game MEEGA. The evaluation involved 25 student of the discipline of data structure of Computer Science course, of the Federal University of Santa Catarina (UFSC).The result of this first evaluation show that student felt satisfied, confident, immersed and have fun with the game, but principally consider that it really contributes to learning the discipline and also professionally.</p>"
6008;en_US;"<p>From time to time, it has been seen increased the dissemination of computing device in the society. However, recent research shows situations of individuals equipped with IT device, but technologically unprepared. Based on this context, it is evident that there is a minimal learning about computational aspects, which assigns the term Computer Literacy (CL). The objective of this study is to evaluate the relevance of CL aspects in the knowledge base formation of young Brazilians. This work is characterized by being an exploratory research using the in-depth interview technique to capture perceptions of three Brazilian institutions related to the subject of study. The research confirms the relevance of CL’s knowledge and skills, identifying particulars of the most important aspects for each of the surveyed institutions.</p>"
6009;en_US;"<p>The e-learning domain is characterized by fragmented solutions and multiple similar implementations. This paper presents an approach to enable the development, sharing and reuse of educational service through the Software Ecosystem perspective, through the extension of existing system information of elearning environments, known as Virtual Learning environments. To become platforms of an ecosystem that enables interorganizational collaboration. The proposal was evaluated by a case study, to verify its feasibility, as well as the concepts, architecture and technologies used.</p>"
6010;en_US;"<p>There is a lack of model and method that effectively help public organization to reduce costs and optimize the use of resource on the personnel management process, specially the vacation control. This paper describes a process mining model that can be useful for the analysis of the vacation control process at public organization. The method will be presented through its overview, a brief presentation of tool and the model application to a real case at a judicial organization, presenting answer to six research questions.</p>"
6011;en_US;"<p>Business Process Office (BPMO) has been structured in public organization with the purpose of formalize BPM actions and increase the effectiveness of service delivery to citizens. Peculiarities inherent this context like little flexibility to change and stiffness of the organizational structure difficult the consolidation of BPMO. This article discusses the factors that influence positively and negatively the structuration of this unity. The research was conducted through an action research. The data were treated using technique of grounded theory. The knowledge of factors and their reported interrelations can help to increase the chances of successful implementation of a Business Process Office.</p>"
6012;en_US;"<p>The process of selection of human resource for software project is complex and subjective, requiring the project manager to assess and identify the knowledge and experience of professionals needed for the project. There is a natural difficulty existing in corporate environments with multiple project in parallel. However in the context of software project, specific requirement must be taken into consideration to the execution of the project, such as very specific skills that the individual should already know in the beginning of the project because there will be no time for the project to develop them. The goal of this paper is to verify in the literature what are the approaches adopted by researcher to automate the selection of individuals for team formation on software project and their skills. For this purpose, this work conducts a systematic literature review. Four research questions were set and from them a search argument was used in seven academic search engines. 497 articles were found and after the criteria for inclusion and exclusion, 12 articles were analyzed. From them, genetic algorithm were identify as one of the approaches most used by the authors in order to automate the selection of individuals supported by a set of skills needed to design, however, it is notorious in the evaluated paper that each author uses a simplified set of individuals, in many cases pointing for example that the individual meets certain programming language only, without highlighting that the professional level of maturity, which in project can be a differentiator.</p>"
6013;en_US;"<p>Call Centers aim to be more productive by performing a standard service for its customers. In order to accomplish this goal, it is used procedures, which contains a set of likely solutions. It must be stressed that the current engine uses a simplified Boolean model, and left the system less consistent e slow with the Call Center needs. This research aims to figure out which information retrieval method, e.g., vector or probabilistic, have better performance in a search engine.</p>"
6014;en_US;"<p>One of the evolution paths of smart city go towards a strong integration of all intelligence dimensions — human intelligence, collective and artificial — available in a city. In pursuit of helping this evolution,this paper presents the mapping of a data model in order to create an ontology for Brazilian smart city in government health care, by applying Semantic Web concepts and data integration, to seek solutions to alignment problem between databases.</p>"
6015;en_US;"<p>The correct and sufficient documentation of an information system tends to facilitate its maintenance. In this sense, the class diagram is an important UML artifact for the design of an objectoriented information system. The development of this type of diagram, however, is often costly and complex because it involves different roles and a thorough knowledge of the domain area. Some experiences have demonstrated the feasibility of the automated generation of class diagrams, and the analysis based on descriptions is one of the possible technique. This study aims to apply natural language processing to support the development of the class diagram. For this, an application prototype is modeled and implemented in order to validate the proposal. The initial evaluation of the use of the tool was considered satisfactory.</p>"
6016;en_US;"<p>As a result of technological advances, many computerized device are communicating over the internet, and with that comes a growing number of distributed application that require continuous processing of large data stream source, geographically distributed in unpredictable volumes, requiring quick answers for complex query. These application, able to process large amounts of information in a timely manner, fit in the category of Information Flow Processing (IFP) [1]. Although they have a common object, these system differ in many aspects, including the architecture, data model, and rule language processing mechanism. Recently, much effort was put in the attempt to define a common background for the IFP system. However, these initiatives are still incipient and no real, standardized and unified model has been proposed so far to describe and classify the elements that compose those types of system. The purpose of this article is to propose a pattern catalog to capture the different aspects of IFP system, specifically focusing on complex event processing. Such catalog can be used as a reference for architects of information system that have realtime data processing as a requirement.</p>"
6017;en_US;"<p>The objective of this work is to identify the theories most widely applied in information system research. In order to achieve this purpose, an exploration of literature 2015 is realized, based on cocitation analysis. result indicate that Dynamic Capabilities Theory appears as main in the discussion of information system research.</p>"
6018;en_US;"<p>In organization, the business process modeling is of big importance to report, understand and automate process. These organization usually come unstructured document and difficult to understand by analysts. The extraction model or fragments process from textual descriptions may contribute to minimizing the effort required to process modeling. In this context, this paper proposes an approach to generate text-oriented process from the text in natural language. This paper proposes to investigate the structure of a text in natural language must show to from this one can extract fragments or process model. Based on the study of grammar classes accomplished in the context of this research, there is no established or standardized order in which the grammar classes should be shown in the text in natural language. Thus, preliminary result of this research show that by mapping rule and correlations between word represent the grammatical classes indicate a process element, through keyword and/or verb tenses.</p>"
6020;en_US;"<p>In a competitive market, adopting suitable business strategies is essential to satisfice and make clients loyal. This research aimed to identify profiles of clients that kept loyal to a telecom company and user that cancelled the service. We have considered reports from occurrence of the phone attendance service, registered to a private database, granted for this research. We have applied text mining for classification of occurrence, to avoid cancellation, and extraction of association rule, to understand the reasons that lead user to cancel the service. In the experienced conditions, the algorithm could predict cancellations with 97,02% accuracy. Besides, the most representative attributes for each class were extracted, providing a framework for strategic decision-making.</p>"
6021;en_US;"<p>In Brazil and around the world, Civil Society organization (CSOs) provide valuable public service for society. Through CSOs, people have organized and defended their rights, communities and interests, and can fully exercise their collective potential, often acting in partnership with governments to carry out public policies and/or develop their own project, financed by the private financing or being self-sucient. Public transparency and availability of quality data are requirement for analyzing the strength and capacity of these organization. Understanding the distribution of non-governmental organization across the world and at the national scale, their area of updating, project in progress, and their execution capacity, is critical to promote the financing conditions of CSOs, to make it visible and to make it more e↵ective, transparent, and strong. With these goals in mind, we developed the Civil Society organization Platform1, an open, free and public on-line portal that provides a wide variety of information on the profile and performance of the population of CSOs in Brazil. Its core mission is to provide data, knowledge, and information on the role played by the almost 400,000 CSOs in activity in Brazil and their cooperation with the public administration in delivering public policies and service. We show how we developed this platform, the integration with several di↵erent databases, the challenges of working with open government data and how we integrated a lot of recent open source technologies in all spheres of system development. The first empirical result are shown and some new feature regarding public data are presented.</p>"
6022;en_US;"<p>Purchasing air tickets by the lowest price is a challenging task for consumers since the prices might fluctuate over time influenced by several factors. In order to support user’ decision, some price prediction technique have been developed. Considering that this problem could be solved by multi-target approaches from Machine Learning, this work proposes a novel method looking forward to obtaining an improvement in air ticket prices prediction. The method, called Deep Regressor Stacking (DRS), applies a naive deep learning methodology to reach more accurate predictions. To evaluate the contribution of the DRS, it was compared with the competence of the single-target regression and two state-of-the-art multi-target regressions (Stacked Single Target and Ensemble of Regressor Chains). All four approaches were performed based on Random Forest and Support Vector Machine algorithm over two real-life airfares dataset. After result, it was concluded DRS outperformed the other three method, being the most indicated (most predictive) to assist air passengers in the prediction of flight ticket price.</p>"
6023;en_US;"<p>The act of searching the web has been the same for years. The user inputs a query and the search engine is responsible for finding the best matches to that query. Often, thereare subjective information that the user can’t transmit when making his query, but he expects that the search engine will infer. This leads to result that are query-related, but not user-interest related. One way of mitigating this problem was the introduction of the Semantic Web, wich aims to allow that the data available on the web have a meaning. Many approaches on semantic web search that crawl the semantic web have been proposed and implemented, as well as solutions to better rank and classify the result. This systematic review of the literature aims to obtain knowledge about the latest trends about the semantic relationships on the semantic web. Of a total of 1194 paper initially obtained during the research, 10 were selected and studied on this subject, giving a special atention to the technique used and the experiment made. It was then observed that promising new solutions involves the use of machine learning algorithm as a means to rank the result of a query.</p>"
6024;en_US;"<p>The objective of this work was to build a thematic database about Zika news, gathered from on-line source such as newspaper, blogs and forums. After explaining the collecting and gathering process it is intended to show how to apply semantic web concepts in order to triplify, connect and perform query on that database. The motivation of this work is to relate different data, such as authors, locations and news to understand the impacts of this disease in social media.</p>"
6025;en_US;"<p>Project management culture is a key element of an IS management model. In this context, this research aims to analyze the relationship between the characteristics of IS professionals and project management culture. To achieve this goal, we carried out a literature review on project management culture and on IS professionals. This research used a survey applied to 256 professionals and through the application of statistical technique concluded that: the culture focused on client and companys goals was the most perceived by the professionals, as opposed to the culture of innovation that was the least perceived. In addition, different types of professionals had different perceptions regarding project management culture.</p>"
6026;en_US;"<p>Falling can have serious consequences, enough to be considered a serious public health problem that affects mainly the older population, in which is related to the loss of confidence, self-esteem and autonomy.This problem is shown even more relevant if we consider the growing number of seniors, who in the search of their independence and autonomy decide to live alone. It is crucial that the elderly have quick access to medical care, a key part for quick recovery. The delay in medical care is linked with the increase of mortality rates and severity in a fall event. Thinking about it, the SafeWatch was developed as a fall detection system embedded in smartwatches. The proposed system will monitor the seniors through sensor at the smartwatch, and when a fall is detected, It will vibrate on the user?s wrist and report to a list of emergency contacts their location and inform the possibility of the elderly to be in a dangerous situation. experiment were performed with eight individuals of different biotypes, in which each one of them simulated a fall event in different directions. According to the experiment, it was possible to evaluate the application reliability through the values of Sensitivity and Specificity that reached 89,06% and 100%, respectively.</p>"
6027;en_US;"<p>Scientific events provide the integration between different communities forming collaborative network that can be characterized by different properties and pattern. The analysis of this information can contribute significantly to the improvement of these network and the dissemination of the knowledge created in these scenarios. Aspects related to the distribution of the content of the publications, the extension of the reach of the network and the increase of the collaboration can be improved from these discussions. The purpose of this work was to analyze how the collaboration between the different communities in the Brazilian Symposium on Information system is defined through the use of a graph-driven database management system. The collected data were analyzed in a first moment for the definition of the data model to be used. Having specified the model, the analyzed aspects were the collaboration network, the geographic distribution and the comprehensiveness of the topic covered. The result indicate that there has been an evolution in the behavior of collaboration network formed over the years and that the pattern seen on this evolution is mainly related to the geographical distribution of authors and institutions.</p>"
6028;en_US;"<p>Information Visualization creates graphical representations for data collections to better communicate its informational content to the user, revealing trends and pattern that allow a better decision making. DataViva is a computational platform that provides a set of visual analysis tool applied on socioeconomic, educational and international trade information from Brazilian localities, to direct the creation of public policies that contribute with the development in these localities. Multidimensional projection technique present potential to highlight the collection global structure, as well as the selection/exploration of interest groups. The collection is organized based on instances similarity, emphasizing the relationships among them. None of the analysis tool currently provided by DataViva offers this data perspective explicitely. In this sense, this paper presents an application of two multidimensional projection technique to the data provided by this platform. The result show the potential of this class of technique in revealing groups of localities with similar profiles, and highlighting the profile of localities with peculiar behavior, representing a potential tool for comprehend the behavior of Brazilian localities, as well as the relationship among them.</p>"
6029;en_US;"<p>The number of researches related to the Top-k Spatio-Textual Query has increased in recent years. This is due to the volume of data with spatial information (latitude and longitude) on the Internet, which necessitate the creation of ecient search method. Most of the researches that address this problem focus on the search method eciency, however, It is also necessary to evaluate the queryt’s effectiveness. This article describes the methodology for qualitatively evaluating a Top-k Spatio-Textual Query, and one method to create space-textual reference collections adapted from traditional collections, such as the Reuters-21578 collection. The tests performed in the two ranking functions indicate that the balance between textual relevance and spatial distance is crucial for better result.</p>"
6030;en_US;"<p>Cognitive model are used as the main source of information to modelling problem when empirical data are unavaliable, scarce or does not have an considerable relevance. The cognitive model are the expert’s opinions related to determined variable based on his knowledgement and experiences. There are some technique which aim to elicitate knowledge from experts, the one which will be used in this paper is the elicitation process. The elicitation process is a ensemble of steps that seeks to get the opinon of the expert in a way to improve the accuracy of the information and reduce some possible biases that the experts may show. This paper aim to compare the performance of cognitive model obtained through elicitation of knowledge and mathematical model in relationship to their accuracy in time serie forecast.</p>"
6031;en_US;"<p>With the advancement of the internet and the era of transparency, several organization disseminate a variety of information and service on the web. But much of this information are inaccessible to the visually impaired, such as information presented in graphic form. Seeking to reduce this lack of accessibility to this information the present research aims to identify the main difficulties related to the understanding of image on government websites for blind citizens and to propose recommendation for the development of these, so that the professionals involved in the information can make them more intelligible to blind citizens.</p>"
6032;en_US;"<p>The internet popularization provided access to different system through different device. In Brazil, access to the public institutions portals has been invested for years in order to guarantee access by different user groups, such as functional illiterates. This article aims to verify the adequacy of the informational content of the service provided in the portals of public institutions for functional illiterates, in order to identify possible improvements in access to information, with the support of a textual analysis tool. For this, we analyzed 26 web text of service available in a public portal with a tool that evaluates the cohesion, coherence and difficulty of the text, besides the application of a formula of intelligibility. The result showed that all service evaluated are not accessible to functional illiterates.</p>"
6033;en_US;"<p>Web accessibility is related to the fact that people with different degrees of capacity or incapacity can perceive, understand, navigate and interact with the web. Each country creates its accessibility laws and in Brazil there is currently a law that guarantees the inclusion of people with disabilities (Law nº13.146). This article presents an accessibility assessment of web sites of the state governments of Brazil and discusses the result considering social and economic indicators. Two software tool that aid in the automation of the evaluation and a metric defined in the literature were used. It was concluded that most states presented several problem regarding web accessibility. Additionally, we could observe barriers to information access.</p>"
6034;en_US;"<p>Resource consumption profile of a computer program is a relevant information with a wide scope of application such as schedulers, load balancers, Quality of Service (QoS) system, among others. Conventional technique available for this purpose include static source code analysis and profile matching based on runtime execution measurements. On the one hand, source code can’t often be available for analysis, but on the other hand, make measurements on an execution system requires special precautions to minimize the overhead. This paper presents the use of DAMICORE data mining technique to promote the characterization of binary computer programs by their resource consumption profile. The technique was successfully applied over a dataset composed by 80 binary programs carefully selected.</p>"
6035;en_US;"<p>Artificial Neural network (ANNs) has been spreading over the years and they have been growing due to the good result found in solving various real world problem. However, the presence of unimportant or redundant input variables that add nothing to the learning process of ANNs makes their training more difficult and time-consuming. The characteristic selection method are aimed at determining which input variables are most relevant for the determination of ANN output or response, thus helping to reduce the number of inputs. In this work four method of selection of characteristics based on ANNs were implemented and evaluated: Garson method; Perturb; PaD; and Sensitivity Analysis. All method were compared with the result obtained by the classical statistical method of Linear Correlation. The data of three recognized problem in the area (Iris, CPU Performance, Concrete Strength) were used for the training of ANNs that, after being trained using the Error Backpropagation algorithm, the characteristic selection method were executed, obtaining the importance of each input. For the Iris problem, all method presented similar result. For the CPU Performance and Concrete Resistance problem, the Perturb method presented the worst result, the Garson method obtained a satisfactory result, and the PaD and Sensitivity Analysis method presented better result and they stood out in relation to the others.</p>"
6036;en_US;"<p>This article aims to demonstrate the eciency of a support tool sports management from the program Olympic Talent of Paraná, denominated SIGE—TOP (Integrated System Of Sports Management — Olympic Talent of Paraná), which was developed by the State University of Londrina in a joint work of the Department of Computing of the State Department of Sport of Paraná (SEES). This tool has the purpose of performing monitoring and automation of program actions, beyond its management, and continually improve its policies, procedures and project process. As a result it was obtained a viable alternative for integration between the area involved in sport, guaranteeing young academics, athletes and technical through participation of systematized activity, the use of time of form contributory to the development of their skills and cooperative work.</p>"
6037;en_US;"<p>The use of intelligent interface, usability feature and voice technologies are enabling application to become increasingly rich, especially to assist inexperienced user or those with special needs. Therewith, many software developers are looking for ways to implement voice technologies in their products, and one of the most commonly used forms is the Application Programming Interface (API). Voice technologies are divided into two categories: voice recognition, which is widely used in voice commands (converts voice to text), and speech synthesizer, which is widely used to improve accessibility in device (convert text to speech). These voice technologies use Natural Language Processing technique, subarea of Artificial Intelligence, in order to process and manipulate human language at several levels. This article presents an analysis of the main voice recognition and synthesizing APIs, describing their characteristics and functionalities. In addition, as a case study, it shows which API was chosen, among those that were researched, and how it was implemented in the Alert Brusque application.</p>"
6038;en_US;"<p>This paper describes the development of an Artificial Neural Network for the classification of vehicle drivers, in order to determine the authenticity of authorized drivers. The input data for the neural network were obtained through the device called On Board Diagnostic (OBD), commonly used to detect defects in vehicle mechanism for maintenance purposes. The system developed sought to provide a differentiated functionality for this device, in the aid of vehicle owners with regard to the safety of their assets. A MLP (Multi-layered Perceptron) network was used with the backpropagation algorithm for training using data from an OBD. Behavior sample of three different conductors were used, obtaining the variables: accelerator position, acceleration in x, acceleration in y and acceleration in z as inputs. Two hidden layers were used, with ten neurons in each. We also used the moving average calculation for data filtering. The result were satisfactory, since the mean squared error during the training was very close to zero, causing the neural network to present a significant number of correct answers during the tests.</p>"
6039;en_US;"<p>Identifying potential victims to avoid alert people who are not in danger is an open challenge to crisis communications system. In an emergency situation alerting individuals out of danger can overload dissemination system and lead to loss of system credibility because people can be overwhelmed with irrelevant information. This paper aims to investigate how to improve the message dissemination process in crisis communication by using context-aware computing concepts. We propose a system to identify potential victims and define a strategy with a better way to contact them. For evaluation we performed two case studies with real emergency message. Finally, we discuss ways to identify potential victims of emergency situations.</p>"
6040;en_US;"<p>The Internet of Things (IoT), coupled with other trends, is being generating large amounts of data. All this data volume bring opportunities for knowledge extraction and value creation. The concept of integrating predictive and prescriptive may help the industry and user to be more productive and successful. This work presents a generic framework for prediction, prescription and actuation, enabling developers to easily integrate these concepts and functionalities in their experiment. The framework has a flexible, micro service based, scalable architecture, that provides eciency, fault tolerance and displays a good performance in IoT and cloud computing scenarios. An implementation of the proposal is presented and significant result are obtained.</p>"
6041;en_US;"<p>In recent years, there has been a significant increase in the scientific interest in usability and Web accessibility process. Nonetheless, there is still a significant portion of user who face barriers during Web interaction, specifically blind user. In this way, usability requirement, process aligned with the Web Content Accessibility Guidelines become paramount. Thus, this systematic review of the literature has focused on the publications of the last six years, aiming at the identification of the main method, technique and tool applied in the process of alignment of usability and accessibility requirement. Through analyzes, 486 scientific articles were identified, which addressed usability and accessibility process. Applying the inclusion and exclusion criteria, 86 articles were selected. The result demonstrate the scarcity of work that verify the eciency of the tool and the main technique that are used in process of accessibility and usability.</p>"
6042;en_US;"<p>The use of mobile application for execution of everyday tasks have made easier the modern life. The popularization of smartphone and the incorporation of multiple embedded functionalities, such as: GPS, Internet access, compass, among others; have enabled different purposes. The advances of social network application and smartphone have increased exponentially the number of photos shared instantly on the Web. Popularly, the photos captured by general people could be categorized in two kind of photos: events (e.g: birthday, concerts, etc.) and points of interest (POIs). The aim of MoveAndShot is to assist general population in finding the best spots to take pictures of POIs in a given city, finding the best direction to the photo taking. This mobile application establishes communication with a web service which provides the geographic position of POIs and the best spots to take pictures. An experiment was proposed in order to evaluate the mobile application. The result validated that MoveAndShot reaches almost 60% of precision on POIs photo taking task. Our experiment proved the effectiveness of MoveAndShot application on a case study developed in Crato, Ceará.</p>"
6043;en_US;"<p>Spreadsheet application have become one of the most popular end-user programming environments with innumerous built-in facilities, including arithmetic, financial and statistical operations. Not surprisingly, spreadsheet application play significant role in decision-making process in organization, thus making spreadsheet errors serious threats. Reports from field audits show that spreadsheet errors may cause company to lose millions of dollars annually. One effective and simple way of helping user to avoid introducing mistakes in their spreadsheets is data validation. Indeed, most spreadsheet application provide a wide range of built-in functions to restrict the type of the input data or the range of valid values entered into a cell. However, in most of them, the underlying design decisions governing how data input should be entered in a spreadsheet are not explicitly visible to its user. Hiding data validation rule from user may hinder the comprehensibility and the usability of a spreadsheet, thus increasing the risks of entering incorrect data input. To assist end-user programmers in explicitly expressing validation rule in spreadsheets, we propose the SpreadSheet Validation Language (SSVL). We conducted a user study to assess the effectiveness of SSVL. The result show that user using SSVL are faster and more productive in tasks involving the comprehension of data validation rule. This is a promising result suggesting that SSVL can actually improve the usability of spreadsheets.</p>"
6044;en_US;"<p>This article aims to present the development of a Network Intrusion Detection System (NIDS), with real environment trac, using the technique of Artificial Neural network to classify trac as intrusion or normal. For the experiment, two databases were used: the network trac database provided by ISCX; and a test database created in real-world environment. The result obtained using the technique of Artificial Neural network, trained with the ISCX database, showed accuracy rates of around 90%, for the ISCX data itself, and 98% for the real environment test data. These result arm the feasibility of implementing the technique of Artificial Neural network to solve problem of classification of trac of computer network.</p>"
6045;en_US;"<p>Markov Decision Process (MDP) has been used very eciently to solve sequential decision-making problem. There are problem in which dealing with the risks of the environment to obtain a reliable result is more important than maximizing the expected average return. MDPs that deal with this type of problem are called risk-sensitive Markov decision process (RSMDP). This systematic review of the literature aims to identify the theoretical result and proposed algorithm to solve RSMDP problem that have an exponential utility function, evaluating their main characteristics, similarities, particularities and differences in order to allow the reader the knowledge of this tool of decision making for risk sensitive problem.</p>"
6047;en_US;"<p>This article discusses the importance of quality assessment in software ecosystem, especially in the educational domain. Some ecosystem health indicators are presented, focusing on BROADECOS, an e-Learning Ecosystem based on educational service, resource reuse and sharing in an inter-organizational context. Metrics were defined for evaluation of ecosystem health, and from the semi-automated HEAL ME architecture the ecosystem quality was evaluated, with four indicators. There are indications of the feasibility of the evaluation process, and its analyzis and result can be used to improve the ecosystem, to survive and to adopt it on a large scale.</p>"
6048;en_US;"<p>With the rise of the Internet of Things (IoT) billion device will be connected to the internet of the future producing, consuming and processing data and communicating with each other. Discover and select eciently the device best suited to a particular need, appear as relevant issues to be investigated in the IoT. In view of this problem, the present work proposes: (i) using and monitoring quality metrics in the description of the data producers, (ii) the propose of a ranking of data producers technique that makes use of quality attributes, (iii) the suggestion of dynamic queue result by the search engine and (iv) the use of REST style for providing data producers as resource. Finally, it was considered a use case scenario of the mobile application Bike Cidadão in order to evaluate the performance of the proposed contributions. The evaluation noted, above all, the response time required to perform query to the catalog using, or not, the concept of dynamic queue result in different situations, varying the amount of data available to consumers and producers.</p>"
6049;en_US;"<p>SWEBOK is a guideline that provides information about Software Engineering (SE) knowledge, including a list of Best Practices (BPs) for adopting. However, small company have restrictions such as, limited budget, reduced schedule, and, small staff that can hinder the advantages of these BPs adoption. Thus, this paper investigated the last decade of BPs adoption reported by small company’ environment. A quasi-systematic mapping was conducted for assessing studies that addressed this issue, and it was possible to observe that the most prominent BPs adopted are “test application” and “software process model adoption”. On the other hand, “limited budget” and “staff size” were found as causes for non-adoption of SWEBOK’s BPs.</p>"
6050;en_US;"<p>Business Process Management (BPM) system have facilitated the rapid production of web application that execute process expressed in BPMN. Automated testing of such application, however, remains a challenge. In this article, we propose an approach for generating scenarios for testing Web application implemented with the support of BPMS, from BPMN model. The approach is intended to abbreviate the effort to construct test scripts and is focused on functional testing using the Selenium and Cucumber tool. The approach was applied to process found in different repositories and was able to generate the expected scenarios.</p>"
6051;en_US;"<p>system for Knowledge Discovery in Databases and Machine Learning predict situations, group and recognize pattern, among other tasks. Although these application are concerned in generate fast, reliable and easy to interpret information, extensive databases used for such application make difficult achieving accuracy with a low computational cost. To solve this problem, the databases can be reduced aiming to decrease the processing time and facilitating its storage, as well as, to save only sufficient and relevant information for the knowledge extraction. In this context, method to reduce and filter databases have been proposed, especially the Instance Selection method that selects a subset of examples from the original training data. The subset should maintain all the information of the original set, so that it can be used to generate classification model with the same accuracy as model generated by using the original set. In the last decades, several approaches have been suggested and studied in order to select instances, among them the Evolutionary algorithm. Although the instance selection method aim to optimize two goals conflicting with each other, accuracy and reduce computational cost, only an algorithm for multi-objective optimization has been applied to this problem. Therefore, the aim of this study is to perform instance selection based on widely known Multi-objective Evolutionary algorithm, such as NSGAII and SPEA-II, and to evaluate the classification performance over different domains dataset. The result, compared to others available in the correlative literature, demonstrate that NSGA-II and SPEA-II algorithm can be applied in instance selection for classification problem, because many superfluous instances are removed from the training set, reducing runtime in the classification stages, without significant changes in accuracy</p>"
6052;en_US;"<p>The company inventory control is a hard and complex job. Despite the effort to increase the level of automation of such tasks, it has been observed that the human presence is still necessary to manage, feed and keep them. This research presents a Web system, named InventoryIoT, that automates the inventory control for ecient management. Based on the concept of the Internet of Things, we propose attaching RFID tags to assets, giving them the status of Smart Objects (OI). For this purpose, this work considers a middleware that allows the communication among OIs and the Web system, which operates as a social network. The result is a platform able to perform the intelligent management and monitoring of the movement of goods within a institution in an automatic way, reducing the human labor time and keeping the information always updated. The system was implemented and validated.</p>"
6053;en_US;"<p>The current political brazilian scenario does not provide effective mechanism to include public participation in the decision-making of government policies. Thus, the objective of this work was to create a mobile app that offers tool for the population to discuss and suggest solutions to problem found in city. In this way, through the use of Collective Intelligence, the platform is able to define the priorities of the city. It was necessary to choose people with specific profile to join the platform and to apply for the Political office of councilor. These people are responsible for solving the demands of the population. As result, a mobile application was developed implementing all the requirement to achieve the objectives. A case study was performed in two city of the country: Ouro Preto - MG and Araraqua - SP. We concluded that the use of information technology can assist in the public participation of political decision-making.</p>"
6054;en_US;"<p>The governments incentive to transparency of public data became increasingly evident after the introduction of the Access to Information Law. Due to this law, new tool for searching, accessing and visualizing open data have been developed for the purpose of improving the social control of government actions. However, these tool, sometimes, are not able to make the access to this information simple to any citizen. This work presents the mobile app FiscalizaBR, whose purpose is to facilitate the access to data on contracts and covenats made by the Brazilian government. By means of an experimental study conducted in this work, it was noticed that the proposed app presented higher effectiveness and efficiency, when compared to another too with the same purpose.</p>"
6055;en_US;"<p>In incremental development approaches, there is a great interest in delivering system releases on-time and on-budget, raising the satisfaction level of the stakeholders involved in the development process. Thus, the software requirement selection process has a key role in identifying a good-enough or even an optimal subset of candidate requirement, which can balance trade-offs among critical aspects, such as project budget, requirement costs, customers’ preferences and their importance. Despite relevant contributions, current proposals do not address software risks involved in the development process, which represents another key aspect that can deeply impact on project cost and stakeholders’ satisfaction. In such a direction, this paper proposes a risk-based approach for selecting software requirement, in which a risk analysis is incorporated for estimating the impact of risks in the cost of the next release requirement and stakeholders’ satisfaction. Evaluation result based on a pilot use case reveal the potential practical applicability of the proposed approach.</p>"
6056;en_US;"<p>The present work makes a proposal that combines a GVA technique with historical data and a use of Random Tree with the objective of improving the predictability of the costs of the project, through a study that uses 23 project of a software factory . For the proposed technique to have more eciency than the traditional technique, the hypothesis tests with 95 % significance.</p>"
6057;en_US;"<p>Since agile method do not have prescriptive characteristics, there is not a formal definition on how requirement Engineering (RE) activity should be executed. This situation leads to a variety of different forms of defining how requirement are elicited, prioritized, documented and validated. So, it is necessary to comprehend how research on RE have characterized such activity. By using a systematic review approach, the objective of this study was to identify practices and technique that have been used for each RE process in agile project. The study also identified challenges and lessons learned that should direct improvements in this area.</p>"
6058;en_US;"<p>Initiatives have emerged in the pursuit of improved software process and service in recent years. These initiatives are guided by Standards, model and Quality Standards, aiming to establish best practices to guide the definition of process and support the assessment of maturity and capacity of organization. Despite the emergence of these initiatives, when the subject refers to the process of contracting IT solutions by the Federal Public Administration (APF), the main contractor of software and service in Brazil, the application of best practices in public organization Obstacles. Among these, the following stand out: the complexity of the process and the continuous supervision of the control bodies. In order to minimize these obstacles, the Court of Audit of the Union (TCU) recommended the preparation of the SLTI / MPOG 04/2014 Normative Instruction, containing guidelines for the process of hiring IT Solutions, supported by the IT Solutions Procurement Guide GCSTI). This work aims to identify the maturity and adherence of the GCSTI in relation to the CMMI-ACQ, CMMI-DEV and CMMI-SVC model. For this, a mapping was used as strategy, resulting in the adherence of the APS GCSTI process and the CMMI model.</p>"
6059;en_US;"<p>Governments use Information and Communication Technology (ICT) to provide citizens, organization and governments with online service and tool. One of the key factors in this context is system interoperability, since it promotes the exchange of information among system in different levels. Achieving high levels of interoperability, however, is challenging because it involves different concepts, business process, standards, language, ontology and laws. The Brazilian government has defined the e-PING Interoperability Standards to specify the guidelines for achieving interoperability in different levels, but many public organization cannot completely implement the interoperability aspects in their solutions. Therefore, the purpose of this paper is to present an investigation we conducted with the ICT departments of the Brazilian federal universities to understand whether and how they use the e-PING interoperability standards, and what are the main challenges. result show that most universities do not fully implement interoperability requirement mainly because of a shortage of ICT staff, lack of knowledge and lack of clear instructions on how to achieve interoperability using the e-PING standards. Such findings allow us to identify several improvements on the Brazilian egovernment strategy.</p>"
6060;en_US;"<p>The Brazilian federal government has promoted several actions towards addressing digital accessibility in e-government system once it is essential for all citizens to take part on participatory digital governance and have access to important information and online service. In this paper, we evaluate the main web portals of 28 federal agencies with ministry status to check whether they comply with the main laws and standards related to digital accessibility, namely the Accessibility Model in Electronic Government, also known in Portuguese as e-MAG; the Digital Government Identity; and the Accessibility Circumstantial Report. Unfortunately, most federal agencies fail to deliver acceptable levels of accessibility and to present a digital accessibility assessment along with a work plan to address the known issues. We also present an interview with a blind citizen to understand the Brazilian digital accessibility scenario from the perspective of a person with disability. The result of the interview confirmed that, even with the existence of e-MAG, the Brazilian federal government has yet a long way to walk to assure citizens the basic rights to access information, online service and take part in important decisions.</p>"
6061;en_US;"<p>This article describes an open architecture for recommender system, with steps, profile and context aspects, technique and method, that can be adapted to several domains. This approach enables cost saving, enhances system reliability and functionality, and streamlines the software development process to meet specific requirement. The proposal was developed from a systematic mapping of the literature and the Research Group experiences. To validate the proposal, a recommendation system for e-Science service is presented, under ecosystem approach. The evaluation of the proposal is composed of a case study and the preliminary result point to the feasibility of the model.</p>"
6062;en_US;"<p>Over the years, Software as a Service (SaaS) has become a common delivery model for many application. In cloud application, a huge volume and variety of data can be generated and they can be available for consumption by DaaS (Data as a Service). For this, the data provided by DaaS can be stored in a non-structured (e.g. text), semi-structured (e.g. XML, JSON) or structured format (e.g. Relational Database). However, the access of that kind of DaaS, in a transparent manner, needs substantial efforts due to the lack of interoperability between SaaS and DaaS. In this paper, we propose a new enhanced version of MIDAS, middleware to provide seamlessly and independently interoperability between SaaS and DaaS. First, this new version of MIDAS allows both semi-structure and structure data format from SaaS. It mediates query from NoSQL (e.g. MongoDB) and SQL (MySQL) databases. Secondly, it was enhanced with Join operations, both in SQL and in NOSQL statements. And lastly, other formats were added for the DaaS to fit SaaS requests, such as JSON, XML, and CSV formats. To evaluate this new version of our middleware, we provide three types of experiment to cover critical issues such as execution time, the overhead of our approach, and scalability of MIDAS. Our result show the effectiveness of our approach to tackling interoperability issues in cloud computing environments.</p>"
6063;en_US;"<p>Cloud computing is a computing style in which resource provider can offer on demand service in a transparent way and clients usually pay according to use. The cloud introduces a new level of flexibility and scalability for user addressing challenges such as rapid change in IT scenarios and the need to reduce costs and time in infrastructure management. However, to be able to offer quality of service (QoS) guarantees without limiting the number of requests accepted, provider must be able to dynamically and eciently scale service requests to run on the available resource. Load balancing is not a trivial task, involving challenges related to service demand, which can shift instantly, to performance modeling, and deployment and monitoring of application in virtualized IT resource. In this way, the aim of this paper is to develop and evaluate load balancing algorithm for a cloud environment in order to establish a more ecient mapping between the service requests and the virtual machine that will execute them, guaranteeing the quality of service as defined in the service level agreement. In the experiment it was observed that the proposed algorithm allowed a reduction in the requests execution time, increasing the number of requests served during the observation time.</p>"
6064;en_US;"<p>A publication venue authority file stores variations in the names of journals and conferences that publish scientific articles. It is useful in the construction of search tool and data disambiguation, and it is of special interest to agencies funding research and evaluating graduate programs, which use the quality of publication venues as a basis for evaluation of publications of researcher and research groups. However, keeping an updated authority file is not a trivial task. Different names are used to reference a same publication vehicles, sometimes they change their name, new venues emerge regularly and their quality indexes are updated frequently. This paper presents the development of PVAF Manager, a system for managing information about scientific publication venues. It represents the evolution of a previous work, and incorporates feature such as the expansion of the publication venue database for all area of knowledge covered by Qualis Capes, tool for annual updating of bibliometric, option for updating and correcting data, management and collecting of user suggestions. We present the implementation details and an experimental evaluation of the result of the expansion and the quality of the data search method. The result show a good coverage of PVAF in relation to international publication venues and low error rates of the data search method.</p>"
6065;en_US;"<p>Security and privacy have always been the subject of research, but currently with the popularization of mass media, such as the Internet, this subject becomes even more fundamental. Communication today is not only done by exchanging text or audio files, but also by exchanging digital image files. Encryption system have been constantly improved and standardized to provide security and privacy, including algorithm specialized in image encryption. Although they are translated into binary data as well as text, the image have particular characteristics that prevent the use of popular cryptographic system such as RSA, DES and AES. Stream cipher system are compact and simple to implement. To promote their development ECRYPT (European Network of Excellence for Cryptology) has organized the eSTREAM project, resulting in a portfolio of validated stream ciphers for software and hardware implementations. This article presents the analysis of eSTREAM Profile II ciphers regarding their quality when applied in digital image.</p>"
6066;en_US;"<p>The goal of Information Technology (IT) is to use information effectively to support organizational activity. Therefore, it is crucial to establish a satisfactory IT plan that enables and strengthens the continuous improvement of the performance of organizational activity and process. The goal of this paper is to assess the capacity if critical IT process of the IT Management Department of the Federal University of Lavras. We selected three critical process to assess using the Cobit Process Assessment Model – PAM – supported by interviews and evidences of executed practices. This paper resulted in the diagnostic of the three selected process and a set of improvement proposal based on Cobit 5.</p>"
6067;en_US;"<p>Bad smells are symptoms that something may be wrong in the information system design or source code. Although bad smells have been widely studied, we still lack an in-deep analysis about how they appear more or less frequently in specific information system domains. The frequency of bad smells in a domain of information system can be useful, for instance, to allow software developers to focus on the more relevant bad smells of a certain domain. Moreover, developers of new bad smell detection tool could take information about domains into consideration to improve the tool detection rates. In this paper, we investigate code smells more likely to appear in four specific information system domains: accounting, e-commerce, health, and restaurant. Our analysis relies on 52 information system mined from GitHub. We identified bad smells with two detection tool, PMD and JDeodorant. Our findings suggest that comment is a domain-independent bad smell since they uniformly appear in all investigated domains. On the other hand, Large Class and Long Method can be considered domain-sensitive bad smells since they appear more frequently in accounting system. Although less frequent in general, Long Parameter List and Switch Statements also appear more in health and e-commerce system, respectively, than in other domains.</p>"
6068;en_US;"<p>Design pattern are general reusable solutions to common recurring problem in software project. These solutions, when correctly applied, are supposed to enhance modular and flexible structures in software. The aim of this work is to study the occurrence of God Class and Long Method bad smells in software system developed with design pattern. To achieve this aim, we carried out a study with five Java project, in order to: (i) investigate if the use of GOF design pattern avoid the occurrence of the bad smells God Class and Long Method, (ii) identify co-occurrence of the GOF design pattern with these bad smells, and (iii) identify the main situations that lead software system to present these co-occurrence. The result obtained suggest that Composite and Factory Method have a low co-occurrence with these bad smells, and Template Method and Observer have a high co-occurrence with God Class and Long Method, respectively. In addition, we have identified that the misuse of design pattern and the scattering and crosscutting concerns has contributed to the emergence of such co-occurrence.</p>"
6069;en_US;"<p>Software metrics provide basic means to quantify several quality aspects of information system. However, the effectiveness of the measurement process is directly dependent on the definition of reliable thresholds. To define appropriate thresholds, we need to consider characteristics of the information system, such as their size and domain. There are several studies to propose method to derive thresholds and evaluate them. However, we still lack empirical knowledge about whether and how thresholds vary across different information system domains. To tackle this limitation, this paper investigates specific thresholds in four information system domains: accounting, e-commerce, health, and restaurant. Our study relies on 40 information system to derive domain-specific thresholds for 9 well-known software metrics. Our result indicate that lower-bound thresholds (e.g., 15% smaller classes) usually do not significantly vary across domains. However, for all analyzed metrics, upper-bound thresholds (e.g., 5% largest classes) are different in some domains. Moreover, our study also suggests that domain-specific thresholds are more appropriated than generic ones. For instance, we observed in our analysis that the more appropriated threshold to select the 5% largest classes is 290 LOC in health system and 147 LOC in accounting system.</p>"
6070;en_US;"<p>application developed with the JavaScript language, have been increasing every day, not only those based on Web (client-side), but also server-side application and mobile device. In this context, the need for tool to identify failures is fundamental, to help developers during the evolution of these application. Di↵erent tool and approaches have been proposed over the years and this knowledge is fragmented in the literature, which makes it dicult for developers to choose the best tool for fault identification. In this way, the objective of this research is to systematically analyze the method and tool that are being used for automatic detection of failures in software written in JavaScript. Besides cataloging the failures most sought in each environment and identify the gaps in the area. For this, a systematic review of the literature was carried out, which resulted in 19 primary studies relevant to the objective of this research. Most of these studies focus on the web-environment (client-side), showing the lack of research to detect failures in server-side and multiplatform environments.</p>"
6071;en_US;"<p>Business process management has become frequent in the context of Information system (IS), allowing a more organized and aligned flow of business to the software requirement. However, the integration of Information system with the current Business Process Management System (BPMS) still has some limitations, such as increased manual work, lack of code standardization, and complexity of BPMS architectures. Based on this, this paper proposes an approach for the integration of Information system and BPMSs. More specifically, an approach that allows abstracting the capture of user activity in an IS and its execution in a BPMS. For evaluation purposes, we use our approach with an example application. In addition, we integrate the same application with a market BPMS directly and with a Business Object-Process mapping framework. From the three system implementations, we performed qualitative and quantitative analyzes.</p>"
6072;en_US;"<p>Modeling a software development process is important as it allows a better understanding of this process, as well as the identification of possible enhancements. In a research, development, and innovation project developed in partnership between a research group of a brazilian university and a mobile phone manufacturer, some changes in the development process resulted in an outdated process documentation. In order to update the documentation to reflect the process that was being used, an interactive approach was implemented. This approach was based on observations of project activity, document analysis, meetings with the project manager, and interviews with the development team. This paper presents an experience report about the application of this approach, describes the lessons learnt, and the team’s perception regarding the process.</p>"
6073;en_US;"<p>Social BPM is the combination of Business Process Management (BPM) with social and collaborative technique for the purpose of exploring collaboration among stakeholders throughout the BPM lifecycle. Its goals are to reduce common problem in BPM by ensuring collaboration and transparency. To the best of our knowledge, there is no information on how Social BPM is being used in organizational environments and on its impacts. This study aims at showing how Brazilian organization are using Social BPM practices and technologies. Therefore, a survey was conducted with employees from different company in order to collect data on their usage of BPM collaborative practices. The survey received 31 replies and 3 of the respondents were also interviewed in order to provide depth to their answers and to enhance the overall understanding. The result show that collaboration happens predominantly in design, modeling, and improvement phases. Collaboration still happens mainly without formal planning and without tool support.</p>"
6074;en_US;"<p>Business Process Model and Notation (BPMN) provides a mechanism to display information about the data flow of a process through artifacts such as objects, associations and data stores. However, these elements provide a limited capacity, especially when referring to the mapping of the data source (e.g. web service) in a process model. In this context, this paper proposes an approach to associate data source to BPMN elements (e.g. service task). Such approach aims to serve as a guide to business process management professionals in order to define, in design time, the most appropriate data source depending on the BPMN elements presented in a given process model. In order to demonstrate the result, five correlations were evidenced, which are called “definitions”, followed by their textual description and an example of use. These definitions were validated through a survey which have their result also presented and discussed during this research.</p>"
6075;en_US;"<p>This article describes a security system to be used in information system based on iris biometrics. The process of authenticating user in an information system is relevant and can be accomplished using several method such as alphanumeric password, digital certification, electronic device, password generator or system that recognize human characteristics such as the iris. A biometric iris system consists of the following steps: acquisition, segmentation, normalization, pattern extraction and finally the recognition step, which consists in the verification or validation of the user in the system. Each of these steps is related to the performance of the biometric system. In this context, the main objective of this work is to study the impact of the iris image quality in the acquisition stage and its overall performance of the implemented biometric system, establishing minimum quality thresholds to guarantee an adequate user authentication in the system. The experimental result demonstrated that the false acceptance and rejection parameters decrease if a threshold quality is established.</p>"
6076;en_US;"<p>This paper proposes a technique for classifying user accounts on social network to detect fraud in Online Social network (OSN). The main purpose of our classification is to recognize the pattern of user from Human, Bots or Cyborgs. Classic and consolidated approaches of Text Mining employ textual feature from Natural Language Processing (NLP) for classification, but some drawbacks as computational cost, the huge amount of data could rise in real-life scenarios. This work uses an approach based on statistical frequency parameters of the user posting to distinguish the types of user without textual content. We perform the experiment over a Twitter dataset and as learn-based algorithm in classification task we compared Random Forest (RF), Support Vector Machine (SVM), k-nearest Neighbors (k-NN), Gradient Boosting Machine (GBM) and Extreme Gradient Boosting (XGBoost). Using the standard parameters of each algorithm, we achieved accuracy result of 88% and 84% by RF and XGBoost, respectively</p>"
6077;en_US;"<p>Complex data, such as video, image and audio, require particular forms of querying, storing and indexing that commercial DBMSs still do not provide. One of the solutions for DBMS to o↵er support for complex data is to extend relational operators to represent similarity query. Similarity query retrieve data based on similarity relations among stored data, which are derived from the intrinsic data content. One important type of similarity query is the similarity join that returns pairs of elements from two input dataset that satisfy the stated join condition, which can be for instance if they are closer to each other than a given threshold (Range join) or if one element is among the k-nearest neighbors of the other (k-NN join). Existing algorithm to execute similarity joins essentially consider input dataset/relations are directly read from disk. However, join is one of the most time-consuming operations in a query, therefore delaying it in the execution plan and join filtered data in memory usually result in performance gain. In this paper, we present range join algorithm developed to perform in memory on filtered data on top of a commecial DBMS. Our proposal is to allow executing similarity joins in di↵erent positions in the query plan and evaluate how distinct algorithm behave according to varied situations. Presented result show that best developed options are the state-of-the-art DBSimJoin algorithm for high selective filtered inputs and an indexbased similarity join for query in which the join selectivity is high and a proper data index is available.</p>"
6078;en_US;"<p>In the last decade, the OLAP technology has been redesigned for the textual data, therefore dimensions, hierarchies and measures are being remodeled. Topic hierarchy is a useful alternative to organize document collections. Currently, the topic hierarchy is defined only once in the data cube, i.e., for the entire lattice of cuboids. However, textual hierarchy is sensitive to the content of the document. Thus, a data cube cell can contain a collection of document distinct from others in the same cube, since they have complementary aggregation levels that potentially introduce changes in the topic hierarchy. In this paper, we present a textual OLAP approach, named DTCubing, which handles multiple topic hierarchies for each cube cell. Multiple hierarchies are feasible because a document can be partitioned into several text segments (e.g., title, abstract, keyword and many more). A second contribution of this paper refers to query response. The state of art in textual OLAP normally returns the top-k document as a query result. We go beyond by returning other text segments, such as the most significant titles, abstracts and paragraph. experiment, using part of the DBLP paper, reinforce our assumptions.</p>"
6079;en_US;"<p>From the analysis of spatio-temporal data one can identify group pattern of moving objects, for example the flock pattern. This pattern can be defined as a minimal number of entities within a defined disk diameter moving together during a certain time-window. However, as the trajectories of different objects are collected, they may be irregular due to problem such as system failures, passing through tunnels or underground, etc., causing gaps in the collected trajectories. One technique to address this problem is path interpolation, which geometrically generates points corresponding to missing spatio-temporal points based on collected data. In this sense, the objective of this work is to include interpolation technique in online flock pattern algorithm for the treatment of lossy spatiotemporal data streams using configurable size of temporary memory. Our approach allows employing different interpolation method with low overhead and good precision result. Comparing result using the original databases and interpolated streams, the experiment showed good result in the search for flock pattern reaching up to 80% recovery of lost answers, without significantly impacting the algorithm execution cost.</p>"
6080;en_US;"<p>Given the growth of the economy based on intangible assets, organization need to adopt practices for creating, retaining and disseminating knowledge. model of Knowledge Management (KM), especially those supported by information system, become an essential mean for the establishment of successful strategies. In this context, emerged the primordial question: how can software be used to manage and support knowledge sharing? In search of answers, this work has the objective of conducting a study on utilizing of KM model, as well as the creation of KM support software in a software development company. The study can be characterized as applied and descriptive with qualitative approach, through a case study with participant observation. Eighteen aspects of fourteen KM model were analyzed together with sixteen employees of a company to identify their perceived relevance to the organizational context, these being the requirement for the development of the proposed software. As a final result have the construction of an information system of support to KM, called TSKM, which was homologated by the companys employees in relation to the relevant aspects identified by the case study and the functionalities implemented in the proposed system. The study fulfilled the proposed objectives and instigates new studies regarding the use of KM support system in different segments of company.</p>"
6081;en_US;"<p>This paper aims to present the result of a research carried out on the use of knowledge management with mobile technology to promote of consumer law. The use of information through mobile learning resulted in an application that provides the information and promoter access to the service of the consumer police station of Pernambuco and to other consumer protection agencies. In addition, an information booklet was developed and made available to be used in an e-learning course, using a virtual environment for public security safety with in the Recife metropolitan region and other actus in the countryside of Pernambuco.</p>"
6082;en_US;"<p>In the intangible economy, knowledge is a valuable asset, and its management has become vital to modern organization. However, the operationalization of Knowledge Management (KM) is a complex activity, since it must consider the treatment of the relationship among many aspects, being technology among them. In this context, information system to support KM are important and, due to their interaction with other aspects, an assessment is required to determine the benefits perceived by user. In this sense, this work has the objective to analyze the impact perceived by the use of the Software Tool of Knowledge Management software in a software development company. Specifically, the goal is to perform an evaluation of this system considering employees vision regarding: a) what is the perception of aspects of KM before and after the use of the software; and, b) what is the impact on the aspects of the KM in detriment to the use of the software. For that, a qualitative-descriptive study was carried out with data collection through a questionnaire considering 18 aspects of KM. The result show that the software have affected positively and significantly several aspects of the organization KM, emphasizing the integrative approach to technology. Although this study’s scope focus the study of only a system in a company, the methodology presented is also useful for future work that fosters the use of system to support KM and other analysis by comparison of the effects on the aspects of KM in different follow-up company.</p>"
6083;en_US;"<p>The use of serious game has emerged as a differentiated strategy to promote the teaching of essential concepts and technique in several area of knowledge. To contribute to the student’s formation process of the Software Project Management, this research presents the development and validation of an electronic board serious game, named SCRUMI, to the teaching of concepts inherent to the SCRUM framework. The evaluation of the proposed game was carried out according to some criteria such as usability, quality of the issues and presentation of the activity, applicability and motivation. The main result showed that the game is presented as a good alternative to be explored in the classroom.</p>"
6084;en_US;"<p>The growth in the number of places in Brazilian higher education was of great benefit to the country, bypassing the elitist model that marked the beginning of academic activity in Brazil. However, the social and economic impact can be minimized by the occurrence of the evasion phenomenon. We highlight the investments in science, technology and innovation that has higher education as its great ally, especially in what refers to technology course. In this sense, this work performs an analysis of the evasion phenomenon in a course of Information system of a public institution under the prism of several previous work on the subject, and with new contributions of the authors. The result bring a discussion about the use of evasion rates and use a categorization of evasion dimensions, adapted from previous approaches.</p>"
6085;en_US;"<p>The rapid development of information and communication technologies has changed the profile of student. Expositive classes tend to be monotonous and may lead student to disinterest. In this context, Active Learning (AA) can help to improve the teaching-learning process. This paper presents an overview of the use of AA in Information system (IS) undergraduate programs, as well as other technique that have proven to be effective for use with IS student in their process of building knowledge of course subjects. In addition to the technique, some result and reflections on the experiences are also presented.</p>"
6087;en_US;"<p>provider need to supply the demand of their clients as optimally as possible and maintaining the quality of their service. However, in many cases this demand is unknown. The problem known as inventory routing problem with stochastic demand combines: (i)inventory control; (ii) product transportation; and (iii) delivery scheduling decisions considering this type of demand. This work aims to improve the state of the art algorithm based on mathematical programming and lagrangian relaxation aiming to find solutions with lower cost. To accomplish this, three variants of the algorithm were proposed considering different heuristics. experiment were performed with test instances containing 15, 25 and 50 clients; and the final cost of the solution and the computational time for the convergence were analyzed.</p>"
6088;en_US;"<p>The elaboration of questionnaires for application in interviews, statistical surveys or scientific research is not a trivial task, because poorly worked questions can lead to direct answers with meaningless or naive interpretations. Therefore, it may be interesting to reuse, partially or totally, questionnaires already constructed with the same purpose. In this paper, we describe an experiment to analyze the execution of the vector model in the retrieval of questionnaires. In this sense, an experiment was carried out to verify the vector model effectiveness in searching and ordering questionnaires. The result of the analysis of the experiment revealed that the vector model was effective in ordering the first relevant questionnaire in most of the query. However, there was a variation between actual and expected result from the ordering of the relevant questionnaires, considering the questionnaires that should appear in the second position.</p>"
6092;en_US;"<p>In complex criminal investigations, those involved deal with a huge and complex amount of data that requires computational resource specialized in extracting information and correlations relevant to the investigative process. In this scenario, it is necessary to have computational support, from storage and integration between different databases, to statistical analysis and pattern discovery. This article discusses the result of a survey applied to the main organs to combat organized crime, such as Public Security Intelligence agencies - ISP, Anti-Money Laundering Laboratories - LABLD and the Special Action Groups on Organized Crime Repression - GAECO. The main objective was to know the current scenario of the use of data analysis tool in these agencies, projecting research and investments needs in this area. Among the result found, 40% of respondents did not know and 15% did not use ETL solutions, although all (100%) declare to have at least one Data Mining tool in your workplace, as well as declaring (100%) to have at least one OLAP / BI tool. Finally, the result highlighted that only 2.77% of respondents directly use some Data Mining algorithm for knowledge extraction. This scenario shows, initially, that most of Brazils specialized investigation agencies do not yet effectively apply Data Mining and Data Analytics technique in their activity.</p>"
6093;en_US;"<p>Google released on November of 2015 Tensorflow, an open source machine learning framework that can be used to implement Deep Neural Network algorithm, a class of algorithm that shows great potential in solving complex problem. Considering the importance of usability in software success, this research aims to perform a usability analysis on Tensorflow and to compare it with another widely used framework, R. The evaluation was performed through usability tests with university student. The study led do indications that Tensorflow usability is equal or better than the usability of traditional framework used by the scientific community.</p>"
6094;en_US;"<p>This study analyzes the association between child labor and teenage pregnancy, taking as reference the municipalities of the Brazilian Legal Amazon in comparison to the other municipalities of the country. For this, we used data obtained from the Demographic Census, conducted in Brazil in 2010, by the Brazilian Institute of Geography and Statistics. The visualization of the spatial distribution of the investigated social phenomena is presented in the form of maps and we apply mining algorithm, in an interactive way, to extract rule of association between the target variables of the problem. Teenage pregnancy and child labor are not dependent variables. However, just as teenage pregnancy is a problem for municipalities in the North, the same scenario was found for the phenomenon of child labor, ie, in municipalities in the Amazon where child labor is high or very high, there is a probability of 76% that this municipality will present a very high percentage of teenage mothers.</p>"
6095;en_US;"<p>This work describes an information system regarding to the telecommunication service with the goal to inform to the telephony service user about the operators signal quality and the user’ opinion about the telecommunication operators. The system contains information of cellular base station locations and the result are crossed with sentiment analyses of sentences extracted from a social network, which are related to the telecommunication service. The study aims to detect complaints and dissatisfaction of user about a determined service, helping to make a relation between the user’ complains extracted from social network with the number of base stations in the same geographic area of the user social network. Therefore, the proposed information system can be used by the National Telecommunications Agency of each country for monitoring the quality-of-service of cellular network operators.</p>"
6096;en_US;"<p>In the information age, a plethora of content is available on a wide range of subjects, requiring an organization capable of making that content more accessible and engaging. An interesting application of classification tasks was identified in the Index project, developed by the Amsterdam-based company The Next Web. To solve this classification task, the Naive Bayes (NB) technique was applied to classify short news in four topic. To evaluate the result produced by such a classifier, a serie of tests using cross-validation were carried out. It was possible to conclude that the NB classifier had satisfactory performance, achieving about 70% of accuracy in the best cases. In this paper, we intend to present the context of the Index project and discuss the result obtained with the NB classifier. Despite the good result, the project is still in progress, as it is necessary to test variations as classification technique and text representation approaches.</p>"
6097;en_US;"<p>Startups company have prominent role in the current business scenario. This is because they can get innovation with reduced costs and risks. However, to ensure the success of these ventures it is necessary to establish a collaborative environment to encourage and support those activity. Understanding and systematizing such startup ecosystem requirement is critical to establishing greater competitive capacity. This paper presents an empirical study of different structures of the collaboration aspects in incubator IETEC CEFET-RJ.</p>"
6098;en_US;"Business Process Management involves theoretical and operationalelements from different area, being a multidisciplinary field. In previousstudies, we identified critical success factors of BPM initiatives in BrazilianPublic organization. In this work, we intend to investigate how to managethese factors. To achieve this goal, we performed a focus group with fiveprofessionals with experience in BPM initiatives within the public sector. Themain contribution of this study is to fill the gap in the literature concerningcritical success factors for BPM initiatives in public organization."
6099;en_US;"<p>This paper describes process and result of a research conduct on the influence of group size on student participation when using educational chat. The research aims to produce a mathematical model to estimate the maximum number of student who must participate in a chat session maintaining the desired level of participation set by the teacher. This research was guided by the method Design Science Research in Information system, which conducts performing a behavioral research and the production of an artifact. Communication of this paper aims both technicians in system modeling and managers in Distance Education (DE).</p>"
6100;en_US;"This article presents a conceptual framework consisting of tool capable of extracting historical data about software evolution from source code repositories, defects and software development process. The tool that compose the framework were obtained in a systematic mapping process. A proof of concept was carried out where data were extracted on defects in project of SINAPAD (National System of Processing of High Performance) that has project in the area of ​​computing. The data extracted were also analyzed, aiming to answer some questions relevant to the project. In the end, it was possible to evaluate the use of the framework GiveMe Metrics (GMM) in the extraction of data about defects."
6101;en_US;"<p>In the prospection of oil reservoirs, geological characterization is a fundamental phase for building model that represent the elements of the petroleum system. The record of provenance data describing the intermediate steps of this process and the data set used in the operations executed, allows the full evaluation of the quality of the resulting characterization. This paper proposes an architecture that supports the collection and recovery of provenance data in application for geological characterization, and presents a prototype tool implemented as a plug-in for Sigeo3 a geoscience software framework used by Petrobras, the main Brazilian oil company.</p>"
6102;en_US;"<p>We explore the differences in key variables from TAM (i.e., attitude, usefulness, ease of use and control) between passengers grouped according to gender, age and experience (i.e., moderators from the UTAUT model). In doing that, we promote an original integration of two popular model of information technology acceptance. The empirical analysis was done with 456 passengers who used check-in totems in a Brazilian airport, verifying the differences in perceptions with MANOVA tests. Ease of use and perceived control were found to vary depending on all three moderators at once, whereas attitude and control were not. The result suggest that: 1) empirical tests must consider all moderators at once, as some differences cannot be detected if they are studied in isolation; and 2) that technology acceptance researcher should aim at the development of an integrative, more general, model.</p>"
6103;en_US;"<p>system integration (SI) is a matter of strategic and economic interest to organization, and many of these integrations involve legacy system (LS). In this scenario, the aim of this study is to identify the critical success factors (CSFs) for SI in public organization. The methodological procedures included a systematic literature review and a survey with 106 IT professionals from one of the world largest public IT company. The search identified 19 CSFs for SI with use of LS.</p>"
6104;en_US;"Legacy Information system play key-roles on organization development and growth. However, they can be considered as risky factor to operations chain whether they do not meet the demanding or become acting as single point of failures. In this work, we propose a migration model which is able to handle system that depend on Relational Databases and its changes were driven through the use of a distributed middleware. We also pose how this approach was successfully applied while migrating a Legacy Information System to a Cloud Computing based infra-structure, adding fault-tolerance to its architecture as a competitive advantage, enabling the related service to be clustered and then horizontal scaled on demand. All major concerns on how the whole solution and its aggregated tool were conceived are discussed in high-level details, so them can be solely reproduced and integrated to another system in order to achieve the same goals or improve its level of quality assurance."
6105;en_US;"<p>Huge sports events host city become centers of great tourist attraction, implying large increase in demand for air travel. In this context, the present study aimed to analyze the role of airport infrastructure as conditioning factor to the capacity of seventeen airports that support the 2014 World Cup. The data were processed according to multivariable analysis approach called Data Envelopment Analysis (DEA), by using the tool called Integrated Decision Support System (SIAD). The result indicate that some airports may have capacity gains by optimizing operating procedures; others, however, may need infrastructure interventions to obtain such gain.</p>"
6106;en_US;"This paper presents a model-based approach to build Information system User interface (ISUI). In this approach, UI presentation and behavioral aspects are modeled as UI Stereotypes, which are high level abstractions of UI appearance and interaction feature. A taxonomy of ISUI elements is proposed as the basis for definition of UI stereotypes. These elements are orchestrated on a software architecture which manages model-based UI building and integration with the IS application. The proposed approach reduces software development efforts and costs, facilitating maintenance and evolution of ISUI. Moreover, UI stereotypes improve usability, consistency, reuse and standardization of both presentation and behavior of ISUI."
6107;en_US;"<p>Scientific application in Space Weather need join data captured by instruments distributed geographically to produce maps, contents and event alerts from the sun. In this context, exists a difficulty in bringing and integrating data to perform analyzes and provide your result on a time interval suitable to monitoring and predict Space Weather events. This prevents the generation of real-time information, necessary to assess impacts on technological and economic activity, such as satellite communication and navigation system of aircraft. The objective of this paper is presents an architectural model called Alfrodul, used in scientific application in SpaceWeather, to integrate and process data in a timely manner for analysis by experts. This model was used in the implementation of six web system for display Space Weather informations.</p>"
6108;en_US;"<p>The management of stakeholders is a concern inherent in the project management. Many project are aborted or not reach his goal in reason of an inefficient management of stakeholders. With the objective of assisting the solution of this question, this article seeks to identify how information technology can contribute to the engagement and construction of sustainable relationships among the stakeholders of a project. For both, it is proposed the confection of a management environment stakeholder called by Viewing Environment of Social Data - VESD, a technological outline that tries to systematize process, contributing to management and constant improvement of the relationships between the stakeholders and project.</p>"
6109;en_US;"<p>The theme of Big Data has grown in importance in the context of web application. As a consequence, NoSQL DBMSs emerged in order to achieve gains in performance and scalability. Within this context, this study aims to identify the main criteria for selecting a NoSQL DBMS in private organization. This research identified through literature review the main criteria for selection of NoSQL DBMSs. Those criteria were checked by a group of 32 specialists and as a result, 22 criteria are identified to be followed by organization in their selection process.</p>"
6110;en_US;"<p>This paper presents a MDA methodology for database project with an extension to geographic database project, that is capable to generate automatic codification for SFS/SQL and ANSI SQL pattern. The methodology uses a generic metamodel for the conceptual and geographic modeling concepts to generate data definition language. This paper also presents a database modeling tool, which is a set of Eclipse plug-ins and a simple example modeled using OMT-G.</p>"
6111;en_US;"<p>Data management has been one of the crucial problem in the development of new computing solutions, especially in this high-speed network age. In network traffic monitoring tasks, protocol such as NetFlow produce a huge amount of data which need to be handled efficiently. In that context, this work proposes employing column-oriented databases for boosting analyses over large IP flow databases. The paper shows experiment comparing row-oriented databases and column-oriented databases. The result achieved using the DBMSs PostgreSQL and MonetDB confirm the potential of column-oriented databases on that type of dataset.</p>"
6112;en_US;"<p>This paper describes a research to develop an integration between tool that support the management of software development project. One of the main motivations for this work is that there is a regular need of software company to use a combination of complementary tool to help them control and manage their software project. However, the heterogeneity of project management tool creates a hard way to integrate their information. Therefore, this paper presents a solution to integrating project management tool using XML technology. We present the result of the integration of two tool using the proposed solution as a way to demonstrate the feasibility of the project.</p>"
6113;en_US;"<p>This paper presents the ClassRiskIndicator, a mobile indicator based tool aimed to assist the risk management of software development project within a context of multiple project environments. Its main goal is to help the project manager in the most important and basic tasks of the risk management process, in an objective, portable and simple way (relevant traits for an efficient risk management). This tool makes use of indicators that can characterize and summarize , in a unique value, the overall risk exposure level from a software development project.</p>"
6114;en_US;"<p>Nowadays systematic review are often part of academic research because through it one can identify, validate and interpret all relevant literature to a particular research question, topic or phenomenon of interest with scientific rigor and in a repeatable and well documented manner. While at first it was mostly used in the health sciences, it is beind used more and more in information system research as well. However, some repetitive and time consuming tasks have to be done by hand because they are not yet covered by computational aid tool. In this context, we developed JustReview, a free and open-source tool that aids the process of systematic review by facilitating and automating recurring tasks, particularly the search and download of paper from online databases and the application of criteria to accept or reject these paper, as well as the generation of documentation. This paper presents JustReview and a case study of its use.</p>"
6115;en_US;"<p>Distance Education has been put in the spotlight in the last years supported by computational tool that help its growth. Virtual Learning Environments (VLE) are the main tool available, and the follow up of student through them can be automated in a way that the environments can be more responsive to the action of the parts involved in the learning process. This work presents the development of a Multiagent System that interacts with the MOODLE using agent based software engineering in development.</p>"
6116;en_US;"<p>The information technology including, increasingly, the service offered to citizens, this necessitates the development of web pages accessible to everyone, regardless of education level. Whereas a significant portion of the Brazilian population is within the low literacy profile, the objective of this research was to analyze the different forms of navigation among user of high and low literacy. Data were collected through user testing through eye tracking. The experiences of interaction were performed from two tasks initiated in the Google search engine and completed in two popular sites. At the end, some suggestions were proposed interface improvements.</p>"
6118;en_US;"<p>The number and intensity of floods have increased worldwide due to climate change, causing more damage, deaths and economic impacts than any other natural phenomenon. Prevent this type of disaster requires current, complete and accurate information on the current state of the environmental variable. Crowdsourcing platforms enable obtaining volunteered geographic information for different context. We propose a crowdsourcing platform for obtaining useful volunteer information for the context of flood risk management, an experimental evaluation is performed in order to verify its effectiveness.</p>"
6120;en_US;"<p>The World Cup is the worlds most widely viewed sporting event. There are hundreds of websites that mention this event, therefore, an evaluation relating to the quality of user interaction is needed. This paper carried out an Ergonomic criteria evaluation of 51 websites related to 2014 World Cup event, and their mobile version, in order to evaluate their ergonomic quality and to find their ergonomic problem. This work aims to present the problem found in websites, their relation to the ergonomic criteria, and to compare the desktop website versus mobile/app version, besides it also wants to contribute for improving the user interaction with World Cup websites.</p>"
6121;en_US;"<p>This paper presents the development of a technological platform for the company Águas do Centro SA, which permits the collection, storage, and management of strategic information. The computer solution based on opensource technologies was developed according to the ICONIX methodology. It is presented as a decision support system, which enables adding intelligence to management, providing greater competitiveness to the company.</p>"
6124;en_US;"<p>Project management is essential for company as it is a competitive differential that represents increasing levels of quality and adds value to the interests of customers. A project office is an organizational unit that centralizes and coordinates project management over your domain. This paper presents an analysis of the maturity level of the company project office in the area of ​​information technology (IT) research using the PMO Maturity Cube method. Based on observations, a literature review and a case study carried out in an IT project office, the PMO Maturity Cube method was applied. The result of the survey were confronted with result from another company.</p>"
6125;en_US;"<p>This paper presents a report about the application of the Design Thinking methodology on the development of a software solution to the context of urban mobility. We have used some technique suggested by the Design Thinking methodology, such as interviews, surveys, brainstorming and software prototyping. We focused this study on the public transportation and its process. As the main result of this research we have the software solution prototype and its evaluation by its the target user.</p>"
6126;en_US;"<p>This paper presents a case study about an application of agile methodology using the framework Scrum combined with the agile software development process XP (Extreme Programming) in project about building system in the Brazilian Electoral Superior Court - TSE. In order to discover new knowledge relevant to the business, it was analyzed evidence collected on the implementation of the methodology and confronted with the most used bibliography about the subject. At the end of the investigation, necessary improvements were found out, and part of them confirmed facts previously known by the managers, and some brought new knowledge which presents a great potential of improvements in the organization.</p>"
6127;en_US;"It is difficult to maintain and to adapt poorly written code presenting shortcomings in its structure. Refactoring technique are used to improve thecode and the structure of application, making them better and easier to modify. Design pattern are reusable solutions used in similar problem in object-oriented system, so there is no need to recreate the solutions. Applying design pattern in the context of refactoring in a corrective way becomes a desired activity in the life cycle of a specific software system. However, in large-scale project, the manual examination of artefacts to find problem and opportunities to apply a design pattern is a hard task. In this context, wepresent a metric-based heuristic function to detect where the Strategy designpattern can be applied in a given project. To evaluate the heuristic functionand its result we have also built a tool to show the result. This tool canexamine source code using ASTs (Abstract Syntax Trees), searching for opportunities to apply the Strategy pattern, indicating the exact location in the source code where the pattern is suggested, also showing some evidences usedin the detection."
6128;en_US;"<p>The Nòmos Framework extends the i * framework to achieve legal compliance of information system requirement. Legal compliance is a requirement imposed by government departments, from the content found in the legal rule. Failure to comply with these requirement by software may lead to legal and financial disruption to company and their solutions. On the other hand, the fact that Nmos is dependent on i * may be a barrier to its wide adoption in industry. Therefore, this paper proposes to make Nòmos independent of business process modeling notation or software requirement, instead of being exclusively applied in i *, as originally proposed.</p>"
6129;en_US;"<p>Biometric system have been remarkably used in the past years, mainly those based on fingerprints. In terms of security, they need the same care which is given to traditional system that uses cards and password. Fuzzy Vault comes in this scenario to provide security to biometric system, specifically, protecting the stored biometric template. In this present study, the Fuzzy Vault scheme will be developed, and then used to hide a 128 bits secret; the scheme will be used into the context of a biometric application based on finger-prints. Evaluation of security and performance of the application will be shown, and experimental result, common to biometric system (FRR, GAR, FAR), will also be presented.</p>"
6130;en_US;"<p>The Brazilian government implemented the National Institute of Science and Technology for Cancer Control (INCTCC) with the purpose of strategically invest in research in this area. Aiming to increase the national collaboration between scientists of the area, a Social Network Analysis approach is important. However, the typical handling and visualization mechanism of software of this type are limited. The aim of this paper is to describe an analytical tool to support decision making that allow a dynamic analysis of the scientific production and collaboration through INCTCC.</p>"
6131;en_US;"Natural disasters have led to the need for urgent measures to mitigate the effects of these accidents. The question of awareness is extremely important in dealing with disasters, and collaborative system are very serviceable for this. In this context, the aim of this work is to outline a gamification-based social collaborative architecture (GSCA) to increase resilience against natural disasters. We have combined technique to produce and share information through the interaction of a large number of people, such as those employed in social media and serious game. This architecturewas evaluated and analyzed using the Voluntary in Action, a web platform which applies the components defined in the GSCA. The result suggest that gamification is a system with a great potential to help increase the knowledge of a community about disasters."
6132;en_US;"<p>This article discusses a research methodology for detecting technique of data collection for identification of user needs, an integral part of the search for efficient mechanism for the development of ERP system that allow for better user interaction and contribute in various stages of the process development. The proposed methodology has been validated with an experiment conducted in Brazilian industry developer of ERP system, whose result are presented in the report of the case study.</p>"
6134;en_US;"<p>The growing demand for cloud application, due to high maintenance costs of the service offered by the traditional model of software offering, created the architectural model multi-tenancy, which allows the optimization of resource and infrastructure software system sharing the same application instance and maintaining customer data logically separate. In the Java language, the JDBC API, widely used by the developer community, still does not natively support multi-tenant connections. This paper presents a framework that has these feature to make possible the implementation of multi-tenant application in Java using JDBC API for connecting to the database. At the beginning of this work, the methodology consists in performing literature searches on the central issue and related topic in order to acquire the necessary theoretical knowledge. Then, using the knowledge acquired in the previous step, are described the requirement and structure of a framework, applying the concepts previously seen. Finally, the creation and implementation of a case study using the framework presented.</p>"
6135;en_US;"<p>In the recent years there is a growing on creation of startups and also model of business management, mainly influenced by different inceptives by investors and governments. This study presents an evaluation of the Lean Startup methodology, under the context of an action research on developing a new enterprise software entrepreneurship. This study emphasizes the use of that methodology by entrepreneurs attending the final year of a course in the field of computing. The research project evaluated the difficulties, facilities and impacts on the application of the methodology for the development of a Startup. Finally, we have a report with result from the experience of conducting this field study.</p>"
6136;en_US;"<p>Modern information technologies have supported a number of area, among them education and health, in order to deliver improvements in administrative process and quality of life. This article presents the trajectory of development and validation of a mobile app, titled Autism ABC, whose main aid in the process of teaching children with autism and hence serve as a supporting tool in the treatment and education of these individuals function. The application adopts assumptions TEACCH program. Children, parents and professionals an association attended the validation step. The result attest to the tool alignment with the TEACCH and a self-explanatory interface.</p>"
6137;en_US;"<p>Mobile technologies have allowed the development of several tool which assist user in their daily activity. Among them, route recommendation apps are gaining ground as powerful allies to urban mobility. However, with the growth of city and complexity of their transport network, providing mobility service has become a challenge, due to such amount of information in a relatively small smartphone screen. This paper proposes a mobile recommendation route prototype that uses Wayfinding technique to represent mapping information, aiming at a more efficient and intuitive interface, as well as a validation experiment and its result.</p>"
6138;en_US;"<p>Regarding the challenges and benefits related to the SOA reuse, this paper presents a Systematic Literature Mapping about this attribute. It aims at identifying factors that influences the reusability, strategies adopted and metrics related to reuse in a SOA context. The 22 mapped paper have evidenced that cost is the most driver to reuse adoption. The strategy most adopted is Software Product Line and the service analysis and design activity are used widely. This paper is relevant to the researcher and practitioners that need a structured work about this area.</p>"
6139;en_US;"To obtain business benefits resulting from the implementation of an SOA approach is not sufficient managing technical feature. A strategy aligned to business should be considered as a basis for activity of implementation, validation,development and service management. A business case, a reference model and anarchitecture of the organization should be established. This paper proposes SOAgovernance process. The process were evaluated by SOA experts who argue thatthey would adopt them for SOA governance in their organization."
6140;en_US;"<p>Grouping by similarity represents a significant step in strategies of Web service discovery and composition. Many clustering method process the service descriptions in natural language to estimate the degree of correlation between them. However, the use of knowledge bases in specific language limits the applicability of these method. In this paper we make an analysis of language independent method for grouping similar Web service using their natural language descriptions. In particular, we applied Latent Semantic Indexing (LSI), a language-independent method of Information Retrieval (IR). Moreover, an experimental analysis was performed with three similarity measures in order to determine which one is best suited to duplicated Web service detection from service descriptions in two language.</p>"
6141;en_US;"<p>The movement of open source software (OSS) has changed the basic nature of the software industry, and today the use of OSS is reality in business. This article aims to identify what has been reported in the literature that discuss the use of OSS in company seeking to characterize factors, forms of adoption and business model applied. The method adopted was the systematic literature review and, as search tool we used Google Scholar. As a result we obtained 137 publications with distribution by topic: 51% discussed factors, 38% ways of adoption and 11% business model. This article contributes to the definition of strategies for adoption of OSS by consolidating characteristics identified in previous studies.</p>"
6142;en_US;"<p>Following the government news is an ordinary activity between managers, journalists and citizen in generals. Simply identify what is news of government can become a laborious process if the search engine is not the most appropriate. An even more challenging procedure is to establish a ranking between government news which are most relevant in a given spectrum. Into this scenario, this work aims to propose an algorithm that assigns a score to the government news that reflects its own importance. This score mainly uses attributes extracted from social network of people or organization profiles that publish government news. Besides showing the construction process of the ranking algorithm, this paper shows a case studywith real news, the proposal and the validation result.</p>"
6143;en_US;"<p>Organizing properly and formally Information Technology (IT) project prioritization and implementation activity in search for solutions to bring business value, is a critical task for organization, from those that use IT as a strategic asset, to those that use its resource as tool to improve operational efficiency. This paper focus on discussing the importance of adopting a formal model for IT Project Management called Innovation Funnel, presenting related concepts and brings the case study of a multinational Consumer Goods company. The study also presents an analysis of the strengths and improvement opportunities found in the model.</p>"
6144;en_US;"<p>Feature interaction is an undesirable interaction between service of a composition which may violate the functional and non-functional user requirement. Due to the dynamic nature, heterogeneity and openness of web service, solve feature interaction is a complex task because it is difficult to control service that was developed by differents vendors. There is no access tosuch web service implementations. The great challenge is feature interaction prevention. It can be done in online or offline mode, however, there aren't work that prevent in online mode. In this article, an autonomic mechanism, based on neural network and genetic algorithm was proposed to prevent feature interaction in web service composition. The result demonstrates a reaction timeand accuracy appropriate to monitor and detect the causes of feature interactioncauses in order to facilitate the prevention.</p>"
6145;en_US;"Service-Oriented Architecture (SOA) and agile method share common drivers. However, there is a lack of guidelines a SOA team should pursue in order to develop service considering best practices, acceptance tests, distributed teams, contract refactoring, among other issues related to SOA principles and agile practices. This work presents a new method that addresses team concerns and needs aiming at a systematic approach for service development using XPs agile practices and SOA principles. We provide best practices, phases and activity that specifically address XPs core practices and service-oriented best practices. We also provide an example of our proposal in order to demonstrate its applicability."
6146;en_US;"<p>Situational application are developed by end user to solve day-today problem in the business scenario. The demand for this type of application is increasing since IT departments usually are not able to delivery it in agile way. Traditional software development process do not have the agility and simplicity to fulfill the requirement of this type of application. This work presents a proposal of architecture for situational application generation using BPM, SOA and Mashup.</p>"
6147;en_US;"<p>The growing popularity of communication-enabled device has led to the eminent emergence of a so-called Internet of Things. In this context, the urban data collection has allowed the emergence of Smart city that need to integrate countless system and device for urban monitoring generating relevant information. This article proposes an architecture model based on a Service Bus that allows the rapid development of application using these system and data.</p>"
6148;en_US;"<p>The identification of business needs and the organization environment is important so that information system meet the desired purposes. In public organization, typically, the definition and hiring in the development of information system do not happen in a systematic way. With the aim of improving the efficiency of system development in the context of public organization, this article presents a model procedure for the identification of the requirement in the draft phase of information system development. The implementation of this process happened in the Mayors Office of the Municipality of Salvador, which provided improvements in the development of the system which will be discussed in this article.</p>"
6149;en_US;"<p>Some changes may occur during the life cycle of a project, impacting mainly in the time, scope and cost parameters. To reduce the possible negative effects and avoid the commitment of the project success, it is necessary a continuous management of change requests, ensuring that only properly analyzed and also formally approved changes are incorporated in the project baseline. This work has a goal to present an approach based on intelligent agent technology for the automation of change management in project, assisting project managers in the decision making process of choosing the most appropriate changes to be approved.</p>"
6150;en_US;"<p>Software organization have been adopting quality improvement model such as the Brazilian MPS.BR in order to enhance their product and service development process. The adoption of process supporting tool is a critical success factor in software process improvement initiatives. This work aims at defining a set of functional requirement for supporting tool so that they can support process adherent to MPS.BR level G. This set of requirement can aid the evaluation and selection of such tool. An evaluation of the Redmine tool is presented based of the reference requirement.</p>"
6151;en_US;"<p>Software development is a dynamic activity and distributed. This article aims to assist project managers in monitoring and control of these process. To make this possible we integrate agent technology, the earned value technique and critical path method in order to generate alternatives for preventive and corrective actions to minimize the negative impact of deviations and thus to generate new estimates.</p>"
6152;en_US;"<p>This paper consists of developing a systematic review about method and technique used for identifying trends in different application types. The first goal is to understand what are the main technique being used and the way that these technique are organized by the researcher. The second goal consists of understanding which of these technique could be applied to social network.</p>"
6153;en_US;"<p>The Traveling Salesman Problem (PCV) is an optimization problem with many variations for which there are many meta-heuristics (MH) capable of generating good solutions. It is difficult to know beforehand that MH will produce the best solution for a given PCV. This paper proposes a meta-learning approach to select the most promising MH for new examples of PCV. This approach is based on meta-model induced from machine learning technique in a set of metadata. Each instance of the metadata is an example of VSC described by characteristics (meta-attributes) of the problem and by an extit {ranking} of performance of the MHs (target meta-attribute). Induced meta-model are used to indicate an ordered list of MHs for new instances. The experimental result show that the proposed approach is quite promising.</p>"
6154;en_US;"<p>The mollusc Limnoperna fortunei (golden mussel) is native to Asia but is spreading around the world mainly transported by transoceanic ships. It is causing several economic and environmental problem due to its greater abilityto attach to any solid substratum and its rapid spreading. Therefore, severalresearcher have published studies related to different aspects of golden mussel. Some of these work used ecological niche model (ENMs) in order to predict the expansion of the invasive golden mussel. However, given the limitations presented by ENMs in previous work, the search for more accurate predictive computational tool is still important. In this work, we evaluated the use of data mining technique aiming at predicting the occurrence of the golden mussel in Latin Americas rivers. The experimental result showed that some classifier have achieved promising predictive performance.</p>"
6155;en_US;"Online Q & A communities have become important places for user to seek and share knowledge. This paper aims to propose a new metric that allows to identify people who have greater chances to give a good answer to a question in a community. In the context of work, these people are called trusted user. To do so, analyzes were performed in three online Web Q & A communities to explore their characteristics to make possible the development of the new metric. The proposed metric is called the Confidence Index."
6156;en_US;"<p>This paper provides contributions to the problem of Off-line signature verification by creating a classifier based on morphism using a technique of triangulation of points. This technique allows checking the distance between the signatures of a particular class, aiming to discrimine false from genuine signatures. In this paper, five scenarios were evaluated using genuine, simulated and random fakes signatures. The fifth scenario use a variable amount of points per experiment, which one obtained the best result, reaching a Global error rate of 0.18.</p>"
6157;en_US;"<p>Our work is an initial step towards understanding how theoretical security metrics are used in practice and which security issues require more attention from security practitioners. The result of the proposed survey reveals important pattern about the use of metrics in practice and highlights the value of analyzing security metrics from the point of view of characteristics such as complexity and importance.</p>"
6158;en_US;"<p>This paper discusses the development of a model of an on rails transport simulation system that combines the usage of cellular automata for the rails and intelligent agent for the user behavior. This paper also presents a framework for the development of this kind of application allowing interconnections between then in the same simulation, allowing the simulation of different transport modals.</p>"
6159;en_US;"<p>This article proposes a short simulation model (two to four hours long simulation) for the teaching of Scrum and its roles. This simulation model possesses, as its focus, quick decision making and this decisions both positiveand negative feedback. Its proposed, alongside this model, a simulation creatorto be used by the teacher to create simulation that follow the proposed model.This article also briefly explores the possibility of a longer model of simulation, where the simulated project would also be implemented.</p>"
6160;en_US;"<p>This paper addresses the hard understanding of the real dinamism of the computational events in the operating system course. Two software are presented here in order to improve this learning process from the graphical illustration of strategies for managing: (i) the first one simulates the routines of real and virtual memory management and (ii) the second one shows how the process scheduling in architectures with multiprocessors work. result show the proposed software give a great support to the conceptual classes of the operating system course and, consequently, they make the classes more dynamics and allow the simulation of different scenarios.</p>"
6161;en_US;"<p>A pervasive hospital environment requires that the entities present in this context (such as people and equipment) are in perfect synchrony to perform the common medical tasks in their daily lives. One of the best ways to represent this domain is through ontology. In this way, this work has as main objective to show the process of development of a tool for the processing of ontology in hospital pervasive environments.</p>"
6162;en_US;"<p>The way Free Software is developed is directly related to collaboration and exchange of knowledge between peers organized in Communities of Practice. The interaction and registration of the content shared by the participant is fundamental in this process. In this way, providing mechanism to support the dissemination of knowledge is extremely relevant. This article presents a research carried out with a view to analyzing a set of communities and how they treat the knowledge, how the participant interact and how the knowledge management is performed. Based on this analysis, a model for knowledge management in open source communities is proposed.</p>"
6163;en_US;"<p>This paper presents a method for the qualitative and quantitative analysis of WorkFlow nets based on the construction of canonical proof trees of linear logic. The qualitative analysis proposed in this work concerns the proof of the correctness criterion for WorkFlow nets called Soundness. The quantitative analysis is based on the calculation of symbolic date interval for the execution of each task of the modeled workflow process, thus allowing the planning of the resource to be used in all the tasks of the process.</p>"
6164;en_US;"<p>This article presents the development of a company game focused on the training of coordinators of undergraduate course in what concerns the learning of the organizational process that are under their responsibility. The game was developed using the Electronic Institutions approach and software agent.</p>"
6165;en_US;"<p>XML-based software representations have adequate abstraction level for the processing, analysis, and manipulation of source code by tool. These representations provide expressive details about the structure of the source code. The high verbosity of some representations and the exposure of details of the source code in excess make it difficult to carry out studies on the evolution of industrial software. In this paper, we present CodeMI, an XML-based source code representation that uses XMI format extension to define elements, with emphasis on the structure of the source code, that enable the collection of metrics without revealing the execution dynamics of the software.</p>"
6167;en_US;"<p>The present work presents a comparative study between accessibility standards: the international WCAG and the national e-MAG. This study describes the main characteristics of the model, their similarities and differences. For this, a research was carried out with Brazilian organization in order to verify the degree of adherence to the two standards; automated tests were conducted to check the accessibility of institutional sites and a questionnaire was developed to analyze the degree of adherence to the guidelines. The result revealed that the recommendation proposed by the two standards show few differences, indicating that the international standard is adequate to national needs.</p>"
6168;en_US;"<p>This paper presents the development of the InterVIU tool, which was based on the CommunicaTEC project approach. A collaborative process is modeled to be run by a generic computing tool and an exploratory study is conducted to identify the problem in the process and the changes needed to improve it for the computational environment. Changes in the process are reflected in new mechanism implemented in the InterVIU tool. The main characteristic of the tool is to allow a specialist to be interviewed by a group, in order to get fewer unanswered questions at the end of the dynamic.</p>"
6169;en_US;"<p>An empirical study was conducted to analyze the influence of organizational factors on the perception of the effectiveness of information security in public universities. The technique of exploratory factorial analysis (AFE) was used to analyze data from a questionnaire answered by 75 ICT professionals from 46 public universities in all Brazilian states. The result of the AFE have led to the conclusion that measures to improve the security aspects of information must be in tune with the support of the higher administration of these institutions.</p>"
6170;en_US;"<p>The diversity of Information system that have used the Web demands an increasing use of Web service to facilitate the interoperability of these system. Currently, many simple Web service no longer meet the needs of these system, and have to be combined to create Web service composites (Web service Composition.) Integrated environments are incorporating feature to facilitate the development of a simple Web service, such as the WTP (Web Tool Plugin) in Eclipse, but few have been worried about the service compositions, and of the proposed environments that deal with semantic compositions, none of them proposes to reuse existing tool to compose Web service, reducing both the development time of the composition The OWL-S Composer is a tool that allows user to create a web-based application that can be used to compose a web-based application, semantics through an intuitive graphical interface and friendly, reusing tool and generating a correct composition, both syntactically and semantically.</p>"
6171;en_US;"<p>Currently there is a growing increase in the popularity of CVEs (Collaborative Virtual Environments), and with this several initiatives have been proposed by several countries in the implementation of e-government within these CVEs. Based on this context, this article aims to develop a virtual space to promote social interaction, dissemination of information and electronic voting, secret and with a single vote. The proposed objective is to verify the feasibility in the transposition of instances of Electronic Government applied under the scope of collaborative virtual environments. The Electronic Government instance addressed in this work is the REUNI, a new decree of the Federal Government Law that aims at the reform of the Brazilian Federal Universities. The CVE chosen for this work was Second Life, one of the most widely used and widely used virtual reality environments in the world.</p>"
6172;en_US;"<p>Several approaches to service-oriented development have business process as a starting point. However, the surveys do not detail systematic identification of service from business process model. It is assumed that the process are automated and that from these are derived the service. However, we propose an earlier step, which corresponds to the understanding of requirement from the entire set of business process of an organization. This article proposes a method for identifying suitable service to support the organization business activity.</p>"
6173;en_US;"<p>This paper presents a case study on the impact of the implementation of an integrated system in a small company. The work was structured from a bibliographical analysis about ERP system and interviews with those involved in the system implementation project. The main result obtained refer to benefits and difficulties obtained by the company different from those indicated by the bibliographic analysis. Among the key feature of the solution is the low cost of deploying the Internet-based system. From the organizational point of view, it was highlighted the simplified process modeling, due to the ISO 9001 certification by the company before the implementation of the integrated system.</p>"
6174;en_US;"<p>This article presents the proposal of an architecture for the development of Mobile Geographic Information system (GIS) capable of managing context information. This architecture is based on the specification of a context model based on ontology and a set of Web service to access information stored remotely in a geographic database. With this mechanism it is possible for a user of a Mobile GIS to receive personalized information on their mobile device by combining their profile information with the display of geo-spatial data.</p>"
6176;en_US;"<p>This research proposes modifications to a.m.i.g.o.s., a web based social network (WBSN). This WBSN is used as a communication and cooperation tool for C.E.S.A.R employees. - an Institute of Software Products Innovation of Recife. These modifications are aimed at improvements in the automated system of a.m.i.g.o.s. recommendation. The recommendation allow the filtering of information relevant to each user of the system. As a result, communication and collaboration in C.E.S.A.R. tend to be significant improvements.</p>"
6177;en_US;"<p>Software development is a set of activity that makes intensive use of knowledge and information. However, a lot of these are lost during the development effort or stay in peoples heads. If someone needs them, it will be very difficult or impossible to get them. This is partly due to the difficulty of recording and retrieving this knowledge quickly and intuitively. This article presents a proposal for the knowledge about the software development process can be shared through the storytelling mechanism. This mechanism is an old human skill applied to a new context: software process.</p>"
6178;en_US;"<p>Business Process Execution Language for Web service (BPEL4WS) is a promising language describing the Service Oriented Software (SOS) orchestrations in form of Business process, but it lacks of a sound formal semantic, which hinders the formal analysis and verification of business process specified in it. Formal method, like Petri Nets (PN), may provide a means to analyse BPEL4WS process, evaluatingits performance, detecting weaknesses and errors in the process model already at design-time. This paper addresses quality of SOS orchestrations created using the BPEL4WS and a framework for transformation of BPEL4WS into Generalized Stochastic Petri Nets (GSPN) is proposed to analise the performance and throughput of SOS, based on the execution of orchestrated process.</p>"
6179;en_US;"<p>The emergency service for prehospital care aim to provide agile mechanism of medical assistance. These service, in general, have some kind of computational system to support the execution of their activity and to record the service rendered. This article presents a method that uses process modeling to identify existing problem in the information system used in a medical regulation center of a national metropolis. The result obtained with the execution of the method show its applicability</p>"
6180;en_US;"<p>The great demand for paternity tests done by forensic genetics laboratories has stimulated the use of information system to aid in the resolution of these tests. system of this size require a high degree of trust, since they deal with kinship identification and, therefore, a formal and efficient approach to the study of genetic link between individuals is of great value. In this work, a tool is proposed that uses the formalism of the Bayesian network to assist in the resolution of paternity tests. Considering the complexity of this type of tests, which analyzes the causal relationship between the paternal genes and the childs gene and the need to perform accurate statistical calculations, the use of Bayesian network in their modeling guarantees not only the reliability of the result, but also the credibility of the system vis-à-vis society.</p>"
6181;en_US;"<p>Solutions to support perception in groupware environments have been proposed. Such solutions often represent transversal interests related to perception through object orientation, resulting in tightly coupled components, as well as redundancy and dispersion of functionalities in various parts of the system. The purpose of this article is to present the experiment performed with a perception service, called Aw2SOA (Awareness to Service-Oriented Architecture), implemented according to the principles of SOA (Service Oriented Architecture) and the concepts of aspect oriented programming. These experiment were conducted by integrating this service with the Web-based Groupware Service-Oriented Architecture (WGWSOA).</p>"
6182;en_US;"<p>Complex project are developed with difficulty, despite the existence of technical and project management tool. Deadlines are extended and the cost of the software ends up being increased. The solution proposed in this article is based on the use of an extension of Petri Nets for project management called the Activity Network, used to detail information on the development of process and project. This network is the main component of an integrated system of management of development project. To determine the structural quality of an Activity Network and to allow simulation and calculations of costs and deadlines, a special type of Petri net was developed, called the Project Network.</p>"
6183;en_US;"<p>The objective of this article is to present a proposal to support the allocation of human resource in project adopting distributed software development. For this, the idea of ​​Process Scheduling with Human Resource Management in Project Management was related. A study on Process Scheduling, traditionally used in Operating system, was carried out, and the different scheduling method used in Computational Grids were identified. Information about resource and activity is necessary for adequate allocation of human resource as well as for scheduling method, thus supporting the mapping performed among the variables involved.</p>"
6184;en_US;"<p>This article proposes a solution to increase the availability of service in cluster of web servers based on multiagent system. We present the architecture, the formal specification in Petri nets and experimental result of the implementation of the solution.</p>"
6185;en_US;"<p>The advent of the Internet and the Web environment made it possible to share information in a way never seen before. However, it has also intensified the problem of finding useful information in information retrieval system. This research seeks to design an information retrieval service that takes advantage of the collaborative possibilities of the Web environment to allow user to share information representations and collaborate with each other so that they can serve as access points in later retrieval attempts.</p>"
6186;en_US;"<p>Semantically rich conceptual model are the basis for semantic data integration. Although conceptual model exist for more than 30 years, little has been proposed in terms of a process for data masking. The construction of a data model implies the acquisition of the concepts of a universe of discourse by the designer, and its subsequent transcription in a modeling language; for this, a method is required. The language used must have sufficient constructs for the semantic description of the concepts involved. An analysis of language, based on linguistic principles that apply to natural language, can attest its appropriateness to the representation of conceptual model. This work proposes a methodology for the conceptual modeling of data that is based on human cognitive process. The representation of the constructed model uses a language developed from an ontology of foundation, which will be, throughout the work, compared to the concept of universal grammar</p>"
6187;en_US;"<p>Knowledge management has been seen as a form of development and a source of learning for company. However, identifying relevant knowledge to be shared is not a trivial task. List only information on how a task was performed, the context (where, when, or who performed it), does not provide all the understanding needed for those seeking that knowledge. Context aspects related to the professionals involved in the task are also important and should be considered. As a proposal to represent these aspects will be elaborated a model, using ontology. In the future, a case study will be carried out to evaluate the proposal.</p>"
6188;en_US;"<p>In the latter years, we noticed a paradigm change in the World Wide Web. New web application functionalities incite a growing change in the user role from a mere information consumer to an active knowledge producer. Web forums are a good example of knowledge repositories which have been collaboratively constructed. However, finding information in these environments could be a time-consuming task, given that sometimes the user cannot suitably express his/her search task in a set of keyword, issue that is specially relevant to novice user. Recommender system have obtained good result in these cases, by guiding user through the informational space and suggesting useful content without posing the requirement that all relevant terms must be known in advance. This paper proposes a recommendation model based on expertise and metadata co-occurrence, which will be evaluated in an experiment conducted with user participation.</p>"
6189;en_US;"<p>Training in organization is an important activity for your survival. Trainings consume financial resource and time, and can not always be done in practice by reproducing real cases. This tends to limit their achievement and sometimes they do not achieve their goals. This article presents a proposal for training project aligned to the needs of organization, starting from real stories told by those who experienced them and, therefore, expressing the application of concepts in practice. A Group Storytelling tool with specific functionalities is proposed in this research.</p>"
6190;en_US;"<p>This mini-course consists of an overview of the Semantic Web. The ways of representing knowledge (dictionaries, indexes, taxonomies, thesauri and ontology) will be addressed, giving a greater emphasis on the latter. Semantic Web (RDF, RDF Schema, XOL, SHOE, OWL, Topic Maps and TMCL) will be introduced in order to allow the specification and processing of ontology. General of the tool that support the development of application and ontology for Semantic Web. At this moment, a methodology will be presented for the ontology project.</p>"
6191;en_US;"<p>The technological revolution has promoted the dissemination of information that is increasingly accurate and fast, and has become an important means of business, education and entertainment. However, problem related to the accessibility of content have been a preponderant factor for the exclusion of people with disabilities. In this context, this mini-course intends to explore elements of accessibility of software system and, especially, the activity that an organization must fulfill for the institutionalization of accessibility.</p>"
6192;en_US;"<p>The main objective of this mini-course is to introduce concepts and a preliminary practice of business process modeling for student and professionals related to the area of ​​computing. A business process is a continuous flow of activity related to an organization goal and that adds value to your products. The knowledge and forms of representation of the process through the modeling activity are fundamental to answer growing demand for quality products and service, establishing the desired level of competitiveness in the market. This mini-course intends to present an introduction about the theory and methodological development in the practice of process modeling, as an important technique to improve the adherence between the business model developed in the organization and the software development process, oriented to the treatment of information and the knowledge.</p>"
6193;en_US;"<p>The objective of the mini-course described in this article is to present a set of modeling technique suitable for the representation of Organizational Architectures of Information Technology (IT), based on Archimate, Business Process Modeling Notation (BPMN) and UML (Unified Modeling Language) . The scope of modeling technique to be addressed includes: (i) the organizational structures (actors, roles, and units of an organization); (ii) organizational activity structured in service and business process; (iii) electronic service and information system that support organizational activity, (iv) conceptual information model, and (v) the technical infrastructure to support information system.</p>"
6196;en_US;"The use of automation in agriculture is becoming increasingly evident. Increasing productivity and reducing the cost of automation solutions are the most obvious reasons for its growth. Though, only medium/large farmers can enjoy the benefits of automation. Small farmers based on family farming are still using traditional method in planting and harvesting. The reason is that small producers still do not have sufficient scale production to invest in automation equipment aimed at the medium/large producer. To contribute to the technological insertion in this context, this work presents a case study of a low-cost solution to automate a greenhouse of tomatoes plantations. The automation system developed provides for the monitoring of environment, soil, irrigation control, energy emergency, remote communication via internet and application for remote monitoring. The technological challenges for the use of low cost sensor are presented."
6197;en_US;"In order to follow the changes demanded by the market, organization need to develop innovative ideas that boost their organizational development. The use of information technology implies cultural changes in organization making them flexible, changeable and innovative. The present article applied the Business Process Management methodology with emphasis on the automation of process performed in a Higher Education Institution. The research is characterized as descriptive and exploratory, the data collection was carried out through meetings with the managers of the sectors involved in the analyzed process. To evaluate the perception of the new process implemented, interviews were conducted with four managers of the Institution. Among the main result is the high satisfaction rate of the target audience in the automation of process due to the reduction of work, making time available for other organizational activity. Thus, the application of the technology-allied methodology proved effective in reaching the study objective."
6198;en_US;"Considering that the rural producer can obtain some variables of influence throughout the productive process of the cut cattle, it aims to predict if the variables of influence obtained until the weaning of the cattle can explain the bonus, average daily gain, age of slaughter and weight of farm. For this purpose, data mining is performed through linear regression in a data set of 167 cattle. Thus, for the bonus and average daily gain the generated model presented low errors, whereas for the slaughter age and farm weight the errors were larger, which allows to conclude that the attributes are not enough to predict the age of slaughter and farm weight, but good for the bonus and average daily gain. "
6199;en_US;"This paper describes a method for obtaining decision trees for predicting carcasse zootechnical quality indicators for bovine based on their breeding data. For such, data mining classification tasks were performed after data preprocessing, where all numeric attributes were discretized by non-equal frequency binning or by cluster discovery in distinct classification experiment. Obtained result showed that clustering technique as means for discretization may generate classes in better balancing conjecture when in comparison to the non-equal frequency binning method, allowing the discovery of model that may be applied to real world problem."
6200;en_US;"organization are increasingly adopting a data-driven decision- making approach to improve their performance. Dashboards are frequently adopted as tool to support the decision- making process. However, a dashboard with a poor information visualization may end up bringing  an  undesired  effect. This research project aims to propose a tool to evaluate information visualization of dashboards, aiming to support their  design  teams. This  article  presents  preliminary  result of our research"
6201;en_US;"The web environment is very important also for people with some type of disability or difficulty, since access, especially to websites, becomes a way of including these individuals  in so-ciety, facilitating access to content that, without the computer and the web,  would not be possible.  However,   it is known that many websites have limited accessibility,  so this article aims to investigate in the literature what are the main difficulti-es experienced by people with visual im- pairment regarding the use of websites. For this research articles, paper, monogra-phs and event presentations were used. In addition, we seek to identify if these difficulties are handled by the current official web accessibility do-cuments (WCAG 2.0 and eMag 3.1)"
6202;en_US;"The computational visualization employs a lot of algorithm and information presentation technique that allow to abs- tract significant knowledge from a complex dataset. The spread of infectious disease generates the need to unders- tand the dynamics of occurrence and propagation of these pathologies to be able to guide more effective public actions of prevention and combat. The paper presents the proposal of a spatiotempo-ral visualization of the incidence and spread of multiple infecti-ous disease based on a geographic map. As proof of concept were used records about the incidence of Dengue, Zika and Chikungunya in the State of Rio Grande do Sul from 2006 to 2016"
6204;en_US;"Software engineering has several steps for software development with the aim of guaranteeing a quality product. Two steps correspond to analysis and design, in which model are built, and testing. Despite the importance of such steps, some teams do not create model for coding support, while others do not perform the tests properly. This article aims to identify factors that influence the analysis and design and testing based on the experience of industry professionals through a qualitative exploratory study."
6205;en_US;"In a microsservice architecture, solutions are created by teams focused on specific domains, which independently develop service distributed on the network. A challenge in this scenario is integrating data from distinct source, such as NoSQL and relational databases, and even unstructured data. This work presents a new event-driven architectural approach to address this problem through a streaming platform. This proposal will be evaluated and compared to other eventoriented approaches available in the literature based on criteria from ISO 25010 and ISO 25012 model."
6206;en_US;"The evolution of the device and the increase of computational power allowed the construction of several intelligent device. Several company have evolved their equipment, communication protocol and hardware and software architecture generating a set of proprietary technologies without standardization, which makes communication between device difficult. Architectures, platforms, framework have been proposed to provide interoperability between heterogeneous device. In isolation, a device can provide a functionality that partially meets the requirement of a user, so it is necessary to compose the device to provide the desired functionality. Although the composition can be treated by a pool of device, it can often cause undesirable side effects generating problem for the device involved. Thus, the purpose of this work is to analyze the side effects between device in intelligent environments, with the aim of developing a method to detect semantically the side effects in the composition of the device."
6207;en_US;"The Brazilian Law on Access to Information determines that process and public information be presented to citizens in an intelligible way. Business process model have been presented as a way to represent organizational knowledge, usually presented through technical notations or natural language, ways that can present problem in relation to the effectiveness of the understanding by the great majority of citizens. This work proposes a framework (method, notation, tool and meta-model) capable of translating technical language into a Citizen Language of process, in order to enable the understanding of process and information. "
6208;en_US;"Digital accessibility is the software capability to be used by the most possible number of people, including user with some kind of disability, either physical or mental. The great effort required to evaluate whether a software meets basic accessibility guidelines motivated the development of several automation tool. However, there has not been yet any comprehensive study about which accessibility guidelines can be automatically evaluated. Therefore, this research project aims at conducting a comprehensive study to identify, among the guidelines, the possibility of performing automatic evaluation"
6209;en_US;"Context: Communication plays an essential role in the professional software development, as it stands as one of the pillars of this collaborative activity. Communication is also one of the leading challenges in Distributed Software Development (DSD), in which aspects such as geographical, cultural and temporal distances may hinder the communicative process. But in spite of extensive literature in DSD area, little was theorized about explaining communication in this context. Objective: This work aims to present a doctoral research proposal for explaining communication in DSD teams by proposing a new communication theory. Method: A Grounded Theory (GT) research as our primary methodological choice. result: We present the preliminary result of a non-extensive literature review. Conclusion: We preliminarily conclude that a new, and specific communication theory in DSD may have its place in literature."
6210;en_US;"Computational simulation of blood is relevant to improve the training of future health professionals. Although this, there is a lack of these system, and those that exist are few realistic, low quality, and with a high execution time. The purpose of our work is to use SPH (Smoothed Particle Hydrodynamics) to develop a computational tool that simulates human blood, with relevance, that achieves the established evaluation criteria and that presents good result in relation to the system available in the current state of the art. In this paper we present the principles of this model, the research problem, the solution proposal, the evaluation criteria, the tasks assigned to reach the goal, and in the conclusion we discuss some expected contributions and the limitations of this work."
6211;en_US;"Markov Decision Process (MDP) are widely used to solve sequential decision-making problem. The most commonly used objective function in this type of problem is to minimize the total expected cost. However, this approach does not take into account cost variability (i.e., fluctuations around the mean), which can significantly affect its overall performance. MDPs that deal with this type of problem are called risk-sensitive MDPs. One type of risk-sensitive MDP is the CVaR MDP, which includes the CVaR metric commonly used to measure financial risk. In this work, we propose an approximate value iteration algorithm to solve the meanCVAR MDP, a risk-sensitive MDP that uses the average total cost in conjunction with the CVaR criterion"
6212;en_US;"Bitcoin emerged in mid-2008 and currently handles more than  200,000 transactions per day. One of the biggest interests of  investors is to know at what point the price will fall or rise, so that  they can make purchases or sales. In this work, machine learning  technique were used to predict Bitcoin’s price trend on a given  day, considering the use of the classifier Random Forest,  Gaussian Bayesian Network and Multilayer Perceptron. The  preliminary result are promising and as future work, it is  proposed to study method of classifier fusion in the prediction of  the daily tendency (high or fall) of the Bitcoin price. To evaluate  the result will be used the metrics: Precision, Recall, Accuracy,  RMSE and F1 Measure."
6213;en_US;"Over the years there has been a growing incentive to use biometrics with initiatives to perfect, and even replace, traditional method of security. Among the biometric modalities, the face stands out because it is commonly seen and used in our daily routine. This modality presents good result when presented to controlled environments, however, in real world application, it does not present satisfactory result. This is due to variations in illumination, expression, pose, and occlusion encountered when collecting face image in these scenarios. Compared with the other variations occlusion is relatively little studied in the area. The main objective of this work is to investigate, evaluate, compare and propose  technique for detection and reconstruction of partial occlusions  in face image aiming at biometric recognition."
6214;en_US;"This paper aims to present the current state of a doctoral research  on citizen engagement in Virtual Environments of Social  Participation (VESP). This research is based on a literature review  in which an analysis of solutions of citizens engagement in virtual  environments of social participation was made. We also studied  the social influence theory and recommendation system. In this  article we consider the possibility of a user influencing other  user, causing them to engage. We hope to develop a  recommendation system based on social influence to contribute to  citizen engagement in VESP."
6215;en_US;"In the context of software ecosystem (SECO), interoperability is relevant for aligning technology, environment, human interaction, and for opening borders where third-party application can be connected and benefited from their interrelated service in order to reduce cost and rework. There are pattern and rule that map interoperability components and provide guidelines for their use, such as e-PING and Data on the Web Best Practices of W3C Recommendation document. Current researches are applied to map the use of interoperability standards and identify difficulties in the application of such standards. In general, initiatives have been proposed, but they include no specific treatment for the context of system-of-information system (SoIS) within a SECO. This Master thesis aims to investigate interoperability as a method for applying e-PING guidelines in the context of SoIS. Based on experimental and literature studies, we intend to develop a technique that allows  us to deal with technical, human and organizational factors of SECO in interoperable SoIS complying with ePING standards. "
6216;en_US;"Teaching and learning of computer programming (TL-PROG) is a fundamental subject to System Analysis Bachelor and related graduation course. In general, teaching programming using traditional method has become much more challenging due to many reasons. It includes changes in the manner new generations are prone to learn and the arising of new programable device. In  this context, Project-Based Learning may offer potential benefits  to TL-PROG, mainly Agile Project-Based Learning (APjBL).  However, there are a few relevant studies relating PjBL and TLPROG  in Brazilian. Therefore, we propose to analyze the benefits  of the APjBL when compared to the traditional Brazilian TLPROG.  As the comparation criteria, we propose to evaluate the  benefits to student’ grades, motivation, communication and  Profession."
6217;en_US;"One of the most important open education resource nowadays are the MOOCs environments (Massive Open Online course). With the growing number of MOOCs provider appearing on the web,  many student find it difficult to choose the best course. A promising approach is to treat it as MOOCs ecosystem inspired in the field of software ecosystem, which brings balance of the ecological environment and the strength of interaction. However, in MOOCs ecosystem, each student usually has individual characteristics, tastes and purposes. Therefore, recommendation system have emerged with the purpose of assisting student in this decision process. This Master thesis aims to combine recommendation system and MOOCs provider’ platforms to help user to achieve their own specific goals based on a combination of course or course modules. As a result, we aim to reduce user’ knowledge gaps (new knowledge according to stakeholder’s interests from different course or parts of them) and to achieve knowledge reuse (platforms’ software demands, improvements and sharing). In addition, this work investigates MOOCs ecosystem characteristics, exploring how this perspective can support provider’ basic process (e.g., MOOC learning support service functionalities, work team partnerships or alliances among company which would benefit all stakeholders). "
6218;en_US;"<p>Crowdsourcing is an emerging business model applied to software development project due to the cost reduction and involvement of experts. However, there are challenges on how to manage it in such project due to the dispersion of participant and the activity of parallelization. In this study, we conducted a literature review and verified practices applied to the management of crowdsourcing in software project. We have compiled the result of our analysis on a management model that has been validated in a quasi-experiment crowdsourcing. The application of the model demonstrated capacity and efficiency to realize the management of dispersed participant and activity.</p>"
6219;en_US;"<p>The Software Craftsmanship manifesto has defined values and principles that software development teams should follow to deliver quality software that fulfills functional and non-functional requirement without dealing with high amounts of technical debt. Software craftsmanship approach to software development prioritizes technical practices in order to provide a clean code base. This work analyzes a set of practices that can be applied to a Scrum project that aims to incorporate Software Craftsmanship values. The process implementation described may be a useful contribution for software development teams who also intend to implement Software Craftsmanship on their project.</p>"
6220;en_US;"<p>Distributed software development has become frequent and the inte- raction between those involved, which is often influenced by social and cultural aspects, reflects in the performance of the teams. Sentiment analysis has been used to capture subjective information and get a better understanding of the interaction of these teams. Therefore, it is interesting to evaluate the perfor- mance of available tool when applied to that domain. In this work nine senti- ment analysis tool were evaluated using GitHub comment manually annotated according to their polarity. result showed that SentiStrength performed best among the evaluated tool, but with average performance below 50%.</p>"
6221;en_US;"<p>Design pattern are defined as reusable solutions to recurring problem. These solutions have many expected benefits for the project, such as ease of communication, maintainability, and organization. Design pattern also bring a common vocabulary to the development team. However, it is necessary for the project to be designed for the correct application of design pattern and organization do not always provide time for such. This paper presents the result of a survey conducted with Java software developers in order to investigate their knowledge, incentives, and difficulties in the adoption of design pattern. As a result, we observed great influence of the companys culture and adopted process practices.</p>"
6222;en_US;"<p>Change involves process, people, skills, organizational culture and leadership, among other topic that include the critical factors to be observed for a successful change. This paper presents a conceptual meta model for organizational change, which is able to represent the important concepts involved with organizational change in a software process improvement (SPI) initiative such as stakeholders, resistance and competence. A case study was applied in a software process improvement initiative in an organization to assess the meta model applicability.</p>"
6223;en_US;"<p>In a mobile software ecosystem (MSECO), the external developer is essential element and the central organization (e.g. Google, Apple and Microsoft) have been investing in actions for the engagement of the developer so that MSECO expands in contributions with quality (e.g. download and the user evaluations). Inside of this scenery, the human factors compose the developer’s experience (DX) and, among them, the personality can have impact in the execution of process for the developer. In that context, the present paper presents a study of exploratory case for analysis of the influence of the personality type in DX in MSECO. The result indicate a correlation between the psychological profile and the developers’ productivity in a new platform of mobile software.</p>"
6224;en_US;"<p>Continuous learning of software development professionals is a requirement for organization that want to remain competitive. In this way, we can perceive a software organization as a environment to foster learning process. Thus, this paper presents a multi-dimensional theoretical model about learning environment in software organization in order to facilitate the understanding of the subject and generate reflections for future research.</p>"
6225;en_US;"<p>Configuration Management (CM) is one of MPS.BR process, which deals with the management software versions. Software version control along its development cycle is not a simple task and the use of computational tool can impact positively or negatively on this control. Therefore, it is necessary to undertake an analysis of support tool for software version control in the literature to find out whether they are appropriate or not. This work consisted in the analysis of the software version control tool Subversion, Git, Bazaar and Mercurial, in order to check if they include the requirement specified by the CM process in MPS.BR model.</p>"
6226;en_US;"<p>This paper proposes an approach about best practices using agile method to manage the software acquisition process in the context of software development company, based on the Supplier Agreeement Management process area in CMMI-DEV and the Acquisition process in MR-MPS-SW.</p>"
6227;en_US;"<p>Software Ecosystem (SECO) is an interaction of a group of players on a common technology platform, resulting in a number of software solutions or service. The analysis of the roles of the actors involved in a SECO is an approach that can be used for understanding their relationships. In this context, this paper presents a preliminary process that aids the analysis of the roles of the actors involved in the SECO based on their relationships and interaction with the central organization (keystone), more specifically in the public domain. We investigate a real SECO, Projudi System of the Court of Justice, and conducted some interviews as our first steps.</p>"
6228;en_US;"<p>Software Ecosystem (SECO) are a set of organization and actors, as well as their relations that cover technical, social and business aspects of software development. As a research field, several studies and review were conducted towards a body of knowledge for the SECO field. In this paper, we preliminarily analyze these studies in order to provide an initial overview of the SECO literature. Our intention is to aid researcher to know some relevant opportunities to foster the fields evolution, such as collaborative governance.</p>"
6229;en_US;"<p>We present a project developed by a university in partnership with Brazil’s Ministery of Culture. The goal is to find innovative solutions to the de- velopment of free technologies by public administarion in order to contribute to policy manegement and cultural democratization, encouraging the development and improvement of free cultural software. The project has 4 axes of action: (1) uses and software appropriation by cultural operators; (2) studies of func- tioning of free software developers communities; (3) testing of relevant cultural software; and (4) proposal of a new management model for the encouragement of integrated development of free cultural software.</p>"
6230;en_US;"<p>A software ecosystem (ECOS) refers to a set of software with a cer- tain degree of symbiotic relationship, and may consist of actors interacting with a market supported by a technological platform or common market. Virtual Le- arning Environments (VLE) aim to create environments based on the Internet to enable the process of building knowledge and autonomy from their interactors. The SOLAR AVA is a virtual space for classroom course and semipresential course. The aim of this paper is to present some research opportunities in the e-learning SOLAR ECOS development and in software quality.</p>"
6231;en_US;"<p>This paper examines two approaches to support the requirement prioritization process: the reqT / CSP Specific Domain Language and the G-4prioritization Guide, in order to identify whether the two approaches overlap or complement each other in support of prioritization of requirement.</p>"
6232;en_US;"<p>This article aims to present the use of Iterative Incremental model as a support tool in the software development process in order to collaborate with the error reduction. For this study, sample of records of a Study Company were taken and analyzed in two phases: the first based on the traditional model, previously used, and the second after adoption of Iterative incremental model.</p>"
6233;en_US;"Mobile application 1developers use Questions and Answers (Q&A) repositories, such as Stack Overflow, to solve technical issues when developing their mobile application. In this formed ecosystem, Q&A repositories can serve as a mechanism to analyze the experiences during mobile application development. Regarding developers feelings about work, we can analyze the emotions involved in developer experience by mining developers questions. We used 1,568,377 body of posts from Stack Overflow related to Android, iOS and Windows to perform comparisons among the three ecosystem regarding the emotions: Joy, Fear, Sadness, Anger, and Disgust. Our result indicate that Sadness, Anger and Joy are the most common emotions. We also identified which technical elements are involved in these emotions."
6234;en_US;"Communication is still one of the main challenges of distributed software development and it is important for distributed teams to be able to maintain effective communication, i.e., to communicate properly and in a timely manner to facilitate the management of project activity and then to contribute to the process quality. Communication is also a critical aspect for Software Reuse in global development since it affects trust and can foster the not-invented-here syndrome. In order to handle such challenge, this paper presents an evaluation of a preliminary version of an assessment method for identifying communication maturity, based on the Communication Maturity Model (C2M), a model that supports the improvement of communication process and practices in distributed organization. We present the preliminary assessment method definition and its evaluation result obtained during two focal group sessions with IT professionals. Findings include a positive and promising perception on the benefits of adopting this method, and a demand for further work towards its maturation."
6235;en_US;"The Internet of Things (IoT) continues to experience rapid growth, and its influence is extending into previously unreached domains. However, some of these new domains impose specific limitations that complicate the design and implementation of IoT system. Examples of such limitations are the exclusion of specific protocol, restrictions on the types of data that can be collected, requirement about what information can be transmitted to the public and controls around how that communication occurs. Capturing, representing and designing for these limitations as well as reuse is essential for the quick and successful deployment of such project. In this paper, we present a case study of an IoT human in the loop monitoring system built for use within an industrial setting. We report our experiences with both designing the first deployment of the system as well as designing variation points into the software architecture to account for future iterations and deployment into other environments."
6236;en_US;"Software ecosystem have adopted many different strategies to achieve success and good health. The role of software architect is one of the main contributors to that success. Their activity are crucial for realizing the business strategy of their organization. Software ecosystem define multi-sided markets that require different strategies from a traditional two-sided market. The architectural practices in the multi-sided market must support the need for flexibility and rapid reaction. These new demands broaden our understanding of the software architects role and the impact of their action on ecosystem structure. In particular the need to understand how to operate in a collaborative, cooperative environment to exploit competition. In this position paper, we discuss how software architects actions influence the ecosystem health through their indicators: productivity, niche creation, and robustness."
6237;en_US;"<p>Breast cancer is one of the biggest causes of death among women around the world. Diagnosing this disease early can offer better treatment to the patient. Intelligent system have been used for the detection of disease using image. In this work a convolutional neural network was used for the detection of breast cancer in histopathological image through Keras library and TensorFlow framework. model were created for 4 dataset with different magnifying factors (40x, 100x, 200x and 400x). Using k-fold cross-validation, it was found that there was a better result for the set of 400x image with 98.44% accuracy in the training data. The set of 200x image obtained a better result for recall and f1-score.</p>"
6238;en_US;"<p>Posture is usually defined as the relative position of body elements. The ideal posture is the one where the articulations are under a minimum amount of stress but it is never achieved due to individual factors. It is im- portant to measure this lack of balance to minimize its effects in long term. This paper presents the creation of a multifunctional 3D scanner for posture analysis that allows the measurement of distances and angles between anatomic points of the body in a semi-automatic way, adding application that only 3D information can aggregate, like the measurement of body volume to calculate the subject’s body fat percentage and body part perimeters. This equipment was built us- ing 2 RGB-D sensor combined with the reconstruction library ReconstructMe and the MeshLab software, creating an easy-to-use and interactive system. The developed application was used in postural analysis tests of a mannequin fol- lowing the SAPO protocol of posture assessment and compared to the SAPO software, indicating good correspondence between the method.</p>"
6239;en_US;"<p>Gliomas are among the most common malignant brain tumors. They can be classified into low-grade and high-grade gliomas and their early iden- tification is crucial for treatment direction. Using a radiomics approach, the present work proposes the use of biodiversity and phylogenetic diversity bio- logy indices to handle the glioma classification problem. The proposed method presented promising result, with AUC, accuracy, sensitivity and specificity of 0,926, 0,902, 0,962 and 0,733, respectively.</p>"
6240;en_US;"<p>Infusion procedures are among the most common in hospitals and have a high volume of adverse events in their operation. This paper presents a simulator, called SPODi, that allows an agile construction of the operational profiles of intravenous device, enabling them to be evaluated when adverse events occur during the period of use. SPODi simulator was validated with real data extracted from a physical prototype (SPODi _Med) which was specifically build with this function. The result obtained, considering a 95% confidence interval when applying the t Student statistical test, indicate that SPODi can be used to infer the behavior of real infusion equipment.</p>"
6241;en_US;"<p>Leukemia is a type of cancer that affects the production of blood cells in the bone marrow which makes it challenging to coagulate blood and fight infection. In this work, we propose a method for the automatic diagnosis of leukemia using Convolutional Neural network (CNNs). We use pre-trained CNNs and learning transfer technique in constructing the proposed method. We employed the Deeply Fine Tuning Modified (DFTM) technique combined with data augmentation operations to fine-tune the pre-trained model. To train and test the proposed method, we used a set of 2304 image from 14 different image databases. The proposed method reached an accuracy of 98.84%, and when compared to other work, we observed greater robustness and consistency in the result. We conclude that the fine-tuning is more robust the classification of heterogeneous image when compared to the feature extraction through CNNs.</p>"
6242;en_US;"<p>The traditional method of mental health assessment, usually perfor- med by a psychotherapist, shows relevant rates of inaccuracy. This work pre- sents RevitalMe model, which analyzes the heart rate in order to contribute to the traditional method. The model provides daily information of the individual to psychotherapist, establishing a correlation between the mental health and the places frequented, through context-awareness. The evaluation of the mo- del was performed with the implementation and use of a prototype applied to stress, which presents F1-Score of 88% in classification status of the individual between “stressed” and “not stressed”. The perceived utility of the model is 83% according to 5 psychotherapists.</p>"
6243;en_US;"<p>This work presents a Systematic Literature Review of Machine Lear- ning Literature in game for Medicine held in 4 international research source in the last 10 years, whose objective is to identify the state of the art of machine learning in medical game. As a result of the Systematic Review presented in this study, 1040 paper were analyzed, of which 40 were pre-selected and 12 were selected for data extraction. Among the selected work, it was possible to list several technique of machine learning, types of learning, health area and game used today.</p>"
6244;en_US;"<p>Chronic renal disease arise from acute or intermittent, not adequa- tely treated pathologies such as minimal change disease (MCD) and focal seg- mental glomerulosclerosis (FSGS). Correct identification of these two disease is of paramount importance because their treatments and prognoses are diffe- rent. Thus, we propose a method capable of differentiating MCD and FSGS through image of pathological exams. In the proposed method, we extracted 10240 feature from three pre-trained convolutional neural network, we se- lected 62 from them through the mutual information algorithm, and we used the Random Forest for the classification. The method obtained an accuracy of 93.33% and Kappa of 85.47%, which is considered “Almost Perfect”.</p>"
6245;en_US;"<p>Even with the many advantages of adopting a structured reporting system, there is little convention on how to disseminate this routine into the report environment. This work proposes a systematic approach to migrate a system routine from free-text reports to structured reports, focusing on the DI- COM Structured Reporting guidelines. We evaluated this proposal by creating a reporting module in the context of a telemedicine system, and performing case study covering ultrasonography reports. Using the AdEQUATE model, the eval- uation showed a high user perception from the system, directly reflecting the quality of our proposal. The result are a set of defined premises and steps that turns a telemedicine system into a complete structured reporting environment.</p>"
6246;en_US;"<p>Lumbar pain is a common reason for clinical visits and magnetic res- onance imaging is frequently used in system to support the diagnosis of spinal pathologies. Aiming to improve and automate this process, this study propo- ses the use of computational technique for the segmentation of vertebrae in magnetic resonance imaging, with the purpose of performing further analysis about pathologies in the spine. To achieve this goal, two Deep Learning archi- tectures are used: U-Net for 3D segmentation and Deep Belief Network for the classification of vertebrae with rupture or not. The result show that U-Net is promising to localize the vertebra region, obtaining an average Dice Coefficient value of 89,51%, thus overcoming several important studies focused on the pro- blem. Classification was also efficient, with values of 94.38% for accuracy and 88.8% for sensitivity.</p>"
6248;en_US;"<p>People affected by Attention Deficit Hyperactivity Disorder (ADHD) tend to present greater difficulties in routine activity than people who do not have the disorder. These effects, which begin in childhood, can continue th- roughout life. This article presents a literature review of developed digital ga- mes and tool aimed at reducing the impact of these symptoms on the life of those who have the disorder. It is a survey that show the current research trends in the area, as well as possible lines of research not explored in the context of digital game applied to ADHD.</p>"
6249;en_US;"<p>An eating disorder is a disturb characterized by an atypical eating behavior. The most common strategy for treatment is CBT, and its limitations have shown to be overcome using virtual reality approaches. Most VR envi- ronments created for this purpose reproduce tasks for treatment of body image disturbances and food avoidance. This work presents a new approach for eating disorders treatment using VR and concepts of serious game and gamification, which have been shown of promising potential in health context due to its ad- vantages when compared to other approaches. Tests assessing the usability and sense of presence in the virtual environment were applied to a group of 10 par- ticipants, indicating that the environment is well suited for medical treatment.</p>"
6250;en_US;"<p>Speech emotion recogntion is commonly performed in categorical classes, such as “sadness” or “joy”. According to Russell’s map of affection, emotions can also be classified by arousal (excitation), valence, and quadrants. In this work is proposed a method to increase the performance of speech emo- tion recogntion in categorical classes using classifier that perform intermediate classification in the classes of valence, excitation and quadrants using a multi- view approach. To combine these result and obtain the final classification, a decision tree is proposed and that increases F1 metrics from 0.73 by Ensemble of three kinds of classifier to 0.87 in a public database.</p>"
6251;en_US;"<p>The objective of this study was to correlate the geography scope of the Basic Health Units with the spatial distribution of leprosy cases in the hyperendemic municipality of Santarém, western region of the state of Pará. The methodology used for this study, was the mapping of the territorial coverage of the UBS, its scope, that is, the area of action of the Community Health agent (ACS) and the cases of leprosy from the period 2003 to 2013, for this was used a Geographic Information System (GIS) to visualize the spatial distribution of leprosy cases in relation to the coverage and coverage of the UBS in the municipality. We have resulted in shapefiles developments in coverage and coverage of UBS and the distribution of leprosy cases. Through the use of spatial analysis, the area discovered by the UBS were identified, as well as the spatial distribution of leprosy cases.</p>"
6252;en_US;"<p>The planning of goal-oriented service for health indices promotes the access and the quality in providing these service. Automatic balancing of goals aims to improve the indicators, try to approximate them to the values initially planned, especially when health managers are dealing with inconstant scenarios. In this context, this paper formalises the automatic goal balancing, incorporating it into a tool. This software is capable of simulate contingent scenarios regarding initial deviation plans. With a set of simulation inspired in realistic scenarios, we find result statistically significant (p &lt; 0.05) that offer satisfactory and positive values for our proposal, suggesting the approach would work in a real environment properly.</p>"
6253;en_US;"<p>Recent research has shown that virtual game stimulate the brain in a way that is beneficial to the user’s health, and these are widely used as an aid to the treatment of disease related to aging. In addition, studies elucidate the use of sensory effects in the treatment of psychopathologies. In this way, this paper proposes the Stroop Game, a cognitive game based on the Stroop test, with a light sensory effect. The game was developed for the Brazilian digital TV, using the Ginga-NCL middleware. After running Stroop Game tests with elder user, we conclude that the game proposed in this paper was well accepted by the user and that the sensory effect influenced their perception about it, making the game more attractive.</p>"
6254;en_US;"<p>Gliomas are one of the most severe brain tumors. However, manual targeting is a difficult and time-consuming task. Therefore, this work proposes an automatic method for the segmentation of sub-regions of lesions in the brain in 3D MR image based on superpixels, PSO algorithm and the auxiliary generator network with auxiliary classifier. The proposed method obtained result for necrosis, edema, solid nucleus and nucleus, an accuracy of 67.71 %, 94.57 %, 18.44 %, 89.35 % in the classification stage and coefficient dice of 60.35 %, 44.22 %, 16.45 %, 31.23 % in the segmentation stage for the respective subregions. The result demonstrate the difficulty in the classification and segmentation of the tumor sub-regions.</p>"
6255;en_US;"<p>The impact in reducing the radiation dose in computed tomography (CT) exams is directly related to the quality of the image obtained in this exam. Such image are degraded by undesirable artifacts, known as noise. In order to improve the quality of these image and provide an accurate medical diagnosis, it is necessary to apply noise reduction technique. In this article, it is proposed a method to filter noise in low-dose dental CT image, based on mathematical morphology and block-matching 3D (BM3D) filtering. Experimental result of the proposed method were compared with several existing method and valida- ted using the PSNR, SSIM and MSE metrics. Through several experiment, the proposed method demonstrated superior performance compared to the analyzed filters, reducing noise and preserving details in a more satisfactory way.</p>"
6256;en_US;"<p>In this paper, we propose HealthDash, a framework for developing IoT solutions for health care. HealthDash employs the data-flow-oriented pro- gramming paradigm, from the cloud layer to the network edge (fog layer), unifying development technologies across layers, that is, from edge device to decision making. We conducted an experiment to evaluate the proposal with the simulation of the transmission of data collected from home-monitored pati- ents with chronic disease. In the simulation, we observed the performance of the two implemented solutions to both continuous and event-based scenarios of data transmission. The result showed that HealthDash solution provides flexi- ble infrastructure, consuming less bandwidth and spending little response time.</p>"
6257;en_US;"<p>Simulating new protocol in WirelessBody Area network (WBANs) is important to evaluate new proposals before developing a real implementation. However, WBAN simulators only provide generic network application, thus it is not possible to simulate a health device in a WBAN network. Therefore, this work proposes an application layer based on the ISO/IEEE 11073 Standard (X73-PHD) for simulating e-health application in WBANs. Our proposal is implemented for the Castalia simulator, using the Antidote library, an open im- plementation of X73-PHD. Simulation result show that the X73-PHD standard communication model does not perform well due to long timeouts defined in the standard. Therefore, this paper also proposes a new communication mode, which reduces the exchange of control packets and the number of associations made by personal health device in WBANs.</p>"
6258;en_US;"<p>This article describes a methodology to aid in the identification of the sixth nerve palsy using video. Since the usual technique for diagnosing this paralysis are invasive or expensive, a non-invasive and affordable method could be helpful, supporting the ophthalmologist diagnosis. The proposed method uses the convolutional neural network YOLO to detect the eyes in a face and the Isophotes Curvature to find the center of the eye. Both technique are applied in each frame of a video in which the patient moves its eyes, keeping track of the eye movement in order to calculate the average speed in which each eye moves. The obtained result showed that the eyes that have the paralysis move 42% slower than a healthy eye.</p>"
6259;en_US;"<p>Cyanobacteria are organisms that can occur in reservoirs and springs. Some species can produce harmful toxins by contact or ingestion and may even cause death. The law requires periodic analyzes of water intended for the use of the population to monitor and control their quality. The process of identification and counting of cyanobacteria cells is costly and manual. Artificial intelligence is active in problem solving, and convolutional neural network are the state of the art in recognition of image and objects. It is proposed to develop an automatic method for identification and counting cyanobacteria cells. Tests have demonstrated the feasibility of the proposal as well as pointed improvements to be made.</p>"
6260;en_US;"<p>This paper describes a update in the development status of a story- telling game to assist in socializing with people with Autism Spectrum Disorder (ASD). Tales of Health-TEA goal is to facilitate the inclusion of people who carries ASD in modern society, in addition to providing greater confidence in neurotypical people when dealing with those who presents behavioral peculia- rities stemming from ASD.</p>"
6261;en_US;"<p>Speech therapies are often repetitive and tiring, causing impatience and often the treatment discontinuation by children and adolescents. This work presents the application of visual recognition technique in the interpretation and capture of tongue movements performed in a speech therapy. As a result, it is possible to integrate basic exercises of oral muscle strengthening with se- veral digital game dynamics, allowing a better acceptance of the patient to the routines applied in the respective therapies.</p>"
6262;en_US;"<p>Autism Spectrum Disorder (ASD) impairs the transmission of kno- wledge, transforming their learning into a time-consuming and laborious pro- cess. Thus, to support the development of social aspects and the linearity of events of ASD patient, this paper presents the development of QuizTEA. It is a digital game that will be developed in digital quiz format, where, after hearing a story, the player must answer the questions in order to put in order the comics that tell the story heard.</p>"
6263;en_US;"<p>The effective involvement of patient in treatment is a big challenge for all health professionals, especially when dealing with chronic disease. The treatment of these disease involves lifestyle changes and a continuous care process. In this context, the use of chatbots allows to offer more personalized care for each patient, reducing the waiting time for basic care and the lack of constant monitoring. This paper proposes a chatbot prototype, called HelpCare, developed through the IBM Watson cognitive computing tool. This prototype aims to help patient with chronic disease, such as diabetes, high cholesterol and hypertension.</p>"
6264;en_US;"<p>Breathing rate is a vital sign that can indicate someone’s health status and even detect early disease. Mobile health application might become the main tool for estimating breathing rate out of the clinical environment. In this research, a review of the literature is conducted, aiming at finding out the most recent researches that have been proposed as solutions for respiratory measurement or monitoring using mobile device. We discuss and compare their method, highlighting pros and cons regarding ubiquity and feasibility. The result indicate that the combination of method is a key aspect to improve measurements.</p>"
6265;en_US;"<p>The Brazilian population has been suffering continuously from peo- ple infected with Aedes aegypti mosquito disease, which present alternating outbreaks and difficult-to-combat epidemics, having killed hundreds of people year after year. This work presents the result obtained with the Aedes na Mira 2.0 development, a game that applies virtual reality mechanics and dynamics in a scenario capable of providing a learning context in prevention and combat to the respective mosquito.</p>"
6266;en_US;"<p>Identifying significant mutations in cancer is a key point in Cancer Genomics, and it is one of the biggest challenges in the area. Computational method for identifying significant mutations have been developed in recent years. In this work, we present a proposal of a flexible computational method with an extensive biological base for ranking significant set of related genes in cancer. Our method considers data about mutations, type of mutations, gene interaction network and mutual exclusivity pattern.</p>"
6267;en_US;"<p>Nowadays, there is a demand of encouraging the blowing exercise in a playful way. This paper presents the development process of Cata-Sopro, a vi- deogame control prototype that has the blowing exercise its main function. For this, the hardware scheme, operational logic control and preliminary tests re- sults are described. As a result, despite the current demands for extra functional tests and aesthetic improvements, a simple and low cost apparatus was provi- ded, being able to be applied in speech therapies aimed to stimulate desired orofacial exercises.</p>"
6268;en_US;"<p>With technological advances, the treatment and follow-up of disease like Diabetes has become easier. However, the developed human-computer interface are generally projected on the assumption that they will be used by people with normal sensory-motor and cognitive abilities. Therefore, any deviation from these standards may hinder the use of these system. This is a work in progress in which we present a mapping of the characteristics/difficulties associated with patient with Diabetes. The result of this mapping were represented ontologically. Aiming to implement an adaptive interface to the system, allowing it to adapt dynamically to the user Needs.</p>"
6269;en_US;"<p>Considering the difficulties of extracting entities from Electronic Health Records (EHR) text in Portuguese, we explore the Conditional Random Fields (CRF) algorithm to build a Named Entity Recognition (NER) system based on a corpus of clinical Portuguese data annotated by experts. We acquaint the challenges and method to classify Abbreviations, Disorders, Procedures and Chemicals within the text. By selecting a meaningful set of feature, and parameters with the best performance the result demonstrate that the method is promising and may support other biomedical tasks, nonetheless, further experiment with more feature, different architectures and sophisticated preprocessing steps are needed.</p>"
6270;en_US;"<p>Parasitic Infections affects more than one billion people in 149 developing countries, and its diagnosis is made through a slow process, capable of adversely affect the health of specialized professionals. Inspired by that, this work proposes a low-cost infrastructure to transform ordinary optical microscopes into digital ones. The solution makes it possible to visualize the microscope’s image on a regular screen, as well as to capture image and relevant information about them. Besides, these device can use IoT platforms to deploy such image. This procedure makes the process easier and more comfortable, avoiding health problem related to the constant and regular use of a conventional microscope.</p>"
6271;en_US;"<p>Mammography is an extremely important examination considering the high incidence of breast-related disease, since it helps to detect several abnormalities. Errors in the acquisition can mask potential problem. The objective of this study is to apply image processing technique for automated detection of some very common errors. Craniocaudal (CC) and mediolateral oblique (MLO) mammograms views were evaluated considering aspects as: (1) breast symmetric positioning, (2) adequate nipples profiling and centering, and (3) properly pectoral muscle location. The image processing technique used are based on: skeletonization, Hough transform and thresholding. The achieved result are impressive especially in the determination of the nipple position.</p>"
6272;en_US;"<p>Melanoma is the most lethal skin cancer compared to others, however, patient have a high cure rate when diagnosed in their early stages. Exist several approaches to automatic diagnosis and detection proposed by different authors. However, the training of model in small and unbalanced databases presents several obstacles. Thus, this work in progress aims to apply the technique of transfer of learning to training model capable of assisting in the diagnosis and screening of melanoma. Preliminary result showed that the use of synthetic data generation in conjunction with the fine-tuning of VGG16, showed crucial improvements, approximately 100% sensitivity and 93.75% specificity.</p>"
6273;en_US;"<p>Glaucoma is an asymptomatic disease that can bring people to blind- ness if not early detected. Computational intelligence method have been pro- posed to provide a computerized diagnosis that can guide patient to the ap- propriate treatment. However, these technique face methodology optmization problem, which depends on the choices of many algorithm from diferent kno- wledge area. This paper suggests a solution through meta-learning of pre- processing method, decomposition and feature extraction which have to be used efficiently in order to solve the problem. Current result are promissing, reaching 91.24% accuracy after 50 evaluations and it is suposed to improve proportionally to the number of evaluations.</p>"
6274;en_US;"<p>Sleep disorders are recurrent problem in society and have gained attention in recent years, especially when considering the changes imposed by Information and Communication Technologies (ICT) because they allow the de- velopment of solutions aimed at the evaluation of sleep. These disorders are usually associated with some clinical condition and usually the diagnosis is ob- tained through laboratory polysomnography, however, this is an expensive tech- nique and may be inconvenient to patient. Therefore, it is worth emphasizing the importance of the sleep environment in the context of the diagnosis, since the variables associated to it play an important role in sleep quality. In this sense, the article presents the development of a non-invasive and low-cost device for monitoring the sleep environment, designed under the Design Science Research Methodology, to aid in the treatment of sleep disorders.</p>"
6275;en_US;"Self-medication without medical advice can lead to health problem through intoxication. The objective of this study is to present MediBot - a chat- bot to consult information about medications and their risks. MediBot enables query through natural language, transformed them into SPARQL query over a Linked Data Mashup about data on medicines provided by ANVISA and Sider source. Finally, MediBot presents itself as a timely tool in promoting access to information by the general public."
6276;en_US;"The Primary Health Care teams have the responsibility to identify the most effective and efficient actions to promote and recover the health of the citizens. One way to carry out these actions is carrying out collective activity with the citizens of the territory or with the health care professionals. Collective activity can be carried out in different locations, which are generally not provided with a computer with internet access. In this context a mobile app for tablet called e-SUS AB Atividade Coletiva was developed. The application allows the digitization of the records of collective action in loco reducing the rework of the professionals and facilitating the access to information of previous activity."
6278;en_US;"Sleep disorders are problem that affect a significant portion of so- ciety and their diagnosis is usually conditioned by the use of the laboratory polysomnography method. However, this is a costly, inconvenient and cumber- some technique to the patient during the screening process. In this sense, the present article presents a low-cost developmental device for monitoring in-situ and noninvasive sleep, designed under the Design Science Research Methodo- logy, which collects the variables of the rest environment, since these aspects have crucial influence on the quality of sleep."
6279;en_US;"With the new digital age, new needs are emerging in the dental market related to infrastructure, specializations or negotiation model. In order to meet such needs, Smiles 3D Project was created aiming at facilitating communication between prosthetists and dentists, improving offer and acquisition of dental service and products. In addition, it enables a more practical and quick commercial, educational or economic relationship for odontology professionals, making the market more competitive."
6282;en_US;"In order to analyze and possibly differentiate the pattern of carcinogenic regions of thyroid nodules, two methodologies to generate temporal serie from region of interest points was proposed, discussed and compared. This method are called Principal Axis orientation and Similarity Transformation Search Between image. Simplified forms of these method are also considered and implemented. Comparisons are done with both result, related their advantages and aspects. As far as we known there is no work employing the idea of the PA in this problem of following a same point through different image without brightness constancy."
6283;en_US;"The World Health Organization reports that respiratory disease are responsible for various disabilities and one of the most common causes of deaths in all regions of the world. Respiratory Rehabilitation (RR) is the process used to treat patient with respiratory disease and requires a systematic, repetitive and long-term approach, leading to a reduction in adherence to treatment by patient. One possibility to raise the patient engagement can be the use of Serious game (JS), developed for a specific purpose other than entertainment and with participation of specialists. The objective of this research was to develop a Biomedical (SB) subject to assist the RR by means of specific hardware and a JS, with involvement and evaluation by professionals of the area of ​​RR. Were JS design methodologies, participatory design and a questionnaire to evaluate the utility perception of SB. A process of (i) design, (ii) a SB with JS called I Blue It, (iii) a respiratory flow, dubbed PITACO, and (iv) an improved version of Seri- ous Exergame Utility Questionnarie. A JS that uses five measures was conceived of the respiratory process (expiratory and inspiratory peak, duration of expiration and inspiration, and respiratory rate) with involvement of 106 subjects in 15 iterations of design where the latter, with a group of 32 physio- therapy, the SB was assessed at 4.1 (on a scale of 1 to 5) for potential of utility to assist RR. Still as a result, this work generated three scientific articles and two awards, one of innovation by the device and another serious game. We conclude that the biomedical system with serious and device has good potential for respiratory rehabilitation. "
6284;en_US;"Test Oracles determine whether an execution of a SUT (from English, System Under Test) is correct or not. However, depending on the nature of the data produced by the system, the SUT is known as the output system complex, making the automation of oracles a challenge. system in the area in particular, which analyze three-dimensional image, exemplify a type of complex exit system. One of the challenges associated with analyzing three-dimensional image is whether the output produced is cor- straight or not. The fact that it is a complex exit system makes this difficult task, making ad-hoc strategies and manuals of the In this masters work, the aim was to contribute through the of test oracles based on the extraction of characteristics from the outputs of the theme. The approach proposed has been applied specifically in system whose outputs consist of three-dimensional synthetic image of blood vessels. To do so, the O-FIm / CO framework (Oracle for image and Complex Outputs), which uses CBIR (Content-Based Image Retrieval) as a way to automate test oracles. Besides adaptations and extensions of the framework, plug-ins have been developed, which represent feature extractors for three-dimensional blood vessels. Two experimental studies were conducted aiming at to evaluate the effectiveness and accuracy of test-based oracles in evaluating this type of image. In addition, an experimental study was carried by comparing automated oracles and human oracles. The result evidence of the effectiveness of the approach as a promising strategy for activity, contributing to the reduction of time and efforts generated by manual approaches during the evaluation of the quality of system three-dimensional medical imagers. "
6285;en_US;"This work investigates how gamification is used in health applica- tions that aim to stimulate self-care. There is evidence in the literature that indicates the need to know the profile of the user to correctly use the elements of game, without extrapolating the main objective of the application, which is to treat health. To overcome this problem, a conceptual framework (method) was developed, consisting of two dimensions, Self-Care and Gamification, which in- corporate some concepts and practices so that an application developer can de- sign his application. At the evaluation stage, the mixed method was used, with questionnaire application and online interview with specialists. The result in- dicate that the framework helps developers marshal the mHealth application, primarily by encouraging engagement."
6286;en_US;"Hemiparesis resulting from a Stroke can affect the patient daily activity. In this study, a biomedical system (BS) based on Serious game (SG) was developed for evaluation and motor rehabilitation in hemiparetic stroke patient, by using a conceptual model for the development of post- stroke rehabilitation system based on the game score. Two experimental studies were performed with twenty-two patient and the result showed that the patient improved significantly in all evaluated clinical variables. The correlations between SG score and clinical assessment scales indicate the potential of BS as a clinical assessment tool."
6287;en_US;"Smart Home Health Care system (Health- Supportive Home or MSM) can provide health service in the homes of patient diagnosed with one or multiple chronic disease, aiming mainly at improvement of the quality of life and autonomy, as well as the reduction of of the costs of public health system. However, MSM system challenges in the design of its architecture and be treated in terms of their high quality and economic viability. Beyond Moreover, MSM system are in most cases constituted by several other system that are complex, independent, distributed and heterogeneous, such as example, medical device, electronic health system (e-Health), health information, among others. In this way, they should not be treated as monolithic system (as they currently are), but rather as system-system (system-of-system or SoS). In this scenario, the main objective of this thesis was to contribute to the architectural design of HSH-SoS 1; for this, it was established the HomecARe, a reference architecture that supports systematic reuse technical knowledge and domain, facilitating the design and development of HSH-SoS. To establish the HomecARe, a systematic process was adopted that supports the engineering of reference architectures. Aiming to analyze the viability and relevance of HomecARe, an extensive case study was conducted in which Ho- mecARe was used to design DiaManT @ Home, an HSH-SoS to support patient with diabetes mellitus for self-management of their disease. result obtained demonstrated the relevance and feasibility of the HomecARe Reusable, interoperable, reliable, secure and adaptive MSM-SoS, including an unprecedented contribution to the area of ​​electronic health, and bringing in the area of reference architecture and SoS. "
6288;en_US;"This paper describes the research involved in the design and evalu- ation the game Sêntimus: A Musical Digital Game for Children with Hyper- sensitivity to Sounds and feature of Neurodevelopmental Disorders. The game was developed based on treatment principles identified in the literature for both disease, and was evaluated with 5 music therapists and also with 3 children with Neurodevelopmental Disorders and Hypersensitivity to Sounds. Our work contributes to the research on serious game, as well as to the treatment of the intended population, through their use of Sêntimus."
6289;en_US;"Thyroid anomalies have high prevalence and their early identifica- tion is crucial for a more effective treatment. Thermograms can be used in this process, since nodules tend to be more vascularized, resulting in a temperature increase. This work presents a methodology for determining thyroid nodules. We evaluate parameters that would allow to segment possibly nodular regions in thermograph. Convolutional neural network (CNN) are used to classify these regions, identifying which ones refer to nodules. The good result of CNN in the classification (with 96% accuracy), show that the viability of the proposed methodology depends on the success of the segmentation."
6290;en_US;"Lifestyle is the main factor for the development of cardiovascular disease. Therefore, proper health care can greatly reduce the likelihood of heart problem, as well as routine examinations and follow-up by a cardiologist. There are several conventional tests to support the diagnosis of cardiovascular disease, which are often tiresome and costly to the patient. DyHEARTMon aims to be an alternative and complementary internet based tool of things for patient and health professionals associated with cardiovascular disease. Through a hybrid solution (smartband, smartphone and dashboard), the heart rate and blood pressure will be captured so that the potential risk of hypertension of the monitored individual is analyzed and presented, thus presenting an alternative to the Ambulatory Blood Pressure Monitoring (ABPM) and Home Blood Pressure Monitoring (HBPM)."
6291;en_US;"This paper proposes a sequence of computational procedures for de- tecting, interpreting and classifying pattern in frontal two-dimensional image of faces for automatic recognition of pain in newborns. Using data transfor- mation and extraction of statistical characteristics from a real-life, healthy-term newborn image database, it was possible to interpret and model the subjectivity of trained health professionals, quantifying human knowledge in the task of re- cognizing pain enabling automatic identification. These result were compared with NFCS based classifications by the same professionals of the same image."
6292;en_US;"Glaucoma is a disease that damages the optic nerve. the second leading cause of blindness in the world. Several have been proposed. However, these system were not able to deal with a great diversity of image. Therefore, such method are not feasible for use in screening programs. We performed an ex- tense study to define the best set of attributes for the representation of image. In total, we evaluated 16,469 characteristics. Our approach to Detection of Glaucoma Uses Texture Descriptors and Neural network Convolute- (CNNs). We evaluated our proposal in a total of 873 image of four public databases and concluded that the merging of GLCM and pre- together with the use of the Random Forest classifier are promis- in the detection of this pathology, obtaining an accuracy of 93.35% and an index Kappa considered Excellent. "
6293;en_US;"Thermography is a technique has been proposed as an auxiliary tool in the screening of breast cancer. These image are also used for the validation Three-dimensional numerical simulation validation. The production of a more realistic model would allow a reliable estimation of the thermophysical properties of the breast. This work aimed to format a methodology in order to develop a three - dimensional breast geometry from the curves extracted from the thermograms in the UFPE Thermographic Imaging Database."
6294;en_US;"This work presents a prototype proposal for a Multisensory Neonatal Incubator, for academic purposes and use in a hospital environment. In the case of use in academic environments, it is intended to improve the quality of the training environment of medical student and other course in the area of Health, offering a very realistic environment, when compared to the environment that many doctors find in everyday situations of care with newborns. In the case of use in hospital environments, it is intended to construct a low-cost but efficient and reliable equipment that can be applied to reduce the important deficit of incubators for newborns existing in Brazil. The prototype is developed in a multidisciplinary way, with student and teachers from the both Medicine and Computer Science course, taking advantage of the resource and simulation feature offered by the Premature Anne robot-mannequin."
6295;en_US;"This article introduces a smart assistant to assist in the prevention of type 2 diabetes. The wizard is based on in- artificial intelligence, based on the model of a specialist system, and representation of the knowledge and reasoning of a specialist. The use of a mobile application can favor, mainly, populations and geographically remote, who have difficulty accessing a specialist for continuous monitoring. "
6296;en_US;"Understanding the linkage among insulin time-action profile, glycemia, diet, and physical activity is an essential skill in the treatment of Type 1 Diabetes Mellitus (DM). Hence, our work presents a graphical data visualization tool that aims to facilitate this task."
6297;en_US;"Due to the high failure rate in the procedure of applying dental anesthesia, this work presents the gamification process of a simulator of this procedure and its validation. From the literature review and simulator analysis, game elements were listed and implemented. The serious game aims to promote a learning strategy that is more attractive, encouraging and allows training eva- luation. Partial result of an experiment performed by volunteers indicate that the gamification process was successful and that the game can be submitted for validation with Dentistry professionals."
6298;en_US;"Nowadays, 93 % of subcortical regions are unknown to neuroscien- tists and, therefore, are classified as terra incognita. Despite the recent advan- ces in medical imaging technologies, the quality of image collected in vivo is still low when compared to the histological image. On the other hand, the area of non-extensive statistics has advanced and presented good result, mainly in image processing. This work proposes the use of the sigmoid fitler with non- extensive entropy in functional magnetic resonance imaging (fMRI), with the purpose of highlighting and mapping brain regions activated during the execu- tion of specific tasks."
6299;en_US;"Autistic Spectrum Disorder (ASD) is among the most damaging mental health problem in child development. In general, people with autism need language, behavioral, and social skills support to be successful. The present study sought to know the main challenges faced by children with ASD and their families / caregivers, based on the difficulties reported by the families of these children and by the multi-professional team that accompany them. The result found may support future research aimed at mitigating these needs."
6300;en_US;"This study provides an electromyography (EMG) analysis to recognize non conventional positions of the MyoTM Armband and expand the gesture pattern list in order to control device more accurately and with more functionality. Among the controls, a library of commands has been developed that can be applied in several different project, such as man-machine interface for game, control of multimedia device, IoT project, control of home appliances or robotic prostheses. The system makes it possible to control any device through muscular contraction."
6301;en_US;"This paper describes challenges to the advances of Big Data Analysis in Health, which are relevant because of the current needs for high demand health system. Therefore, it is important to develop new analytical tool that are easy to use, reflect the aggregation of knowledge from different area and solve real health problem. As a way of validating the new tool, it is suggested to use data from the various Health Information system of the Brazilian Ministry of Health."
6304;en_US;"<p>Deep learning model expect a reasonable amount of training in- stances to improve prediction quality. Moreover, in classification problem, the occurrence of an unbalanced distribution may lead to a biased model. In this paper, we investigate the problem of species classification from plant image, where some species have very few image sample. We explore reduced versions of imagenet Neural Network winners architecture to filter the space of candi- date matches, under a target accuracy level. We show through experimental result using real unbalanced plant image dataset that our approach can lead to classifications within the 5 best positions with high probability.</p>"
6305;en_US;"<p>Severity scores provide a consolidated index of the patient’s health status in the ICU. These scores are based on linear model and analysis of each single variable in isolation. Data mining technique have been applied to generate more complex predicion model for prediction, but did not deepen in the analysis of class imbalance and treatment of missing data. This work analyzed technique for class balancing and imputation of missing values, together with Random Forest (RF), Artiﬁcial Neural network (RNA) and Logistic Regression (RL) classiﬁcation model. As a result the RF obtained the best performance with the mean AUC of 0.784±0.006, sensitivity of 0.738±0.002 and speciﬁcity of 0.700±0.003 with missing values replaced by default values and trained with the base with NCL undersampling.</p>"
6306;en_US;"<p>Malaria is an infectious disease that mainly affects the Legal Ama- zon. dataUS includes the Malaria Epidemiological Surveillance Information System. Monitoring this dataset and integrating it with additional data source, as well as performing proper data preprocessing is crucial to understand the phenomena behind the occurrence and medical care. Therefore, in this paper we make use of the Data Science Platform Applied to Health (PCDaS) as an enabling tool to analyze the evolution of malaria in the Legal Amazon. From its use, we raised research questions that can help in understanding and controlling this disease in Brazil.</p>"
6307;en_US;"<p>This study presents a proposal for modeling regulatory network ba- sed on public biological data from three classes of regulatory elements (ncRNAs) such as miRNAs, circRNAs and piRNAs and their relations (regulation and ori- gin) with genes. The integrated network and its association with clinically rele- vant biological data allowed the discovery of potential candidate genes related to complex disease. According to this network’s centrality and neighborhood overlap, we identified novel potential genes and ncRNAs that could act as bio- markers of complex disease considered major public health issues.</p>"
6308;en_US;"<p>Several existing workflows require many computational resource because they process a large amount of data. Thus, High Performance Processing (PAD) en- vironments must be applied in conjunction with parallelization technique to support their execution. Although PAD environments offer several advantages, failures are a reality, not a possibility, due to the large number of computing node involved in the execution of the workflow. Verifying workflow failures is a challenge that still requires effort. In this paper we propose the use of DS 3 , a dynamic logic taiored to reason about stochastic Petri nets, to verify and predict failures in workflows.</p>"
6309;en_US;"<p>Scientific system focused on workflows have several pros and cons and share several characteristics such as the need to provide support for scientists to analyze data. Data provenance can play an important role in providing the information needed in different experimental steps. This way, the present paper aims to map and characterize four provenance ontology, analyzing factors such as adequacy, execution requirement and architecture. After the study, it was realized that provenance methodologies can be applied at different stages of the scientific workflow life cycle, but mainly in the analysis phase.</p>"
6310;en_US;"<p>Missing data is a common problem in the world of data analysis. They appear in dataset due to a multitude of reasons, from data integration to poor data input. When faced with the problem, the analyst must decide what to do with the missing data since its not always advisable to discard these values from your analysis. On this paper we shall discuss a method that takes into account information theory and functional dependencies to best imput missing values.</p>"
6311;en_US;"<p>In scientific collaboration, the data sharing, the exchange of ideas and result is crucial to promote knowledge and accelerate the development of science. Trust is extremely important in this context as well as reproducibility. Although in scientific workflow the provenance has been the basis for reproducibility, in collaborative environments it is necessary to ensure integrity and trustworthiness of this provenance data. One of the technologies that have emerged and can help to address these issues is blockchain. A blockchain-based provenance system for collaborative scientific experiment could lead to a trustworthy environment for scientific experimentation. In this vein, this paper presents the specification of an architecture, named BlockFlow, that provides trust for distributed provenance data.</p>"
6312;en_US;"<p>Binning consists of grouping DNA sequences according to taxonomic units, widely used in the Metagenomics, field that studies the genome of communities of microorganisms. New tool are developed for metagenomic pipelines, necessitating the establishment of paradigms in this type of analysis through the verification of the performance of assembly and binning tool. For the comparative tests of this work, data sets of 10 and 100 species of bacteria were used, as well as 3 assembly software: IDBA_UD, Megahit and MetasSPAdes, and 2 binning software: MetaBAT-2.12.1 and MaxBin-2.2.4. We verified that MetaBAT exceeded MaxBin in the quality of the generated bins.</p>"
6314;en_US;"<p>Textual data source may assist in the detection of adverse events not predicted for a particular drug. However, given the amount of information avail- able in several source, it is reasonable to adopt a computational approach to analyze these source to search for adverse events. In this scenario, we created an extension of CoreNLP to process Brazilian Portuguese text from pharma- covigilance area. We trained three natural language model: a Part-of-speech tagger, a parser and a Named Entity Recognizer. Preliminary result indicate success in generating a dependency tree for phrases in the pharmacovigilance area and in identifying pharmacovigilance named entities.</p>"
6315;en_US;"<p>Given the current context of increasing data production and strong potential for value creation in health through the exploration and analysis of data, this paper presents a framework designed with the objective of facilitating the implementation of software for analysis of large data volume and thus promote e-science in health. The general functioning of the framework is presented and technologies for its implementation are mentioned. However, it is worth mentioning that, for wide use of the framework, cooperation and data sharing initiatives between health system are necessary.</p>"
6316;en_US;"Deep learning model expect a reasonable amount of training in- stances to improve prediction quality. Moreover, in classification problem, the occurrence of an unbalanced distribution may lead to a biased model. In this paper, we investigate the problem of species classification from plant image, where some species have very few image sample. We explore reduced versions of imagenet Neural Network winners architecture to filter the space of candi- date matches, under a target accuracy level. We show through experimental result using real unbalanced plant image dataset that our approach can lead to classifications within the 5 best positions with high probability."
6317;en_US;"Severity scores provide a consolidated index of the patient’s health status in the ICU. These scores are based on linear model and analysis of each single variable in isolation. Data mining technique have been applied to generate more complex predicion model for prediction, but did not deepen in the analysis of class imbalance and treatment of missing data. This work analyzed technique for class balancing and imputation of missing values, together with Random Forest (RF), Artiﬁcial Neural network (RNA) and Logistic Regression (RL) classiﬁcation model. As a result the RF obtained the best performance with the mean AUC of 0.784±0.006, sensitivity of 0.738±0.002 and speciﬁcity of 0.700±0.003 with missing values replaced by default values and trained with the base with NCL undersampling."
6318;en_US;"Malaria is an infectious disease that mainly affects the Legal Ama- zon. dataUS includes the Malaria Epidemiological Surveillance Information System. Monitoring this dataset and integrating it with additional data source, as well as performing proper data preprocessing is crucial to understand the phenomena behind the occurrence and medical care. Therefore, in this paper we make use of the Data Science Platform Applied to Health (PCDaS) as an enabling tool to analyze the evolution of malaria in the Legal Amazon. From its use, we raised research questions that can help in understanding and controlling this disease in Brazil."
6319;en_US;"This study presents a proposal for modeling regulatory network ba- sed on public biological data from three classes of regulatory elements (ncRNAs) such as miRNAs, circRNAs and piRNAs and their relations (regulation and ori- gin) with genes. The integrated network and its association with clinically rele- vant biological data allowed the discovery of potential candidate genes related to complex disease. According to this network’s centrality and neighborhood overlap, we identified novel potential genes and ncRNAs that could act as bio- markers of complex disease considered major public health issues."
6320;en_US;"Several existing workflows require many computational resource because they process a large amount of data. Thus, High Performance Processing (PAD) en- vironments must be applied in conjunction with parallelization technique to support their execution. Although PAD environments offer several advantages, failures are a reality, not a possibility, due to the large number of computing node involved in the execution of the workflow. Verifying workflow failures is a challenge that still requires effort. In this paper we propose the use of DS 3 , a dynamic logic taiored to reason about stochastic Petri nets, to verify and predict failures in workflows."
6321;en_US;"Scientific system focused on workflows have several pros and cons and share several characteristics such as the need to provide support for scientists to analyze data. Data provenance can play an important role in providing the information needed in different experimental steps. This way, the present paper aims to map and characterize four provenance ontology, analyzing factors such as adequacy, execution requirement and architecture. After the study, it was realized that provenance methodologies can be applied at different stages of the scientific workflow life cycle, but mainly in the analysis phase."
6322;en_US;"Missing data is a common problem in the world of data analysis. They appear in dataset due to a multitude of reasons, from data integration to poor data input. When faced with the problem, the analyst must decide what to do with the missing data since its not always advisable to discard these values from your analysis. On this paper we shall discuss a method that takes into account information theory and functional dependencies to best imput missing values."
6323;en_US;"In scientific collaboration, the data sharing, the exchange of ideas and result is crucial to promote knowledge and accelerate the development of science. Trust is extremely important in this context as well as reproducibility. Although in scientific workflow the provenance has been the basis for reproducibility, in collaborative environments it is necessary to ensure integrity and trustworthiness of this provenance data. One of the technologies that have emerged and can help to address these issues is blockchain. A blockchain-based provenance system for collaborative scientific experiment could lead to a trustworthy environment for scientific experimentation. In this vein, this paper presents the specification of an architecture, named BlockFlow, that provides trust for distributed provenance data."
6324;en_US;"Binning consists of grouping DNA sequences according to taxonomic units, widely used in the Metagenomics, field that studies the genome of communities of microorganisms. New tool are developed for metagenomic pipelines, necessitating the establishment of paradigms in this type of analysis through the verification of the performance of assembly and binning tool. For the comparative tests of this work, data sets of 10 and 100 species of bacteria were used, as well as 3 assembly software: IDBA_UD, Megahit and MetasSPAdes, and 2 binning software: MetaBAT-2.12.1 and MaxBin-2.2.4. We verified that MetaBAT exceeded MaxBin in the quality of the generated bins."
6326;en_US;"Textual data source may assist in the detection of adverse events not predicted for a particular drug. However, given the amount of information avail- able in several source, it is reasonable to adopt a computational approach to analyze these source to search for adverse events. In this scenario, we created an extension of CoreNLP to process Brazilian Portuguese text from pharma- covigilance area. We trained three natural language model: a Part-of-speech tagger, a parser and a Named Entity Recognizer. Preliminary result indicate success in generating a dependency tree for phrases in the pharmacovigilance area and in identifying pharmacovigilance named entities."
6327;en_US;"Given the current context of increasing data production and strong potential for value creation in health through the exploration and analysis of data, this paper presents a framework designed with the objective of facilitating the implementation of software for analysis of large data volume and thus promote e-science in health. The general functioning of the framework is presented and technologies for its implementation are mentioned. However, it is worth mentioning that, for wide use of the framework, cooperation and data sharing initiatives between health system are necessary."
6328;en_US;"<p>Diabetic Retinopathy is the leading cause of blindness in working- age adults. This work aims at enhancing lesion detection, reinforcing referral decisions, and integrating our solutions with low-cost retinal imaging device. For lesion detection, we proposed a novel coding technique robust to any kind oflesion. For referral decisions, we designed a robust method that does not rely upon lesion detection, proposed an effective data-driven model that significantly improves the performance, designed an accountable model that produces a re- liable response and enables pixel-based importance comprehension, and create local descriptors that are encoded into a rich mid-level representation. Our work has invaluable impacts both in biomedical and technical context.</p>"
6329;en_US;"<p>Learning to Rank (L2R) is one of the main research lines in Information Retrieval. Risk-sensitive L2R is a sub-area of L2R that tries to learn model that are good on average while at the same time reduce the risk of performing poorly in a few but important query (e.g., medical or legal query). One way of reducing risk in learned model is by selecting and removing noisy, redundant or feature that promote some query in detriment of others. This is exacerbated by learning method that usually maximize an average metric (e.g., mean average precision (MAP) or Normalized Discounted Cumulative Gain (NDCG)). However, historically feature selection (FS) method have focused only on effectiveness and feature reduction as the main objectives. Accordingly, in this work we propose to evaluate FS for L2R with an additional objective in mind, namely risk-sensitiveness. We present novel single and multi-objective criteria to optimize feature reduction, effectiveness and risk-sensitiveness, all at the same time. We also introduce a new methodology to explore the search space, suggesting effective and efficient extensions of a well-known Evolutionary Algorithm (SPEA2) for FS applied to L2R. Our experiment show that explicitly including risk as an objective criterion is crucial to achieve more effective and risk-sensitive performance. We also provide a thorough analysis of our methodology and experimental result.</p>"
6330;en_US;"<p>Existing machine learning solutions for network-based intrusion detection cannot maintain their reliability over time in production environments. In such context, detection schemes must be able to detect intrusion attempts at a high network bandwidth, besides having to deal with the lack of realistic training/testing data, changes in network traffic behavior, unreliable classifications over time and adversarial settings. In this work a new intrusion detection model, namely reliable intrusion detection, is introduced, whose main characteristic is the usage of both batch and stream learning algorithm coupled together. The proposed model advances the state- of-the-art in intrusion detection, providing reliable detection even in the presence of network traffic behavior changes and lack of model updates. The work relevance was recognized in the publication of 5 international top-tier journals, 6 international and national conference paper, and 1 registered patent.</p>"
6331;en_US;"<p>We present a novel recolouring procedure for graph edge-colouring. We show that all graph whose vertices have local degree sum not too large can be optimally edge-coloured in polynomial time. We also show that the set ofthe graph satisfying this condition includes almost every graph (under the uniform distribution). We present further result on edge-colouring join graph, chordal graph, circular-arc graph, and complementary prisms, whose proofs yield polynomial-time algorithm. Our result contribute towards settling the Over- full Conjecture, the main open conjecture on edge-colouring simple graph. Fi- nally, we also present some result on total colouring.</p>"
6332;en_US;"<p>Traffic congestions present a major challenge in large city. Consid- ering the distributed, self-interested nature oftraffic we tackle congestions using multiagent reinforcement learning (MARL). In this thesis, we advance the state- of-the-art by delivering the first MARL convergence guarantees in congestion- like problem. We introduce an algorithm through which drivers can learn opti- mal routes by locally estimating the regret associated with their decisions, which we prove to converge to an equilibrium. In order to mitigate the effects ofselfish- ness, we also devise a decentralised tolling scheme, which we prove to minimise traffic congestion levels. Our theoretical result are supported by an extensive empirical evaluation on realistic traffic network. 1.</p>"
6333;en_US;"<p>The minimum labeling spanning tree problem (MLSTP) is a combinatorial optimization problem that consists in finding a spanning tree in a simple edge-labeled graph, i.e., a graph in which each edge has one label associated, by using a minimum number of labels. It is an NP-hard problem that has attracted substantial research attention in recent years. In its turn, the generalized minimum labeling spanning tree problem (GMLSTP) is a generalization of the MLSTP that allows the situation in which multiple labels can be assigned to an edge. Both problem have several practical application in important area such as computer network design, multimodal transportation network design, and data compression. The thesis addresses several connectivity problem defined over edge-labeled graph, in special the minimum labeling spanning tree problem and its generalized version. The contributions in the work can be classified between theoretical and practical. On the theoretical side, it has introduced new useful concepts, definitions, properties and theorems regarding edge-labeled graph, as well as a polyhedral study on the GMLSTP. On the practical side, we have proposed new heuristics and new mathematical formulations and branch-and-cut algorithm. The new approaches introduced have achieved the best result for both heuristic and exact method in comparison with the state-of-the-art.</p>"
6334;en_US;"<p>Shared system have contributed to the popularity ofmany technolo- gies. However, these system often confront a common challenge: to ensure that resource are fairly divided without compromising utilization efficiency. In this master’s thesis we look at this problem in two distinct system—software mid- dleboxes and datacenter task schedulers. We first present Sprayer, a system that uses packet spraying to load balance packets to cores in software middleboxes. Our design eliminates the imbalance problem of per-flow solutions and ad- dresses the new challenges ofhandling shared flow states that come with packet spraying. Then, we present Stateful Dominant Resource Fairness (SDRF), a task scheduling policy for datacenters that looks at past allocations and en- forces fairness in the long run. SDRF reduces user’ waiting time on average and improves fairness by increasing the number of completed tasks for user with lower demands, with small impact on high-demand user</p>"
6335;en_US;"<p>Network virtualization is a technique that allows the emulation of multiple virtual network (VNs) together on the same physical network structure (SN). This technique induces benefits inherent to freedom of network protocol rigidity, in addition, promote the new web technologies development. Define which physical device set will host the virtual network is a problem belongs to the NP-hard class and known as Virtual Network Embedding (VNE). Unlike the current literature, this work was singled out because it presented different exact and heuristic approaches for the resolution of VNE, operating in environments composed of one or more network domains. Moreover, the approaches developed can serve the different VNs demands characteristics, working on online, periodic and offline processing model. Beyond that, was introduced the application of the heuristic approach in an online and multidomain context, through the control of a network orchestrator. A comparative study of three distinct orchestration model was made, with: (i) total knowledge, (ii) partial knowledge and (iii) without knowledge of the internal physical network infrastructure of the domains. At the end of the paper, the different proposed approaches behaviors were contrasted and discussed using four different objectives: (i) load balancing, (ii) energy consumption, (iii) service provider profit, and (iv) message exchanged between different domains.</p>"
6336;en_US;"<p>This paper is a summary of the dissertation with the same title. In the dissertation we study the complexity of computational problem that are candidates for NP-intermediate status. In this process, we connect the comple- xity class SZK, related to zero-knowledge proofs, to the computational problem MKTP, related to algorithmic information theory. As original contributions, we highlight randomized reductions from the HIDDEN SUBGROUP PROBLEM (HSP) and other problem in computational group theory to MKTP, and statis- tical zero-knowledge proofs for decisions versions ofHSP</p>"
6337;en_US;"<p>Finding a genome rearrangements sequence capable oftransforming one genome into another can be very useful in comparative genomics. Depen- ding on the scenario in which we come across, the characteristics sought for this genome rearrangements sequence may be different. In this dissertation, we work with genomes in which the orientation ofgenes is known and we conside- red the reversal and transposition rearrangement events. We address the clas- sical problem in which both events affect the genome with the same frequency. In addition, we investigated a version ofthe problem in which the events occur with a different frequency. Resumo.</p>"
6338;en_US;"<p>Several device have allowed the acquisition and editing ofvideo in various circumstances, such as digital cameras, smartphone and other mobile device. However, the use ofcameras under adverse conditions usually result in non-precise motion and occurrence of shaking, which may compromise the stability of the obtained video. To overcome such problem, digital stabiliza- tion aims to correct camera motion oscillations that occur in the acquisition process, particularly when the cameras are mobile and handled in adverse con- ditions, through software technique, without the use of specific hardware, to enhance visual quality either with the intention of enhancing human percep- tion or improving final application, such as detection and tracking of objects. This is important in order to avoid hardware cost and indispensable for video already recorded. This work proposed three method to perform digital video stabilization and two other technique to evaluate video stabilization quality. 1.</p>"
6339;en_US;"<p>We introduce a new covering problem, called Component Cover by Vertices (CCV). In this problem, we are given a graph G and a partition A,B ofV(G), and our goal is to find the smallest subset B? ofB such that, for every connected component C ofG[A], there is a vertex v ∈ C with some neighbor in B?. We study the complexity of this problem and give positive and negative result. We show that the CCV problem is NP-Complete in several classes of graph. We also show that the problem is hard to approximate and parame- terize. On the other hand, we present polynomial algorithm for other classes of graph. Finnaly, we show FPT parameterizations and approximation algo- rithms for certain classes ofgraph. Resumo.</p>"
6340;en_US;"<p>Mirtrons arise from short introns with atypical cleavage by using the splicing mechanism. In the current literature, there is no repository centralizing and organizing the data available to the public. To fill this gap, we developed mirtronDB, the first knowledge database dedicated to mirtron, and it is available at http://mirtrondb.cp.utfpr.edu.br/. MirtronDB currently contains a total of 1,407 mirtron precursors and 2,426 mirtron mature sequences in 18 species. MirtronDB is a specialized resource that provides free and user- friendly access to knowledge on mirtron data; it is useful to explore mirtrons and their regulations. This pape was based the original publicaion in Bioinformatics IF: 5.481 (https://doi.org/10.1093/bioinformatics/btz153).</p>"
6341;en_US;"<p>This dissertation investigates the use of Virtual Reality for the exploration of multidimensional data represented as 3D scatterplots. After an initial user study indicated that an immersive environment required less effort to find information and less navigation, but resulted in inefficient times and frequent user discomfort, we proposed and evaluated an alternative data exploration approach based on the use of physical movements, direct interaction with data at arms reach and a virtual reproduction of the analysts work desk. Through a second study, we demonstrate that this setup, named VirtualDesk, presents excellent result regarding user comfort, and performs equally or better in all tasks, while adding minimal or no time overhead and amplifying data exploration.</p>"
6342;en_US;"<p>The goal ofagrarian reform project is the redistribution offarmland from large latifundia to smaller, often family farmers. One ofthe main problem the Brazilian National Institute ofColonization and Agrarian Reform (INCRA) has to solve is to subdivide a large parcel ofland into smaller lots that are balan- ced with respect to certain attributes. This problem is difficult since it considers several constraints originating from legislation as well as ethical considerati- ons. Current solutions are computer-assisted, but manual, time-consuming and error-prone, leading to rectangular lots ofsimilar area which are uneven with respect to soil aptitude and access to hydric resource. In this thesis, we propose a genetic algorithm to produce fair land subdivisions automatically. We pre- sent a greedy randomized constructive heuristic based on location-allocation to generate initial solutions, as well as mutation and recombination operators that consider characteristics of the problem. experiment on real-world and artificial instances confirm the effectiveness of the different components of our method, and show that it leads to more fair solutions than those currently ap- plied in practice.</p>"
6343;en_US;"<p>Given a simple graph G, an ordered pair (π, cπ) is said to be a gap- [k]-edge-labelling (resp. gap-[k]-vertex-labelling) ofG ifπ is an edge-labelling (vertex-labelling) on the set {1, . . . , k}, and cπ is a proper vertex-colouring such that every vertex of degree at least two has its colour induced by the largest difference among the labels of its incident edges (neighbours). The decision problem associated with these labellings are NP-complete for k ≥ 3, and even when k = 2 for some classes of graph. This thesis presents a study of the computational complexity of these problem, structural properties for certain families of graph and several labelling algorithm and technique. First, we present an NP-completeness result for the family of subcubic bipartite graph. Second, we present polynomial-time algorithm for families ofgraph. Third, we introduce a new parameter associated with gap-[k]-vertex-labellings ofgraph.</p>"
6344;en_US;"Studies show that every year the number of accidents and medical care expenses increase due to the work accident. In the context of transporting objects, many activity are still carried out by human labor which in many ca- ses may be subject to disasters due to the high number of hours worked or due to unhealthy activity. Taking into account the presented scenario, this work aims to introduce the robot ROBTK an intelligent robot to transport objects. We developed robot intelligence building a convolutional neural network (CNN) to perform object classification. The tests performed showed that both the intelli- gence and the mechanics designed are efficient."
6345;en_US;"Computer programming is a complex activity, student entering computer course show difficulty during the programming learning process, this difficulty is even greater for student with special needs. In these cases, alternative teaching methodologies, such as image-based teaching materials, achieve better result. In this context, we propose the development of software called Visual Programmer. It allows the student constructs the source code of a simple application based on a symbolic language, where the symbols represent the C language commands."
6346;en_US;"This article presents the development of a mobile application for au- tomated generation of desktop RPG adventures with the option of inserting di- dactic subjects to the story. The aim is to use the technological tool only to start the game that will have the physical presence of the players in the same environment, favoring the socialization and the desvirtualization of human re- lations. The developed application allows besides the automatic generation of adventures also the storage and sharing of these with other user."
6347;en_US;"Access to public information is essential for the sake of transparency on governmental actions. Budgetary transparency is a key factor to better mo- nitor public expenditure and this kind of information improves the knowledge and participation of the Brazilian population [Beluzo and Craveiro 2014]. In Brazil, laws have been defined that require the publication of public expendi- ture in transparency portals, allowing the emergence of civil application that facilitate the access to government’s budget data. This study addresses the diffi- culties identified by using a transparency portal to build a data warehouse, such as: the manipulation of open data, the lack of metadata and the semantic loss of the Entity-Relationship model in the data schema."
6349;en_US;"Since the Industrial Revolution, the planet has been suffering drastically with the population neglect, especially with regard to the environment. Reflecting on the fierce dispute that the society has been blocking with the growth of the amount of garbage, we identified the problematic of the incorrect disposal and waste of the organic residues. In view of this we intend to develop a web platform and a smart bin that can establish a communication between who owns the organic waste, a compost or biogas plant and who wants to buy the fertilizer. To achieve this general goal, we will organize the methodological strategies of this research in the following specific steps: first develop the web platform and then develop the recycle bin establishing communication between them. As justification, we realize the importance of developing this work for the management of organic waste and for the technology to be used in favor of the collective. In conclusive terms, this research aims to generate a web platform and a user-friendly intelligent bin capable of managing the waste of organic waste and contributing to technological and environmental advancement."
6350;en_US;"T his paper aims to present a way to increase awareness among children from 2nd to 5th grade about environmental pollution and its impacts, besides showing solutions that may be used to fight against some kinds of pollution. This can be achieved through U.M.E. a digital and interactive game that will help the child to understand the environmental problem arising from human attitudes, showing dialog boxes as a way of communication. The game has as main character a droid, who is responsible for alerting about the actions of environmental degradation and how to preserve it."
6351;en_US;"The use of Learning Objects (OAs) in teaching and learning proces- ses has been widely advocated in literature, and this work aims to quantify their effectiveness in the context of preparation for entrance exams. The unique cha- racteristics of this type of exam demand a more directed teaching process and, therefore, conducive to a quantitative investigation. Thus, the Educare web sys- tem was developed to support the proposed research, using as a case study the Portuguese language subject of the selective admission process for the integra- ted technical course from campus Charqueadas of IFSUL."
6352;en_US;"With complex and extensive syntax, programming has always been a great challenge in course involving computer science. The Aprenda Scratch was developed in 2015 to try to make the learning process of programming easer. It is a web education software that helps student use Scratch independently. The software was used by 298 student of the Technical Course in Informatics at a Distance from Ifes. The experience proved to be quite successful: 90% stated that the Learning Scratch has facilitated the understanding of programming language concepts, while 89% considered that the experience served to build a basis for learning more complex language."
6354;en_US;"The information is generated by thousands of people around the world every second on several device available in the world. As a result of a conversation with ACOPASB members in the city of São Borja, a large amount of abandoned animals were found on the streets of the city and a large amount of animals were available for adoption. It has also been noted that people use social network to search for animals for adoption or to inform others of lost and / or abandoned animals. Due to these problem, the present work proposes the development of an information system that will manage animals for adoption in the city of São Borja."
6357;en_US;"<p>Role-based access control (RBAC) is a NlST standard that establishes a generalized solution for the access control problem in information system (TS). This work presents and discusses how to use MACA (contextual authorization model) to administer access control policies for RBAC in large organization. MACA supports decentralized and autonomous policies as well centralized ones or a mix of both.</p>"
6358;en_US;"<p>This article proposes an architecture for distributing and managing the digital contents, combining traditional access control and Digital Rights Management (DRM) aspects, which executes the content usage control. The architecture defines security policies to establish access rights to protected content and to establish licenses to control the use of digital contents at the client side. This work also defines model for the authorization and rights distribution entity and for the license creation, distribution and management entity. Prototypes are implemented using XML-based technologies, which facilitates the integration of different modules of the architecture.</p>"
6359;en_US;"<p>When developing large system, besides the usual care that needs to be taken with analysis, design and implementation, special care with requirement elicitation is needed, as they are prone to possible changes before the delivery of the final system. In this paper we suggest an adaptatton of the RUI' process to solve this problem, promoting the incremental development of subsystem. As each subsystem is deployed, risks are mitigated, process efficiency is enhanced through the reuse of the acquired knowledge and produced artifacts, as well as allowing the customer to see the result of his investments before the conclusion of the whole project.</p>"
6360;en_US;"<p>Information technology has clearly incremented the number of people interacting with computer through user interface (UI). Besides, there is a lack of concern regarding the User Interface design in the main software development methodology. This document describes a process for the UI, which is integrated with the Microsoft Solution Framework: It also defines workers, activity and involved artifacts.</p>"
6361;en_US;"<p>This paper presents the experience of the Nucleus of Artificial Intelligence of the Banco do Brasil in the development of a solution for the problem of prevention of frauds in credit card through a tool set combined to subsidize business analysts decision. The solution uses Bayesianas network model and architecture multi-platform.</p>"
6362;en_US;"<p>The paper presents a decision support system (DSS) for recyclable waste collection planning. The computer system has the following objectives: (a) to define the vehicles allocation and routing; (b) to determine the quantity of solid waste to be sent to each waste recyclable trial unit; and (c) to generate operational scenarios to be taken into account in the decision process. To accomplish such objectives the decision support system employs two well-known operations research technique, namely simulation, and assignment/VRP algorithm. The DSS was implemented in Borland Delphi, using the commercial package Arena 3.5 to carry out the simulation. The system was validated using a field test in one city of Rio Grande do Sul.</p>"
6363;en_US;"<p>Nowadays, it is very easy to publish document in the Internet. Thus, a large number of document become available every dav, making the management and manipulation of these document progressively more difficult. Moreover, the existence of several incompatible formats makes the development of efficient tool to deal with such document a very complex task. This paper proposes a semantic restructure framework for the conversion of document to XML, to make it possible the consistent use of query and transformation language.</p>"
6364;en_US;"<p>The customization process of the integrated system management, denominatedERP system, is realized in the organization during the system implemenlation phase and its considered as a traumatic phase almost all the time, when you can observe the same problem frequently founded in the software development. Based in a customization process analysis in comparison with the software maintenance process, the experiences and researches made before in the second topic were used to improve the first one. In these researches, taking as bases the ABNT 1S0/1EC12207 rule, which treats the software life cycle process, a formal process of ERP system customization will be proposed.</p>"
6365;en_US;"<p>Wallet of Work and Social Welfare comes today as the only document that possesses information on the worker, such as, local where worked, functions that carried out and another. However, for being a small paper block, these data are incomplete and there is lack of more information. This appears as a great problem for the company, because they need the maximum of possible information to hire a person. The objective of this paper is to present the construction of software Wallet of Work On-Line that will solve these problem. It will be benefited to employees as the company. The first ones won't take the risk of losing theirs data due to some fatality with the document. The company will have easier and reliable way to know information on futures employees.</p>"
6366;en_US;"<p>The primary objective of this paper is to bring the strategy and the managemenl model of a project under development funded by the CT-ENERG/FINEP. The projet enrolls seven Electric Power company located in the States of RS, SC and MS. lts objetive is to make available through a information system (IS) based on the web informations about lightning and severe thunderstorms. The lS will be devoloped by the IGTl team from UFSC. The collected and preprocessed data by the sensor will be sent to Epagri that will be the reponsible for the generation of the meteorological analyses and reports. The post processed informations wlll be available to company involved in the project and to the civil and aviation authorities.</p>"
6367;en_US;"<p>Web Usage Mining (WUM) aims to discover navigation pattern from the analysis of logs in Web servers. The present work describes the functionalities and implementation of WebPath, a support tool for the discovery of sequential navigation pattern. The striking feature are the directed search for pattern based on user-specified criteria; as well as the visualization functionality for pattern interpretation. Preliminary tests disclose a good performance of the implemented algorithm.</p>"
6368;en_US;"<p>This paper presents a recommender system to support collaboration among people. The system provides a private chat room, where people can exchange textual message. Analyzing the message, the system discovers the themes discussed and then it can help people by recommending complementary knowledge source. Furthermore, chat sessions are stored and can be retrieved later, so that people can review decisions process or learn from past discussions. Statistical analyses of the sessions can reveal important knowledge about the discussions.</p>"
6369;en_US;"<p>This paper presents OCCOM, a Java component for the task of mining outliers in a multidimensional and multi-granular data warehouse. OCCOM explores the synergie integration of OLAP and data mining and is based and extends previous theoretical work that mathematically defines the concept of outlier in a data warehouse.</p>"
6370;en_US;"<p>This paper presents a software system that automatically identifies expertise in personal curriculums, stored in the Lattes format. The identification is made through the extraction of textual information from XML structures used in the Lattes format. Text mining technique are used to classify the text according to themes defined in a domain ontology. This process allows identifying user expertise, that is, competences and area of interest. Since curriculums in Lattes format are structured by sections (publications, experience, project, etc), it is possible to identify different area in different fields of action.</p>"
6371;en_US;"<p>The new times have generated, by society, new demands and expectations related to administration way and performance of the public organization. The knowledge generated and used by these organization is that provide to capacity of change and innovation capable to answer these expectations. This paper presents the prototype of a portal of the knowledge to be used in the Federal Revenue and Customs Secretariat (SRF) in PR and SC, that assist in the efficient knowledge management of its employees, improving the work process of TI support, preventing the loss of valuable knowledge and integrating the already existing knowledge bases, adjusting it to the new times and administration way.</p>"
6372;en_US;"<p>The organization has been searching productivity and profitability into current competitive environment with news organization model and technology. But the human resource conjugated with the competence politics are becoming the differential more important for the organization The objective of this article is propose a new role of system developers which should facilitate and stimulate the emergence of user competencies into organization during technological development. This way, the professional valorization for workers and the improvement of productive performance for organization are becoming common objectives.</p>"
6373;en_US;"<p>The objective of this article is to propose a classification model of the levels of dispersion of stakeholders involved in distributed software development project. For this, some criteria are proposed for the definition of dispersion levels. The proposed classification model is part of a master dissertation and was applied in two case studies, the result of which are presented and discussed. These case studies comprise a multinational organization that develops project with teams distributed in several countries on more than one continent. This research is characterized as exploratory, with case study as the main research method. As a result, the proposed model is presented, discussing its advantages and its representation.</p>"
6374;en_US;"<p>This article is related to distributed development of components for pervasive application. lt shows how the software components can add functionalities to mobile device (such as cell phones, handhelds, and a few others), as well as the impact that these types of aggregations have on the distributed development process. This work presents a case study in which a distributed process was used to build up an application.</p>"
6375;en_US;"<p>The distributed software development has different forms, each one generating benefits, problem, and solutions. This paper proposes an abstraction of the distributed software development into a set of characteristics, in order to highlight the differences of this kind of software development when considering the main problem pointed out by the current research. Three case studies discussing how these characteristics are differently instantiated in software development project are presented.</p>"
6376;en_US;"<p>Fusion and restructuring of enterprises may affect mainly their IT area. and a solution found by those company to not compromise application development and reduce costs is outsourcing. They usually manage this process based in their own experience because the existing model are not flexible enough to attend their dynamic. This paper has the aim of introducing MUDAS (Software Acquisition Unified Model), specific to software development outsourcing, attempting to conciliate the principles defined by SA-CMM and IEEE standards, RUP, besides concepts defined in the PMBOK and related to management project.</p>"
6377;en_US;"<p>The objective of this study is to present the implications in the model of management of project considered for the Project Management Institute (PMI) considering the performance in an environment of development of software physically distributed (EDSPD), having for base a model of management of project for this type of environment. The research is a qualitative study, aiming to develop new method and model. The result point to the extension of the process of management of the PMI, adapting the existing area already and considering new area toward the performance in this type of environment, adding new process of management. This study it presents resulted that they stgnificantly contribute in direction to currently take care of the existing demands in the business, mainly in that says respect to the area of software development, where the enterprise world and practical the business-oriented ones are walking very the existing front of the theories and conceptual model.</p>"
6378;en_US;"<p>This work proposes the use of Groupware, specifically Computer-Supported Collaborative Leaming (CSCL), to support to the implementation of information system in small company. A method based on this approach has been developed. A tool, BSCL, was used and submitted to experimentation on a commercial application, developed by a small software-house, in five company. The result obtained indicate a reduction in the average time of response, and in the volume of the requests to the technical support service, an indication of effectiveness in the process.</p>"
6379;en_US;"<p>It is proposed a model for analyzing qualitative data from lexical and content analysis technique and tool: while reading and analyzing, the researcher can see the result of his more or less objective analyzes taking shape, regulating , for that matter, its own protocol or analysis vocabulary. The proposed model integrates the best known technique, allowing the analyst to register the subjectivity of his perception and at the same time have a notion of the result of the analysis under way.</p>"
6380;en_US;"<p>The comprehension of the organization on different performance environments is important because this knowledge permit an evaluation and a better vision about it actions. The organization search model and technique to understand these environments. The construction of scenario is used to make a map the external and internal environment of the organization. The use of the scenario technique by organization permits to formulate of strategies and implement the actions minimizing uncertainties and risks. The aim of this paper is propose a process of scenario development and identifying the potential contributions this technique. This study is characterized as exploratory, since the main research method was the case study. A proposal of model of process for the scenario development is presented as result.</p>"
6381;en_US;"<p>This work aims to identify the charactertstics inherent to the process of information technology outsourcing via Data Centers (DCs). To do so, we revised national and international bibliographies, analyzed qualitatively the result of a field research encompassing 18 DCs, and undertook a case study of two corporate DC user. With reference to the contracts and service offered, we discovered that DCs user are getting increasingly more exacting to reduce costs and increase the efficiency of their business with quality, security, focus on core business and payment on demand. Furthermore, we discuss measures that should be taken into consideration when service are being contracted so as to ensure that profitable project do not turn into business failures.</p>"
6382;en_US;"<p>This paper presents the result of an investigation aimed to develop project management competencies. The methodology simulates situations that happen during information system implementation project. A/fer each simulation the participant identified attitudes, knowledges and skills to manage project. The methodology was applied in Computer Science and Information system undergraduate course. The result confirmed the methodology validity to develop project management competencies.</p>"
6383;en_US;"<p>This paper presents a computational environment for organizational modelling named RÉGULA. The approach is based on Business rule (BRs) in order to facilitate the alignment of the specification and development of information system to the needs of an organization. The discussion on RÉGULA emphasizes three points: the incorporation of the definition of objectives and goals to BRs, the guided definition of the business vocabulary with respective internal representation and the query to permissions, obligations and prohibitions. The solution to the second point enables the automatic generation of some of the Business rule classified as facts, while the third issue is illustrated by the query to permissions.</p>"
6384;en_US;"<p>The area of Information system suffers great impacts due to the decisions made by its strategists. This paper seeks to examine the main trends presented in research related to strategy and information system, using the classification proposed by Whittington (2001). Subsequently, the consequences of the application of each perspective in the formulation of strategies related to the area of information system will be analyzed. As a consequence of this classification will be proposed a more comprehensive meaning to the term strategic alignment between the business and the Information system department.</p>"
6385;en_US;"<p>Recognizing the importance of Information Technology (IT) in the organization scenario, regardless of size or branch of activity, this article presents the result of three studies that had as their central theme the use of IT in gaucho organization. a survey of the type of survey, applied separately (independently) in large company, small company and agricultural cooperatives in the State of Rio Grande do Sul. result are a characterization of these organization with the profile of the use of IT, Internet and perceptions changes in IT.</p>"
6386;en_US;"<p>The development of new technologies has been driving significant advances in computational architectures, thus reflecting massively heterogeneous and parallel mobile architectures. Effective use of processing units on mobile device, however, is still a challenge. In this work, we proposed ParallelUS, a parallel and distributed platform, that allows different mobile device to cooperatively execute the same application, through task offload. We evaluate ParallelUS through different scenarios and our result show that the proposed platform provides efficient resource for implementing and executing mobile application.</p>"
6387;en_US;"<p>This work presents a delay-tolerant sensor network model for environmental application where a data-aware drop strategy is applied to improve the phenomenon coverage. We design a model for application that monitor the forest temperature incidence for wildlife observation. The proposed solution modeling comprises of: (i) Phenomenon generation based on Gaussian random field; (ii) Sensing node with a mobile sink; (iii) Data processing based on a data-aware drop strategy; and (iv) Phenomenon reconstruction based on simple kriging interpolation. Besides the satisfactory application of our model, the result show that the performance of our strategy is approximately twice better than traditional ones.</p>"
6388;en_US;"<p>system-of-system (SoS) combine heterogeneous, independent system to offer complex functionalities for highly dynamic smart application. Due to their critical nature, SoS should be reliable and work without interruption that could cause serious losses. SoS architectural design can facilitate the prediction of the impact of failures due to SoS behavior. However, existing approaches do not support such evaluation. The main contribution of this paper is to present Dynamic-SoS, an approach to predict, at design time, the SoS architectural behavior at runtime to evaluate whether the SoS can sustain their operation. result of our multiple case studies reveal Dynamic-SoS is a promising approach that could contribute to the quality of SoS by reliably enabling prior assessment of their dynamic architecture.</p>"
6389;en_US;"<p>This work presents some outcomes of a theoretical investigation of incompressible high-order network defined by a generalized graph represen tation. We study some of their network topological properties and how these may be related to real world complex network. We show that these network have very short diameter, high k-connectivity, degrees of the order of half of the network size within a strong-asymptotically dominated standard deviation, and rigidity with respect to automorphisms. In addition, we demonstrate that incompressible dynamic (or dynamic multilayered) network have transtemporal (or crosslayer) edges and, thus, a snapshot-like representation of dynamic network is inaccurate for capturing the presence of such edges that compose underlying structures of some real-world network.</p>"
6390;en_US;"<p>Graph matching problem are well studied and bring great contributions to Graph Theory from both the theoretical and practical points of view. There are numerous studies for unrestricted and weighted/unweighted matchings. More recently, subgraph-restricted matchings have been proposed, which consider properties of the subgraph induced by the vertices of the matching. In this paper, we approach one of these new proposals, disconnected matching, which seeks to study maximum matching, such that the subgraph induced by the matching vertices is disconnected. We have described efficient algorithm to solve the problem for chordal graph and block graph based on a theoretical characterization.</p>"
6391;en_US;"<p>The Red-Blue Facility Location problem is a generalization of Facility Location where clients may have two types of demands and each open facility must provide for one of the types of demands. We present preliminary result for two special cases of this problem.</p>"
6392;en_US;"<p>A graph is (k, l) if its vertex set can be partitioned into k independent sets and l cliques. Deciding if a graph is (k, l) can be seen as a generalization of coloring, since deciding is a graph belongs to (k, 0) corresponds to deciding if a graph is k-colorable. A coloring is equitable if the cardinalities of the color classes differ by at most 1. In this paper, we generalize both the (k, l) and the equitable coloring problem, by showing that deciding whether a given graph can be equitably partitioned into k independent sets and l cliques is solvable in polynomial time if max(k, l) 2, and NP complete otherwise.</p>"
6393;en_US;"<p>In this paper we investigate the equitable coloring problem on unipolar graph, a superclass of split graph. In particular, we present an algorithm based on the maximum flow which solves our problem in polynomial time, generalizing the previously known result for split graph.</p>"
6394;en_US;"<p>We study the problem of performing data clustering in a distributed setting, which is a problem that may arise in many practical area such as machine learning and data analysis. The way in which the sites communicate and the way data is allocated define a model of communication. We develop a protocol to compute distributed clustering in the Number on Forehead model of communication complexity. In our model, we requiere that each site is aware of all cluster in its own data and all data allocated among sites define a sunflower. We show that there exists a two round communication protocol for data clustering where each site knows an to all cluster.</p>"
6395;en_US;"<p>The family of graph H,p has been defined in the context of edge partitions. The established properties such as vertex transitivity and low diameter suggest this family as a good topology for the design of interconnection network. The vertices of the graphH p are the tuples with values between 0 and p1, such that the sum of the values is a multiple of p, and there is an edge between two vertices, if the two corresponding tuples have two pairs of entries whose values differ by one unit. In order to work towards the diameter, the difference between an upper and a lower bounds is established to be at most and we present subfamilies of graph H p such that, for several values of and p, the bounds are tight.</p>"
6396;en_US;"<p>The class of k-thin graph have recently been introduced generalizing interval graph. The complexity of the recognition of k-thin is open, even for fixed k 1. We introduce a subclass of the k-thin graph, called precedence k-thin graph, presenting an efficient recognition algorithm based on PQ trees.</p>"
6398;en_US;"<p>Given a (vertex)-coloring C = C 1 , C 2 , ...C m of P a digraph D and a positive integer k, the k-norm of C is defined as C k = m i=1 min C i, k. A coloring C is k-optimal if its k-norm C k is minimum over all colorings. A (path) k-pack P k is a collection of at most k vertex-disjoint paths. A coloring C and a k-pack P k are orthogonal if each color class intersects as many paths as possible in P k , that is, if C i k, C i P j = 1 for every path P j P k , otherwise each vertex of C i lies in a different path of P k . In 1982, Berge conjectured that for every k-optimal coloring C there is a k-pack P k orthogonal to C. This conjecture is false for arbitrary digraph, having a counterexample with odd cycle. In this paper we prove this conjecture for bipartite digraph.</p>"
6399;en_US;"<p>In the Cable-Trench Problem (CTP), the objective is to find a rooted spanning tree of a weighted graph that minimizes the length of the tree, scaled by a non-negative factor , plus the sum of all shortest-path lengths from the root, scaled by another non-negative factor. This is an intermediate optimization problem between the Single-Destination Shortest Path Problem and the Minimum Spanning Tree Problem. In this extended abstract, we consider the Generalized CTP (GCTP), in which some vertices need not be connected to the root, but may serve as cost-saving merging points; this variant also generalizes the Steiner Tree Problem. We present an 8.599-approximation algorithm for GCTP. Before this paper, no constant approximation for the standard CTP was known.</p>"
6400;en_US;"<p>We investigate a packing problem where each item has a weight and is associated with one or more scenarios, and all containers have a fixed capacity. A packing is an assignment of item to bins in a manner that the total weight of the item allocated to a bin for the same scenario does not exceed the capacity of the bin. The objective of the problem is to find a packing of all item into the bins that minimizes the maximum number of bins used in any given scenario. We present an asymptotic approximation scheme when the number of scenarios is bounded by a constant.</p>"
6401;en_US;"<p>We study a model of society consisting of agent and a government interacting according to decisions regarding cost-effective punishment of crime. We evaluate different strategies for the government in order to reduce the criminal activity, considering degrees of honesty and a possible cost for monitoring and apprehension. We extend a previous model by introducing a contagion effect for the degrees of honesty, and study properties which may lead to a crime-free society, including a game-theoretic formulation.</p>"
6402;en_US;"<p>List coloring is a generalization of the classical vertex coloring problem in graph. Such a problem has some variations, among them the coloring. In this work, we show the reducibility of the list-coloring problem, coloring and pre-coloring extended, to better provide an analysis of coloring under the parameterized complexity, where it is FPT when parametrized by vertex cover and color lists. We also present the correctness proof of a polynomial algorithm for coloring, from the literature, in complete bipartite graph.</p>"
6403;en_US;"<p>For a nontrivial connected and simple graph G= (V(G), E(G)), a set S E(G) is called edge geodetic set of G if every edge of G it’s in S or is contained in a geodesic joining some pair of edges in S. The edge geodetic number eds(G) of G is the minimum order of its edge geodetic sets. We prove that it is NP-complete to decide for a given bipartiti graph G and a given integer k whether G has a edge geodetic set of cardinality at most k. A set M V(G) is called P3 set of G if all vertices of G have two neighbors in M. The P3 number of G is the minimum order of its P3 sets. We prove that it is NP-complete to decide for a given graph G(diamond,odd-hole) free and a given integer k whether G has a P3 set of cardinality at most k.</p>"
6404;en_US;"<p>A beginner programming discipline usually includes logic concepts and programming fundamentals, challenging both learners and teachers. Teaching, learning and evaluation process in programming have been the subject of several discussions in the literature. In addition to the technical aspects re- quired for programming learning, there are also social and human aspects that impact on learning, such as communication, motivation and profile. This article aims to analyze open answers obtained from the evaluation of teaching by student for programming classes in an undergraduate course. As a consequence of this analysis, a conceptual map was generated identifying large categories of student feedback.</p>"
6405;en_US;"<p>Software bots are becoming more and more popular, this is due to the fact that they are a tool that can be used in different context. With this, software developer has more interest in developing bots, however they may have to face challenges intrinsic to the development of bot software. With this, we seek to understand the profile of bot developers, what motivates them, or what challenges they face when dealing with bot development. To shed an initial light on this direction,we conducted a survey with 43 Github user who have been involved (showingtheir interest or actively contributing to) in bot software project.</p>"
6406;en_US;"<p>The high evasion rates demanded researches for understanding and mitigating the problem that lead to this phenomenon. Despite of the government programs trying to make education accessibility easier, such as REUNI, the enrollment cancellation rates are still growing, even in course with high job opportunities, such as Information system (IS). Thus, this work investiga- ted the evasion on human and social perspectives of a IS course at a federal university, implanted outside of the metropolitan context. A survey was applied with ex-student, obtaining 54 answers, which indicates that the lack of public and internal policies related to education fund support is one of the major evasion causes.</p>"
6407;en_US;"<p>A career in Software Engineering demands the development of several technical skills. However, these professionals also need to develop non-technical skills related to soft skills. Through an electronic survey, this research raised the importance of soft skills and which have the greatest impact on career development and daily activity, based on the perception of professionals in this area. The result showed that these professionals understand that soft skills have a high impact on the development of their careers and daily activity. However, there is no greater concern with their development when considering the sample of this research.</p>"
6408;en_US;"<p>The Software Product Strategy is concerned with the constraints and internal (business) and external (market) perspectives to the organization that should be considered in software product planning. Knowledge Management can be used in the design of a software product through socialization in which the tacit knowledge of the different stakeholders (partners, clients, sponsors, etc.) is accumulated and shared so that this knowledge is articulated in a product concept through externalization. This paper presents an overview about software product development strategies supported by knowledge management mechanism resulting from a systematic mapping of the literature.</p>"
6409;en_US;"<p>Several software application have been modifying the humans way of life in the technological and social aspects. A certain set of application supports the creation of Smart city (SM). Like any other type of application, they need an assessment in order to guarantee an adequate software quality level and to provide the best experience to user. However, application in the smart city context can include more technological characteristics than a traditional application, such as interoperability and context-changing according to the modification of the user environment. This paper presents a study with regard to two software quality characteristics for SM (context-awareness and calmness). Moreover, we present a discussion of such characteristics and their metrics in relation to human aspects of software application interaction.</p>"
6410;en_US;"<p>Context: The internalization of new members into software development teams causes changes in organization. Objective: To investigate the benefits and limitations of internalization in software development teams. Method: A qualitative study was carried out in a software development startup where internalization was observed recently. result: The data collected were analyzed using qualitative coding technique and the result were verified and validated with the participant through the verification of members. Conclusion: It was noticed that the internalization is strongly influenced by the companys culture and the reception and integration of the team.</p>"
6411;en_US;"<p>The management of people in the contemporary world has undergone several changes, from the technological advance that modifies the way of working of various positions, as well as the quick access to the information. In addition, there is the global competitiveness provided by the internet in search of new talents or experts in certain area of knowledge. That is, globalization can be understood as an economic and social process that established an integration between the countries and the people of the world. In this sense, the general objective of this research is to gather good practices that help reduce employee turnover in organization. In order to reach this objective, the methodology used in this research was a literature review in conjunction with a qualitative research with 46 managers belonging to 43 company embarked in Porto Digital. The collection instrument used was a semistructured online questionnaire with open and closed questions. Based on the result obtained from the participant, it is hoped to contribute to a better management of people within the organization by explaining the good practices on turnover recommended by the current research.</p>"
6412;en_US;"<p>The software development process is a complex activity that involves uncertainties and challenges. These uncertainties and challenges become more potent as we seek to build system and technologies for the third sector, an area that have different practices and values of business management. Currently, Information Technology (IT) field does not hold debates about the characteristics of the organization frequently. This article presents reflections on a construction in progress of a software used by social organization.</p>"
6413;en_US;"<p>This research seeks to make a study about the main aspects that influence the employability of a software engineer. After this stage a survey is carried out with the professionals of the area to ascertain the relevance of the difficulties raised. Knowledge gaps were in certain subjects regarding time of service and degree of schooling and optimism regarding the employable degree of obsolescence of professionals with a high degree of schooling.</p>"
6414;en_US;"Weather measurement system became an important tool for the ef- ficient operation of various economic activity. Automated irrigation system, that improve agricultural productivity and reduce the consumption of water resource, relies on data collected by these system, for example. Due to the inherent complexity of these system (i.e. stations with multiple sensor communicating through multiple communication channels to cloud service), it is very important to have measures that clarify how faults behave allowing better planning of maintenance and establish a degree of system reliability. This work presents a study of the availability of all meteorological stations of the National Institute of Meteorology-INMET installed in the Brazilian territory in the year 2017. The result present the first analysis of this parameter and serve both for academic and commercial user, as a form of measurement of these system reliability, as well as for weather measurement infrastructure provider as a tool for improving the effectiveness of their maintenance policy and as a support for the strategic planning of new investments."
6415;en_US;"Decision-making system, when conceived and implemented in a correct way, have a positive impact on the decision support process, in particular on the management of water resource. Business Intelligence-BI technology allows the adoption of a management process in which data from the operating system are extracted, transformed and loaded into the Datawarehouse, data cubes are created for analysis, and frontends implemented for performing the analysis in the form of charts, maps, tables and dashboards. This paper uses this important BI technology to implement a decision-making process for the control of water use. The decision support system that implements such a process is innovative and enables a more efficient and easier management of water resource."
6416;en_US;"<p>This article presents an architecture of a reduced-size greenhouse, so-called mini-greenhouse monitored via Internet of Things (IoT). For this purpose, a prototype has been built with support of a computational system installed in its interior. So, sensor are used for monitoring and control of the variables that most influence in the development of a vegetal species. This text gives a brief description of the germination factors related on the various possibilities of its use. The proposed system has a cloud-based storage and the effective contributions of the computer system are started from the web platform, transfer the set-points to the controllers, and upload data read from sensor to the same web page.</p>"
6417;en_US;"The benefits of photovoltaic system (PV) for the environment and the diversification of the energy matrix are notorious, but the harmful effects due to the intermittent nature of these system (power profile with high variations) can compromise the energy quality of the distribution network. The work aims at a PV power controller system based in fuzzy logic that smoothing the power profile exchanged with the grid and maintains the use battery in levels safe. A comparative simulation with another simpler proposal is performed to attest the gains of the fuzzy proposal to the problem in focus."
6418;en_US;"The collection of solid waste in the municipality of Cametá lacks efficiency. One of the main factors is the lack of planning by the municipal government that is not building efficient policies. In this sense, this work uses technological means to improve the quality of such service. It is proposed two pieces of software, i.e., one for tracking garbage trucks and other for community use. The usability of the tool was analyzed through controlled tests and validated using criteria consolidated in the literature."
6419;en_US;"Seasonal Black River floods  affects mainly the riverside population. In this work we present a methodology to predict the flood peak, using two types of predictors: Artificial Neural network (ANN) and Decision trees. For the training of the predictors, the variables were selected using a modified characteristic scalar selection technique. The data used corresponds to the period 1951-2017. For improving the neural network generalization, the technique of regularization L2 and early stop, associated with bootstrap were employed. For improving decision trees performance, committee-based learning method (boosting and bagging) was employed.  Additionally, this work proposes classifying the river floods into four ranges of values. The efficiency of the predictors was evaluated using the Pearson correlation coefficient and accuracy in range classification. The predictions were obtained with 4,3,2 months and 1 month before the occurrence of river peak level. The best accuracy obtained in range classification was 85,07%, for one month before the occurrence of peak level."
6420;en_US;"In order to identify the impacts of climatic variation on the aquatic life of the Central Amazon Basin, a new Long-Term Ecological Research Program: Varzea Diversity (PELD-DIVA) was proposed. This work presents e-DIVA computational infrastructure, which is a process of several ichthyological databases integration related to different research sites, besides offering a computational architecture for management and analysis of the data related to the Program."
6421;en_US;"Amazon forest’s vast biodiversity opens doors to many studies, including the use of computational method to analyze the fauna and flora. Checking the gap in the study of unconventional edible plants (UEPs) in the western region of Pará, in this work are used computer vision technique to automatically identify plants belonging to this category. For such a result, we evaluated the use of seven classifier for recognition in digital image of UEPs. The result showed good accuracy in the recognition of the classes on the test image. As a direct impact of the study, we highlight the possibility of developing a decision support application for automatic recognition of UEPs in order to be used by regulatory institutions."
6422;en_US;"Bees are the main pollinators of most wild and cultivated plant species, thus being essential for the maintenance of plant ecosystem and for food production. But they are threatened due to a serie of drivers such as pesticides, habitat loss and climate change. Here, we propose a method to iden- tify the loss of thermoregulation capacity in honeybee colonies. We applied the Long Short-Term Memory (LSTM) algorithm, which is based on Recurrent Neural network (RNN), to six real dataset of the Arnia remote hive monitoring system. From brood temperatures gathered along the European fall season in 2017, the LSTM was able to detect when a honeybee colony is about to lose its thermoregulation capacity. Our result showed an error of only 0.5% in predic- tion for well-thermoregulated beehives."
6423;en_US;"The present paper presents the study of the area of water resource management, Multi-Agent system (MAS) and Role Playing game (RPG), as well as the integration of these initial participatory management modelling of the actors involved in this case study. In this context, the ComMod approach was used considering the São Gonçalo and Mirim Lagoon basin. The modelling was performed using the integration diagram, which represents the general view of the problem, and the UML diagrams (class and sequence), which expose the formalization of actions and the interaction between the agent of the system. As a result, we obtained the agent actions and their interaction with the system. For future work, we intend to evaluate tool and develop the agent-based computational game."
6424;en_US;"This work presents an Adaptive Fisheries Monitoring Model that was evaluated by the method of clustering fishery data collected in 2016-2017 in the Araguaia-Tocantins basin. Data were obtained from the Integrated Fish Statistics System (SIEPE), which generated categorical and numerical variables. The analysis reveals the most significant numerical variables in the study were the fishing yield and engine power of the watercraft, while the most expressive categorical variables were popular species name and fishing environment. These variables should be taken into account in fisheries monitoring programs in the Araguaia-Tocantins basin, as well as the use of SIEPE to support fisheries management at different scales."
6425;en_US;"Incidents caused by precipitation (rains) such as flooding and landslides are recurrent in Brazilian city. Such events usually result in result in material damage and threaten the lives of people residing in an area of risk. Weather and climate information, when accessed and shared timely through efficient communication channels, can help good decision-making by public agent and the general population. In this scenario, this paper presents an experience report about the application of the HCD (Human-Centered Design) process for the development of a software solution based on the use and exchange of weather and climate information between the public organization and the population in the context of a Brazilian large city."
6426;en_US;"Identify the soil moisture and a determining factor to propitiate satis- factory conditions for the development of any vegetative vegetation system. An automated irrigation control system, based on the potential of ground water, is a tool that can optimize the use of natural resource in water. This article aims to present a prototype based on the Internet of Things (IoT) for the development of a tool to support systematic soil moisture monitoring of the vegetation of the Environmental Studies Unit (NEAMB), linked to the Biology Sciences course of the Federal University of Tocantins (UFT), Porto Nacional campus. The development of the prototype aims to offer a low cost automation for the irrigation process, above all, to provide a database with continuous information on the characteristics of the soil. was used in this work an ESP8266 microcontroller, together with sensor and actuators that allow to do both the control of the irrigation system and the real-time monitoring of soil moisture characteristics. The use of this tool broadens the horizons of the researches developed as researcher in the area can achieve a better understanding of the impacts of changes in soil moisture on the development of the vegetative system surveyed."
6427;en_US;"Weather conditions have a great impact on peoples lives. Public organization responsible for monitoring and disseminating weather and climate information often use technical language that can be confusing and lead to misunderstanding by non-specialist user. This paper seeks to mitigate this problem by applying a knowledge management approach called the KM Cycle to develop a solution to improve communication and dissemination of time information to ordinary people. As a result we developed a chatbot prototype integrated to different communication channels, such as Web Site and social network."
6428;en_US;"Efficient land uses are critical to many countries. The objective of this work is to model a Next Generation Agronomic System (NGAS) to Soil Sciences. We present and evaluate a service called OpenSoils Edu which is part of a NGAS focused on pedological data management. The application is capable of mapping large amounts of soil data and can be used by many types of user to view and share curated soils dataset."
6429;en_US;"The accumulation of garbage is a serious problem for the health of the population and the environment. In this way, the present work aims to verify the difficulties and needs of the subjects that are included in the recycling process, to develop a web application that promotes environmental education and allows the proper disposal of recyclable waste. From the result it was found that many people do not have the time to take the recyclable material to a recycling cooperative or they do not know the alternatives for disposal of the recyclable waste. In this sense, a web platform has been developed using the DAO and MVC standards, in which user can make and fulfill offers or requests for recyclable materials."
6430;en_US;"MASE, acronym for Multi-Agent System for Environmental Simula- tion, is a tool that was conceptualized for environmental simulation with anth- ropic exploration represented by BDI-cognitive agent. The current version is denominated MASE-BDI because of the cognition of their agent. MASE specia- lizes in Land Use Cover Change model, with spatially-explicit agent exploring the natural environment according user-determined rule. This article introdu- ces MASE-EGTI, a extension for MASE that presents social submodel based on Evolutionary Game Theory for spatial conflict resolution. The submodel not only represent social behavior, but also the environment exploratory profile of the agent. Equilibrium points of the strategies are elucidated in scenarios of physical space competition, and the simulation result are compared with the ones executed on MASE-BDI."
6431;en_US;"This article presents a web system integrated to a prototype electric energy meter for the monitoring of consumption in household appliances. Measurement data is collected and sent by communication network to the system, which provides the user with real-time information on consumption and charging, assisting him in making decisions about the use of electric power in his residence. Thus, this tool intends to assist the user for the conscious and sustainable use of electric energy."
6432;en_US;"This article proposes a Web application for the identification and cost determination of the documentation regarding environmental regulation in Minas Gerais. The process of obtaining a license comprises five stages: 1-characterization, 2-activity classification, 3-formalization, 4-analysis and 5-evaluation, observing that in stages 1 and 2 the human and financial resource required are significant and susceptible to errors. The application seeks to assist in the transparency and assertiveness of documentation required by law, minimizing classification errors and the resulting costs."
6433;en_US;"The mapping of vulnerable area needs updated data about the geological and structural situation in place. However, the existing process of data collection, storage, and data analysis are still not effective due to the lack of proper technological resource. This paper presents a software development project of a mobile app to support the establishment of susceptibility maps of geological risks. Preliminary result derived from an interactive research methodology provided evidence on the usefulness of mobile app by domain specialists."
6434;en_US;"SipamHidro is a system of Censipam that has a set of technologies to assist monitoring, analysis and prediction of spatial information on hydrological and meteorological conditions. One of its modules is the Meteorological Radar that provides information on different meteorological parameters. This work introduces it, integrating it to different layers of technologies, such as satellite image and atmospheric discharges."
6435;en_US;"Lightning is a natural phenomenon and presents severe risks to people and animals, as well as affects several segments of the productive sector. A web-based lightning monitoring system has been developed to integrate different lightning detection system, as well as to generate spatial and tabular data and products, capable of assisting specialists and decision makers. The system also allows combining lightning data with satellite image, increasing the capacity of analysis in near real time. This tool proved to be stable and efficient, with an intuitive interface that facilitates interaction with user."
6436;en_US;"dataUS (Information Technology Department of the SUS) provides information that supports objective analyzes of the Brazilian health situation, assisting in evidence-based decision making and elaboration of health action solutions. In order to access this information, it is necessary to use the tool provided by the dataUS portal that are very limited technically and complex. In the dataUS portal, this information is in .DBC files and encrypted by means of a private algorithm, making it difficult to interpret the information. This work presents a tool developed in JAVA with the purpose of treating the public data provided by dataUS and exporting them to a relational database in a simpler way. To this end, a tool was developed responsible for capturing, decrypting and exporting the information to a relational database."
6437;en_US;"The Brazilian Government adhered to the policy of publication of lin- ked open data, thus promoting a more transparent and open administration, allowing greater participation of society, strengthening democracy and comba- ting corruption. In order to do so, it is necessary to collect information from provenance to know, for example, when, how, and why the data were created and published. In this paper, a provenance data model for a connected open data architecture was defined. For validation of the proposal, a real use case scenario was described in which the provenance data model was used."
6438;en_US;"Society is influenced by new technologies, culminating in new ethical issues. How to enable data protection in an era in which algorithm use it for whatever the purpose it may have? The Brazilian government, motivated by this issue, sanctioned a comprehensive legislation for data protection. In its writing the concern for transparency is clear. Noting this, what will be the technological issues associated with transparency in a privacy law?"
6439;en_US;"<p>The aim of this paper is to present the methodology and the mechanism used by the Pro-Rectory of Information and Communication Management in order to comply with the transparency requirement of LAI, Federal Decree 7,724/2012 and other regulations that impose on federal agencies the obligation to disclose information of interest the society. In addition to promoting the opening of data at the Federal University of Pelotas, with efficiency and quality, the actions taken out have provided greater visibility of the administrative and academic activity of the Institution, resulting in a reduction of requests for access to information.</p>"
6440;en_US;"<p>There are different ways of encouraging scientific work. One of them is the research productivity grants given by CNPq. However, with the scarcity of resource, analyze the performance of researcher and select those who will receive the grants are becoming even more complex and challenging activity. Thus, this paper aims to build a classifier by using the Lattes Platform as a data source that can identify the grant level of a given researcher and help researcher to contextualize themselves in relation to other scholars, considering social network and bibliometric analyses.</p>"
6442;en_US;"Through online review, consumers can communicate with product suppliers and influence the buying decision of other consumers over the Internet. However, thanks to the high number of published review daily, it is difficult to identify which text to read. As a solution for that problem, some websites use a review evaluation system based on the user votes, which, while useful, is not always ideal. This paper proposes an automatic method to analyze the helpfulness of online user review from Steam using Multilayer Perceptron Artificial Neural Network. We found out that certain feature of review affect the perception of helpfulness and we discuss application and future researches."
6443;en_US;"This paper presents a resulting study of user data analysis in Instagram, identifying the different existing profiles. Instagram is an application for sharring photos and video that became popular in recent years and because of this, businesses are increasingly investing in dissemination of advertisement through it. This shows that brands are interested in disseminating their products in a relaxed atmosphere, so that their customers can have a closer relationship with the company. Thus, this research aims to characterize Instagram user, identifying and differentiating ordinary user from commercial ones. We leveraged our characterization study towards a classification approach able to differentiate these user with high accuracy."
6444;en_US;"In this paper we compare the graduate programs in Computer Science of levels 6 and 7 (which CAPES assume to be equivalent to the international best) and those programs best ranked in three international rankings. We used both bibliometric metrics and social network analysis and found out that there is a great difference between the result achieved by the national and international programs. The result from a principal component analysis show that the Brazilian programs are a class of their own and do not share the characteristics of the best international graduate programs."
6445;en_US;"The prediction of relationships in a social network is a complex and extremely useful task to enhance or maximize collaborations by indicating the most promising partnerships. In academic social network, prediction of relationships is typically used to try to identify potential partners in the development of a project and/or co-authors for publishing paper. This paper presents an approach to predict coauthorships combining artificial intelligence technique with the state-of-the-art metrics for link predicting in social network."
6446;en_US;"This paper first introduces technique for comparing conferences that use familiar similarity measures and a new measure based on co-authorship communities. Then, it focuses on two families of technique for conference recommendation, the first one based on the similarity measures and the second on the idea of finding the most related authors in the co-authorship network. The experiment suggest that the best performing technique are: the technique for comparing conferences that uses the new similarity measure based on co-authorship communities; and the conference recommendation technique that explores the most related authors in the co-authorship network."
6447;en_US;"Recommender system aims to help a user or groups of user in identifying the most relevant item based on their needs. The item may have different characteristics and can be service, products or miscellaneous information. With the growth of data amount, recommender system are being increasingly studied because it is increasingly difficult to find the desired information due to the available alternatives. This paper proposes and develop a model for a recommender system based on bipartite graph, formed by semantic information of user and item. This recommendation model was evaluated based on two Proof of Concepts (PoC)."
6448;en_US;"In order to capture the effects of social ties in knowledge diffusion, this paper examines the publication network that emerges from the collaboration of researcher, using citation information as means to estimate knowledge flow. For this purpose, we analyzed the paper published in the PLOS ONE journal finding strong evidence to support that the closer two authors are in the co-authorship network, the larger the probability that knowledge flow will occur between them. Moreover, we also found that when it comes to knowledge diffusion, strong co-authorship proximity is more determinant than geographic proximity."
6449;en_US;"The significant growth of the Web has made from it a rich source for the evaluate of public opinion on a specific entity. Consequently, the number of opinions available makes the decision-making process impossible if it was necessary to read and to analyse all review. This paper presents a Web application prototype where from a review are returned the feeling (positive, negative or neutral), its feature and other analysis metrics using Natural Language Processing and Sentiment Analysis. experiment show efficacy in the precision of review with negative polarity and recall of review with positive polarity in 84.93% and 94.33% respectively."
6451;en_US;"The goal of this work is to analyze two of the most central activity in the life of a congressman: raising funds and voting bills. We investigate the Brazilian Congress to shed light on the relationships between the donations received by congressmen elected in 2014 and their voting behaviors during the year of 2015. We merged publicly available data obtained from the Brazilian House of Representatives and the Superior Electoral Court (TSE) in order to create a tripartite network containing campaign donors, elected congressmen, and legal bills. Using this data, we create two projected network having congressmen as node and links given as follows: 1) congressmen who received donations from the same donors (donation network); and 2) congressmen who voted in accordance to each other on legal bills (voting network). After characterizing these network, we propose three fundamental questions on the behavior of congressmen that could benefit from the method and concepts provided by Network Science. Finally, we analyze the result and compare them to general domain knowledge."
6452;en_US;"The social network analysis area is on the rise. An important task in this area is link prediction, in which the goal is to predict connections between user. For this task it is necessary the use of attributes, method, algorithm and technique that measure, somehow, the possibility of a relationship be created. However, there are many approaches and combinations of attributes for predicting links. This paper aims to conduct a comprehensive survey of the attributes/characteristics that can be used to predict links in various context of social network, based on the Systematic Review methodology."
6453;en_US;"Web-based online newspaper have become a very popular way to share information as well as to allow user to comment news and each others comment. In such environments some user play a prominent role and eventually influence other user thus leading discussions as they please. So far, there is no way of identifying and quantifying such influence. This paper proposes and analyzes a methodology for identifying influential user that builds implicit social network upon user who post comment in the same news, suggests three different ways of identifying influential user and measures influence based on similarity of comment. We applied it to data collected from a Brazilian online newspaper and result confirm its effectiveness by revealing a significant similarity between comment of identified influential user and the remaining ones."
6454;en_US;"In the last years, with the growth of the internet as a means of communication, a large number of people changed the way they consume news, replacing the traditional newspaper and magazines with the virtual and online versions. In order to lure peoples attention and attract their clicks, news websites have to create effective strategies. Considering this, we investigate the possible strategies used by Brazilian news websites in the design of their headlines. Specifically, we analyze the number of 59.510 news produced by 8 different and important Brazilian newspaper over a 3-month period in 2015. To find the strategies that could be used to attract clicks, we extracted news text feature with the polarity within the headlines. We also present a methodology to evaluate the headline polaritys strength over time. Our result reveal a number of interesting observations on polarity within the news and, in addition, we identified strong evidence that the polarity of the headlines is impacted by the occurrence of specific events."
6455;en_US;"Studying the strength of ties in social network allows to identify impact at micro-macro levels in the network, to analyze how distinct relationships play different roles, and so on. Indeed, the strength of ties has been investigated in many context with different goals. Here, we aim to address the problem of measuring ties strength in co-authorship social network. Specifically, we present four case studies detailing problem with current metrics and propose a new one. Then, we build a co-authorship social network by using a real digital library and identify how the strength of ties relates to the quality of publication venues when measured by different topological properties. Our result show the best ranked venues have similar pattern of strength of co-authorship ties."
6456;en_US;"In recent years, cases of patrimonial violence have become part of the daily lives of Brazilians. This situation imposes on public security managers a big challenge: look for alternatives to the official statistics in order to reflect a more consistent overview of the reality. The popularity of social network has resulted in continuous data generation about stories, feelings and opinions of their user. This work presents DETECT, a system which analyzes Twitter data in order to detect message (tweets) that indicate the occurrence of patrimonial violence crime, filling the gap presented in official data. We have experienced DETECT and initial result showed to be equivalent to the official data."
6457;en_US;"This work presents preliminary result of an experimental evaluation about the inference of user gender in a Brazilian social network. This is done using a feature extraction process associated with those user. To achieve this goal, we use a Portuguese version of the linguistic feature called LIWC. Initial experimental result allow us to conclude that the classification task using dataset produced with LIWC is able to present satisfactory result. This occurs with no direct influence of word that manifest gender traits."
6458;en_US;"<p>Distributed algorithm that operate in the fail-recovery model rely on the state stored in stable memory to guarantee the irreversibility of operations even in the presence of failures. The performance of these algorithm lean heavily on the performance of stable memory. Current storage technologies have a defined performance profile: data is accessed in blocks of hundreds or thousands of bytes, random access to these blocks is expensive and sequential access is somewhat better. File system implementations hide some of the perfor- mance limitations of the underlying storage device using buffers and caches. However, fail-recovery distributed algorithm bypass some of these technique and perform synchronous writes to be able to tolerate a failure during the write itself. Assuming the distributed system designer is able to buffer the algorithm’s writes, we ask how buffer size and latency complement each other. In this paper we start to answer this question by characterizing the performance (throughput and latency) of typical stable memory device using a representative set of current file system.</p>"
6459;en_US;"<p>This paper proposes an adaptation of the peer-to-peer BitTorrent algorithm to perform interactive on-demand video streaming over mobile ad hoc network. This adaptation mainly lies on the idea of prioritizing the sharing of data between peers which are geographically close to each other, as well as restricting the data that may be requested by peers during video playback. Through simulation and assessing different metrics, the proposed adaptation is validated and its attractive performance is proven. In this sense, the main contribution of this article is to provide a new algorithmic solution for the design of real protocol targeted at mobile ad hoc network. At last, overall conclusions and future work conclude this article.</p>"
6461;en_US;"<p>Although typically the lightweight and distributed emulation solu- tions used in network experimentation follow the container virtualization concept, implementation differences can generate distinct behavior regarding computational resource consumption and supported scalability. Thus, in this work we experimentally evaluates the Mininet Cluster and Maxinet with the emulation of data center topologies with different requirement regarding the number of elements created and the size of the cluster. result point to relevant differences in memory consumption, number of process created and connections established between cluster node, showing characteristics that help identify the technology best suited for specific scenarios.</p>"
6462;en_US;"<p>The algorithm commonly used for energy control in IoT network involve optimization functions with considerable complexity and rigorous control of the test environment. It creates a gap between design, theoretical analysis and real-time processing of the network device. In this paper, we propose a novel approach based on machine learning which considers the input and output of a power consumption control algorithm in multi-variable slotted Aloha ad hoc network. result show that the proposed neural network presented better performance concerning processing time and computational cost when compared to the currently used greedy search energy control algorithm.</p>"
6463;en_US;"<p>Recommender system are increasingly present in Internet user’ routine. Therefore, platforms like Youtube and Netflix seek to improve their recommendation system, to provide a better experience for their user. However, the user’ experience depends on a multitude of factors. In particular, caching system have an important influence in the quality of experience (QoE), since they impact quality of service (QoS) metrics (such as the delay and the throughput) experienced by user. Our goal is to study the viability of a QoS-aware and QoE-friendly content recommendation system. To this aim, we conduct an experiment with real user, having different profiles. Each user is requested to evaluate different video, which vary in their contents and in the corresponding QoS. Given our findings on QoS-QoR tradeoffs, we investigate their impact on the design of a recommendation system. A decision tree classifier reached accuracy of 77% using cross validation, which allows us to further understand the user’s decision making process.</p>"
6464;en_US;"<p>Data exchange in sensor network under interference from other technologies requires multichannel communication strategies and several methodologies of medium access protocol were adopted seeking better performance. This paper proposes a new method of searching and owning a communication channel, considering the signal-to-noise ratio acting in environments under interference from other wireless local area network (WLANs), where the channel to be occupied result the lowest level of interference. Comparative result are presented with other technologies that employ channel switching under the use of blacklist, such as ISA100.11a and IEEE802.15e / ATSCHa, where we show that the proposed method obtains the best performance because it ensures that the channel occupied is the best available.</p>"
6465;en_US;"<p>In information security, software and hardware vulnerabilities are increasingly prevalent at the expense of today’s technological advances. In this work we present an analysis of time serie on vulnerability life cycle searching for trends in information security industry. We also present a machine learning model to predict the occurrence of exploits. The training process was done using approximately 26,000 vulnerability data sample and 132 feature, resulting in a model with an initial accuracy of 60% for predicting the first exploit. After adjusting the parameters of the algorithm using grid search, an increase to 67% was achieved using error metrics such as mean absolute error and root mean square error.</p>"
6466;en_US;"<p>Network epidemics are ubiquitous. As botnets evolve, they compromise additional user to join DDoS attack campaigns. Such user face a dilemma with respect to which countermeasures to take: hard (e.g., vaccination), soft (e.g., rebooting and rejuvenation) or no countermeasures at all. To tackle this dilemma, one option is to leverage insights from analytical model. Our key contribution consists of novel result on the steady state solution of epidemic model wherein the attacker is strategic and has a finite attack budget. To this aim, the most probable states of the model are analyzed, and are used to derive closed form expressions that approximate the steady state probability of infection of a node. Then, model’s insights are contrasted against simulation. The simulation qualitatively support the observations of the model and extend the analysis allowing general distributions to the times between the events.</p>"
6467;en_US;"<p>The concept of computational virtualization, though old, has become a commonplace in enabling application that share computing resource in the cloud infrastructure. Virtual machine (VMs) have brought benefits such as the ability to perform live migration to provide fault tolerance and load balancing. However, despite the advantages, VMs add extra layers of abstraction, resulting in loss of efficiency. As an alternative to VMs, today’s containers present them- selves as a lighter, better-performing solution. This work performs a performance evaluation based on sensitivity analysis with the objective of identifying the factors that most impact on the efficiency of a Database Management System (DBMS) using Docker as a container.</p>"
6468;en_US;"<p>The C-RAN (Centralized Radio Access Network) architecture is a proposal to meet the high demand of fifth generation (5G) network. Because the communication traffic has a dynamic behavior due to the ”Tidal Ef- fect”(phenomenon responsible for variation in network flow), the current architecture, D-RAN (Decentralized Radio Access Network) does not guarantee the efficient delivery of resource. This work presents a heuristic for the dimensioning of hardware resource considering the Number of user Served and Aggregate Flow. The proposal addressed traffic variability, maximizing the efficiency of BBU (BaseBand Unit) and quantifying SCs (Small Cells) needed to cover the network demand.</p>"
6469;en_US;"<p>Video traffic accounts for 75% of Internet traffic today. In this paper, we characterize the evolution of a large video streaming service use in Brazil, comparing streaming logs from FIFA’s 2014 and 2018 World Soccer Cups. We report a 166% increase in the average number of unique IP addresses and more than a 300% increase in traffic volume. Arrival rate has also changed and it’s more concentrated at the beginning of the match nowadays. We also compare the impact of QoE metrics on user engagement. For instance, we note that engagement has increased for all bitrate rates and it’s also higher when there are fewer bitrate adaptations. Furthermore, the high rate of rebufferings substanti- ally decreases engagement, but only up to a certain value.</p>"
6470;en_US;"<p>Genome analysis is an area with extensive research because it allows the study of disease and the development of new treatments. To do this, researcher use the genome, assembled with computational tool to perform their analysis. This work presents a performance analysis of a hybrid correction algorithm for genome sequences, this being a necessary stage for the assembly of the genome. Seven versions of the algorithm were implemented to compare their performance. The result obtained from the tests show that it is possible to obtain performance gains of up to about 17 times in relation to the sequential version, and that the best version of the algorithm has scalability higher than linear.</p>"
6471;en_US;"<p>Online social network play an increasingly important role in society, given its influence on the opinion formation of millions of user. However, the presence of bots (user with programmed behavior) emerges as a concern given their potential to dissiminate information and consequently influence opinion formation, evidencing the need for its characterization and identification. This work considers a directed network of user constructed from comment in Reddit to characterize and identify bots. The network characterization highlights the significant structural differences of bots, allowing them to be classified with high accuracy using only network feature.</p>"
6472;en_US;"<p>With the great development of computational technologies, it has been possible to use social network to collect and analyze information of individuals, communities and with respect to city in real time. The information overload, however, is a challenge even in the context of city, where many events occur in parallel. In this context, this paper describes the development of a framework that seeks to ease the extraction, treatment and identification of events and their locations in tweets written in the Portuguese language using the Conditional Random Fields technique to address the Named Entity Recognition task. The obtained result demonstrate the potential of the tool in identifying important traffic events in a given location of interest.</p>"
6473;en_US;"<p>computer have network cards that are mandatory electronic components to perform communication between machine. The 10GbE board is one of the boards most commonly used by Internet company. Package capture framework are used to process large quantities of packages without discarding them. Network infrastructures managers do not have at their disposal studies that help them in deciding which board and framework to adopt according to their needs. The present work presents a sensitivity analysis evaluating the impact of two network card brands with 10 GbE capacity and two packet capture framework. Different combinations were indicated making this work an aid tool for network professionals.</p>"
6474;en_US;"<p>Mobile Edge Computing (MEC) has emerged as an alternative to re- duce network latency that has leaded to the data flow processing closer to the user. However, the server machine resource capacity can directly influence MEC performance. This paper proposes a Stochastic Petri Net (SPN) model to such a scenario and analyzes its performance, considering several parameters that can directly affect the Mean Response Time (MRT) and Utilization Level. We also present numerical analysis that serve as a practical guide to assist computer infrastructure managers to design their architectures, finding the trade-off between MRT and utilization.</p>"
6475;en_US;"<p>The sensor node are low-cost electronic device able to self- organizing in low-power network and susceptible to loss data packets, having computational and energy limitations. For these network, the IETF standardized the Routing Protocol for Low Power and Lossy network (RPL), in which each secondary node select a better parent according to some objective functions (OFs). In this work, we propose the evaluation of the energy consumption of the RPL routing protocol in scenarios on lossy network. We did simulation in the Contiki Cooja 3.0 considering the ETX and HOP metrics to evaluate three distinct topologies: tree, circular and mesh. Our result of the simulation show that the circular topology has the best (lowest) energy consumption, with 15% better than the mesh topology and 30% against the tree topology.</p>"
6476;en_US;"<p>This document describes a preliminary study on computing framework and technologies, for the purpose of developing machine learning (ML) system application. Several framework, application programming interface and programming libraries for ML algorithm have been developed in the last few years, in a relatively short period of time, making difficult a decision on which one to chose in a particular application. This study review some criteria and performs a preliminary evaluation of some of the most used ML technologies for developing system application, with the purpose to guide and facilitate the decision on which of them to apply, given a particular application.</p>"
6477;en_US;"<p>The most used way to evaluate the stator insulation condition in hydrogenerators is partial discharge (PD) monitoring. In this work, a PD classification system is developed using Kohonen self-organizing maps (SOM). Several literature technique were combined for preprocessing and pattern visualization. It is proposed a methodology that obtains the separation boundaries in the Kohonen map that maximizes the accuracy, besides automating the classification of unknown pattern. The trained Kohonen map presented a high success rate, generalizing the problem to the point of showing subgroups associated to variations of the pattern of the same type of PD.</p>"
6478;en_US;"<p>Docker is one of the platforms for the creation and management of containers with wide use in the market. A problem that affects availability is the phenomenon of software aging, an unavoidable process, where the application process suffer degradation of performance throughout their use. This study aims to monitor and evaluate the performance of the Docker platform in the context of the cloud computing paradigm, including possible software aging effects. We conducted an experimental study with a workload to simulate the life cycle of containers, while the system monitoring was performed. The result show high resource consumption as RAM and CPU usage in the network utility of operating system (OS) , in addition to memory fragmentation an important subprocess of the platform.</p>"
6479;en_US;"<p>Despite the recent advances that have made Unmanned Air Vehicles (UAVs) in several scenarios a reality, there are several challenges to be faced to exploit their full potential. The use of Fog Computing becomes a solution to help these resource-constrained mobile device to outsource all processing power to a remote cloud resource at the network edge. This paper presents the performance evaluation of the offloading technique using drone and cloudlet in a fog computing environment for the image transmission and processing through the algorithm of faces detection and recognition in real time.</p>"
6480;en_US;"In developing countries, electricity theft is a common type of non- technical losses (NTL, i.e., losses associated with electricity that is consumed but not billed by some type of anomaly), financially affecting not only distribu- tion system operators (DSO) but also customers. Similarly to frauds in other context, there is evidence that electricity theft is highly influenced by social in- teractions. Here we propose a multiplex and heterogeneous network model to evaluate how social and professional interaction influence on electricity theft. Particularly, by employing a variation of the random walk with restart algo- rithm we were able to derive a new exposure score for discriminating between fraudsters and regular customers."
6481;en_US;"The Chamber of Deputies is the maximum degree of people represen- tativity in Brazil, having as one of its main goals the approval of law and project to develop and manage the country. We have deputies from different regions, parties, sex, ethnicity, and education levels occupying the 513 existing chairs and creating alliances and negotiations to approve their project in this hete- rogeneous environment. The goal of this work is to describe the coauthorship network among these deputies, concentrating in identify and characterize ho- mophily and asymmetry pattern. We will propose and evaluate a new metho- dology to analyze the homophily in the congress network. Using the proposed methodology we will identify important aspects, as a high level of asymmetry and a lack of homophily among minorities."
6482;en_US;"LIWC is a text analysis program that categorizes word into gram- matical and psychologically derived categories. The currently available LIWC lexicon for Brazilian Portuguese (LIWC 2007pt) is based on the 2007 version of LIWC program. As several studies indicated, LIWC 2007pt shows perfor- mance and categorization problem. In this scenario, this work highlights a new Brazilian Portuguese LIWC lexicon (LIWC 2015pt), based on LIWC 2015 pro- gram. This work compares the performance of LIWC 2007pt and LIWC 2015pt in classification tasks. Three experiment were conducted and the result indi- cate LIWC 2015pt outperforms LIWC 2007pt in all three tasks."
6483;en_US;"Nowadays, social media has been widely used to search and share information about healthy eating. The goal of this study was to analyze the representation of the term 'healthy eating' in Instagram by means of a hashtags network based on cliques. The study was conducted in seven steps. The most important hashtags in terms of degree were #saude, #dieta, #fitness, #vidasaudavel, #comidadeverdade, #emagrecer, #emagrecimento, #nutrição, #saúde and #reeducaçãoalimentar. We analyzed 10 main communities, of which five relate to the biological aspect of adequate and healthy eating, while the others also highlight cultural, environmental and hedonic aspects."
6484;en_US;"Social media plays an important role in the feminist agenda by pro- viding a channel for denouncing and also inducing support network. However, hate speech is conveyed in this type of media. Aiming to study this counterpoint, this paper analyzes news commentary on the feminicide attempt of the landscape artist Elaine Perez Caparroz. The approach was carried out with the collection of news and their comment, which were later analyzed using topic modeling, sentiment analysis, correlation analysis of likes and dislikes and the comment scholarly level. The result show that most of the comment share the opinion that it was the fault of Elaine Caparroz, highlighting the chauvinism that still existing in our society."
6485;en_US;"Reddit is an online social network where user interested in a com- mon subject may interact with each other through subreddits. Subreddits for language learning have been attracting user of various proficiency levels each year, interested in boosting their learning. In particular, on subreddit German, user are advised to inform their proficiency level when writing a post. Yet, only 20% of the posts have such tags. In this paper we address the problem of classifying user’ proficiency from their publications. We conduct experiment which show that classifier that treat publications as independent observations perform poorly. We then propose a new model dubbed SEMPLICe, which uses both textual feature and the publication history of an user to classify her pro- ficiency level over time. By assuming that proficiency is monotonically non- decreasing as long as the user remains active, SEMPLICe yields a weighted F 1 score up to 29.6% higher than previous method. SEMPLICe uses dynamic programming to achieve linear complexity on each user’s history size."
6486;en_US;"There are two main problem when performing Opinion Mining (OM) with data streams: the lack of labeled data and the need to update the learning model. The most used OM technique cannot deal well with these challenges, so, an alternative is to use semi-supervised method, such as the Active Learn- ing, which is a method to label only selected data rather than the entire data set; however, it requires the choice of a sampling strategy to select the data to be labeled. In this paper, we evaluated eight strategies in ten data sets, in order to identify the best ones for OM with Twitter streams. According to our experi- ments, the Entropy strategy showed the best result, but it selects a large number of instances to be labeled, requiring further investigation."
6487;en_US;"This paper describes a methodology for analyzing sentiments and for knowledge discovery in tweets regarding the Brazilian stock market. The pro- posed methodology starts by preprocessing and characterizing tweets to obtain an associated vector-space model. After that, a dimensionality reduction is em- ployed by using Principal Component Analysis and t-Stochastic Neighbor Em- bedding. Sentiment analysis of stock market tweets is performed by considering the tasks of sentiment classification, topic modeling and clustering, along with a visual analysis process. experiment result showed satisfactory performances in single and multi-label sentiment classification scenarios. The visual analysis process also revealed interesting relationships among topic and cluster."
6488;en_US;"The time user spend on social network is in vogue. The retention of social network has important implications, encompassing economic, psycho- logical and infrastructure aspects. In this article, we consider the problem of determining the optimal rate at which user should access a social network. To this aim, we propose an analytical model that allows us to determine, depending on the rate at which source generate content, the chance of a user accessing the network and obtaining new content, referred to as the value of access (VoA). Next, we pose an optimization problem wherein the utility of user equals the VoA minus the costs to access the network. Using the proposed framework, we provide insights on the optimal access rate. Our result are parameterized using Facebook data, indicating the predictive power of the approach."
6489;en_US;"This paper presents a new approach to predict the helpfulness of opi- nions. Usually, researcher in this area use tables of attribute-value to aggregate the feature that represent the evaluated text. In this paper, this task is mode- led as a network, considering the information of relations among objects in the network (comment, stars, and word). A regularization technique of graph is used to extract the relevant feature of graph structure and, after that, the com- ments are classified as helpful or unhelpful. We compared our network model with a baseline method based on fuzzy logic. Our model outperformed the fuzzy logic method in 0.13 of F1 measure."
6490;en_US;"In 2018 occurred the Brazil’s presidential elections and it was widely spread on the media that bots were used in social media to share fake news and increase online support. That given, the goal on this paper is to characterize bot’s behavior in Twitter during the electoral campaign. To do so, we identified 2,000 bot user, calculated behavior metrics and compared them with common user. After that, we were able to estimate their influence on the social network by quantifying influence metrics and the result suggested that they indeed af- fected the online discussions."
6491;en_US;"Depression is an illness that has taken worrying proportions all over the world. According to the World Health Organization, more than 300 million people suffer from this disease. With popularization and facilities became from the Internet, it’s common to find depressive peoples that in attempts to relieve their symptoms, end up exposing their feelings in social network before rea- ching the extreme of suicide. This paper proposes the use of a lexicon to improve the identification of depressive symptoms in a Brazilian social network. Preli- minary experiment indicated that using the lexicon leads to an improvement in the result in the classification tasks for the detection of depression symptoms on text."
6492;en_US;"Online social network are relevant even in elections process. In this context, this work characterized data collected from Twitter during the Bra- zilian presidential elections in 2018. For that, the data were analyzed over time as the percentage of followers, the number of mentions to the opposing can- didates, the most used word and the tweets shared, liked and retweet. It was possible to identify that the candidate who won the elections was not the candi- date with the largest number of followers, but the one that was most cited by his opponents and in the trending topic, which showed a greater variation in his number of followers and accumulated a larger number of likes and sharing of his publications."
6493;en_US;"Nowadays, social application represent one of the main threats to children and adolescents on the Internet. Among the various existent risks is the presence of sexual predators that seek, among the most diverse purposes, to obtain child pornographic content, to extort for financial purposes and, in more severe scenarios, the sexual abuse. The present work aims to identify Brazilian sexual predators through Convolutional Neural network. In order to achieve this goal, it is considered conversations coming from criminal evidence that recently became publicly available. Preliminary result consolidate the presented methodology as an alternative for tasks of binary classification of text for the Portuguese language."
6494;en_US;"This work aimed to characterize how Facebook stimulates the affective responses of its members during the interaction. Through the result it was possible to demonstrate that the Facebook designer adopts strategies of affectibility that, in the view of the user, contribute to stimulate emotions and positive feelings during the use of this network."
6495;en_US;"This paper aims to analyze, using data mining technique, the party fragmentation existing in a Legislative Assembly. Voting data given by congressman of the Rio Grande do Sul State were collected on different proposals between 2000 and 2017. result obtained suggest that there is a high similarity among the different political parties with similar ideologies, demonstrating that the number of parties could be reduced without affecting the ideological preferences and positions."
6496;en_US;"Identifying prestigious researcher in their fields of research is an arduous task. The greatest difficulty is the evaluation of the prestige of each researcher on the local structure that surrounds them. In this work we present a new adaptation of the PageRank algorithm on an academic genealogical graph, called Normalized Local Inverted PageRank, in means of identifying the most prestigious researcher in terms of human resource production constrained by the number of academic generations. As a case study, we use data gathered from more than a million of researcher."
6497;en_US;"With the popularization of the Internet in recent years it has been pos- sible to accumulate large amounts of unstructured data in the form of comment or review thus interpreting them can generate important information for any company that wants to improve its service or products. Therefore this article aims to create a machine learning model capable of inferring which topic are being mentioned within a sample of online review free text. Being shown in restaurant evaluation case study."
6498;en_US;"Social media allows user to engage and protest about political issues. However, does this process have any real effect on real-world outcomes? It is necessary to verify the impact of the engagement of the user of social network in the electoral campaigns. For this, a research was conducted that aims to develop a model that allows us to gauge if there is a visible impact of social media in the scenarios of the presidential election in 2018 through data collected from Twitter and Google. It should be noted that this is a work in progress."
6501;en_US;"This article presents an architecture of a reduced-size greenhouse, so-called mini-greenhouse monitored via Internet of Things (IoT). For this purpose, a prototype has been built with support of a computational system installed in its interior. So, sensor are used for monitoring and control of the variables that most influence in the development of a vegetal species. This text gives a brief description of the germination factors related on the various possibilities of its use. The proposed system has a cloud-based storage and the effective contributions of the computer system are started from the web platform, transfer the set-points to the controllers, and upload data read from sensor to the same web page."
6543;en_US;"<p>In developing countries, electricity theft is a common type of non- technical losses (NTL, i.e., losses associated with electricity that is consumed but not billed by some type of anomaly), financially affecting not only distribu- tion system operators (DSO) but also customers. Similarly to frauds in other context, there is evidence that electricity theft is highly influenced by social in- teractions. Here we propose a multiplex and heterogeneous network model to evaluate how social and professional interaction influence on electricity theft. Particularly, by employing a variation of the random walk with restart algo- rithm we were able to derive a new exposure score for discriminating between fraudsters and regular customers.</p>"
6544;en_US;"<p>The Chamber of Deputies is the maximum degree of people represen- tativity in Brazil, having as one of its main goals the approval of law and project to develop and manage the country. We have deputies from different regions, parties, sex, ethnicity, and education levels occupying the 513 existing chairs and creating alliances and negotiations to approve their project in this hete- rogeneous environment. The goal of this work is to describe the coauthorship network among these deputies, concentrating in identify and characterize ho- mophily and asymmetry pattern. We will propose and evaluate a new metho- dology to analyze the homophily in the congress network. Using the proposed methodology we will identify important aspects, as a high level of asymmetry and a lack of homophily among minorities.</p>"
6545;en_US;"<p>LIWC is a text analysis program that categorizes word into gram- matical and psychologically derived categories. The currently available LIWC lexicon for Brazilian Portuguese (LIWC 2007pt) is based on the 2007 version of LIWC program. As several studies indicated, LIWC 2007pt shows perfor- mance and categorization problem. In this scenario, this work highlights a new Brazilian Portuguese LIWC lexicon (LIWC 2015pt), based on LIWC 2015 program. This work compares the performance of LIWC 2007pt and LIWC 2015pt in classification tasks. Three experiment were conducted and the result indi- cate LIWC 2015pt outperforms LIWC 2007pt in all three tasks.</p>"
6546;en_US;"<p>Nowadays, social media has been widely used to search and share information about healthy eating. The goal of this study was to analyze the representation of the term 'healthy eating' in Instagram by means of a hashtags network based on cliques. The study was conducted in seven steps. The most important hashtags in terms of degree were #saude, #dieta, #fitness, #vidasaudavel, #comidadeverdade, #emagrecer, #emagrecimento, #nutrição, #saúde and #reeducaçãoalimentar. We analyzed 10 main communities, of which five relate to the biological aspect of adequate and healthy eating, while the others also highlight cultural, environmental and hedonic aspects.</p>"
6547;en_US;"<p>Social media plays an important role in the feminist agenda by pro- viding a channel for denouncing and also inducing support network. However, hate speech is conveyed in this type of media. Aiming to study this counterpoint, this paper analyzes news commentary on the feminicide attempt of the landscape artist Elaine Perez Caparroz. The approach was carried out with the collection of news and their comment, which were later analyzed using topic modeling, sentiment analysis, correlation analysis of likes and dislikes and the comment scholarly level. The result show that most of the comment share the opinion that it was the fault of Elaine Caparroz, highlighting the chauvinism that still existing in our society.</p>"
6548;en_US;"<p>Reddit is an online social network where user interested in a com- mon subject may interact with each other through subreddits. Subreddits for language learning have been attracting user of various proficiency levels each year, interested in boosting their learning. In particular, on subreddit German, user are advised to inform their proficiency level when writing a post. Yet, only 20% of the posts have such tags. In this paper we address the problem of classifying user’ proficiency from their publications. We conduct experiment which show that classifier that treat publications as independent observations perform poorly. We then propose a new model dubbed SEMPLICe, which uses both textual feature and the publication history of an user to classify her pro- ficiency level over time. By assuming that proficiency is monotonically non- decreasing as long as the user remains active, SEMPLICe yields a weighted F 1 score up to 29.6% higher than previous method. SEMPLICe uses dynamic programming to achieve linear complexity on each user’s history size.</p>"
6549;en_US;"<p>There are two main problem when performing Opinion Mining (OM) with data streams: the lack of labeled data and the need to update the learning model. The most used OM technique cannot deal well with these challenges, so, an alternative is to use semi-supervised method, such as the Active Learn- ing, which is a method to label only selected data rather than the entire data set; however, it requires the choice of a sampling strategy to select the data to be labeled. In this paper, we evaluated eight strategies in ten data sets, in order to identify the best ones for OM with Twitter streams. According to our experi- ments, the Entropy strategy showed the best result, but it selects a large number of instances to be labeled, requiring further investigation.</p>"
6550;en_US;"<p>This paper describes a methodology for analyzing sentiments and for knowledge discovery in tweets regarding the Brazilian stock market. The pro- posed methodology starts by preprocessing and characterizing tweets to obtain an associated vector-space model. After that, a dimensionality reduction is em- ployed by using Principal Component Analysis and t-Stochastic Neighbor Em- bedding. Sentiment analysis of stock market tweets is performed by considering the tasks of sentiment classification, topic modeling and clustering, along with a visual analysis process. experiment result showed satisfactory performances in single and multi-label sentiment classification scenarios. The visual analysis process also revealed interesting relationships among topic and cluster.</p>"
6551;en_US;"<p>The time user spend on social network is in vogue. The retention of social network has important implications, encompassing economic, psycho- logical and infrastructure aspects. In this article, we consider the problem of determining the optimal rate at which user should access a social network. To this aim, we propose an analytical model that allows us to determine, depending on the rate at which source generate content, the chance of a user accessing the network and obtaining new content, referred to as the value of access (VoA). Next, we pose an optimization problem wherein the utility of user equals the VoA minus the costs to access the network. Using the proposed framework, we provide insights on the optimal access rate. Our result are parameterized using Facebook data, indicating the predictive power of the approach.</p>"
6552;en_US;"<p>This paper presents a new approach to predict the helpfulness of opi- nions. Usually, researcher in this area use tables of attribute-value to aggregate the feature that represent the evaluated text. In this paper, this task is mode- led as a network, considering the information of relations among objects in the network (comment, stars, and word). A regularization technique of graph is used to extract the relevant feature of graph structure and, after that, the com- ments are classified as helpful or unhelpful. We compared our network model with a baseline method based on fuzzy logic. Our model outperformed the fuzzy logic method in 0.13 of F1 measure.</p>"
6553;en_US;"<p>In 2018 occurred the Brazil’s presidential elections and it was widely spread on the media that bots were used in social media to share fake news and increase online support. That given, the goal on this paper is to characterize bot’s behavior in Twitter during the electoral campaign. To do so, we identified 2,000 bot user, calculated behavior metrics and compared them with common user. After that, we were able to estimate their influence on the social network by quantifying influence metrics and the result suggested that they indeed af- fected the online discussions.</p>"
6554;en_US;"<p>Depression is an illness that has taken worrying proportions all over the world. According to the World Health Organization, more than 300 million people suffer from this disease. With popularization and facilities became from the Internet, it’s common to find depressive peoples that in attempts to relieve their symptoms, end up exposing their feelings in social network before rea- ching the extreme of suicide. This paper proposes the use of a lexicon to improve the identification of depressive symptoms in a Brazilian social network. Preli- minary experiment indicated that using the lexicon leads to an improvement in the result in the classification tasks for the detection of depression symptoms on text.</p>"
6555;en_US;"<p>Online social network are relevant even in elections process. In this context, this work characterized data collected from Twitter during the Bra- zilian presidential elections in 2018. For that, the data were analyzed over time as the percentage of followers, the number of mentions to the opposing can- didates, the most used word and the tweets shared, liked and retweet. It was possible to identify that the candidate who won the elections was not the candi- date with the largest number of followers, but the one that was most cited by his opponents and in the trending topic, which showed a greater variation in his number of followers and accumulated a larger number of likes and sharing of his publications.</p>"
6556;en_US;"<p>Nowadays, social application represent one of the main threats to children and adolescents on the Internet. Among the various existent risks is the presence of sexual predators that seek, among the most diverse purposes, to obtain child pornographic content, to extort for financial purposes and, in more severe scenarios, the sexual abuse. The present work aims to identify Brazilian sexual predators through Convolutional Neural network. In order to achieve this goal, it is considered conversations coming from criminal evidence that recently became publicly available. Preliminary result consolidate the presented methodology as an alternative for tasks of binary classification of text for the Portuguese language.</p>"
6557;en_US;"<p>This work aimed to characterize how Facebook stimulates the affective responses of its members during the interaction. Through the result it was possible to demonstrate that the Facebook designer adopts strategies of affectibility that, in the view of the user, contribute to stimulate emotions and positive feelings during the use of this network.</p>"
6558;en_US;"<p>This paper aims to analyze, using data mining technique, the party fragmentation existing in a Legislative Assembly. Voting data given by congressman of the Rio Grande do Sul State were collected on different proposals between 2000 and 2017. result obtained suggest that there is a high similarity among the different political parties with similar ideologies, demonstrating that the number of parties could be reduced without affecting the ideological preferences and positions.</p>"
6559;en_US;"<p>Identifying prestigious researcher in their fields of research is an arduous task. The greatest difficulty is the evaluation of the prestige of each researcher on the local structure that surrounds them. In this work we present a new adaptation of the PageRank algorithm on an academic genealogical graph, called Normalized Local Inverted PageRank, in means of identifying the most prestigious researcher in terms of human resource production constrained by the number of academic generations. As a case study, we use data gathered from more than a million of researcher.</p>"
6560;en_US;"<p>With the popularization of the Internet in recent years it has been pos- sible to accumulate large amounts of unstructured data in the form of comment or review thus interpreting them can generate important information for any company that wants to improve its service or products. Therefore this article aims to create a machine learning model capable of inferring which topic are being mentioned within a sample of online review free text. Being shown in restaurant evaluation case study.</p>"
6561;en_US;"<p>Social media allows user to engage and protest about political issues. However, does this process have any real effect on real-world outcomes? It is necessary to verify the impact of the engagement of the user of social network in the electoral campaigns. For this, a research was conducted that aims to develop a model that allows us to gauge if there is a visible impact of social media in the scenarios of the presidential election in 2018 through data collected from Twitter and Google. It should be noted that this is a work in progress.</p>"
6562;en_US;"This work describes the Interdisciplinary Project for Dialectology, Computing, Cartography and Lexicography–INDICCALEX. It brings together researcher and professionals from various theoretical and methodological perspectives to meet the wishes of undergraduate and graduate student of the literature course, as well as of researches in the area involved in this knowledge field from various Higher Education Institutions and it is intended to maintain cooperative agreements with these institutions for the development of project related to these subarea. This paper will demonstrate a bit about the history of the INDICCALEX, its steps and some of the result achieved."
6563;en_US;"Distributed architectures for modeling and simulation can scale the execution of large and complex model. These architectures frequently utilize checkpoint strategies to guarantee the execution of synchronous and asynchro- nous components. However, the complete avoidance of useless checkpoints is impractical, and it can severely decrease the simulation performance. In this paper, we present a set of metrics to identify useless checkpoints at run-time. Additionally, we extended a probabilistic decision that employs our proposed metrics to create only checkpoints with high probability to be loaded by roll- back operations. The method identifies inconsistent checkpoints based on the communication pattern and granularity of the events since the last rollback. The result showed that the proposed metrics allow reducing the number of useless checkpoints without negative impacts on simulation performance and outperforms traditional probabilistic strategies in terms of rollback time."
6564;en_US;"This paper describes the development of a part-of-speech (POS) tagger for a frequently asked questions (FAQ) page about telecommunication service. POS tagging consists of a serie of adjustments in context rule or adjacent word in text sentences for precise grammatical classification of a particular application. Lexical categories and associated attributes are summarized with presentation of relevant statistics from the system’s Portuguese language dictionary, whose lexical processing was assisted by the open-source Flex library. This morphological lexical analyzer represents the initial part of a complete chatbot system, which can potentially replace the FAQ page and assist visitors in a more user-friendly and interactive way. This is possible through the evolution of Natural Language Processing (NLP) technologies, which can reduce operating costs in a number of area, including Customer service and sales."
6565;en_US;"The Data Structure discipline is of fundamental importance for the Computer Science course area and it has presented high repetition rates and low performance achievements. Thus, the purpose of this word is to present the “Visual TaHs” software, which can contribute to the teaching of Data Structure, based on the contextualization approach of the Hash table. An experiment with fourteen hash functions was implemented in the software, and an overload of elements in the lexicon was performed. With this experiment, it was possible to analyze and identify the best hashing functions through report and graph. All the performed analysis can be evaluated by student, contextualizing the concept worked in the classroom."
6566;en_US;"The volumes of agricultural data available are increasing. One of the obstacles faced in this context is to approach the data in Natural Language (NL) for information management and process improvements of a culture. This paper proposes the development of a Decision Support System for NL processing in the field of agronomy, using the data on the pests in the soybean crop that will be stored in a database, thus allowing consultations to build dialogues and obtain accurate diagnoses. The proposed theme indicated possibilities of positive effects and that may facilitate the work of agricultural professionals who need to be involved with a large volume of information."
6567;en_US;"Cloud computing, in addition to promoting a shared data storage and processing model, strengthens the Cloud Service Provider (CSP) technical and economic potential, presenting numerous investment possibilities. This paper proposes a cost model and an evaluation scenario based on Total Cost of Ownership (TCO), evaluating the context of acquisition and operation of equipment for the implementation of cloud infrastructure. Hence, it was possible to specify the main assets of typical cloud infrastructures and, above all, to evaluate their financial performance based on cost projections that took into account aspects that directly infer the return of Data Center investments."
6568;en_US;"Forest inventory and management are important topic to enhance environmental protection initiatives and policies. Thus, sampling process in- side the forest environment are normally manual and limited. These conditions nurture an increasing need for novel solutions to enhance environmental perception, especially in ground-sampling process. In this work, we present a new solution to augment environmental perception. The proposed appliance is a wearable embedded system based on a helmet and projected to acquire environmental data. It also allows the development of new application to expand the researcher reality perception."
6569;en_US;"The misuse of air conditioners has been identified as a significant influence factor on the waste of eletricity due to its high energy consumption and widespread use in Brazil. Aiming at optimizing the use of those equipments towards energy efficiency, this work presents Smart Place, an ambient manage- ment system for automated control of air conditioners. In this system, sensor and cameras collect data regarding temperature, humidity, and presence of people in the monitored spaces, so that these data are used to perform interventions in air conditioners to prevent them from remaining turned on when the place is not being used. This paper describes Smart Place, its deployment and operation at the Federal University of Rio Grande do Norte (UFRN), Natal, Brazil, and discusses some benefits resulted from the automated intervention made by the system compared to the traditional manual control."
6570;en_US;"Application of Artificial Neural network (ANN) in data classification in area requiring high technology such as the aerospace, automotive and energy sectors has been shown to be a promising approach in behavioral discrimination. An ANN together with clustering algorithm were then used to model computationally pattern of the occurrence of the anode effect of the furnace of the aluminum reduction industry. The input data used in the classification consists of the collection of a Brazilian company, internationally recognized by the quality standards of the metal produced. The result obtained demonstrate a good approximation of the simulation against the experimental data."
6571;en_US;"According to the National Water Agency (ANA), approximately 46.2% of all clean water used in Brazil is destined for irrigation, which has been motivating the evaluation of alternatives for water supply agricultural crops. Considering this scenario, this article presents the I 2 WAC proposal, which aims to explore Situation Awareness in the decision making process, with the perspective of minimizing socioenvironmental impacts. For evaluation of I 2 WAC a prototype was developed that integrates open-source IoT technologies to the EXEHDA middleware and explores a weather prediction service. The result achieved were promising, reaching a success rate of approximately 94% regarding the irrigation decision."
6572;en_US;"In the development or modification of a software, the software must have least amount of possible errors. method of predicting defects in software could be used for this. In this paper we present a study of the use of Just-In-Time (JIT) error identification using Artificial Neural Network (ANN) and decision tree (DT). The databases used as training, test and validation in this work were the same ones used and compiled by [Kamei et al. 2013]. The result obtained with both, ANN and DT, are on average higher than the work of [Kamei et al. 2013] and [Yang et al. 2017]"
6573;en_US;"This paper addresses the problem of clearing detection in the Amazon rainforest using remote sensing data and (un)supervised machine learning technique. A clearing (or canopy gap) is a small area in a forest where there are no trees, or there is only low-lying forest which differs from its surroundings. experiment carried out with 44 satellite image, divided into 3,288 segments, evaluated by experts, where 1,652 of non-clearing class and 1,636 of clearing. The segments were represented by a set of feature that include first and second order statistics and color information. In the supervised learning approach, the best result were obtained with the rule-based method, Decision Tree and Random Forest, reaching 97% in both classes. method that use different approaches have got worse result, which suggests the need for a better analysis of the relation between the attributes. Among the unsupervised learning technique, the best performance was achieved by the BIRCH method, which obtained 94.48% for both classes. However it required a higher number of cluster under higher execution time. Preliminary result indicate that the proposed approach is promising, which must continue to be investigated."
6574;en_US;"Seam Carving is a content-aware resizing method capable of modifying the width or height of pictures. This algorithm applies an energy function to evaluate the importance of each pixel. In special cases, such as image that contain people, the method frequently presents deformation of objects, due the energy function not being able to detect a person. In this context, this paper presents a modification of the energy function used in seam carving aiming to better preserve people in image. This energy function is generated from a neu- ral network that has as input arguments the color of the skin in order to classify the pixel in skin or non-skin."
6575;en_US;"The growing demand for information access, generated by multi- media application, is one of the challenges of the new generation of mobile network. One of the proposed architectures to support this traffic is the Cloud Radio Access Network (C-RAN), which centralizes the processing power to solve the load unbalance, allocating resource according to the demand of the network. This paper proposes an optimized resource allocation model that performs load balancing on BBUs (Baseband Units). To this end, a DPSO (Discrete Particle Swarm Optimization) was developed to optimizes the proposed objec- tive function. result point to superior performance of this objective function in comparison to the proposed benchmarking, both in high and low traffic densities."
6576;en_US;"Optical character recognition software is designed to convert document textual elements into editable and searchable text. This task presents specific challenges when the textual elements are in image captured by smartphone cameras. One of these challenges is the bending of text that affects the effectiveness and efficiency of current recognition method. This work presents an approach to extract textual elements in image with inclined text lines. The experiment demonstrated that the approach obtained a significant increase of effectiveness in relation to the baseline, at the moment that it also presented superior efficiency."
6577;en_US;"The present work is related to SELT tests by proposing a methodology for measuring the main parameters related to the loop qualification. For the proposed methodology, some important procedures should be followed in order to provide trust measures such as: appropriate selection of the equipments/device for the measurements, appropriate choice of the calibration process for the measurements and a statistical treatment of the measurements of the parameters which are Input Impedance, Transfer Function and Scattering Parameter. The present work defines such procedures. For validation of the methodology, some studies of cases were accomplished considering two situations: all of the procedures of measuring were made according to a proposed methodology and, the second case; the measurements made did not follow the proposed procedures. In both cases (application of the proposed methodology and in the comparison evaluation) the result showed the applicability of methodology. The data were reliable and coherent with the expected values and theory."
6578;en_US;"<p>This article describes an environment for knowledge acquisition, learning, use and collaboration inter agent over Internet Infrastructure. Four agent types are used in a previously applied four-tier model, such as the use case on the Internet Routing Registry. This model, which can be implemented in each Autonomous System domain of the Internet infrastructure, is integrated into an environment with (a) capturing information from unstructured databases, (b) creating and updating training bases appropriate to machine learning algo- rithms and (c) creation and feeding of a knowledge base. Such resource become readily available to agent in each domain and to agent in all other domains with the aim of making them autonomous. The agent collaborate and interact with each other, through individual blockchain structures that also take care of operational security and integration aspects. In addition, a test bed to validate the entire model, including the functionalities of the agent, is also proposed and characterized.</p>"
6579;en_US;"<p>This paper presents a set of three data bases that make up the In- ternet Infrastructure Data Base (IIDB). IIDB has three data bases – iidb.rfc, iidb.person, and iidb.acronym – that are key pieces to support the development of machine learning technique by the intelligent elements of the Autonomous Architecture Over Restricted Domains (A2RD). The data contained in iidb.rfc and iidb.person were created after processing the contents available at the RFC Index web page. While the data contained in the iidb.acronym was created af- ter processing the contents of the files available at the Request for comment (RFC) repository, produced and maintained by the RFC Editor. The data format of IIDB data is JavaScript Object Notation (JSON), whose template are avail- able in the same site where the data bases are deposited, making them accessible through any programming language.</p>"
6580;en_US;"<p>UEPA - Campus XX is included in Brazilians Civil Rights Framework for the Internet as an Autonomous System Administrator, but it lacks a method of storing Internet access and Internet application’ registries, required by law. This study aims to present a solution to identify user and to store logs of connections using FreeRadius, MySQL and Syslog-NG system to fit in the law requirement. It was used Laravel PHP framework to develop a user and logs management application. The conclusion was that the goals were accomplished.</p>"
6581;en_US;"<p>A comprehensive monitoring system is essential to assist solutions for most of SFC problem. Therefore, in this work, we propose SFCMon, an efficient and scalable monitoring solution to keep track network flows in SFC environments. To achieve the desired goals, SFCMon work with a pipeline of probabilistic data structures to detect and store large flows as well as perflow counters. For evaluation purposes, based on the SFC reference architecture defined by RFC 7665, we implement a Proof-of-Concept (PoC) framework, which provides a P4-based SFC switch and Python-based SFC Controller. Presented initial experiment demonstrate that SFCMon introduces a negligible performance penalty while providing significant scalability gains.</p>"
6582;en_US;"<p>Many technologies are needed to build computational system in the context of Smart city. At present, the construction of scalable, intelligent and ubiquitous system is a constant challenge for developers. The evolution of the Internet of Things is one of the several paths to be pursued with the aid of this development. In this way, new model and platforms have been proposed to support the development of its application. Allied to this challenge this work presents a generic and a conceptual model of an IoT application for Smart Parking. This model is implemented as RFID and RaspberryPi. In addition, it eval- uates the ThingSpeak cloud service for its use as an IoT platform.</p>"
6583;en_US;"<p>We present a model for predicting geographic distribution of anurans based on Autoencoder. The prediction problem is treated as an One-Class clas- sification task, in which each sample is represented by its geographic coordinates, temporal and correlated meteorological variables. Our model shows a high degree of accuracy when used to predict the occurrence of the Bufo Americanus species in southern Canada. The proposed method is computationally inexpensive and can be coupled to sensor network for environmental monitoring.</p>"
6584;en_US;"<p>According to official data, the accidental fall is the main cause of morbidity due to unintentional external causes to people over 60 years. This article presents a model for ubiquitous care applied to the prevention of falls in the elderly. The classification algorithm adopted is based on relative thresholds, for this purpose, it is proposed the Fall Risk Index (IRQ). The main scientific contribution of this study is the preventive analysis of the risk of falls, considering the profile, the health history and the context of the elderly in intelligent environments. Usability and acceptance evaluations were performed by 2 elderly people in a real setting. The result indicate the approval of 87% in the perceived ease of use and 100% in the perceived utility. In addition, we performed tests by simulation of 5 postural states by 10 elderly people with different profiles, resulting in a mean accuracy of the algorithm for prevention and detection of events related to falls of 96%.</p>"
6585;en_US;"<p>With the advancement of communication technology, wearable device have emerged which periodically monitor a user vital signs. The present work aims to propose a model of vital signs collection called Odin. Odin in comparison to related work is the only one that presents an adaptive collect of vital signs, which enables a generation of historical context. The adaptability changes the time between collects and in the activation or deactivation of sensor in wearable device. Odins evaluation was based on a simulation with requests control to optimize the parameters of the collection. This optimization result in a 214% increase in battery life in a proposed scenario compared to a collection without adaptivity.</p>"
6586;en_US;"<p>Mental stress is a major cause of physical and emotional health pro- blems in the world. In this way, it becomes strategic to measure daily stress throught physiology, using these measures in application that aim individuals well-being. However, daily motion influences physiological data collection, producing noise. This work collects and analyzes the context histories of 5 individuals with the purpose of classifying mental stress through heart rate variability. As a scientific contribution, the method identifies and removes noise, as well as shows a relation of the stress levels and the location in which they were measured. The best performance, among three machine learning algorithm was obtained from Support Vector Machine classifier, resulting in 82% of accuracy.</p>"
6587;en_US;"<p>Voice-based biometric system are very common nowadays, especi- ally with the popularization of voice command system and digital assistants such as Google Assistant or Alexa. An important feature of these system is to detect the user giving a command, as it controls the access to personal or sensitive information to your profile. Thus, as in face-based biometrics, audio biometrics can be attacked by synthetic data, where recordings can be presented as real data. This work presents a model based on deep neural network capable of detecting this invasion technique. For the training, we used real data of recordings and synthetic data generated from the original recordings. We obtained satisfactory result, mainly due to the low rate of false acceptance and high rate of F1-Score, even in different environments and noises.</p>"
6588;en_US;"<p>Telementoring is a subarea of Medicine that aims to approach and allow assistance from geographically distant health professionals. Though, high costs and a lack mobility of medical equipment make it difficult to implement this type of system. With the advent of the Internet of Things area, it became possible to miniaturize and popularize device that are able to process data and connect remotely. The objective of this paper is to introduce a Telementoring system connected to a low-cost robotic platform, allowing audio and video traffic through smartphone between physicians, for real-time monitoring of procedures, ensuring greater safety and assistance for medical teams and patient.</p>"
6589;en_US;"<p>The growth of the Internet of Things (IoT) paradigm, popularized the use of wireless device in the most diverse environments, creating the concept of Smart Environments (SE). SEs can be anything from a factory floor to our homes and are equipped with intelligent device that automate most human activity. These device suffer from the coexistence problem, as they often use the 2.4 GHz ISM band to communicate. In this context, this article presents the CASE algorithm to minimize interference in those environments through the proper allocation of wireless channels. The result suggest that the proposed algorithm reduces total interference as well as maximizes packet delivery when compared to existing approaches.</p>"
6590;en_US;"<p>Time is one of the most relevant aspects when we model contextual variability. The temporal perspective guides the modeling of context-aware system. Despite natural and consensual perception of time, the integrated modeling of its dimensions for developing context-aware software is a recent theme of study. The Past is stored in Context Histories, the Present is modeled through Profile Management and the Future is anticipated using Context Prediction. This article discusses the modeling of these three dimensions in the context-aware system, indicates challenges to each dimension and proposes a system architecture to manage the contextual variability on multi-temporal system. I believe that this text can be a seminal article to stimulate and guide future researches on temporal aspects of computational environments.</p>"
6591;en_US;"<p>The broadcast storm is characterized by unwanted packet retransmission, causing frequent flooding, contention, and collisions that compromise network performance. This paper presents a new protocol for the dissemination of message in vehicular network through the observation and analysis based on complex network metrics. It is called CN-vP (Complex Network-vehicular Protocol). In order to mitigate the sending of unnecessary message, the present work combined probabilistic and delay approaches together with a better knowledge of the network, in particular, the neighboring vehicles of a certain transmitter. Once the three best relays have been chosen, by means of the probabilistic calculation, waiting interval are estimated, for each retransmission, in order to avoid packet flooding. The analysis of the result shows that the solution developed allows a more assertive decision making for the dissemination of message in vehicle network, thus mitigating the problem of broadcast storm.</p>"
6592;en_US;"<p>The application of ubiquitous computing has increased in recent ye- ars, especially due to the development of technologies such as mobile compu- ting and its integration with the real world. One of the challenges in this area is the use of context awareness. In agriculture, the context can be related to the environment, for example, the chemical and physical aspects that characterize different types of soil over time. This paper proposes a computational model applied in precision agriculture that uses the context history to predict soil fer- tility. The best result were obtained in the prediction of organic matter, with a coefficient of determination (R 2 ) of 0.9102 for root mean square error (RMSE) of 0.49%.</p>"
6593;en_US;"<p>A care plan is a set of information that links patient to their health care. This paper presents a scenario for using a platform developed to enable the composition and coordination of care plan tasks that can be implemented as service. This platform has a domain-specific language that allows the mode- ling of the tasks of a care plan as a sequence of actions that is controlled from workflows.</p>"
6594;en_US;"<p>Internet-of-Things (IoT) environments will have a large number of node organized into groups to collect and to disseminate data. In this sense, one of the main challenges in IoT environments is to dynamically manage com- munication characteristics of IoT device to decrease congestion, traffic colli- sions, and excessive data collection, as well as to balance the use of energy resource. In this paper, we introduce an energy-efficient and reliable Self Ad- justing group communication of dense IoT Network, called SADIN. It configures the communication settings to ensure a dynamic control of IoT device consid- ering a comprehensive set of aspects, i.e., traffic loss, event relevance, amount of node with renewable batteries, and the number of observers. Specifically, SADIN changes the communication interval, the number of data producers, the reliability level of the network. Extensive evaluation result show that SADIN improves system performance in terms of message loss, energy consumption, and reliability compared to state-of-the-art protocol.</p>"
6595;en_US;"<p>Information about the occupation of an environment is necessary to implement advanced energy efficiency optimizations. In this sense, this work presents a monitoring and actuation system for intelligent buildings, detecting in a non-intrusive way whether the environment is occupied or not. The system consists of a low cost wireless network that monitors data of temperature, hu- midity, luminosity and the electric charge of the room while controlling both the illumination and temperature of the environment, a data analysis is performed to characterize the behavior of the environment. Finally, we obtain a 99.7% ac- curacy in detecting the environment using classification technique in the sensed environmental data.</p>"
6596;en_US;"<p>This paper presents an embedded system to control an intenvise care enviroment which aims to support the planning of actions that mitigate unfa- vorable conditions and out of safety standards in NICUs. We used to develop our embedded system the WiFi Module ESP8266 NodeMCU, DHT11 sensor, BH1750 sensor and Grove sound sensor, all on a perforated phenolite plate and controlled by an Android application with the Firebase API. The monitoring was performed at the Neonatal Intensive Care Unit of the Santa Mônica School Maternity Unit in Maceió-AL, where the device were active for a period of 31 uninterrupted days.</p>"
6597;en_US;"<p>Urban area are growing over the years and this, together with the modernization of city, allows us to have access to heterogeneous data that can be used to create new service and use existing resource and infrastruc- tures efficiently. With this, several platform architectures for Smart city were proposed with the purpose of managing a large volume of data and providing solutions for urban issues. In this way, this work proposes a middleware to faci- litate the knowledge extraction from the data generated in the city, monitoring abstract information generated from low level data. As proof of concept, we made a case study with a large volume of open data from an urban area.</p>"
6598;en_US;"<p>This work proposes a data flow reduction algorithm based on the behavior of time serie in the Complexity-Entropy plane for wireless sensor network (WSNs). The system dynamic variation is identified in real time th- rough a delimiter built into the plane, called the Maximum Complexity Cut-off Point. Thus, we can determine at which instants the sample interval must be updated in order to maximize the statistical complexity of the resulting data sample. This method was applied to a chaotic database and the obtained re- sults were compared with those of other sampling algorithm, presenting better performance in the statistical metrics evaluated.</p>"
6599;en_US;"<p>With the growing number of mobile device receiving daily notifications, it is necessary to manage the variety of information produced. New smart device are developed every day with the ability to generate, send, and display message about their status, data, and information about other device. Consequently, the number of notifications received by a user is increasing and their tolerance may decrease in a short time. With this, it is necessary to develop a management system and notification controls. In this context, this work proposes a notification and alert management system called PRISER. Its focus on user profiles and environments, applying data privacy criteria.</p>"
6600;en_US;"<p>In the functional evaluations (FE), the lack of technological equipment for end-to-end hand grip experiment create difficulties in offering feed- back to physiotherapists, such as the ideal amount of force to apply in each grip experiment. As a result, an early prototype to study the amount of force involved in these experiment was created. The hardware has wireless communication interacting with a mobile application. In the current state-of-the-art, there is a low cost architecture of hardware operation and production, making possible its use and adhesion in therapeutic studies with technological demand. To identify the grip strength, piezoresistive sensor as fingertip touch sensor were used. The hardware is equipped with capabilities to receive and store online data from each experiment, sending the result to the cloud and providing access to historical data. experiment were performed to determine the viability and performance of each fingertip sensor. The result show that the smart glove can detect the grip strength and communicate the data without issues.</p>"
6601;en_US;"<p>A smart campus refers to a campus where modern information and communication technologies bring more benefits to life on campus, help user to improve and perform daily activity more efficiently, and improve social interaction. This article aims to present an approach based on personalization and recommendation, developed for mobile device, which provides opportunities to user the pointing of infrastructure problem in the smart campus context, monitoring the development of problem solving, as well as interaction with user who reported the same problem.</p>"
6602;en_US;"<p>Geographic Information system (GIS) is a technology with significant potential for transformation for Governments. Since 1999, the municipal government of Porto Alegre, capital of the State of Rio Grande do Sul, has initiated a serie of actions to develop and implement a enterprise GIS. However the imbalance in the development of enterprise GIS is very strong between different institutions within Porto Alegre City Hall (PMPA). In this context, the proposal of this work was that of carrying out a comparative study between three different model of maturity of GIS capacity. This is done in order to identify the most appropriate model for measurement of the GIS maturity level of institutions within the centralized and decentralized administration of Porto Alegre City Hall (PMPA).</p>"
6603;en_US;"<p>The optimization of commercial routes has become of paramount importance for the company offering this service, seeking to reduce costs, optimize resource, improve the process and satisfy its customers, and contribute to the improvement of urban mobility. This work presents a computational solution for route optimization in real time, using heuristic algorithm for the best path, structured in two modules (web and mobile) connected via web service. The Google Maps API provides geographic information. The solution was used in a real company and gains were identified regarding route optimization.</p>"
6604;en_US;"<p>This work presents the SmartNode Dashboard (SND), a tool based on front-end technologies for creation of intelligent dashboards. SND has implemented design and interface web standards focused on content with reusable structures. In addition, a case study was created using Node-RED as an execution platform. As a result of this work, SmartNode Dashboard was developed, a framework for creating standardized and extensible interface. In addition, it offers dashboard developers a methodology for using the framework with Node- RED to facilitate and extend teams ability to perform performance, time and quality in creating dashboards.</p>"
6605;en_US;"<p>Smart Home Energy Management system are powerful tool for efficient energy management. In this scenario, monitoring is done by reading information generated by intelligent home appliances. However, it is not every home that owns such equipment, which makes management difficult. In this work, we present a minimum viable product (MVP) of a residential electrical monitoring system capable of extracting information about the energy consumption of common household appliances, through a single point of collection and through consumer signatures to identify these appliances when they are connected to the electrical network.</p>"
6606;en_US;"<p>The increasing urban concentration has made city complex social ecosystem with innumerable management challenges. In order to face such challenges, it is necessary that this ecosystem be viewed in a holistic way, understanding the complex and multifactorial nature of the demands, being fundamental the use of quality information for decision making and service delivery. Based on the concept of Smart city, within a bottom-up view, the city hall of Fortaleza with the support of the academy, has been developing a project to create a robust data management infrastructure in the city to provide information and digital service (for the management and the population) that help in the improvement of the city and the quality of life of the citizen.</p>"
6608;en_US;"<p>Smart city are a standard concept of automated and sustainable city that adopt technology to increase efficiency in communication, management and globalization of information. Despite the success of the concept, there is an emerging need to develop and deploy software and software-based system for these city. Thus, agile methodologies can play an important role, once they are broadly adopted in system development lifecycle. This paper presents the result of a systematic mapping conducted on agile process to develop software for smart city. A systematic mapping identified 246 studies, from which 10 were selected for analysis and presentation of the result obtained.</p>"
6609;en_US;"<p>One of the characteristics of the Smart Grid is the restoration of the electrical network, using metaheuristics to find the best temporary configuration after a fault. Based on the probabilistic characteristic of metaheuristics, this article aims to perform a comparative analysis between four metaheuristics applied to the restoration problem, using the node-depth representation as a data structure to represent the electric network.</p>"
6610;en_US;"<p>Smart city are characterized by providing new service through Information and Communications Technologies. However, it is important to gather data from citizens to discover new knowledge about certain aspects of a city. One example of a rich domain for collecting data in a smart city is exploring the use of mobile fitness application. user usually record outdoor activity in the form of trajectories, which can later be acquired for further analysis. In this work, we leverage Semantic Web technologies to propose an annotation algorithm that segments trajectories according to their spatial context. We demonstrate how the method work and the impact of OpenStreetMap related ontology in the annotation process.</p>"
6611;en_US;"<p>Gamification consists of the use of game mechanics and dynamics to engage people, solve problem, and improve learning. When applied in the classroom, it allows to arouse student curiosity and increase their motivation. This paper presents an experience report about the adoption of gamification elements in an elective course in the Information system at the Federal University of Pará, whose objective is to teach Web Programming. Thus, the activity of the discipline were organized in phases so that the student-player could follow a pre-established path of teaching-learning. Additionally, he scores system, medals and awards were defined. This report is described both from the point of view of teacher-facilitator (teaching) and student-player (learning).</p>"
6612;en_US;"<p>A computer programs performance is affected by the operational system (OS). Its possible to improve the performance by making use of the parallelism approach. To use this technique, the developer must know the operational system functionalities and how to utilize them. This article proposes the development of a program that uses parallelism with Hyper- Threading technology and its equivalent without parallelism. Therefore, a performance analysis is inferred by tracing a relationship between program performance and knowledge regarding operational system. The result showed that the performance of an application is directly related to the programmers knowledge about the OS.</p>"
6613;en_US;"<p>Computing skills are increasingly needed in contemporary life. This makes educators consider teaching computing from the initial grades of basic education. However, in addition to the need of defining reference curricula, our community needs to develop materials appropriate to the age of these student and to the Brazilian reality. This paper describes a proposal of a computing textbook for the sixth year of Brazilian middle school that seeks to integrate fundamental concepts of computer science, domain of technologies and computational thinking skills. Part of the developed materials were preliminarily used with sixth-grade student from a state public school. result suggest that the book has proven appropriate to the target audience, ensuring student immersion in the world of information technology.</p>"
6614;en_US;"<p>It is known that novice student have difficulties to learn programming. In the first programming course in higher education, such difficulties are more evident, and lead to high levels of dropout and failure. To deal with this issue in our institution, we held introductory programming workhops with Computer Engineering freshmen. We used a playful approach based on challenges and game building in Scratch and Python. result point to the advantages of Python as the first language, student high participation in the learning process, as well as their integration with classmates and senior student.</p>"
6615;en_US;"<p>Faced with the effort to use information and communication technologies (ICT) in the teaching-learning process, it aims to introduce digital tool to promote greater engagement and participation of student. One such tool is Kahoot!, a learning platform that uses digital-based learning for this purpose. Through teaching experiences in programming course, with this research, it was possible to observe that the Kahoot! functioned as a potentiating instrument for a greater participation and engagement of the student, besides helping to fix concepts related to the logic of programming.</p>"
6616;en_US;"<p>This paper reports an experience of undergratuate student teaching children in an elementary school basic concepts of programming. Aiming to set up an attractive and fun learning context, it was used an educational game named Robotizen. Its game design while enhance the experience of learning to code during the gameplay, also allowed researcher to come up with several new instructional strategies. The project was driven by a method that took in account stages of cognitive development of participant. Also, in strategically splitting the levels of Robotizen to achieve an iterative and collaborative model of learning. result suggests how potential is this game to engage and provide an environment to learn interest and discovery-driven.</p>"
6617;en_US;"<p>This paper reports an experience of teaching Computational Thinking (CT) to K-12 educators through an online Scratch programming short course. The meeting of CT and modern technologies is extending the use of coding in K-12 education. An essential requisite for this to prosper is the teacher prepa- ration. However, most current teacher training programs fail to supply with pedagogical knowledge for educators to teach CT. Thus, it is critical to present CT to K-12 teachers, providing proper conditions to learn and use its concepts. In this context, this work aimed to design and implement an online Scratch programming course for K-12 educators. result suggested that using Scratch to teach CT for K-12 educators is adequate, and analyzing educators context when presenting tutorial Scratch project is relevant.</p>"
6618;en_US;"<p>In Software Engineering higher education, besides learning theory and acquiring technical skills, student need to develop the ability to apply, evolve, and practice those skills throughout their lifetime. From 2016 to 2018, we had been adapting an introductory Software Engineering course from a theory-oriented course to a more practical experience for student. Therefore, the goal of this paper is to describe our experience incorporating Project-based Learning (PBL) principles and gamification elements in practical assignments for SE education. To achieve this goal, we present the structure of PBL project we have been using and how we adapted game elements to the context of SE education in order to create a gamified course. Based on our experience, we defined 17 guidelines that instructors may follow when defining a practical assignment for SE education. While PBL was helpful to create a practice-oriented teaching experience, gamification was not only useful in improving the engagement of student, but also in creating a roadmap of activity and a structure for student to self-assess their progress in the project.</p>"
6620;en_US;"<p>This article aims to propose activity for teaching childrens programming to be performed in any environment, without the need for computer. Sixteen activity were developed and applied to a public of three hundred and eighty three children and young people in three different environments: a public school, a summer course and workhops. In order to allow the reproduction of this experience in other times and spaces, a application for smart-phone was de- veloped and is available for free. Finally, it was observed that the student liked and enjoyed the activity and understood the main concepts of programming.</p>"
6622;en_US;"<p>This paper presents the EDATM method of teaching. This method aggregate exercises (E), dynamics (D) and play activity, lessons (A), evaluations through tests (T) and missions or challenges (M). The method assists the teacher in his pedagogical activity, guiding you to review contents, present new contents in a more fun way and measure the learning of his student with tests and challenges. Two different context of evaluation of the method are presented in the paper: elementary school student and higher education entrants. The result of self-evaluation of the student feeling in the elementary school classes showed positive levels for satisfaction, motivation, and control. The method was also evaluated by the student of higher education, satisfying the expectation in the learning of programming concepts.</p>"
6623;en_US;"<p>This paper aims to present an analysis of the strategies of the ML- SAI pedagogical model, which was developed to guide m-learning activity, based on the Inverse Classroom Theory (IC). To this end, a bibliographical research was carried out on the pedagogical model, aspects related to m- learning, the basic principles of IC and the structure and strategies of the ML- SAI. Next, we analyzed the result obtained with the experimentation of the model, in the discipline of introduction to programming, promoting some reflections and considerations about the same. These analyzes revealed that the model collaborates positively with the acquisition of knowledge and skills.</p>"
6624;en_US;"<p>This paper reports the experience undergone by student of the course of Degree in Computation of the University of Pernambuco Campus Garanhuns in the accomplishment of the discipline Supervised Stage IV. In this sense, the practice developed addresses the teaching of Computation in the blended mode with support from Google Classroom for Elementary School student. The result present opportunities that the teachers have when dealing with the teaching of Computation in the semipresencial modality in basic education. In addition, it was evidenced that the student of the elementary school managed to obtain an excellent performance in the face and distance classes in an autonomous, playful and pleasurable way.</p>"
6625;en_US;"<p>This article presents a teaching experience that involves the use of the WhatsApp application to perform extra class online, in the course of Web Programming of the course of Information system (IS). For that, a WhatsApp group was created in which the student could share the contents and at the end they answered an electronic questionnaire, obtaining 32 answers. The objective was to analyze the possibilities and potentialities of the use of extra class activity with the assistance of WhatsApp in Programming Teaching. It was found that online educational activity facilitated the promotion of teaching and learning of knowledge.</p>"
6626;en_US;"<p>This work constitutes the experience report of a preparatory course for the Brazilian Olympiad of Informatics (OBI) and algorithm solutions, with the purpose of stimulating the student for the computation, in addition to opportunizing the participation of student in scientific competitions. Thus, it was possible to verify the methodology used and to suggest a new teaching-learning approach. As a result, it was possible to obtain an improvement of the logical reasoning, to instruct the computational thinking and to encourage the interest for the learning in programming language of the involved ones, having as consequence a good classification in the phases of the OBI.</p>"
6628;en_US;"<p>This paper aims at analyzing educational tool for the compilers dis- cipline, which is considered complex, once considered the number of technique involved. Allied to this factor, there are not practically any comprehensive tool in this area. Focusing on this issue, the contribution of this research is a comparison between the Flex, JFlex, and GALS tool to the lexical analysis phase of the construction of a compiler. As final considerations, this research presented tool that can be used in the compilers teaching, providing the student with a wider interpretation at each stage of the compilation, making it possible for the Compiler discipline to be more attractive and didactic for student.</p>"
6629;en_US;"<p>Active learning has revolutionized education. By fostering greater interaction between student and teachers, active learning increases learning effectiveness and may help reducing the student dropout rate. However, active learning is challenging in an online environment, where student interact through online platforms such as those offered by CEDERJ. In this paper, we propose the use of interactive questionnaires to increase the interaction between student and teachers in CEDERJ distance learning course. Then, one of the challenges is to determine the difficulty of questions which, for the most part, are answered only once (i.e., as the number of questions is very large, we have at most one sample answer for each question). In order to overcome this challenge, we propose the use of machine learning to extract attributes from the questions and classify them according to these attributes. With the help of decision trees and a naive Bayes classifier, preliminary result indicate that the difficulty level of questions can be automatically inferred.</p>"
6630;en_US;"<p>This paper presents a way of evaluating and validating a gamified framework for the teaching and learning process of algorithm. In the research we report the planning for the experiment, the SWOT matrix evaluation adapted to the practices worked in the classroom, the cases that occurred, the quantitative data generated by the gamification. The main contribution of the work is to inform that gamification promotes engagement and enables the teaching and learning of algorithm, from the use of a framework.</p>"
6632;en_US;"<p>This initial work aimed to identify attributes of student, detectable in the first two weeks of the undergraduate program, that present a strong correlation with parameters identified in literature as associated with risk of evasion. This is an exploratory research, quantitative approach, characterized as evaluation research, delimited to three undergraduate programs in the area of Computing, with incoming student from 2012 to 2018, at Federal University of Amazonas (UFAM). It was observed that the following attributes are significantly associated to a good GPA in the first term: participation of welcome activity for freshmen, affirmative policy, modality of High School, previous knowledge in programming, and choice of the program as first option.</p>"
6633;en_US;"<p>Computer programming is an important activity that allows for the development of logical thinking and creativity, increasing the problem-solving ability of those who know how to program. However, programming learning requires a high degree of abstraction, as well as time and effort from the apprentice. In this paper we conduct a survey with student of Computer course, trying to identify the barriers and difficulties related to programming learning. The result indicate the need for new approaches (combined with current teaching practices) that make programming learning more attractive, interactive and playful, instigating the interest and engagement of the student.</p>"
6634;en_US;"<p>There is growing need for intelligent environments for distance learning. One of its elements is a system of automatic evaluation of conceptual discursive issues. In this work, we propose a method of automatic evaluation of a test in the Portuguese language based on the refinement of content, coherence and surface statistics feature to predict the score of an essay. The accuracy of the system was contrasted with the accuracy measured between two human evaluators (HxH), which resulted in an average error value of 0.91 SxH versus 0.89 HxH and a quadratic kappa accuracy of 0.62 SxH versus 0.52 HxH.This study shows that this technology is reaching maturity for use in environments.</p>"
6635;en_US;"<p>Graphic contents are key resource to display certain informations. People with visual impairments do not have an easy access to this resource because of their impairment. Assistive technologies have been developed to help them access graphic content. This article presents a systematic review of the literature that aims at conducting a survey about assistive technologies developed to assist visual impaired people in reading and interpreting graphic contents. The review followed the proposed guidelines for this kind of research and, as a result, presents 51 studies about technologies that help visual impairment peoples in the creation and reading of graphic contents. We observed that, in this field of research, it is possible to improve technologies that will help to reduce the limitations found by the visually impaired individuals in accessing graphic contents and thus to reach higher levels of accessibility.</p>"
6636;en_US;"<p>Learning programming is a challenging task for many novice student in Computer Science programs. This article proposes the use of Coding Dojos while teaching introductory programming aiming to evaluate if this practice influences aspects related to motivation, collaboration and learning. Data obtained are a result of surveys applied with novices of two introductory programming course. The result point to the following general positive conclusions: programming Dojos might encourage student to learn in a more participative and motivated way; and create a collaborative environment that work in favor of learning. On the other hand, some negative aspects emerged: in some classes coding with a colleague is a big challenge.</p>"
6637;en_US;"<p>The discussion about teaching and learning process has been the subject of research in Computer Science (CS) in Brazil and abroad. Teacher training in CS for higher education should also be thematic of research and action. In this sense, this paper presents an expansion in the scope of an initial research, presented previously, with a quantitative documentary analysis of the master and doctoral course of the Brazilian CS area. As a result, the emphasis is placed on research to the detriment of university teacher training at masters and doctoral course, which is contrary to the first objective of the Brazilian post-graduation stricto sensu given by the Parecer MEC/CESu no. 977/65.</p>"
6638;en_US;"<p>The area of Software Engineering (ES) consists of several sub-area and is usually taught in disciplines with a dense theoretical-conceptual content distributed in the curricular matrix of undergraduate course. In this context, several researcher have sought to create a motivating environment by proposing ES teaching technique, tool and experiences. Based on semistructured interviews with five Professors and eighteen student from disciplines related to the ES of an undergraduate course in Information system, this work presents an analysis of problem and solutions from the perspective of faculty and student in a Federal Institution. Despite being based on a single case study, the result generate reflections on the teaching of Software Engineering in course in the area of computing.</p>"
6639;en_US;"<p>The high rate of dropout in technology course is a challenge faced by a large number of educational institutions. Therefore, identifying the risk of student dropout is relevant once actions can be taken to encourage permanence and success. In this context, this paper presents a proposal for predicting dropouts at educational institutions considering academic and socioeconomic information of student. In particular, one of the proposal steps involves the application of Machine Learning algorithm. A case study is presented making use of a 8-years dataset of a Computer Technician course at IFCE. The result demonstrate the effectiveness of the proposal, reaching an accuracy about 97.97% to predict student situation.</p>"
6640;en_US;"<p>Software Engineering aims to support the development of quality computer system, reducing production costs and increasing the productivity of practitioners. Understanding the needs of beginning student in this research area is vital in order to propose appropriate teaching methodologies. This paper presents the result of the application of a questionnaire regarding the student experience of an introductory course on Software Engineering. We captured the expectation of student who have not yet studied software engineering, as well as the vision of student who have already attended, reproving or not. The result of this research allowed identifying possible aspects that may have a positive or negative influence on the learning process.</p>"
6641;en_US;"<p>algorithm can be defined as a sequence of executable actions to obtain a solution for many kind of problem. The discipline of algorithm, which is the first contact the student with Computer Programming, and beyond all is the basis of any course of Computing. However, for many student, there is a difficulty in the course, in which the problem is often due to technical impasses, which hinder the development of the algorithm, many technologies are used for the elaboration of algorithm and many of them have peculiarities that make the student have obstacles. Faced with these difficulties, there may be cases in which the teacher can not identify the frequency of these errors, which are motivated by technical order. This work aims to proposes the creation of programmatic technical content, and it is suggested from the data mining process of the StackOverflow data base that contains specific aspects of the discipline of programming. Some preliminary result of this model have already been obtained with the accuracy level of data greater than 90%.</p>"
6642;en_US;"<p>The low student performance in CS0 course is a common scenario in undergraduate programs in science and engineering. External factors to the academic environment are as decisive in relation of these student result as the inherent aspects of the learning process. Based on the application of educational data mining technique on the data of a Brazilian higher education institution, the student performance in a CS0 course for non-majors was observed to be correlated to previous socioeconomic and educational characteristics or to a subset created from the combination of these attributes. In its turn, the early identification of student at risk of failure can help to mitigate dropout in CS0 course.</p>"
6643;en_US;"<p>This article describes an experience report of an intervention project, in which gamification was used to teach algorithm. The activity were developed in an 8th grade (eighth) year of elementary school at a public school, in the municipality of Capitão Poço-PA. This presented the purpose of assisting in the development of logic of programming and logical reasoning, in addition to providing student with adaptation in different educational environments and the comprehension and importance of the algorithm in daily life for problem solving. The result showed that most of the student were able to understand the proposal and constructed knowledge about computing in a practical, interactive and dynamic way.</p>"
6644;en_US;"<p>The student assessment, formative or summative, is a topic of interest in Computer Science Education. One of the important functions of the assessment is to estimate the risk of some student do not obtain a satisfactory performance in the discipline. This mapping is intended to list the difficulties of predicting the final performance of student in of the course of Computer Science, in the beginning of the discipline, as well as proposed method for such. The mapping has special emphasis on identifying method that use data from teaching methodologies to adopt continuous, formative evaluation, like the Peer Instruction. In total, 81 paper were found. When applying the inclusion and exclusion criteria, it was selected 33 paper for a perusal, which led the choice of 18 paper for this work. During the mapping, it was realized that it is possible to predict, with a certain level of accuracy, student with risk of rejection and that, once avoiding her, to reduce the chance of evasion of these student.</p>"
6645;en_US;"<p>Many researches deal with the values and principles of agile methodologies. Philosophy is the basis for the main practices proposed by these methodologies. However, few studies deal with the impact of agile philosophy on success/failure of a software project. This paper presents an analysis of student learning in academic software project that follow the practices and values of the Scrum framework. We seek to qualitatively analyze the impact of commitment, communication and teamwork on the outcome of these software project through a case study. The result of this research suggest that the absorption of these values by the teams impacts directly on the follow-up of the practices of Scrum and, consequently, on the success of the project.</p>"
6646;en_US;"<p>In the last decade, there has been an expansion of policies to encourage student to enter higher education. However, the same concern was not observed with regard to retaining these student in these system. The area of Information Technology is one of those that most needs the workforce. To meet the demands of the market, it is necessary to train qualified professionals. However, their course present a higher dropout rate. Thus, aiming to incentive the permanence of student, the present study intends to draw a comparison between the characteristics of student who gave up from a course in this area and the student who were successful and completed the same course. The result demonstrate the social and professional transformation that alumni have passed. In addition, we outline possible reasons that may have contributed to the student evasion.</p>"
6647;en_US;"<p>Teachers currently deal with student who interact with digital technologies, so it is necessary to use teaching methodologies that attract attention and motivate them to learn. When teaching theoretical subjects in the area of computation was verified dispersion, demotivation and low income of the student. Aiming to make the teaching-learning process attractive, the methodology was proposed: EduGamification, which uses gamification and active methodologies. Initially a bibliographical research was done on the subject, afterwards, after the application of the methodology in three case studies, and after the feedback of the student, adjustments were made, aiming to improve it. To validate it, a qualitative and quantitative analysis was carried out and it was verified that there was an increase in the engagement and the academic performance.</p>"
6648;en_US;"<p>The article presents the 7Cs Methodology, which consists of a proposal culminating in the product of the master of the stricto sensu postgraduate program in creativity and innovation in methodology of higher education of the Federal University of Pará. This methodology aims to minimize the difficulties faced by undergraduate student in Computer undergraduate course or equivalent in the process of learning by providing the understanding of the algorithm basic contents based on a new form of pratice construction of algorithm, supported by Ausubels Meaningful Learning theory (2000).</p>"
6649;en_US;"<p>The significant difference between the percentage of men and women in Computer-related course Is remarkable. In Order to understand the reasons for the low number and high degree of evasion of girls enrolled in this area, studies and project have been developed, outlining actions to add more women to the field of technology. Thus, this article presents the levels of female participation in the Information system course of the state of Alagoas, considering the number of entrantmen and the enrolled student, which result in very low percentages when compared to the number Of men in this field. From the initial result, intervention initiatives are proposed, aimed at attracting, retaining and increasing the representativeness of the female gender in Computing, discussing the professional and social equity between genders, in addition to delineating the Next steps of this work.</p>"
6650;en_US;"<p>The Brazilian Olympiad of Informatics is an annual event to middleschool and high-school student. In the modality called “Initiation”, participant have to answer logic problem without the use of a computer. One method to study is by resolving previous tests. In Brazil, some project offer trains to participant in the Olympiads. However, choose specific questions to compose study material can be a tough task. This paper presents Pratique OBI, a web system to create personalized tests and to easily consult questions to support trains for the Initiation modality. We performed user tests with tutors of a project to train participant, and made improvements that are available for all.</p>"
6651;en_US;"<p>Database Management system (DBMS) are fundamental in day-to-day, for this reason, learning it is essential for professionals in the field. In addition, the topic is approached in computer course at universities which, in turn, encourage the student to practice. This study aims to present an E-learning CASE tool that support the learning of Transactions and Concurrency Control in Relational DBMS. The evaluation of the prototype was performed with specialists and a class of Database system through the application of the TAM(Technology Acceptance Model) model and in the application of exercises. The result were satisfactory, showing that the tool had achieved good performance and acceptance.</p>"
6652;en_US;"<p>computer programming has been adopted as tool to conceive scientifically and technologically literate people. However, professors face challenges during the teaching process, especially when student have special needs. Recent studies show that visual tool, such as teaching software, facilitate the understanding of the contents, even if tool is not linked with the teaching material. Thus, we propose the creation of a programming teaching methodology for deaf student, called Symbolic Teaching Methodology. The Methodology integrates the Symbolic Didactic Material and Educational Software, both created for this purpose.</p>"
6653;en_US;"<p>Teaching Computing fundamentals in primary and secondary education has been advocated as a necessity, but it is also recognized as a major challenge. student are familiar with a connected world, so it is important that pedagogical resource align with this reality. Aiming to contribute in this direction, this article presents the project HortaDuino, a resource that integrates hardware and software tool to explore concepts of Computing associated with the Internet of Things, with the theme of irrigation and monitoring of a school garden. The resource was appreciated in a primary school and the result indicate that the approach was well accepted, as well as motivating student to learn more about the subject.</p>"
6654;en_US;"<p>This paper presents Computação Plugada, an application for developing computational thinking skills. Its main goal is to simplify teaching involving unplugged computing activity and also allow user to individually learn the concepts with automatic feedback. The application is easy to use an is built upon the well known Computer Science Unplugged lessons.</p>"
6655;en_US;"<p>The learning of dynamic routing protocol requires complementary approaches because of their complexity. One of such approaches is the use of serious game. This paper describes the development of RIPChallenge, a serious game specifically aimed to boost the learning of the RIP protocol. The game has as major points its easiness to play and the addressing of protocol’s operating characteristics student report more dificult to learn about. It was validated using the EGameFlow methodology, which shown it helped student to get a better confidence about the understanding of those characteristics</p>"
6656;en_US;"<p>The goal of this paper is to show the advances of the IDE didactic Portugol Studio (PS) in these last 5 years detailing the improvements made in the newer versions, the enhancements focused in expanding the usability of the tool, video lessons, didactic material produced by its user, emphasize the interface for the development of plugins, the produced work and show the user profiles the platform attends. Lastly to invite the community to develop new plugins and evolve PS.</p>"
6657;en_US;"<p>This paper presents the prototype of a serious game called Curupira Machine that aims to present the concept of the Turing Machine in a playful way. This is inspired in a scenario that emphasize the environmental responsibility. In the scenario, the main character has the mission to rescue caged animals and, for this, needs to decipher the codes using a Turing Machine. The game it was developed following a puzzle strategy, for the Android platform and third-person perspective. In solving the puzzle, the player develops Computational Thinking through the creation of strategies and algorithm to solve the problem proposed.</p>"
6658;en_US;"<p>Educational game have been gaining more space and facilitating the teaching-learning process. Software testing is one of the most important tasks of the software development process, to ensure the quality of the product. Due to this importance and aiming to make the lectures more attractive and motivating, an online tool was developed with the objective of offering an educational game, called IslandTest, to help the teaching-learning process in the area of software testing. For the development of the game, the language PHP (Hypertext Preprocessor), JavaScript, CSS and HTML and MySQL database were used. The game was validated by student regarding motivation, user experience, learning and learning objectives and the result showed that it facilitated the teaching-learning process of software testing</p>"
6659;en_US;"Gamification consists of the use of game mechanics and dynamics to engage people, solve problem, and improve learning. When applied in the classroom, it allows to arouse student curiosity and increase their motivation. This paper presents an experience report about the adoption of gamification elements in an elective course in the Information system at the Federal University of Pará, whose objective is to teach Web Programming. Thus, the activity of the discipline were organized in phases so that the student-player could follow a pre-established path of teaching-learning. Additionally, he scores system, medals and awards were defined. This report is described both from the point of view of teacher-facilitator (teaching) and student-player (learning)."
6660;en_US;"A computer programs performance is affected by the operational system (OS). Its possible to improve the performance by making use of the parallelism approach. To use this technique, the developer must know the operational system functionalities and how to utilize them. This article proposes the development of a program that uses parallelism with Hyper- Threading technology and its equivalent without parallelism. Therefore, a performance analysis is inferred by tracing a relationship between program performance and knowledge regarding operational system. The result showed that the performance of an application is directly related to the programmers knowledge about the OS."
6661;en_US;"Computing skills are increasingly needed in contemporary life. This makes educators consider teaching computing from the initial grades of basic education. However, in addition to the need of defining reference curricula, our community needs to develop materials appropriate to the age of these student and to the Brazilian reality. This paper describes a proposal of a computing textbook for the sixth year of Brazilian middle school that seeks to integrate fundamental concepts of computer science, domain of technologies and computational thinking skills. Part of the developed materials were preliminarily used with sixth-grade student from a state public school. result suggest that the book has proven appropriate to the target audience, ensuring student immersion in the world of information technology."
6662;en_US;"It is known that novice student have difficulties to learn programming. In the first programming course in higher education, such difficulties are more evident, and lead to high levels of dropout and failure. To deal with this issue in our institution, we held introductory programming workhops with Computer Engineering freshmen. We used a playful approach based on challenges and game building in Scratch and Python. result point to the advantages of Python as the first language, student high participation in the learning process, as well as their integration with classmates and senior student."
6663;en_US;"Faced with the effort to use information and communication technologies (ICT) in the teaching-learning process, it aims to introduce digital tool to promote greater engagement and participation of student. One such tool is Kahoot!, a learning platform that uses digital-based learning for this purpose. Through teaching experiences in programming course, with this research, it was possible to observe that the Kahoot! functioned as a potentiating instrument for a greater participation and engagement of the student, besides helping to fix concepts related to the logic of programming."
6664;en_US;"This paper reports an experience of undergratuate student teaching children in an elementary school basic concepts of programming. Aiming to set up an attractive and fun learning context, it was used an educational game named Robotizen. Its game design while enhance the experience of learning to code during the gameplay, also allowed researcher to come up with several new instructional strategies. The project was driven by a method that took in account stages of cognitive development of participant. Also, in strategically splitting the levels of Robotizen to achieve an iterative and collaborative model of learning. result suggests how potential is this game to engage and provide an environment to learn interest and discovery-driven."
6665;en_US;"This paper reports an experience of teaching Computational Thinking (CT) to K-12 educators through an online Scratch programming short course. The meeting of CT and modern technologies is extending the use of coding in K-12 education. An essential requisite for this to prosper is the teacher prepa- ration. However, most current teacher training programs fail to supply with pedagogical knowledge for educators to teach CT. Thus, it is critical to present CT to K-12 teachers, providing proper conditions to learn and use its concepts. In this context, this work aimed to design and implement an online Scratch programming course for K-12 educators. result suggested that using Scratch to teach CT for K-12 educators is adequate, and analyzing educators context when presenting tutorial Scratch project is relevant."
6666;en_US;"In Software Engineering higher education, besides learning theory and acquiring technical skills, student need to develop the ability to apply, evolve, and practice those skills throughout their lifetime. From 2016 to 2018, we had been adapting an introductory Software Engineering course from a theory-oriented course to a more practical experience for student. Therefore, the goal of this paper is to describe our experience incorporating Project-based Learning (PBL) principles and gamification elements in practical assignments for SE education. To achieve this goal, we present the structure of PBL project we have been using and how we adapted game elements to the context of SE education in order to create a gamified course. Based on our experience, we defined 17 guidelines that instructors may follow when defining a practical assignment for SE education. While PBL was helpful to create a practice-oriented teaching experience, gamification was not only useful in improving the engagement of student, but also in creating a roadmap of activity and a structure for student to self-assess their progress in the project."
6668;en_US;"This article aims to propose activity for teaching childrens programming to be performed in any environment, without the need for computer. Sixteen activity were developed and applied to a public of three hundred and eighty three children and young people in three different environments: a public school, a summer course and workhops. In order to allow the reproduction of this experience in other times and spaces, a application for smart-phone was de- veloped and is available for free. Finally, it was observed that the student liked and enjoyed the activity and understood the main concepts of programming."
6670;en_US;"This paper presents the EDATM method of teaching. This method aggregate exercises (E), dynamics (D) and play activity, lessons (A), evaluations through tests (T) and missions or challenges (M). The method assists the teacher in his pedagogical activity, guiding you to review contents, present new contents in a more fun way and measure the learning of his student with tests and challenges. Two different context of evaluation of the method are presented in the paper: elementary school student and higher education entrants. The result of self-evaluation of the student feeling in the elementary school classes showed positive levels for satisfaction, motivation, and control. The method was also evaluated by the student of higher education, satisfying the expectation in the learning of programming concepts."
6671;en_US;"This paper aims to present an analysis of the strategies of the ML- SAI pedagogical model, which was developed to guide m-learning activity, based on the Inverse Classroom Theory (IC). To this end, a bibliographical research was carried out on the pedagogical model, aspects related to m- learning, the basic principles of IC and the structure and strategies of the ML- SAI. Next, we analyzed the result obtained with the experimentation of the model, in the discipline of introduction to programming, promoting some reflections and considerations about the same. These analyzes revealed that the model collaborates positively with the acquisition of knowledge and skills."
6672;en_US;"This paper reports the experience undergone by student of the course of Degree in Computation of the University of Pernambuco Campus Garanhuns in the accomplishment of the discipline Supervised Stage IV. In this sense, the practice developed addresses the teaching of Computation in the blended mode with support from Google Classroom for Elementary School student. The result present opportunities that the teachers have when dealing with the teaching of Computation in the semipresencial modality in basic education. In addition, it was evidenced that the student of the elementary school managed to obtain an excellent performance in the face and distance classes in an autonomous, playful and pleasurable way."
6673;en_US;"This article presents a teaching experience that involves the use of the WhatsApp application to perform extra class online, in the course of Web Programming of the course of Information system (IS). For that, a WhatsApp group was created in which the student could share the contents and at the end they answered an electronic questionnaire, obtaining 32 answers. The objective was to analyze the possibilities and potentialities of the use of extra class activity with the assistance of WhatsApp in Programming Teaching. It was found that online educational activity facilitated the promotion of teaching and learning of knowledge."
6674;en_US;"This work constitutes the experience report of a preparatory course for the Brazilian Olympiad of Informatics (OBI) and algorithm solutions, with the purpose of stimulating the student for the computation, in addition to opportunizing the participation of student in scientific competitions. Thus, it was possible to verify the methodology used and to suggest a new teaching-learning approach. As a result, it was possible to obtain an improvement of the logical reasoning, to instruct the computational thinking and to encourage the interest for the learning in programming language of the involved ones, having as consequence a good classification in the phases of the OBI."
6676;en_US;"This paper aims at analyzing educational tool for the compilers dis- cipline, which is considered complex, once considered the number of technique involved. Allied to this factor, there are not practically any comprehensive tool in this area. Focusing on this issue, the contribution of this research is a comparison between the Flex, JFlex, and GALS tool to the lexical analysis phase of the construction of a compiler. As final considerations, this research presented tool that can be used in the compilers teaching, providing the student with a wider interpretation at each stage of the compilation, making it possible for the Compiler discipline to be more attractive and didactic for student."
6677;en_US;"Active learning has revolutionized education. By fostering greater interaction between student and teachers, active learning increases learning effectiveness and may help reducing the student dropout rate. However, active learning is challenging in an online environment, where student interact through online platforms such as those offered by CEDERJ. In this paper, we propose the use of interactive questionnaires to increase the interaction between student and teachers in CEDERJ distance learning course. Then, one of the challenges is to determine the difficulty of questions which, for the most part, are answered only once (i.e., as the number of questions is very large, we have at most one sample answer for each question). In order to overcome this challenge, we propose the use of machine learning to extract attributes from the questions and classify them according to these attributes. With the help of decision trees and a naive Bayes classifier, preliminary result indicate that the difficulty level of questions can be automatically inferred."
6678;en_US;"This paper presents a way of evaluating and validating a gamified framework for the teaching and learning process of algorithm. In the research we report the planning for the experiment, the SWOT matrix evaluation adapted to the practices worked in the classroom, the cases that occurred, the quantitative data generated by the gamification. The main contribution of the work is to inform that gamification promotes engagement and enables the teaching and learning of algorithm, from the use of a framework."
6680;en_US;"This initial work aimed to identify attributes of student, detectable in the first two weeks of the undergraduate program, that present a strong correlation with parameters identified in literature as associated with risk of evasion. This is an exploratory research, quantitative approach, characterized as evaluation research, delimited to three undergraduate programs in the area of Computing, with incoming student from 2012 to 2018, at Federal University of Amazonas (UFAM). It was observed that the following attributes are significantly associated to a good GPA in the first term: participation of welcome activity for freshmen, affirmative policy, modality of High School, previous knowledge in programming, and choice of the program as first option."
6681;en_US;"Computer programming is an important activity that allows for the development of logical thinking and creativity, increasing the problem-solving ability of those who know how to program. However, programming learning requires a high degree of abstraction, as well as time and effort from the apprentice. In this paper we conduct a survey with student of Computer course, trying to identify the barriers and difficulties related to programming learning. The result indicate the need for new approaches (combined with current teaching practices) that make programming learning more attractive, interactive and playful, instigating the interest and engagement of the student."
6682;en_US;"There is growing need for intelligent environments for distance learning. One of its elements is a system of automatic evaluation of conceptual discursive issues. In this work, we propose a method of automatic evaluation of a test in the Portuguese language based on the refinement of content, coherence and surface statistics feature to predict the score of an essay. The accuracy of the system was contrasted with the accuracy measured between two human evaluators (HxH), which resulted in an average error value of 0.91 SxH versus 0.89 HxH and a quadratic kappa accuracy of 0.62 SxH versus 0.52 HxH.This study shows that this technology is reaching maturity for use in environments."
6683;en_US;"Graphic contents are key resource to display certain informations. People with visual impairments do not have an easy access to this resource because of their impairment. Assistive technologies have been developed to help them access graphic content. This article presents a systematic review of the literature that aims at conducting a survey about assistive technologies developed to assist visual impaired people in reading and interpreting graphic contents. The review followed the proposed guidelines for this kind of research and, as a result, presents 51 studies about technologies that help visual impairment peoples in the creation and reading of graphic contents. We observed that, in this field of research, it is possible to improve technologies that will help to reduce the limitations found by the visually impaired individuals in accessing graphic contents and thus to reach higher levels of accessibility."
6684;en_US;"Learning programming is a challenging task for many novice student in Computer Science programs. This article proposes the use of Coding Dojos while teaching introductory programming aiming to evaluate if this practice influences aspects related to motivation, collaboration and learning. Data obtained are a result of surveys applied with novices of two introductory programming course. The result point to the following general positive conclusions: programming Dojos might encourage student to learn in a more participative and motivated way; and create a collaborative environment that work in favor of learning. On the other hand, some negative aspects emerged: in some classes coding with a colleague is a big challenge."
6685;en_US;"The discussion about teaching and learning process has been the subject of research in Computer Science (CS) in Brazil and abroad. Teacher training in CS for higher education should also be thematic of research and action. In this sense, this paper presents an expansion in the scope of an initial research, presented previously, with a quantitative documentary analysis of the master and doctoral course of the Brazilian CS area. As a result, the emphasis is placed on research to the detriment of university teacher training at masters and doctoral course, which is contrary to the first objective of the Brazilian post-graduation stricto sensu given by the Parecer MEC/CESu no. 977/65."
6686;en_US;"The area of Software Engineering (ES) consists of several sub-area and is usually taught in disciplines with a dense theoretical-conceptual content distributed in the curricular matrix of undergraduate course. In this context, several researcher have sought to create a motivating environment by proposing ES teaching technique, tool and experiences. Based on semistructured interviews with five Professors and eighteen student from disciplines related to the ES of an undergraduate course in Information system, this work presents an analysis of problem and solutions from the perspective of faculty and student in a Federal Institution. Despite being based on a single case study, the result generate reflections on the teaching of Software Engineering in course in the area of computing."
6687;en_US;"The high rate of dropout in technology course is a challenge faced by a large number of educational institutions. Therefore, identifying the risk of student dropout is relevant once actions can be taken to encourage permanence and success. In this context, this paper presents a proposal for predicting dropouts at educational institutions considering academic and socioeconomic information of student. In particular, one of the proposal steps involves the application of Machine Learning algorithm. A case study is presented making use of a 8-years dataset of a Computer Technician course at IFCE. The result demonstrate the effectiveness of the proposal, reaching an accuracy about 97.97% to predict student situation."
6688;en_US;"Software Engineering aims to support the development of quality computer system, reducing production costs and increasing the productivity of practitioners. Understanding the needs of beginning student in this research area is vital in order to propose appropriate teaching methodologies. This paper presents the result of the application of a questionnaire regarding the student experience of an introductory course on Software Engineering. We captured the expectation of student who have not yet studied software engineering, as well as the vision of student who have already attended, reproving or not. The result of this research allowed identifying possible aspects that may have a positive or negative influence on the learning process."
6689;en_US;"algorithm can be defined as a sequence of executable actions to obtain a solution for many kind of problem. The discipline of algorithm, which is the first contact the student with Computer Programming, and beyond all is the basis of any course of Computing. However, for many student, there is a difficulty in the course, in which the problem is often due to technical impasses, which hinder the development of the algorithm, many technologies are used for the elaboration of algorithm and many of them have peculiarities that make the student have obstacles. Faced with these difficulties, there may be cases in which the teacher can not identify the frequency of these errors, which are motivated by technical order. This work aims to proposes the creation of programmatic technical content, and it is suggested from the data mining process of the StackOverflow data base that contains specific aspects of the discipline of programming. Some preliminary result of this model have already been obtained with the accuracy level of data greater than 90%."
6690;en_US;"The low student performance in CS0 course is a common scenario in undergraduate programs in science and engineering. External factors to the academic environment are as decisive in relation of these student result as the inherent aspects of the learning process. Based on the application of educational data mining technique on the data of a Brazilian higher education institution, the student performance in a CS0 course for non-majors was observed to be correlated to previous socioeconomic and educational characteristics or to a subset created from the combination of these attributes. In its turn, the early identification of student at risk of failure can help to mitigate dropout in CS0 course."
6691;en_US;"This article describes an experience report of an intervention project, in which gamification was used to teach algorithm. The activity were developed in an 8th grade (eighth) year of elementary school at a public school, in the municipality of Capitão Poço-PA. This presented the purpose of assisting in the development of logic of programming and logical reasoning, in addition to providing student with adaptation in different educational environments and the comprehension and importance of the algorithm in daily life for problem solving. The result showed that most of the student were able to understand the proposal and constructed knowledge about computing in a practical, interactive and dynamic way."
6692;en_US;"The student assessment, formative or summative, is a topic of interest in Computer Science Education. One of the important functions of the assessment is to estimate the risk of some student do not obtain a satisfactory performance in the discipline. This mapping is intended to list the difficulties of predicting the final performance of student in of the course of Computer Science, in the beginning of the discipline, as well as proposed method for such. The mapping has special emphasis on identifying method that use data from teaching methodologies to adopt continuous, formative evaluation, like the Peer Instruction. In total, 81 paper were found. When applying the inclusion and exclusion criteria, it was selected 33 paper for a perusal, which led the choice of 18 paper for this work. During the mapping, it was realized that it is possible to predict, with a certain level of accuracy, student with risk of rejection and that, once avoiding her, to reduce the chance of evasion of these student."
6693;en_US;"Many researches deal with the values and principles of agile methodologies. Philosophy is the basis for the main practices proposed by these methodologies. However, few studies deal with the impact of agile philosophy on success/failure of a software project. This paper presents an analysis of student learning in academic software project that follow the practices and values of the Scrum framework. We seek to qualitatively analyze the impact of commitment, communication and teamwork on the outcome of these software project through a case study. The result of this research suggest that the absorption of these values by the teams impacts directly on the follow-up of the practices of Scrum and, consequently, on the success of the project."
6694;en_US;"In the last decade, there has been an expansion of policies to encourage student to enter higher education. However, the same concern was not observed with regard to retaining these student in these system. The area of Information Technology is one of those that most needs the workforce. To meet the demands of the market, it is necessary to train qualified professionals. However, their course present a higher dropout rate. Thus, aiming to incentive the permanence of student, the present study intends to draw a comparison between the characteristics of student who gave up from a course in this area and the student who were successful and completed the same course. The result demonstrate the social and professional transformation that alumni have passed. In addition, we outline possible reasons that may have contributed to the student evasion."
6695;en_US;"Teachers currently deal with student who interact with digital technologies, so it is necessary to use teaching methodologies that attract attention and motivate them to learn. When teaching theoretical subjects in the area of computation was verified dispersion, demotivation and low income of the student. Aiming to make the teaching-learning process attractive, the methodology was proposed: EduGamification, which uses gamification and active methodologies. Initially a bibliographical research was done on the subject, afterwards, after the application of the methodology in three case studies, and after the feedback of the student, adjustments were made, aiming to improve it. To validate it, a qualitative and quantitative analysis was carried out and it was verified that there was an increase in the engagement and the academic performance."
6696;en_US;"The article presents the 7Cs Methodology, which consists of a proposal culminating in the product of the master of the stricto sensu postgraduate program in creativity and innovation in methodology of higher education of the Federal University of Pará. This methodology aims to minimize the difficulties faced by undergraduate student in Computer undergraduate course or equivalent in the process of learning by providing the understanding of the algorithm basic contents based on a new form of pratice construction of algorithm, supported by Ausubels Meaningful Learning theory (2000)."
6697;en_US;"The significant difference between the percentage of men and women in Computer-related course Is remarkable. In Order to understand the reasons for the low number and high degree of evasion of girls enrolled in this area, studies and project have been developed, outlining actions to add more women to the field of technology. Thus, this article presents the levels of female participation in the Information system course of the state of Alagoas, considering the number of entrantmen and the enrolled student, which result in very low percentages when compared to the number Of men in this field. From the initial result, intervention initiatives are proposed, aimed at attracting, retaining and increasing the representativeness of the female gender in Computing, discussing the professional and social equity between genders, in addition to delineating the Next steps of this work."
6698;en_US;"The Brazilian Olympiad of Informatics is an annual event to middleschool and high-school student. In the modality called “Initiation”, participant have to answer logic problem without the use of a computer. One method to study is by resolving previous tests. In Brazil, some project offer trains to participant in the Olympiads. However, choose specific questions to compose study material can be a tough task. This paper presents Pratique OBI, a web system to create personalized tests and to easily consult questions to support trains for the Initiation modality. We performed user tests with tutors of a project to train participant, and made improvements that are available for all."
6699;en_US;"Database Management system (DBMS) are fundamental in day-to-day, for this reason, learning it is essential for professionals in the field. In addition, the topic is approached in computer course at universities which, in turn, encourage the student to practice. This study aims to present an E-learning CASE tool that support the learning of Transactions and Concurrency Control in Relational DBMS. The evaluation of the prototype was performed with specialists and a class of Database system through the application of the TAM(Technology Acceptance Model) model and in the application of exercises. The result were satisfactory, showing that the tool had achieved good performance and acceptance."
6700;en_US;"computer programming has been adopted as tool to conceive scientifically and technologically literate people. However, professors face challenges during the teaching process, especially when student have special needs. Recent studies show that visual tool, such as teaching software, facilitate the understanding of the contents, even if tool is not linked with the teaching material. Thus, we propose the creation of a programming teaching methodology for deaf student, called Symbolic Teaching Methodology. The Methodology integrates the Symbolic Didactic Material and Educational Software, both created for this purpose."
6701;en_US;"Teaching Computing fundamentals in primary and secondary education has been advocated as a necessity, but it is also recognized as a major challenge. student are familiar with a connected world, so it is important that pedagogical resource align with this reality. Aiming to contribute in this direction, this article presents the project HortaDuino, a resource that integrates hardware and software tool to explore concepts of Computing associated with the Internet of Things, with the theme of irrigation and monitoring of a school garden. The resource was appreciated in a primary school and the result indicate that the approach was well accepted, as well as motivating student to learn more about the subject."
6702;en_US;"This paper presents Computação Plugada, an application for developing computational thinking skills. Its main goal is to simplify teaching involving unplugged computing activity and also allow user to individually learn the concepts with automatic feedback. The application is easy to use an is built upon the well known Computer Science Unplugged lessons."
6703;en_US;"The learning of dynamic routing protocol requires complementary approaches because of their complexity. One of such approaches is the use of serious game. This paper describes the development of RIPChallenge, a serious game specifically aimed to boost the learning of the RIP protocol. The game has as major points its easiness to play and the addressing of protocol’s operating characteristics student report more dificult to learn about. It was validated using the EGameFlow methodology, which shown it helped student to get a better confidence about the understanding of those characteristics"
6704;en_US;" The goal of this paper is to show the advances of the IDE didactic Portugol Studio (PS) in these last 5 years detailing the improvements made in the newer versions, the enhancements focused in expanding the usability of the tool, video lessons, didactic material produced by its user, emphasize the interface for the development of plugins, the produced work and show the user profiles the platform attends. Lastly to invite the community to develop new plugins and evolve PS."
6705;en_US;"This paper presents the prototype of a serious game called Curupira Machine that aims to present the concept of the Turing Machine in a playful way. This is inspired in a scenario that emphasize the environmental responsibility. In the scenario, the main character has the mission to rescue caged animals and, for this, needs to decipher the codes using a Turing Machine. The game it was developed following a puzzle strategy, for the Android platform and third-person perspective. In solving the puzzle, the player develops Computational Thinking through the creation of strategies and algorithm to solve the problem proposed."
6706;en_US;" Educational game have been gaining more space and facilitating the teaching-learning process. Software testing is one of the most important tasks of the software development process, to ensure the quality of the product. Due to this importance and aiming to make the lectures more attractive and motivating, an online tool was developed with the objective of offering an educational game, called IslandTest, to help the teaching-learning process in the area of software testing. For the development of the game, the language PHP (Hypertext Preprocessor), JavaScript, CSS and HTML and MySQL database were used. The game was validated by student regarding motivation, user experience, learning and learning objectives and the result showed that it facilitated the teaching-learning process of software testing"
6707;en_US;"<p>This work was developed to characterize-through a visualization portal-the panorama and the impacts of female acting in computing in Brazil. This initiative encompasses a national scope, with academic and job market analysis, and presents as final product a portal that facilitates the sharing of information and the dissemination of knowledge related to Brazilian womens acting in computing.</p>"
6708;en_US;"<p>This paper describes the experience of planning and executing workhops that integrate the following content: women in computing, hardware and software fundamentals, game programming using Python, and local job opportunities in computing. The Program offered 03 workhops, with 08 meetings of 04 hours each, for student of a state public school in the periphery of the city. The workhops were offered as a way to attract the interest of girls to the area, however, boys could also participate. The use of the Dialogic Learning approach was the differential of this Program, since its principles guided all actions and activity carried out.</p>"
6709;en_US;"<p>Several studies pointed women as minority in the higher course of Technology, however there are few studies that investigate their participation in technical course. This paper presents an overview of the participation of women in higher education, as well as in the professional technical course of the Brazilian Professional, Scientific and Technological Education Network and in particular of the course offered by Cefet/RJ campus Nova Friburgo. Aspects related to admission and the academic situation of the student of these course are discussed.</p>"
6710;en_US;"<p>The reinforce of women participation in IT has been a growing concern in universities and company. Due to the variety of actions that can be carried out with this objective, people interested in starting project in this area may face difficulties in selecting suitable actions to the context in which they are part of. The aim of this paper is to report the experience in a joint research and extension project for directing the systematic adoption of actions for women participation in Software Engineering and Computer Science course in an university. The adopted methodology involved the conduction of a systematic mapping, a survey and brainstorming for selecting appropriate actions for the campus and the student’ challenges and needs of student.</p>"
6711;en_US;"<p>Aiming to investigate the gender gap in access to universities in the area of exact sciences, this paper analyzes, under several factors, the performance of the ENEM (National High School Examination) participant from 2013 to 2017. The result showed that the superiority performance of the male participant is not so evident when compared with the performance of the female participant. It is concluded that there is a need for educational public policies and more detailed analysis of a larger set of data, besides the integration of ENEM information with SISU (Unified Selection System) and ProUni (University for All Program) to help achieve the gender balance in accessing universities with a focus on exact sciences.</p>"
6712;en_US;"<p>The history of Lovelace Deaf Countess narrates the learning experience of a deaf student through face-to-face workhops before and during the execution of a Python distance-learning program designed for girls. The hereby report developed by a teacher, a tutor and a Libras interpreter shows the development of the deaf student through a hybrid teaching approach for Programming and SWOT analyzes of assistance for the deaf student along her program trajectory. The result show advancement, nevertheless, the Deaf Countess of Lovelace wrote down an open letter to the Digital Girls Community reporting her experience, difficulties and development in Programming what illustrates how the Digital Girls can collaborate to the inclusion of more deaf girls in computing careers.</p>"
6713;en_US;"<p>In Brazil, only 14% of women enrolled in computing undergraduate degree programs conclude it. For reducing the percentage of women’s drop out, it is necessary first to identify their causes. This paper has as its main objective to present the result obtained through the application of questionnaires containing questions about gender to student and teachers of the Computing undergraduate degree programs in Alegrete city. In addition to the stereotypes created since childhood, bad comment, chauvinism and the work devaluation of the women undergraduates were enunciated as difficulties, being able to contribute to women drop out.</p>"
6714;en_US;"<p>In its emergence, an expressive social communication of female participation, gave a social and professional contribution to the activity of mathematical education and secretariat. However, as the fields of informatics and technology gained greater value, the female position in the area declined progressively. This extoporcionalities are being refined to stigmas of gender and the struating the contribution of businesswoman with computed, desestimulating and desmerdentement the actions in the reports ramos. In this sense, we propose to present the initiatives of training and capacity building in the scope of an extension project with the computer course, middle and higher level, with the objective of combating female school dropout.</p>"
6715;en_US;"<p>The article aims to identify the professional profile of the female graduated student of the course of Degree in Computer Science and Bachelor of Information system, considering their activity in the market area and in the academic area. In order to know how and where the women who completed these superior course are working, a conditional questionnaire was applied covering the possible cases. As a result, the article shows that most women who chose the market work as analysts, and those who have continued in the academic area, continue to conduct researches.</p>"
6716;en_US;"<p>This paper aims to realize a speech analysis of statements published in electronic newspaper from two black women, who are protagonists in Computer Science. The methodology adopted was the French Speech Analysis by Pêcheux, in order to identify ideological circumstances of the hegemonic forces on the history of fight against the sexism and racism in the area of Computing. The starting point is the imaginary body projected in the professional field, which demands the confrontation of the mechanism that are fragmenting the identities of race and gender, by a social excluding logic.</p>"
6717;en_US;"<p>In celebration of the 60th anniversary of UFRN, we have proposed an initiative by IEEE WiEUFRNat CIENTEC aiming to highlight the female contribution to the STEM (Science, Technology, Engineering and Maths) degrees at UFRNover the last 60 years. The highlights were made through an exhibition, composed of four parts: I) description of renowned female icons and their contributions to the STEM area. II) History of female participation in STEM course at UFRN, through graph showing the percentage of female student in the course since its creation. III) #euexisto campaign: display of testimonials video from current student of STEM course explaining why they chose the course. IV) Tribute to female Lecturers: display all female lecturers names that have taught in STEM course at UFRN. As a result, the group paid a tribute to those brilliant women and highlighted their contribution to STEM; acknowledged the current student and teachers of the course; and helped raising awareness about the need to encourage the participation of women in these course and in order to build a more diverse environment. Our main goal was raise awareness that the degrees of STEM had consistently less women than man and thus, our feminist group had a very important role to play in increasing those numbers. From the informal feedback we received, we believe our goal was achieved.</p>"
6718;en_US;"<p>This paper presents a project proposed by female teachers from an educational institution that has two technical course and a graduation course in Computing. We present an experience report of the actions in the context of the project that have been directed to the female student in order to encourage and support them to complete their course, as well as encourage them in relation to the job market. As a result of the project, we expect to create and consolidate a network of mutual support between the female student, as well as a group to advise those student, with systematic activity supervised by the teachers.</p>"
6719;en_US;"<p>This paper deals with the retraction of women in the career of computer science and the difficulties of understanding and its implications in the process of training programmers. In this way the work proposes the offer of workhops based on the pillars of computational thinking for girls from the fifth to ninth grade ofelementary school in public school. The proposal is the result of an experience of initiation to programming with a deaf student, and aims to develop literacy in programming through computational thinking to understand the problem arousing the interest of girls in the area.</p>"
6720;en_US;"<p>This paper presents the result of a survey with girls who are attending or have completed IT course on the factors that may attract or make women less motivated to conclude course in the area. The survey was conducted using an online form and the result show some factors that may attract girls to the area and that may be more exploited in actions with this purpose. We also obtained some factors that negatively impact the motivation of the girls to complete their course and that should lead to more reflections in undergraduate programs and mitigated.</p>"
6721;en_US;"<p>This article presents and discusses the result ofthe analysis oftriennium of the Course of Initiation to Programming (CIProg) women-only classes, an initiative by Meninas Digitais-Regional Bahia which seeks to bring women closer to Computer Science through programming. The discussion that follows is a brief history of this initiative and of the CIProg. Also, it presents a historical analysis of the classes, its specifications and particularities, the profile of graduates regarding schooling and the policy ofquotas practiced in the selection edicts for the CIProg.</p>"
6722;en_US;"<p>Introducing programming for high school student can facilitate the learning process and the understanding about algorithm. This paper presents an experimentation using the Code.org platform with 28 high school student from state public network. The aim of the experience was to introduce them to programming logic and to arouse the student interest for Computer course. The evaluation method applied was a questionnaire for evaluating digital game provided by MEEGA + model which evaluates the players experience. A gender analysis was conducted on the evaluation result of the the Code.org.</p>"
6723;en_US;"<p>Several tool and strategies can be used to foster the debate about the low participation of women in the area of Computer Science. Disseminating reference model can be an option. This article reports the experience of inserting this debate in public school, using as an educational resource a sculpture of Ada Lovelace made with electronic junk, promoting interdisciplinary activity. Testimonials of student who have had contact with the sculpture and participated in related workhops show that integrating art in this debate can have good result.</p>"
6724;en_US;"<p>The decrease in the number of girls entering (and completing) course related to the area of Engineering and Computer Science at PUCRS, brought the need to create actions that motivate them both to enroll and to continue in course of these area. Considering the course related to Computer Science of PUCRS, a serie of actions were carried out during the year 2018. Our intent is to build–with the girls who are in these course-a group identity. With the creation and strengthening of this identity, we hope that they feel that they belong to their course, this way staying in them and inspiring other girls to join them.</p>"
6725;en_US;"<p>Women were very important for the History of Computing, however, throughout the process, women were excluded from historical reports. This paper describes a teaching-learning experience with a existing card game called Computasseia which addresses the History of Computing, showing its main events and important personalities, showing the image and importance of women who collaborated for the area. We adopted and evaluated the game with high school and undergraduate student. The result indicate that the experience contributed for the construction of student knowledge, enhancing interest in the area of Computing and the interaction among the players.</p>"
6726;en_US;"<p>It is important to assess the student profile at the Information Technology (IT) course in the IFSP–Bragança Paulista, to collaborate with the inclusion and permanence of the student in the field and to promote the participation of women in the job market as well. The campus provides technical course integrated to the High School, Higher Education and Post-Graduation in IT, being possible to act in different educational levels. This work relates to an extension project that aims to promote the participation of women in Exact Sciences. Therefore, the purpose of this paper is to bring forward the profile of student in different school levels at the IT field in the campus and, based on the result, define pIt is important to assess the student profile at the Information Technology (IT) course in the IFSP–Bragança Paulista, to collaborate with the inclusion and permanence of the student in the field and to promote the participation of women in the job market as well. The campus provides technical course integrated to the High School, Higher Education and Post-Graduation in IT, being possible to act in different educational levels. This work relates to an extension project that aims to promote the participation of women in Exact Sciences. Therefore, the purpose of this paper is to bring forward the profile of student in different schoo.l levels at the IT field in the campus and, based on the result, define proper strategiesroper strategies</p>"
6727;en_US;"<p>The statistics indicate that women represent approximately 14% of the student who start an undergraduate degree program in Computing in Brazil. Many project have performed workhops to high school student, aiming to attract more women to these programs. However, most of the studies found on these workhops do not bring enough information to allow their replication. This paper presents in detail the planning and execution of a 3-hour workhop focused on high School student, besides supplying all the material used.</p>"
6728;en_US;"<p>This paper introduces PyLadies Manaus, the local chapter of an in- ternational mentorship group with a focus on helping more women to become active in the Python open-source community. We describe some historic back- ground that motivated the creation of this group, the profile of its current mem- bers and the result and impacts of 11 activity carried out in 2018.</p>"
6729;en_US;"<p>The Brazilian Society of Computing (SBC) is the main scientific society which brings together student, professors, researcher, professionals and enthusiasts of Computing from Brazil. Then, the present paper aims to present a quantitative analysis of the SBC members, according to their gender, location, type of association and area of interest in Computing, in order to delineate a national panorama.</p>"
6730;en_US;"<p>While women have pioneered computing, the interest of female high school student in computing and female participation in the academic and professional computing environment has been declining over time. In this article, we show the result of the research carried out with female high school student during an inclusion action designed to increase the visibility of women who were part of the history of Computing and to encourage female participation in Computing. It was concluded that the inclusion action positively influenced interest in Computing by female high school student participating in the research.</p>"
6731;en_US;"<p>The gender gap in Computer Science is a fact in undergraduate Major in Brazil. However, there are few studies about the gap gender in the master and doctoral degrees. This paper presents the gender gap in the Graduate Program at the University of Brasilia, Brazil. That program has academic master and doctoral degrees, and the professional master degree.</p>"
6732;en_US;"<p>This paper characterizes the female participation in CS subarea th- rough the program committees of the main SBC symposia over time.</p>"
6733;en_US;"<p>The objective of this work is to outline the profile of women in the computing field through the analysis of the database of the National Examina- tion of Student Performance (ENADE) for the year 2017. The motivation for this work is the desire to understand and identify the factors that may show the differences between men and women in the computing study field. All the result reached by this study, the most significant one was that the main motivation for the women to enroll in a computing field course was the insertion in the labor market whilst the men declared to have a vocation for the field.</p>"
6734;en_US;"<p>The imbalance of gender in the information technology area expresses itself both in the shy presence of women as in your little knowledge. For understanding questions like that, we search hereby this paper to do a sampling analysis through profiles of women registered in the Linkedin social media, to identify the several functions that they occupy and/or long for. The computing area is divided in several subarea and, starting from this question, we consider relevant to know in which working spaces are the women, what is fundamental to contribute to the studies about equality of gender in the field of computing.</p>"
6735;en_US;"<p>Ada Lovelaces life is a source of inspiration for women and men of all ages, for being a bright-eyed and visionary person. Her greatest achievement was to have drawn up what is considered the first computer program in history. This article presents a methodological proposal for the didactic use of a childrens book about the life of Ada Lovelace, through the proposition of a circuit of unplugged activity, to work on the pillars of computational thinking in children and adolescents. This approach was applied in a workhop at the LAWCC–CLEI 2018 (X Congress of Latin American Women in Computing-Latin American Conference on Informatics). A quali-quantitative analysis was performed, indicating the suitability of the proposal.</p>"
6736;en_US;"<p>The IT area is constantly advancing, but the low participation of women is becoming increasingly alarming. This work aims to analyze the participation of women in the computational area and to report the development of the Gurias Digitais project, which seeks to encourage girls from a municipal school in the city of Santiago to better understand the area of Computing, also encouraging them to consider the area as a valid career option, teaching them how to develop their own game.</p>"
6737;en_US;"<p>This article discusses model, methodologies, biases and their impacts for a group of freshmen girls on a computer course. As well, discussed about the creation of focus groups, for girls with a view to empowerment as an initial, empowering measure. The method used was the case study with a quality-quantity approach. result show that the measure: creation of a group of mentored studies was a good initiative given the degree of acceptance and result evaluated qualitatively (student description) and quantitative (evaluation of contests).</p>"
6741;en_US;"A smart campus refers to a campus where modern information and communication technologies bring more benefits to life on campus, help user to improve and perform daily activity more efficiently, and improve social interaction. This article aims to present an approach based on personalization and recommendation, developed for mobile device, which provides opportunities to user the pointing of infrastructure problem in the smart campus context, monitoring the development of problem solving, as well as interaction with user who reported the same problem."
6742;en_US;"Geographic Information system (GIS) is a technology with significant potential for transformation for Governments. Since 1999, the municipal government of Porto Alegre, capital of the State of Rio Grande do Sul, has initiated a serie of actions to develop and implement a enterprise GIS. However the imbalance in the development of enterprise GIS is very strong between different institutions within Porto Alegre City Hall (PMPA). In this context, the proposal of this work was that of carrying out a comparative study between three different model of maturity of GIS capacity. This is done in order to identify the most appropriate model for measurement of the GIS maturity level of institutions within the centralized and decentralized administration of Porto Alegre City Hall (PMPA)."
6743;en_US;"The optimization of commercial routes has become of paramount importance for the company offering this service, seeking to reduce costs, optimize resource, improve the process and satisfy its customers, and contribute to the improvement of urban mobility. This work presents a computational solution for route optimization in real time, using heuristic algorithm for the best path, structured in two modules (web and mobile) connected via web service. The Google Maps API provides geographic information. The solution was used in a real company and gains were identified regarding route optimization."
6744;en_US;"This work presents the SmartNode Dashboard (SND), a tool based on front-end technologies for creation of intelligent dashboards. SND has implemented design and interface web standards focused on content with reusable structures. In addition, a case study was created using Node-RED as an execution platform. As a result of this work, SmartNode Dashboard was developed, a framework for creating standardized and extensible interface. In addition, it offers dashboard developers a methodology for using the framework with Node- RED to facilitate and extend teams ability to perform performance, time and quality in creating dashboards."
6745;en_US;"Smart Home Energy Management system are powerful tool for efficient energy management. In this scenario, monitoring is done by reading information generated by intelligent home appliances. However, it is not every home that owns such equipment, which makes management difficult. In this work, we present a minimum viable product (MVP) of a residential electrical monitoring system capable of extracting information about the energy consumption of common household appliances, through a single point of collection and through consumer signatures to identify these appliances when they are connected to the electrical network."
6746;en_US;"The increasing urban concentration has made city complex social ecosystem with innumerable management challenges. In order to face such challenges, it is necessary that this ecosystem be viewed in a holistic way, understanding the complex and multifactorial nature of the demands, being fundamental the use of quality information for decision making and service delivery. Based on the concept of Smart city, within a bottom-up view, the city hall of Fortaleza with the support of the academy, has been developing a project to create a robust data management infrastructure in the city to provide information and digital service (for the management and the population) that help in the improvement of the city and the quality of life of the citizen."
6748;en_US;"Smart city are a standard concept of automated and sustainable city that adopt technology to increase efficiency in communication, management and globalization of information. Despite the success of the concept, there is an emerging need to develop and deploy software and software-based system for these city. Thus, agile methodologies can play an important role, once they are broadly adopted in system development lifecycle. This paper presents the result of a systematic mapping conducted on agile process to develop software for smart city. A systematic mapping identified 246 studies, from which 10 were selected for analysis and presentation of the result obtained."
6749;en_US;"One of the characteristics of the Smart Grid is the restoration of the electrical network, using metaheuristics to find the best temporary configuration after a fault. Based on the probabilistic characteristic of metaheuristics, this article aims to perform a comparative analysis between four metaheuristics applied to the restoration problem, using the node-depth representation as a data structure to represent the electric network."
6750;en_US;"Smart city are characterized by providing new service through Information and Communications Technologies. However, it is important to gather data from citizens to discover new knowledge about certain aspects of a city. One example of a rich domain for collecting data in a smart city is exploring the use of mobile fitness application. user usually record outdoor activity in the form of trajectories, which can later be acquired for further analysis. In this work, we leverage Semantic Web technologies to propose an annotation algorithm that segments trajectories according to their spatial context. We demonstrate how the method work and the impact of OpenStreetMap related ontology in the annotation process."
6751;en_US;"<p>Message from the Coordination of the&nbsp;XXVII&nbsp;Computing Education workhop, and informations about the Committee.</p>"
6752;en_US;"<p>Message from the Coordination of the XXXII Theses and Dissertations Contest, and informations about the Committee.</p>"
6755;en_US;"<p>Message from the&nbsp;Coordination of the XXXIX Brazilian Computer Society&nbsp;Congress, and informations about the Program Committee.</p>"
6757;en_US;"<p>Message from the Coordination of the XXXIX Brazilian Computer Society Congress and the Coordination of XIII Brazilian e-Science workhop.</p>
<p>&nbsp;</p>"
6758;en_US;"<p>Message from the General Coordination of the XXXIX Brazilian Computer Society Congress and information about the management committees.</p>"
6759;en_US;"<p>Message from the Coordination of the VIII Brazilian workhop on Social Network Analysis and Mining and the Message from the Coordination of the IV Computer Theory Meeting.</p>
<p>&nbsp;</p>"
6760;en_US;"<p>Message from the General Coordination of the XXXIX Congress of the Brazilian Computer Society and Message from the Coordination of the XI Brazilian Symposium on Ubiquitous and Pervasive Computing</p>
<p>&nbsp;</p>"
6761;en_US;"<p>Message from the Coordination of the CSBC, and WCAMA. Informations about program committee.</p>"
6763;en_US;"<p>Message from the General Coordination of XXXIX Brazilian Computer Society Congress, of XVIII workhop on Computer system Performance and Communication, and information about the event coordinators.</p>
<p>&nbsp;</p>"
6764;en_US;"<p>Message from the General Coordination of the XXXIX Brazilian Computer Society Congress, and the Coordination of the VII system Transparency workhop</p>
<p>&nbsp;</p>"
6765;en_US;"<p>Messagem from the General Coordination of the XXXIX Brazilian Computer Society Congress, and Coordination of the WPIETF</p>
<p>&nbsp;</p>"
6766;en_US;"<p>Message from the Coordination of the XXXIX Brazilian Computer Society Congress, and the IV workhop on Social, Human, and Economic Aspects of Software</p>
<p>&nbsp;</p>"
6767;en_US;"Sentiment analysis has become an essential tool for application in a variety of context, including reviewing user opinions about products and service, forecasting during political campaigns, and even financial market trends. Despite the great interest in this topic and the amount of research in the area, most method are designed to work with English content. In this study, we aim to fill this gap by proposing an approach for the use of certain state-of-the-art method for analyzing feelings in 9 different language. To do this, we used databases previously labeled in each language and a simple automatic translation into English and developed a methodology to compare and validate the result. Our result demonstrate the potential of this approach to make the analysis of feelings independent of the English language."
6768;en_US;"Flood risk management requires updated and accurate information about the overall situation in vulnerable area. Social media message are considered to be as a valuable additional source of information to complement authoritative data (e.g. in situ sensor data). In some cases, these message might also help to complement unsuitable or incomplete sensor data, and thus a more complete description of a phenomenon can be provided. Nevertheless, it remains a difficult matter to identify information that is significant and trustworthy. This is due to the huge volume of message that are produced and which raises issues regarding their authenticity, confidentiality, trustworthiness, ownership and quality. In light of this, this paper adopts an approach for on-the-fly prioritization of social media message that relies on sensor data (esp. water gauges). A proof-of-concept application of our approach is outlined by means of a hypothetical scenario, which uses social media message from Twitter as well as sensor data collected through hydrological stations network maintained by Pegelonline in Germany. The result have shown that our approach is able to prioritize social media message and thus provide updated and accurate information for supporting tasks carried out by decision-makers in flood risk management."
6769;en_US;"Academic genealogy is defined as the study of the intellectual inheritance perpetrated through the relationship between counselor and counselor. The set of such relationships over many generations is commonly abstracted by a social structure that is represented by a graph. In this work, we present the definition of a new metric, called extended genealogical index-h, that can be used to evaluate the impact of an academic through its orientation relationships and having its scope limited only by the topology of the graph. This metric is based on the bibliometric index-h and expands its concept to measure the impact of an academic across different generations. To exemplify the new metric, we present a case study considering a genealogy graph composed by more than 178 thousand doctors in mathematics registered in the Mathematics Genealogy Project."
6770;en_US;"In this article we present a view of the Brazilian stock market based on the characterization and analysis of data collected from Twitter from July 2013 to July 2014. This work has as main differential the first to point out the BOVESPA shares that may have its financial volume and number of purchase orders monitored by Twitter. In addition, in our analyzes, we observed that events and news about the stock market are able to generate post spikes by Twitter user and that the frequency of postings accompany the beginning of the negotiations and is maintained for about three hours after the stock market closing. In addition, we found that 10% of user account for more than 90% of Twitter posts. Finally, we observe that the financial amount and the volume of buy and sell orders are positively correlated to 66% of the actions mentioned in Twitter, whereas the dimensions of oscillation and maximum oscillation are not correlated."
6771;en_US;"In the last few years, Twitter has been used to understand several real world events such as political elections, civil conflicts, NFL game, to name a few. Motivated by these many examples we asked ourselves, what does Twitter reveal about the 2014 FIFA TM World Cup? In this paper we (i) analyze the frequency of tweets to show how support evolves during the tournament, to distinguish traditional teams from underdogs, and to show that we can identify important events during matches. Moreover, (ii) we applied clustering technique to discover similarities on supporters behavior (tweets) that allowed us to infer countries supporters worldwide. Lastly, (iii) for each match we created cartograms to express the volume and the level of polarization of supporters."
6773;en_US;"In this work, a characterization of the behavior of user in social media application of online video streaming is presented. The characterization is done with the objective of answering three motivating questions: (1) Which external source (websites) most often take user to video? (2) How is the browsing behavior of user within the video streaming application? (3) How exposed are user to different types of advertising in such application? Using a navigation database of user of a large Brazilian university campus, studied the behavior of user on YouTube, the largest video streaming application currently. Different from past studies, this work describes the individual behavior of user in the application. In addition, access to data made it possible to analyze the behavior of user when exposed to a new type of online advertisement, advertisements in video format. The main result show that: (1) links that most often lead user to YouTube video vary depending on the category of the video, (2) after viewing a video, user tend to use search engines and lists of related video to continue browsing in the application, and (3) advertisements in the video format tend to attract more attention from user than traditional advertisements on links."
6774;en_US;"The mobility of researcher is one of the factors that significantly affect the progress of science. In this study, we analyze the mobility pattern observed among researcher working in Brazil or teaching and research institutions through the extraction and treatment of locally dependent metrics present in their curricular records. With this analysis, we were able to identify the most influential human resource training centers for the national scientific community and the network formed by training and research institutions registered by the Lattes platform."
6775;en_US;"The international student exchange market has grown significantly over the last decade. In an effort to improve the countrys science and technology production, the Brazilian government created the Ciência sem Fronteiras program. The program provides funding for undergraduate and postgraduate student to study abroad. This paper analyzes data from this program, identifying pattern on distributions of student, their states in Brazil, destinations and area of study. The result show that the long tail distribution appears ordinarily in the data. Furthermore, between pairs of data, the result showed that Quetelets index was low in most cases, except in a few outliers, such as countries that have hosted a very small number of student."
6776;en_US;"Studies show that a Twitter user popularity is closely tied to the amount of followers he or she owns, while a large number of scientific citations are synonymous with high academic impact. In this context, this study created a database of searchers with accounts on Twitter and Google Scholar with the goal of calculating the Gilberto-Arruda index. The result show that there are researcher in this study who are associated with João Gilberto and others with Geisy Arruda, that is, some researcher have few followers but many citations while others have many followers and few citations. A web application was developed that allows researcher to consult what their Gilberto-Arruda index is."
6777;en_US;"Social media communities are usually formed by similarities among user. In educational social network, several factors propitiate the user group generation, e.g. share the same academic environment or interested in common curricular. In order to explain the group formation resulted from educational social network, we applied two group profiling method based on differentiation. Wilcoxon rank-sum test and PART rule algorithm were applied to a dataset available, the OJE educational social network. The performed experiment showed that the method were effective to group profiling generation, characterizing 81.81% and 100% of groups, respectively."
6778;en_US;"Sarcasm and irony are widely used forms of speech inside and outside the Web, having the power to transform characteristics like polarity or sense of a sentence. Being able to characterize and detect sarcastic or ironic message in data collected from the Web can enhance several decision-making system based on Natural Language Processing (PLN) such as the task of feeling analysis, text summarization and review ranking system. In this work, we propose several approaches for the characterization and later classification of sarcasm and irony in message posted on the online social network Twitter. Using an automatically collected base of tweets with the #sarcasm and #irony hashtags, and using a wide range of characterization and classification technique, our detection result achieved satisfactory rates of accuracy and Macro-F1."
6779;en_US;"In this work, we explore the possibility to detecting life events from Social Media by means of machine learning classification algorithm. One important difficulty of this kind of detection task is that, typically, Social Media posts are quite short, and there is not much context provided. This lack of context usually implies strong ambiguity leading to poor classification performance. Here, we propose the use of conversations as a means to augment context and improve classification performance. We evaluate single-post vs. conversation classification performance and compare different model for the conversations classifier. Finally, we describe the performance of the different classifier in a large data set with 20,000 posts."
6780;en_US;"The main objective of this work is to classify academic events, such as symposiums, conferences, seminars, workhops, lectures and course with the objective of analyzing the virality in the field of education. The experiment were performed with a set of three algorithm in which the SMO was one of the ones that obtained better performance. As result, it can be observed that the seminars are the most propagated events in the analyzed social network."
6781;en_US;"Social network is currently an area of ​​great interest on the part of researcher worldwide. This can be evidenced by the significant increase in the number of articles published in journals in the Web of Science in recent years. The objective of this work is to present a mapping of the scientific production of the Social network area considering the articles published in periodicals indexed in the Web of Science. For this, a bibliometric analysis and an analysis of the co-authorship network were carried out for the main countries and authors of the area. The result shows that the countries and authors that publish the most are not always the ones that most influence this area."
6782;en_US;"This paper uses the context of the Brazilian presidential elections in the year 2014 to investigate whether the winner of an election can be discovered from public message of Twitter user. Approximately 3 million and 200 thousand message, of more than 460,000 thousand distinct user, making reference to the main presidenciáveis ​​were collected and analyzed. Our result show that it is possible to estimate the election result based only on the tweet counting technique. Other result also show that other technique such as user counting and message feeling analysis can increase the accuracy of prediction model."
6783;en_US;"Publications archived in high-impact scientific journals shape the scientific memory of mankind over a period of time. Therefore, it is necessary to study the relationships between publications, authors and the editorial line of journals, based on the contents printed in their articles. This work seeks to differentiate journals from the semantic network of their titles (RST), using a mechanism inherent to semantic network for access to memory: the critical network. The method is based on the construction of network from the incidence-fidelity index. The result show the presence of the phenomenon in network of titles and suggest ways to differentiate journals from the indexes of network in the critical network."
6784;en_US;"Social media is used to share information and express opinions about events. But not all content generated is reliable. This work performs a study of the characteristics that this type of message has. Specifically, postings on Twitter were analyzed, where seven rumors were chosen that spread through Brazil between July 2014 and January 2015. This research is the basis for a method to identify inconsistency of information in social media."
6785;en_US;"The area of ​​Social Network Analysis (ARS) is a multidisciplinary area. Recently, we have witnessed the great insertion and contribution of the Computer Science community due to the growing number of social data available and the increased use of interaction tool. Despite this, there are still few quantitative records of this growth. The objective of this work is to show this movement in Brazilian scientific research, based on the Brazilian scientific community in the field of Computation. With this analysis it is possible to see the growth of ARS in Brazil, as well as the main researcher and the events recognized by the researcher of the area."
6786;en_US;"In this article, we built a co-authorship network among CNPq productivity fellows from the production engineering area and analyzed which ARS metrics impact on their productivity levels. Our result indicate that the productivity level shows a significant positive Spearman correlation with five of the seven metrics analyzed. We conclude that researcher who take on an intermediary role, who have a greater number of links, or are more likely to establish publications partnerships tend to have a higher level of productivity. In addition, it was also found that collaborating frequently with the same researcher does not impact on the level of productivity."
6787;en_US;"Rulers around the world need to monitor various aspects of their territory and planet Earth in order to prevent and solve problem. This monitoring, in most cases, occurs through the analysis of statistical data, which can be difficult and costly to acquire. By analyzing news, you can create a simple and inexpensive alternative to get the data you need. For this, it is necessary to perform two mining tasks: (1) recognition of entities of interest and (2) geolocation of the subjects encountered. In this work the second problem is focused, with special focus for the countries that have Portuguese as one of its official language."
6788;en_US;"The identification of authors is fundamental to the accuracy of bibliometric calculations, but homonyms and polysemy hinder identification, requiring the application of an algorithm of disambiguation of author names. This article proposes a technique of disambiguation that consists of automatic extraction of characteristics followed by the application of a classifier. The result obtained in the case study reached a precision of 96%, similar to the state of the art in the literature."
6789;en_US;"This article presents an analysis of Tattoos pattern associated to occurrence of crime registered by the Public Security Secretariat of the State of Bahia using the theory of Social and Complex network. Built network consider relationships between criminals, crime and tattoos. The result presented point to network with a Small World topological feature. The result found point data relevant to the understanding of crime pattern associated with tattoos, and may support public safety authorities in decision making in the future."
6790;en_US;"The present work presents a method of network construction based on analysis of a historical social network, made up of scientists who are part of the narrative of James Gleicks book The History, Theory and the Flood (2011). The data obtained allowed to evaluate the structure of the network and the influence of certain characters throughout the book. The characteristics that the network acquired after being modified with the removal of the highest degree vertices were analyzed. As a result was found a network with the small world phenomenon."
6791;en_US;"This article proposes to show the recent contribution of complex network to the economy, especially the economics, by giving a brief introduction about it and then demonstrating the contribution of complex network to the financial markets and the understanding of production for the economy."
6792;en_US;"The political history of Brazil reveals that, since the time of hereditary captaincies, family groups are responsible for most of the candidates elected in Brazil. No information medium has been found that identifies these connections and measures the size of these families. This work uses Human Computing to map the families of politicians who are perpetuating themselves in power, providing a means to collect data from taxpayers that identify whether or not two elected candidates are relatives. Politicians personal data are taken from the repository of electoral data made available by the TSE for scientific purposes. The collection of data regarding kinship and is performed through the Contribua platform that generates the data of the classifications made by the user. When processed, these data are structured into graph that make up the genealogical trees of the political oligarchies in Brazil. The size of the oligarchies and is represented by the size of these trees."
6793;en_US;"In every software system, there is interaction between components. By joining a technical network of artifacts with a social environment, a socio-technical network is created. Aiming to develop a tool that model, analyzes and encourages social relations in the socio-technical network, was proposed to SocialSECO Brechó. The Brechó component library was extended to better understand software ecosystem and to support decision making. This work presents the tool and its operation."
6794;en_US;"Google Scholar and other academic research network provide a wealth of information on the Internet. In many cases it is not possible to consult and analyze the information in more detail. This research proposes to use Follow Model as a tool to categorize the node of a network. Because Follow Model has great potential for working with online social network, it has been adapted to rank us, as well as the PageRank and InventorRank model, in the MRSA study. The study demonstrates how Follow Model is robust and how we can improve consultation of academic material."
6795;en_US;"This paper presents an analysis of the research topic addressed in the area of ​​Embedded system based on a network of significant word present in the titles of the articles. For that, a tool was developed for extraction, characterization and assembly of network using the IEEE Xplore base. At the end, more than twenty thousand articles were extracted and analyzed, and the most relevant area and publications were raised."
6796;en_US;"Twitter has been used by researcher as an important source of data for research and prediction of various aspects of human behavior in social network. We investigate in this work the synergy between the performance of participant in popular voting programs in Brazil and their popularity on Twitter. As a case study, we collected Twitter data about the most recent editions of two popular popular voting programs in Brazil, they are Superstar and Big Brother Brazil, and we found that the popularity of the participant of these programs on Twitter is a important indicator of their respective performance. Another interesting finding was that the top performers had more positive tweets than the other competitors during the program."
6797;en_US;"The present work presents a methodology for visualizing large network in a web environment through the use of different layout algorithm and hierarchical grouping, which are combined and evaluated by several grouping metrics. From the best combination of grouped layout evaluation is generated a visualization of graph in the plane using multiple levels of grouping, allowing searches by attributes, exploration of information in groups and vertices at several levels simultaneously."
6798;en_US;"Social analysis in Twitter has become a very interesting research scenario. Twitters popularity and the millions of spontaneous interaction between its user turned the social network into a rich data source. A possible use of this data is to measure collective sentiments related to events. In this short paper, we propose an analysis of the content shared in Twitter during the event 2014 FIFA World Cup Brazil TM. The sentiment classifier utilized in this work is the SentiStrength tool. The steps of this work are Composing the corpus, Preprocessing, Classification and Temporal Analysis. Finally, we propose some preliminary result that indicates the distribution of sentiments across the corpus."
6799;en_US;"The temporal analysis of scientific collaboration network is crucialfor understanding the emergence of new area of research as well as the evolutionof the impact of the scientific production. Furthermore, effective grantpolicies can be defined. This paper presents the study of the evolution of theBrazilian scientific collaboration network, through classical metrics of complexnetwork as well as endogamy and stable research groups metrics."
6800;en_US;"Documenting individuals and their relationships using the genealogyaims to obtain knowledge about the origin, evolution and characteristics of interrelatedgroups. This approach allows to understand the formation and futuretrends of groups. In this context, the characterization of the academic genealogytrees by topological metrics allows to categorize individuals screened bytheir academic lineage and enables to obtain important new knowledge for understandingthe scientific scenario about an area. In this work, we present nineadapted and developed topological metrics to characterize academic genealogytrees. In order to show the feasibility of our characterization method by makinguse of topological metrics, we present an experiment focusing on the analysis ofthe genealogy of Johann Bernoulli (1667-1748), consisting of 81, 768 mathematiciansand 88, 955 relationships of academic advising."
6801;en_US;"The Brazilian social and cultural diversity and the size of the countrymake any general analysis miss interesting details about the regional peculiarities.In this work, the Brazilian academic network of PhDs who work incomputer science is analyzed, as well as, their sub-network in order to identifytheir characteristics in terms of relationships between doctors and the keywordused in publications in each of the Brazilian states."
6802;en_US;"Evidences show that the way researcher collaborate has a strong impact on their productivity. This study analyzed the correlation between Social Network Analysis metrics applied to a Computer Science scientific collaboration network and the researcher scientific performance. The correlation was studied using the Spearman correlation coefficient and the result show that researcher who establish strong bonds of collaboration and act as a mediator within a network, in general, have a higher scientific rank."
6803;en_US;"Multi-relational data mining technique (MDMR) are the most appropriate strategies for dealing with databases containing multiple relationships between non-homogeneous entities, which is precisely the case obtained from social network. However, the search space for candidate hypotheses of such strategies is more complex than those obtained from traditional data mining technique. To enable a feasible search in the space of hypotheses, the MDMR technique adopt language and search biases in the mining process. However, a detailed experimental analysis requires the combination of several distinct parameters, which makes the manual control of such process complex. In this article, we present a tool that instantiates a scientific workflow for the analysis of an MRDM process, modeled from the SciCumulus Workflow Management System, called LPFlow4SN. By controlling the experimental process automatically, LPFlow4SN has the potential of making social networking efficient."
6804;en_US;"Recommendation system play a key role in the decision making process of user in online system. In this work, we propose a city recommendation system that exploits the user interests and the similarity between different user. The proposed method builds a social network among user where the edges are weighted by the similarity of interests between pairs of user. This network is then used as a component of a collaborative filtering strategy. We evaluate our method using a large dataset collected from TripAdvisor. Our experimental result show that our approach can double the precision achieved by baseline approaches, which exploit only the overall popularity of city, reaching 65%for the most active user."
6805;en_US;"Over the past years, social network have increasingly become part of everyday life for great part of the Brazilian population. Due to that, enterprises are increasing their presence in social network. In doing this, these enterprises aim at combining the usage of both digital marketing and new technologies. In this context, there is much room for enterprises to explore their participation in social network. This article introduces RFIDBook, a Facebook application which, combined with radio-frequency identification technology (RFID), makes ground for the creation of a new type of bonus program for consumers. A preliminary study on the developed prototype was made to assess its feasibility. The study showed a good potential for use, but at the same time revealed that the project needs better marketing to have greater acceptance among potential user."
6806;en_US;"Technological advances and the use of social network have increasingly promoted the virtualization of real groups, which are usually related to common interests such as family and studies. Particularly, in undergraduate course, student are used to belong to social network groups related to classes. We argue that we can take into account the context of these group interaction and of each belonging member in order to enhance the learning process among them. With this in mind, this work presents the Ask4Inapplication which assists the process of learning by means of questions and answers based on the perceived context of the user and of the occurred interaction. Some contextual information is acquired from social network."
6807;en_US;"We find in the literature empirical result and model to explain the growth of Small World and Scale Free network but very little on Core-Periphery network. The present work focuses on a co-authorship network based on scientific publications for Dengue Fever, a so-called Neglected Disease. We found that for this network the Core Periphery structure presented resembles a crossover between Small World and Scale Free network, with a heterogeneous behavior of its authors. As a further result of this research we demonstrate, based on the network cores, how the authors divide themselves into groups and their influence over the network."
6808;en_US;"This paper presents an analysis of the perception of health workers who work in primary care in small towns members of the 13thRegional Board of Health in the state of Bahia, with respect to perceptions of health promotion for this social group. We use a sematic network, where the vertices represent the word evoked by the workers, and the edges connect the word that have been evoked by the same worker. The analysis was based on theory of social representations and on network theory. This analysis is a possible strategy to comprehend the social representations from a social group. From the result, it was possible to identify management action undertaken by health workers who work in primary care of the investigated small towns."
6809;en_US;"The sentiment analysis of citizens is possible by using suitable technique of analyzes applied to a massive database which is composed by message provided by persons on Web. The goal of this paper is to analyze the opinion about protests that occurred in Brazil in 2013. For this, a database composed by tweets written in Brazilian Portuguese was used. This database was pre-processed for the corpus 'creation. We observed that polarity (agreement or disagreement with the protests) of these message and the final result have shown that the majority of message are agreement ones."
6810;en_US;"Multilingual Opinion Mining deals with the analysis of opinions regardless of the language in which they are written. The vast majority of the work in this area focuses solely on classifying the polarity of the sentiment, overlooking the analysis of the emotions. In order to fill this gap, this work presents a case study about the classification of emotions present in product review, evaluating an approach that combines lexicon-based emotion classification and automatic translation. The case study aims at finding out if it is best to translate the text of the review or the dictionary. It also evaluates whether lemmatization can bring any benefits. The result of our experiment on real data show that translating the review yields better result and that lemmatization does not bring significant changes."
6811;en_US;"This paper shows a tool to classify web publications made on social network such as Facebook and Twitter as positive, negative and neutral. For the classification task, this tool uses SentiWordNet lexical resource and Naïve Bayes algorithm. In the realized experiment, the collected publications to classification are from three Brazilian e-commerce company. The result were very relevant for publications from Twitter using Naïve Bayes algorithm, with correct classification rate between 71% and 95%."
6812;en_US;"This paper aims to use public data from social network to conduct election surveys and studies. Although prior work has already focused on this task, none has taken into account the unique user identification together with inherent factors of the virtual environment, such as sentiment analysis of message, detection of spammers as well as of journalistic content. Our experimental result show that more elaborate analyses are able to improve the numbers achieved by the method used in other work."
6813;en_US;"It is useful to determine how electoral candidates are evaluated by the population on issues related to their daily lives (e.g. health, education, security). People is increasingly sharing their opinions on the internet through forums, comment, or social network. The non-trivial problem of identifying and classifying this opinionated content is the concern of Opinion Mining. This paper presents partial result of a research on aspect-based opinion mining, using comment expressed about news as data source. Unlike product review, this type of data source does not allows assumptions about opinionated content, nor opinion targets. The paper describes a case study involving the 2012 municipal elections of Sao Paulo, and it is focused on the extraction of the target aspects of the opinions expressed by online newspaper readers. Our best result were obtained in the experiment with technique of co-occurrence (EMIM and phi-squared)."
6814;en_US;"Link prediction is an important research line in the Social Network Analysis context, as predicting the evolution of such nets is a useful mechanism to improve and encourage communication among user. In co-authorship network, it can be used for recommending user with common research interests. This paper presents a systematic process based on non-dichotomic metrics for evaluation of link prediction in co-authorship network considering the definition of method for the following tasks: data selection and new link determination. Fuzzy sensor based on node attributes is adopted for data selection. Fuzzy compositions are used to predict new link weights between two authors, adopting not only attributes node, but also the combination of attributes of other observed links. The link weight called relation quality is obtained by using structural feature of the social network. The AUC is used for result evaluation"
6815;en_US;"Online social network have attracted a large audience of user, who take advantage of their tool to discuss all kinds of subjects. Several studies have been conducted to identify the topic discussed, and there is a growing number of studies focusing on the personal characteristics of the user participating in these discussions. This study is interested in the gender and age of user, and as many others, relies on the message posted by the user to infer their characteristics. Previous studies have been proposed to infer the gender and age of the individuals, but mostly in English. We develop an approach that deals with the Portuguese language. The method developed for gender and age inference obtained an approximate accuracy of 90% and 80%, respectively."
6816;en_US;"The field of Intelligence and Security Informatics (ISI) is a relatively new research area and co-authorship is the predominant trend in the field of ISI. This study aims to investigate the collaborative characteristics in the ISI research community through social network analysis. The collaboration network of ISI researcher at the domain/disciplinary level based on publications in the field of ISI is built, and three centrality measures, closeness, betweenness, and degree centralities, are used to identify the most prominent researcher in the community. The visualization tool of pajek is also used to identify the main actors, cluster and components in the network."
6817;en_US;"There is no simplified way of analyzing changes in members of parlaments behaviour. Consequently, it is difficult to visualize the impact caused by historical events, such as corruption scandals or popular manifestations. In our understanding, such events result in discussions, affecting members cohesion. We propose a tool to monitor cohesion metrics over time, making it possible to visualize changes in the way members of parliament vote."
6818;en_US;"Public Brazilian Universities have adhered to the quota policy with the aim of expanding the number of minorities inside them. Despite the inclusion ensured by the vestibular, the process of integration of shareholders at the university is yet to happen. It is necessary to know the impacts of adherence to quotas and understand how university actors have lived. This study evaluated homophily by quotas in the relationship between 1086 student in high and low competition course at UFBa, at the first, third and fifth semesters. Four types of ties were surveyed, friendship, information, gap and rejection. result indicated that homophily is higher in course in high competition and information network. When observed by subgroups, student not selected by quotas have higher rates of homophily course mainly in high competition course."
6819;en_US;"This work proposes a procedure that explores sociotechnical network to support the allocation of tasks to available human resource in a team. The procedure considers the interaction history between employees and artifacts, skills required to perform tasks and workload assigned to employees."
6820;en_US;"Through a systematic mapping of the literature, this paper aims to map studies directly related to social network analysis in the context of collaboration in software development. We seek to list the key authors and data source used by the primary studies. Also, identify the main metrics of social network analysis and research method used."
6821;en_US;"This paper extends a previous work, presenting an approach to predict new co-authorships combining artificial intelligence technique with the state-of-the-art metrics for predicting relationships in social network."
6822;en_US;"Online social network have attracted millions of user to integrate their daily life into these social media. As an important e-activity, the Friend Recommendation System (FRS) has been designed to help the user exploring new friends with common interests. However, most existing FRS are using simple method, such as mutual friends, location-based information etc. This paper proposes a hybrid technique utilizing Support Vector Machine (SVM), recommending people in social network based on user attributes. With the case study from Tencent Weibo, the proposed method has improved the accuracy of recommendation comparing with two classic algorithm, Naïve Bayes and Random Forests. Furthermore, considering nine attributes in FRS, we identified that the acceptance of followers is the most important factor to influence the user decision."
6823;en_US;"This article focuses on the discursive violence and the symbolic violence propagation through discourse on social networking sites. The objective is to analyze the mechanism by which the relation of symbolic power and the relation of domination are exposed and reinforced in Facebook through content published by fan pages about the application. Data from two fan pages was summit to bring evidences to this discussion – Não aguento quando and Tubby App, where one post of each is going to be analyzed and its comment through of Computer-mediated Discourse Analysis (CMDA)."
6824;en_US;"This paper proposes an affinity network model that favors the management of eLearning training course as a conducive space to the knowledge diffusion, from the technological profile of the course participant. This is an instrumental case study, which research method was strongly influenced by the netnography. Data were collected from the participant of the editions of the Programme of Support to Municipal Education held in 2010 and 2012 in the state of Alagoas. Itis considered that the topology of the network together with the individual metrics of each actor make possible to define different strategies for management of course in these teaching modality"
6825;en_US;"With the fabulous development of information technology, big data application prompts the development of storage, network and computer field. It also brings new security problem. This security challenge caused by big data has attracted the attention of information security and industrial community domain. This paper summarizes the characteristics of big data information security, and focuses on conclusion of security problem under the big data field and the inspirations to the development of information security technology. Finally, this paper outlooks the future and trend of big data information security."
6826;en_US;"This paper describes an approach of searching by influential user on Twitter, related to protests which took place in Brazil in 2013. The analyzed social network was constructed from the most referenced hashtags and retweets. This paper shows the result of this study, as well as exemplifies how events affect in the communication of Twitter. Moreover, we describe some future work."
6827;en_US;"Social network Analysis (SNA) has been a topic of interest for many researches in last years. These network can be established from the relation between people or the relation of information that can be analyzed in order to assist decision-making. The purpose of this article is to describe and analyze semantic network constructed from the keyword present in trouble tickets titles submitted by user of a customer service system (Help Desk). Applying SNA technique to an instance of this semantic network allowing the identification of the most common problem and facilitating the troubleshooting process."
6828;en_US;"This paper presents the result of an analysis of the influence and reputation of publications on Social Network Analysis. Its purpose is, through Social Network Analysis metrics, analyze if is possible to identify the most relevant publications on a given field by conducting automatic searches on scientific digital libraries. We conduct a literature survey on the subject in focus and an analysis of the interaction between publications and their citations. Additionally, we conducted a quantitative analysis of the journals with the highest number of publications and the growth of publications over the years."
6829;en_US;"In order to identify new leaderships through the concepts of centrality and prestige inside software communities, complex network study and analysis can help us understand if the collaboration activity is capable of producing knowledge inside the community. This article proposes the usage of a mobility rate metric, calculated as the reason between the members who could actually learn through collaboration. The calculation is made by analyzing the creation of collaboration objects, and the result is exemplified applying the technique to Brazilian Public Software Portal communities collaboration data."
6830;en_US;"There is an increasing incentive to the participation of advisees in the advisors production. Coauthoring an scientific production or, specially, to be the first author of this production is considered a very important activity in the education of undergraduate and, mainly, of graduate student. This paper analyses the advisees participation in the production of their advisors, correlating information about advisory, production and first authors in a Computer Science case study. Moreover, the coauthorship network composed of advisors and advisees were constructed and evaluated comparing network metrics with productivity and advisory metrics."
6831;en_US;"This paper aims to analyze network of coauthors who publish in the same journal by means of semantic network based on titles of their articles. The use of semantic network allows a better understanding of how authors in the same journal are integrated, since a coauthorship network can be highly fragmented. Two journals have been chosen for implementing the method that consists of obtaining, by means of uniform semantic network, an associated coauthorship network. The result suggest how researcher deal with the choice of word of titles of paper in keeping with the journals identity."
6832;en_US;"This article discusses some aspects of interactivity in a large-scale training program and presents indicators based on social network analysis, which contribute to the evaluation of training programs based on Information and Communications Technology. The case study consists of a large-scale training course for digital inclusion agent in semi-distance mode, with emphasis on the use of online social network. In the course, social network are planned to: (i) operate as articulation space of community project involving digital inclusion agent and communities, and (ii) share solutions to common technical problem, indicating appropriation and community involvement in these spaces."
6833;en_US;"Multidisciplinarity is increasingly present in Science. The huge amount of available data as well their complexity have been demanding a large deal of effort from different area for the understanding and resolution of problem. On the other hand, the interaction between people with different disciplinary education - alone - is a defying field. This paper describes the roles of the researcher in Brazilian post-graduate programs on Bioinformatics - an essentially multidisciplinary area - characterizing their interesting area and collaboration network."
6834;en_US;"Polarized social network arise from domains where people have two conflicting and opposing viewpoints regarding an issue, such as abortion, gun control and same-sex marriage. However, in many real scenarios, multiple positions can be adopted in relation to a topic, as in multipartisan political system and sports competitions. In this work, we show that multipolarized social network unveil inconsistencies and simplistic assumptions on model that deal with bipolarized network. In particular, we find that the proximity of a pair of user in the social network does not necessarily implies sharing of viewpoints. Moreover, we propose a simple model that capture relationships of support, antagonism and indifference which can be seen on multipolarized network, by combining endorsement and communication interaction among user."
6835;en_US;"The automatic identification of expertises area or the main subject of a scientific paper is an important activity which work as basis for different social network analysis system for the evaluation of interdisciplinary groups, detection of new trends and search for experts. This paper presents an approach for the automatic identification of researcher area of expertise combining text mining and social network analysis technique."
6837;en_US;"Online social network have become extremely popular, leading to emergence and growing popularity of a new wave of Web-based application. The presence of this type of media is important since they provide a special kind of debate that conventional forms fail to bring about. The proximity that a tool like Twitter offers its user have power to humanize the figure of candidate from the direct communication between the parties, which takes a different form of communication between the main actors of election. In this sense, the present work aims to show how to obtain data from a social network can be significant, comparing them not only with the outcome of the election itself, but also with the result predicted by conventional surveys."
6838;en_US;"Twitter has become an important social communication mean where user post message about everything. Several social networkings user use emoticons, a pictorial representation of a facial expression, to try to represent the sentiment expressed in their message. Potentially, when analyzed in large scale, message containing emoticons could be used to measure public mood fluctuations at the level of populations. Such measurement could have several application, such as to predict collective mood trends of populations related to specific topic as well as to understand the effects of social phenomena in peoples feelings. In this paper, we give a first step on this direction by providing a deep understanding of how emoticons are used by Twitters user, analyzing the most popular emoticons and how they appear associated to global scale events. In order to validate our approach, we used a unique dataset containing 1.8 billion tweets to evaluate public mood fluctuations on a serie of events that span topic related to tragedies, releases, politics, health, as well sport events. Our result suggest that emoticons can correctly capture expected sentiments of message of this social networking."
6839;en_US;"The identification of future relationships in a social network is a re-levant subject which is receiving, in the last years, attention from both, the scientific community and the industry, because it allows the prediction of the networking behavior or the recommendation of new relationships in order to optimize the network evolution. This paper presents a methodology and the result of the use of attribute selectors, filters, classifier and functions to predict coauthorships in academic social network in order to evaluate the performance of different algorithm and to identify some of the most relevant attributes for this prediction."
6840;en_US;"Link prediction deals with the occurrence of connections in a net-work. In this work, we propose a new proximity measure for link predictionbased on the concept of temporal events. We defined a temporal event relatedto a pair of node according to the creation, maintenance or interruption of the relationship between the node in consecutive periods of time. We proposed an event-based score which is updated along time by rewarding the temporal events observed between the pair of node under analysis and their neighborhood. The assigned rewards depend on the type of temporal event observed (e.g., if a link is conserved, a positive reward is assigned). In the performed experiment, we evaluated the proposed event-based measure for link prediction in co-authorship network. Promising result were observed when the proposed measure was compared to previous work developed in the literature of link prediction."
6841;en_US;"The personality traits are directly related to all actions and thoughts of aperson, whether in real life or online social network. On Twitter, a user popularity is related to his number of followers, but this measure may not reflect on their ability to influence others. This paper presents an experimental study to predict influencers on Twitter, based on personality traits. Two types of user were investigated, celebrity followers and regular ones. The experimental result showed that regression model for influence indicators can be learned with acceptable accuracy in both cases. Several insights about the relationship between personality traits and twitter usage are also reported."
6842;en_US;"In this paper we present a research on the existence of relationship pattern in a scientific community and its trends over time. network are formed by cliques from the titles of scientific articles published in the Nature journal. The method has its theoretical basis in Time-Varying Graph (TVG). We consider a window bimonthly (week by week) and advancement in time shows the evolution of network of word from the titles of paper published. The analysis is carried out using indicators timeless. The result compare the pattern of vertex connections of each network TVG at different times. network have the small-world phenomenon."
6843;en_US;"Considering the interaction and evolution of human activity associated relationship in online social network (OSNs), we describe the Follow Model to present the relationships between user and further extend this logical formulation to Adjacency Matrix (AM) as Relationship Committed Adjacency Matrix (RCAM). With this relationship presentation by matrix, K-step multiplications of the RCAM can be used to query k-th sequence of the followers of followers etc. The paper establishes several mixed model with target and similarity functions to query who may probably retweet. A framework for retweeting prediction by Conditional Random Fields (CRF) method is developed and implemented together with the data from a Chinese famous micro-blogging, Sina Weibo. The simulation obtained the result of retweeting prediction with the indexes of precision larger than 61% and recall larger than 58% in some case studies."
6844;en_US;"This article presents an analysis of the meaning of the concept of correspondence attributed by an elderly social network. The vertices of the network are represented by the word evoked by each elder, and the connections between these word characterize the edges. The analysis was based on the theory of social and complex network and performed from the largest component. The result show that this is a small world network. It is concluded that the analysis of semantic network from the theory of social and complex network is an interesting strategy to understand the meaning of co-residence from the perspective of the elderly, an understanding that can aid in planning and health care actions for this population ."
6845;en_US;"Social media has made possible new customs and cultural practices. Through them, people can exchange ideas, disseminate information, promote debate, and plan actions. Through social media, real social network between people are replicated in the virtual world, enhancing interaction in different context. One of the predominant problem in social interaction is the process of event planning and task assignments. This work proposes a tool that supports the planning of events and assignments of tasks, in a collaborative way, using Facebook. This tool enables the rapid formation of teams, providing a recommendation resource for the participant of the proposed tasks and through the interaction between leader and participant."
6846;en_US;"When observing a scene, the human eye usually filters out a large amount of visual information and focuses its attention on selected (outgoing) regions. This selection process is actively controlled by oculomotor mechanism that allow the focus of attention to be maintained in a given location (fixation), that is, moved to another outgoing location (balconies). In this way, visual attention is a characteristic of the human eye system that aims to reduce the complexity of the data to be processed and maximize the amount of useful information to be assimilated in a given scene. In turn, social network provide rich environments in terms of visual information, ie photos, video, graphics, etc. Despite this, there is a gap in work that exploits user behavior in online social network based on aspects of visual attention. In this work, we used computational visual attention model to analyze captured image of a set of user profiles in social network considered popular in Brazil. We get as a result of our model, overhang maps and the intended order in which the user fix the looks on the captured image. We compared our result with studies that analyze how user interact with online social network using clickstream data. The result show that there is a strong correlation between the predicted ocular fixation order and the navigation priority obtained by the clickstream data analysis."
6847;en_US;"Social network have been used as data source to predict the occurrence of real events. However, the success of such predictions depends on the ability of the model to capture the characteristics of the event in focus, and determining the most appropriate model is a challenge. In this work we present a methodology to evaluate comparatively different model with a view to selecting the most appropriate one. We also apply our methodology in the context of predicting the dengue epidemic, being able to identify the best model for each city to be employed and the characteristics that justify its choice."
6848;en_US;"This paper presents a mathematical model of contagion that admits that the phenomenon of propagation of information can be modeled matematically with the same principles as the transmission of disease."
6849;en_US;"This paper describes an approach for analyzing the structure of dialogues produced in textual communication tool. The text generated in chat sessions has a non-linear format, because the message are not associated with the preceding message. Therefore, it is interesting to analyze the structure of the dialogue building a graph with the associations between message for later analysis and a better understanding. This paper presents an approach based on comunicografia, a theoretical methodology for automating the analysis of dialogues."
6850;en_US;"Software Ecosystem (SECO) emerge from the interaction among actors around a common technological platform, which is centered in a software product. Due to the different kinds of interaction derived from artifacts that compose SECOs, the created network is no longer exclusively social; it includes both actors and artifacts. In order to better visualize, organize and use those network, this paper describes an approach to organize SECO elements through socio-technical network."
6851;en_US;"The analysis of social network has been the focus of several studies in different area of knowledge. Mainly scientific collaboration network, where data on productivity and intensity of collaboration reveal important information for understanding the evolution of research. This article presents the process of data extraction from Plataforma Lattes and modeling the extracted data in a huge network of scientific collaboration. From this network are produced several result that provide an overview of the productivity and collaboration of all user of the platform."
6852;en_US;"An important problem in social network analysis is the partitioning of its user, in order to discover groups of user that have common interests or characteristics. Given a collection of objects to be clustered, typically there is not a single way of forming the partitions. Besides, when objects are user of a social network, each object may be present in several dataset associated to the social network. This paper describes work in progress on a procedure to cluster user of a social network. The particular characteristics of the social network we study motivates us to use a relatively new approach to clustering, namely multi-view clustering. We present our multi-view clustering procedure, that uses several existing perspectives of these user to generate alternative and complimentary clusterings, that in turn can reveal novel ways of interpreting these user."
6854;en_US;"The subjective character in movie analysis makes any prediction an unreliable one,even when made by experts. The propose of this paper is to investigate how human relations contribute to the success of the cultural industry, namely, cinematographic productions. This work was based upon the Susceptible-Infected-Recovered (SIR) epidemiological model and the concept of the influence coefficient and Peer Pressure phenomenon."
6855;en_US;"In this work, clustering heuristics combined with PCA (Principal Component Analysis) technique are proposed in order to create recomendation system of study groups. The composition of these groups is built in such way to ensure a minimal heterogeneity among the characteristics (learning style) of their members, in order to promote better efficiency in collaborative learning."
6856;en_US;"Most recommendation algorithm in the context of large-scale social network struggle with the need of an efficient exploration of the underlying user graph. Current solutions in the form of graph-specific databases or framework for graph algorithm do not scale well for processing complex navigational pattern. In this paper we present an approach for supporting social recommendation algorithm that operate with large graph in a computer cluster based on policies, rule that allow user to throttle the amount of parallelism and control task location."
6858;en_US;"Scientific social network help to understand the dynamics of scientific knowledge production. The present work aims to analyze the social network of computation in Brazil in relation to parameters of productivity and metrics of social network, making a comparative between both. For this purpose, a Data Warehouse model is proposed that is able to cross the spatial, temporal and research groups information in relation to their productivity and in relation to the measured social metrics."
6859;en_US;"Social network are dynamic social structures formed by individuals or organization. Generally, these network are represented pornos connected by one or more types of relationships. Although the structures are extremely complex, analyzing them allows us to detect different types of connections between people inside and outside their institutions."
6860;en_US;"The curiosity to know what people think and how they feel about the day to day events has always existed. This paper aims to meet this need and analyze whether people react positively or negatively to news stories in the media. For this, 3 topic were selected and, for each of them, information published in the Twitter microblogging service were collected, analyzed and had their polarity identified. The experiment used language classifier and, in addition to verifying the opinion of the population in relation to the selected news item, it was possible to identify among 3 different linguistic model which obtained the best result when classifying tweets."
6861;en_US;"This article presents a study of the interrelated and oriented temporal academic relations for a group of researcher in the area of ​​Computer Science with curricula registered in the Lattes platform. We analyzed the main characteristics of the group and their coauthor relations. We observe that the duration of co-authorship, which is established between oriented orientador, can extrapolate the formal period of orientation, and, moreover, we show that the duration of the collaboration time, in the form of co-authorship, correlates with the number of articles in magazines, ."
6862;en_US;"The average distance between us in a social network is small, considering the theory of the six degrees of separation. However, online social network offer no way to find ways among their user. Traditional algorithm are applicable for offline copying of your graph. However, in the Web, the ideal is to find ways using online data, which is a difficult task considering the limitations of access imposed by social network. In this work, we introduced an algorithm to find ways in temporeal, called CUTE. It uses a heuristic that considers the geographic distance between user. In our experimental evaluation with Twitter, oCUTE finds short paths between user, expanding less than 40 node."
6863;en_US;"Polarized network constitute a type of social network that has been gaining increasing attention from researcher, social scientists and marketing agent. Such network are manifested in various context in which individuals organize themselves into groups that oppose each other, because they have goals, ideologies, and conflicting visions, and can be observed in relevant context such as Politics, Sports, and controversial themes that stimulate debate However, in the literature there is no precise and coherent analysis of the structural feature of a polarized network. In this work we show that the current concept of polarized network - network that have user groups with high internal cohesion - is not enough to classify a network as polarized, since non-polarized network (like network of friends) also have this property. Our main contribution is to demonstrate that polarized network exhibit an additional structural characteristic - low edge density at the border of the communities."
6864;en_US;"The topological characterization of complex network allows us to analyze the behavior of natural and social system. These analyzes facilitate the understanding of the structure and dynamics of network. In recent years, (complex) co-authoring network have attracted considerable interest due to the fact that they represent social behavior among researcher. This work describes a proposal for (i) the automatic identification of coauthors in bibliographic productions, and (ii) the topological characterization of coauthor network of groups of researcher enrolled in the Lattes Platform. The proposal was evaluated considering 176 114 Lattes curricula of researcher associated with the Great Area of ​​Exact Sciences and Earth."
6865;en_US;"This article shows the classification of profiles in an academic social network, Scientia.Net to allow user with similar profiles to interact. This classification is done automatically using algorithm of Machine Learning, in this sense this work shows result of the selection of profiles using unsupervised algorithm in order to choose the one that will be chosen to be applied in the social network. We address the problem of profile classification focusing on social network citing implications regarding network structure, and quality of links formed from this grouping."
6866;en_US;"Social network have played an increasingly fundamental role as a means for the dissemination of information, ideas and influences among its members. The objective of this article is to determine both influential user and relevant content, that is, to order both groups of user and the content disseminated by them. We propose a new technique based on an intuitive and circular definition of relevance and influence. This technique is described in detail as well as its efficient implementation. It has been validated using two real Twitter databases for purposes of recommendation. The result obtained show that the proposed technique presents 37% NaHs when compared to a collaborative filtering method, while both influential user and relevant content are qualitatively superior."
6867;en_US;"This paper describes the bases for a study of the dynamics of co - authoring relationships among researcher associated to the postgraduate programs in Computer Science evaluated by CAPES in the 2007-2009 triennium. In all, 889 permanent researcher were identified in the 45 postgraduate programs evaluated. A robust heuristic of entity resolution was developed, allowing the identification of the co-authorship relationships among researcher, with a hit rate higher than 96%. By observing the co-authorship network, it is possible to observe interesting phenomena of the dynamics of Brazilian research, especially related to the increase in joint production between and within postgraduate programs."
6868;en_US;"Lattes Platform Resumes are a vast source of information for the creation and analysis of social network of researcher. Due to the amount of data, the manual completion and the use of semi-structured data, there are several challenges for the use of these curricula. This article presents a database produced from the mining of more than one million Lattes Curricula, describing some characteristics and relationships of these curricula, directions and challenges for the production and analysis of social network from this data."
6869;en_US;"This work presents an approach for the analysis of scientific communities from its publications. The main objective is to understand the community profile, by obtaining indicators from scientific publications through text mining. These indicators are generated automatically, and can be: a collaborative network and the publications context (classification). A system was developed to support this analysis and comprises two main modules: graph generation and document classification. A case study with the Brazilian research community in Information system was conducted."
6870;en_US;"This article presents the use of the most popular Microblogging, called Twitter, in order to define the degree of interactivity and content collaboration among student of the same class. Thus, the present work deals with the application of Social Network Analysis technique as an instrument to achieve the aforementioned objectives. Using theTwitter, a study was carried out with a group of higher education student, applying the following analysis metrics: in-degree centrality, outdegreecentrality closeness centrality and betweenness centrality. The result obtained were compared by the teacher with the face-to-face conduct of the student, helping to define the profile of each of their student in relation to their interactivity and collaboration and enabling the accomplishment of a work that stimulates group participation."
6871;en_US;"Twitter has become an important medium of social communication, where user post message about everything. Some of these message express information about the user emotional state, which can be useful in developing application that predict the emotive tendencies of a population or simply to better understand the effects of world phenomena or places in peoples moods. In this work, we adapted a metric scale known as PANAS-x, commonly applied in questionnaire form, to measure the feelings of Twitter user about a serie of social, political and sports events. Our result suggest that PANAS-t, our adapted version of PANAS-x, correctly captures feelings for the analyzed events"
6872;en_US;"system that classify influential user on social network have been used frequently, being referenced in scientific articles and in the media as the ideal standard for assessing influence on Twitter social network. We consider this measurement to be somewhat complex and subjective and so we suspect the vulnerability and ease of manipulation in these system. Based on this, we perform experiment and analyzes in two influence classification system: Klout and Twitalyzer. We create simple robots capable of interacting through Twitter accounts and measure their influences. Our result have shown that it is possible to be influential through simple strategies. This suggests that system do not have ideal metrics for classifying influence."
6873;en_US;"The production, appropriation and diffusion of knowledge occur in diversified ways. In science there is the publication of articles. In the case of datecnologia, the appropriation of knowledge is guaranteed by industrial know-how or patent protection. This work allowed us to measure the national insertion in the research and development network (PeD) of vaccines by the existence of co-authorship / cotitularity (proxy variables) of epistatic articles. The case study shows that there is a significant difference in the number of scientific publications of national authors and patents deposited byresidents (institutions / researcher). There are few collaborations (co-authorship / joint ownership) of articles and patents, despite being carried out with the most productive groups in the world in the sector. The use of social network analysis (ARS) can be a useful tool to provide technical support for decision-making in the public and private sectors, besides making public policy evaluation possible."
6874;en_US;"Political discussions are characterized by conflicts of interest and decisions are made based on negotiations. In general, participant in these discussions need to strengthen their opinion and influence the other participant so that the decision taken favors their vision of solution. In this context of intense relations of influence, it is important to know how allies and opponents are positioned to understand the situation of the discussion and to plan appropriate manifestations. The purpose of this article is to use visualization of social network to explain confrontations and alliances to support the understanding and follow-up of political discussions."
6875;en_US;"Some social network consist of links between groups of mutually connected actors that form a click. The classical approach with Social Network Analysis indexes does not take this particularity into account. We have introduced new cohesion indices based on the click-through approach, and have re-defined the concept of network density. These were applied to two co-authoring network: one formed by researcher who publish mathematical education journals and another by researcher of a Graduate Program in Computational Modeling. A comparative and contextualized analysis is done to show the applicability and the potentiality of the indices, in the treatment of data of social network."
6876;en_US;"This article presents preliminary result of a study on the use of cellular by the Brazilian public. The focus was interviews from a sample of 40 children in the range of 8 to 14 years old attending public and private school of the ABC of São Paulo. Using quantitative method, it was developed to clarify the main motivations for cell phone use and which were the main functionalities of the device that were indicated as preferential. Special attention was given to accessing the internet through the mobile phone and its impact on social networking. result show that the children interviewed use their cell phones as an essential means of communication, and this can be observed in different age groups regardless of the profiles of social distinction."
6877;en_US;"The objective of this study is to discuss how process of scientific collaboration can be characterized from complex network. For this, we studied the bibliographic productions of a post-graduation program in computational modeling. The data source was the CAPES scorecard. Complex network indices show a small-word pattern and exhibit scale-free distributions behavior."
6879;en_US;"The article studies the champions of the years 2009, 2010 and 2011, of the serie A of Brasileirão. Substitutions between players were seen as relationships in a social network. The objective of this work is to study the topological properties of the network and to establish, through the analyzes, common properties between the three years."
6880;en_US;"Given the importance of INCT for Cancer Control and the existence of several groups working on the same theme, it is important that they collaborate with each other. For this, the BRINCA project was created and it was conducted a serie of analyzes of the scientific network of this INCT. These analyzes were conducted using Lattes and PubMed data mining. The analyzes served to coordinate this INCT to take actions to understand and improve scientific collaborations."
6881;en_US;"Traditionally the search engines are designed to support a single user working alone. However, the construction of knowledge is enriched by the collaboration of search tasks. We proposed an architecture of identifying opportunities for collaboration to guide the construction of a collaborative web search system for children aged 6 to 8 years. The architecture was driven by the dimensions of 5W + 1H (who, what, where, when, why, how) and identified 9 remote collaboration opportunities for the search process. The social search model of architecture integrates parents and children and aims to improve the search process for children."
6882;en_US;"The Work Education for Family Health Program (PET), created by the Ministries of Education and Health, is a proposal for a teaching-service-community interaction, whose objective is to foster the formation of learning groups within the scope of the Family Health Strategy . The purpose of this article is to analyze the information and knowledge flows of this network from the analysis of social network. The role of the Coordinator of the PET Family Health in the organization and articulation of the network was highlighted in the study."
6883;en_US;"Microblogging offers fast, portable and organic information and can be considered as meaningful source of learning. This article presents a social recommendation mechanism that, based on the temporal analysis of the message, outlines the interest profile of the user, recommending new relationships, in order to help the learning process."
6884;en_US;"This work draws on Cancho e Solé (2001) on pattern of association between the word of a language from the concept of small network (Watts e Strogatz, 1998). Calculating the most likely connections in such a wide scope has led to this exploratory study based on a single text in Portuguese language, seeking to verify how semantic and semantic associations in the limited domain (climate change) behave. The objective is to generate objective measurement of the degree of semantic similarity between word that co-occur in a text, assuming that they can be treated as network vertices where co-occurrence measures and distance between node are indicators of similarity, allowing the modeling of lexical network."
6885;en_US;"The advancement of social media in recent years the user defines their identity through information sharing. This article aims to show the evolution of these media highlighting the effects and transformations they cause in society through the scenario of SuperBowl XLVI, as well as pointing out the important role they have for the marketing area of ​​company."
6886;en_US;"Each year the number of Brazilians who have access to the web increases and a large part of them use social network. Each social network has a parameter to classify an individual, because each measure is different and presents only one perspective, it is necessary a measure that shows the absolute influence among all social network. This article uses the Wentropia method to calculate the influence among various social network. This method is defined based on information theory and uses Twitter data, Facebooke Google search. Comparison with the Starcount method shows that W-Entropy is more appropriate in a case study."
6887;en_US;"Currently there is a breakthrough in technology, especially in the area of ​​social networking, which allows us to access newly released information at a fascinating speed and a comprehensive audience. Inserted in the business field, the area of ​​data mining is gradually being used in the media, in order to find groups of people who have an ideal pattern of purchases for a particular company. We present in the following article a case study related to data mining on the social network Twitter."
6888;en_US;"The new references established by the information society and the progressive introduction of technology as a facilitator of communication and access to information have great impact in the educational area. The current student of higher education come from a generation that actively participates in virtual communities, where they share content and act collaboratively.It is expected that teaching strategies aimed at this audience take advantage of these new skills. This article discusses the use of social networking tool for e-learning, and presents a pilot experience of using Facebook to support university education."
6889;en_US;"Social media are important tool that the worlds user have to connect and exchange experiences. These mediums opened space for a new form of patronage to establish that consumers would unite with the objective of raising funds to make feasible the performance of an event or service, called 'crowdfunding'.This article brings a study on the subject through data extracted from various campaigns by establishing a profile of its investors."
6890;en_US;"Currently, the popularization of Web 2.0 has caused an increase in the use of textual communication application. To complement the exchange of information and collaboration, data already available in open databases on the Internet can be used to enrich discussions and even help reduce problem of ambiguity and interpretation in this type of communication. This article introduces an approach to the recommendation of content in the form of open data interconnected in textual communication tool, presenting the first result of experiment for the recognition and extraction of named entities, mechanism considered essential in recommendation strategies."
6891;en_US;"The present study addresses the characteristics of personal social network and the resilience of 12 (twelve) women deprived of liberty housed in the Criminal Unit ofMujeres (Mendoza Argentina). This research is non-experimental of correlational type. The central objective is to infer about the relationship between resilience and social network quemantém a group of women deprived of freedom. The instruments used to pave the data were: ERAC (Mikulik e Crespi, 2005) and Egonet. The present study is a contribution to the scarce existing research on the topic addressed."
6892;en_US;"The subjective character present in the evaluation of films makes any prediction of success uncertain, even when done by specialists. The purpose of this work is to investigate how human relations contribute to the success of cultural industry products, especially cinematographic productions. The study was based on the epidemiological model Susceptible-Infected-Recovered (SIR), on the definition of the coefficient of influence concept - extracted from the analysis of social network - and the phenomenon Pressure per Group."
6893;en_US;"The growing use of mobile device by the population and the high popularity of the social media in current society, such as Facebook, produce plenty of information with contextual data. One obstacle to the emergency response team during the response phase of emergency management is to obtain information that could lead to solving a particular situation involving victims. In this paper we present a proposal which aims to collect information from social media and mobile device, identify the contextual information and analyze them to indicate people who could help in the identification of victims."
6894;en_US;"There are plenty of public content available on the Internet, especiallyin online communities, enabling researcher to study society in new ways.Since the qualitative content analysis of online forums is very time consuming,the following problem arises: how to select the content to be analyzed? Thispaper introduces a new process to support solving this problem. This process isbased on unsupervised machine learning technique and provides consolidatedand structured result. This includes measurements and a content explorationmethod. A tool that helps to apply the proposed process was created and ispresented as well."
6895;en_US;"Customized social grouping system can be viewed as referral system that signal to a specific person other members of the same social network with desirable skills and / or characteristics. In this work, an algorithm based on ants colony is applied to the problem of optimization of grouping / correspondence of individuals in a specific social network for this purpose; during this process, their personal characteristics and preferences (and their relevance) in relation to the individual (s) with whom they are related are taken into account."
6896;en_US;"Isolated document visualization method are usually simple, based only on the frequency of terms, or depend on the lack of syntactic and semantic information to be more meaningful. This work proposes an intermediate method, based on automatic text-based algorithm, and attempts to aggregate more information without requiring external data. We consider the frequency of repetition of pairs we hold important and the distance between them at each encounter."
6897;en_US;"The development of software has been evolved to a multiple-product development created into a platform and based on a common architecture integrated to other system. This integration happens through components and third-part developers network in software ecosystem (SECOs). So, social network can be important to coordinate a collaborative and distributed environment to develop SECOs platforms. This paper analyses the impact of social network in SECOs and extends a social lifecycle for SECOs"
7057;en_US;"The objective of this proposal is to present steps for the development of future work, which will perform an analysis of supervised machine learning algorithm of classification task, which will address classification accuracy in sending and receiving notifications in environments intelligent, based on the control and privacy management middleware, called UBIPRI."
7062;en_US;"This paper aims to analyze the parallel programing interface OpenMP and Intel Threading Building Block (Intel TBB) in a new benchmark composed by a set of application. The execution times obtained in five application were compared using the two interface, along with the sequential versions of the algorithm. The paper evaluates the parallelization strategy of each interface. The result obtained showed that in the majority of tests performed OpenMP had a better result than TBB. The TBB interface obtained result very close to those of OpenMP in most application."
7094;en_US;"<p>Introduction to the Proceedings of the Undergraduate Forum by the coordinators Marcia Pasin (UFSM) and Carlos Oberdan Rolim (URI).</p>
<p>&nbsp;</p>"
7095;en_US;"<p>Introduction to the Proceedings of the Graduate Forum by the coordinators Claudio Schepke (UNIPAMPA) and Guilherme Piêgas Koslovski (UDESC).</p>
<p>&nbsp;</p>"
7096;en_US;"This paper is based on a Natural Language Processing tool called Doc2Vec, for the semantic representation of textual document. The database of interest is composed of 44 (forty-four) undergraduate course final paper. Text mining technique were used to process the digital archives of the monograph and generate the text. Each document is represented by word vectors and the model performs term inferences for semantic analysis. As a result, the similarity of the document is in the form of a weighted graph, closeness between each element of the data sample."
7097;en_US;"The analysis of Big Data has become so important with the progressive increase of the information stored in digital media. Extracting more value from diversified and unstructured data is really challenging. With the help of predictive model, it is possible to find new pattern and trends that could be innovation bases. Predictive model need to have a relevant reliability rate to aid us in decision-making process. In this context, this article discusses the influence of confounding variables on predictive model and proposes technique for identifying and minimizing their effect. Through a database with information collected in a hospital, it was possible to construct a predictive model, to identify possible confounding variables, to apply a technique to minimize its influences and to evaluate the accuracy of the model through machine learning technique. The result was an efficient prediction model. "
7098;en_US;"The next-generation wireless network (5G network) predict an expantion in the connected device number and network interface with higher transmission capacity, and consequently an exponential increase in the amount of traffic. In this context, solutions that do not overload the wireless communication infrastructure are needed to improve efficiency. This paper presents a cache’s proposal based on interest and interaction between device in network with D2D communication, which seeks to settle some of these problem. The proposal is based on cache approaches’ and solutions case studies aimed at improving the network’s use through the efficient use of its resource. It was verified that the proposal presents improvement of 25% when compared to another cache’s approach. From these result we can conclude that the use of this information can be beneficial for 5G network strategies."
7099;en_US;"Electric vehicles are rising in popularity because of the politicians, automakers, and citizens’s interests. The same event happens with the number of mobile network (mobile or wi-fi). With the growing of user each day, many researcher are concerned that the infrastructure can become insufficient, leading them to believe in opportunistic network protocol as a solution. About the growing of electric cars, these protocol can impact in their autonomy. With that in mind, we propose a model of electric vehicles to analyze the effect of these protocol on the autonomy of the vehicle."
7100;en_US;"Accessing unauthorized device on a network is an security issue on Internet of Things. The unique identifiers of the device used to authenticate them can be easily cloned, thus requiring another form of authentication. By monitoring the electromagnetic spectrum by means of a software defined radio it is possible to capture data transmitted by various wireless communication device. These data allow us to extract unique characteristics of a device, since an electric circuit that generates the electromagnetic signal does not behave perfectly like another. These characteristics can then be used to create a unique signature, thus enabling device differentiation. There are several IoT technologies on the market and it is expected that the implementation of an authentication technique will be technology independent. For the validation of the technique are collected signals of nRF24L01+ technology device, extracting characteristics of the magnitude of the signal. These characteristics are used in a classifier, which gives an accuracy of 94.7% in device differentiation."
7101;en_US;"This work proposes a flight path optimization model for drones that serve as a communication gateway or data mule for IoT (Internet of Things) sensor scattered in an Intelligent Campus. This drone has limited power autonomy (battery), and in many cases can not fly over the course required to serve all allocated sensor. Therefore, the paper proposes, using Linear Program-ming, a model that ensures the maximum of sensor are satisfied considering the autonomy found in the drone."
7102;en_US;"This work aims to evaluate the implementation of the photovoltaic solar energy system by shared generation in ten residences in the state of Goiás, from a economic-financial point of view. For the economic-financial analysis, the optimistic and pessimistic scenarios were economic indicators of the net present value, profitability index, internal rate of return and payback (simple and discounted), in addition to comparing with a case study reference. The result showed that the system is feasible, can be accepted in the two scenarios evaluated, it is superior to the reference case study and can attract participant with potential investors."
7103;en_US;"A candidate technology to be used in the new generation of mobile communication, the 5G, is the F-OFDM (Filtered-Orthogonal Frequency Division Multiplexing) modulation, which basically consists of the application of filters in the OFDM modulation subbands. technique such as windowing allow the design of FIR (Finite Impulse Response) filters with variable performance depending on the chosen window, but which generally provides greater efficiency in the transmission and reception of data signals when compared to the OFDM modulation. In this article different types of windows are analyzed for the FIR filter design to be used in F-OFDM. In addition, this article proposes the use of pulse shaping technique to design the FIR filter prototype in order to increase its performance. In order to evaluate the proposal of the article, simulation of image transmission using F-OFDM modulation are carried out in comparison to OFDM modulation in terms of BER (Bit Error Rate). The result obtained in the simulation indicate that the performance of F-OFDM is generally higher than that obtained with OFDM modulation, but variable according to the filter design. In simulation, reduced BER values were obtained using the proposed filter: an application of the pulse shaping technique to the FIR filter prototype combined to the appropriate choice of the window to be used in the filter. The result indicate the relevance of the F-OFDM modulation filter design to make F-OFDM a modulation candidate to be used in new data communications architectures, including 5G."
7105;en_US;"This article reports the use of metaheuristic technique for the resolution of the so-called Teacher-Classroom Timetabling Problem, one of subcategories of the Educational Timetabling Problem. The three metaheuristic technique employed are: In Vitro Fertilization Genetic Algorithm, Tabu Search and Greedy Ramdomized Adaptive Search Procedure. The experimentation was carried out with one real instance of the problem coming from a Brazilian school dedicated to elementary education and, in addition, with instances from widely known dataset. It turns out that the method are able to produce solutions suitable for practical use in their context, being that method In Vitro has overcome the others for the established optimization goal."
7106;en_US;"The problem of longest paths in graph, began to be discussed in 1966 from a question raised by Gallai, which questions whether any connected graph has at least one vertex that appears in all the longest paths. In this work, we studied the longest paths in chordal graph, weighted graph, trees and complementary prisms graph and we obtained theoretical result and some factorial time algorithm, trying to understand the problem and the behavior of the longest paths in some types of graph."
7108;en_US;"The aging population in the world has grown considerably, and the forecast for the year 2050 is around 22% of the worlds population. People over 65 years of age tend to face some health-related problem such as falls, respiratory, cardiovascular, and other disease. In this context, solutions that offer improvements in the quality of life are relevant. This project aims to build a health monitoring system for the elderly, in a way that is economically feasible and technologically possible. The system includes monitoring heart rate, body temperature and detection of falls. For family members or caregivers, a mobile application is offered to monitor data and receive alerts on monitoring situations."
7109;en_US;"Identifying activity, establishing precedence, deadlines, and those responsible are initial tasks for good planning of software development. For this, there are important tool to help managers, such as the application of Critical Path Method (CPM) method and the development and monitoring of the Program Evaluation and Review Technique (PERT) network diagram. In the combination of these method we have the PERT-CPM, which, in this work, was applied on a case study about the production of a Web and mobile educational game using agile method. As a result, with PERT-CPM it was possible to identify experiences and lessons for other project."
7110;en_US;"The reality in the organizational context is perceived by its complexity and manage it has been a challenge to your leaders. The dynamic inherent to the organization difficulties the adoption of the Knowledge Management (KM) practices, because the instability, uncertainties and turbulences imply in constants changes of the business. The objective of this study is to define evaluation parameters that can contribute to the maturity specification model of KM, in way to assure the relational and conceptual precepts inherent to organizational system. This is a narrative review that culminated with a discover of multidimensional nature parameters to evaluation of the maturity level of KM in complex scenarios."
7111;en_US;"This article provides the characterization of textual data with traces of racism in Portuguese obtained from Twitter. It discusses racism in ethical and legal terms for conceptual identification. It explains Sentiment Analysis and some approaches and possible levels of analysis. At the end, the facts perceived during the data collection process are discussed."
7112;en_US;"The present work aims to extract associations in data of criminal oc-currences in the city of Goiânia, identifying the neighborhoods where there is a greater concentration of crime, considering the spatial and temporal distribution, as well as the socioeconomic profile of the place of occurrence. The developed process uses all phases of knowledge discovery-KDD (Knowledge Discovery in Databases), including the selection of attributes, cleaning, standardization, pre-processing and data transformation. The data set used in this study refers to the record of criminal occurrence provided by the Information Analysis Management of the Public Security Secretariat of the State of Goiás. The result obtained through the use of association rule gathers important information about criminal occurrence, such as the identification of the most frequent crime in a specific place, in a time period, with a specific victim profile. The result are relevant to help decision making and also to inform and alert the population about the places with the most criminal occurrence at certain times in the municipality of Goiânia."
7113;en_US;"This article aims to use Multiagent system, through the GAMA platform, to simulate an electric power distribution network and its regular and irregular consumers. To identify the irregularities is proposed a computing analyzing agent that, from the simulated data, suggests the possible irregular consumers. Through the simulator and the analyzing agent, it is possible to do complementary studies about the efficiency and effectiveness of the method used to detect non-technical losses (PNT)."
7115;en_US;"This research intends to evaluate the level of learning achieved with the application of methodology based on the discipline of Business Process Management (BPM). The study was developed through an exploratory analysis of a set of company, located in the State of Goiás, that underwent a process of intervention at the level of consulting or training to improve business process. In order to do so, an evaluation tool was structured based on factors considered critical for success in the implementation of business process in the corporate scope. The result allowed to reveal an acceptance framework favorable to the assimilation of the applied methodology, but with a strong tendency of unsatisfactory in terms of support and accommodation of the planned practices and actions."
7116;en_US;"This work consists of displaying the study, analysis and survey of requirement of administrative relations, interconnections with the production of information and system operation in the Support Hospital of Brasília. And subsequent construction of an ERP capable of reformulating the communication process and optimizing the administrative activity, current reason of disorders and impediment in the agility of tasks. The process of gathering requirement was performed, through ethnography, technique used in Software Engineering for this purpose. The artifacts found and built: responsibilities of the sectors, diagrams and description of use cases, class diagrams, demonstrate how efficient the technique is and able to uncover problem and operations not perceptible to the requirement analyst only with quick technique such as interview."
7117;en_US;"In the face of constant changes and cyber threats, information and information assets become a fundamental and extremely valuable asset for many company, determining their competitiveness. In order to ensure that the information is not with unauthorized persons, nor corrupted or even inaccessible, it is necessary to invest in confidentiality, integrity, and availability, which are the pillars of information security. In this sense, this paper approaches this theme through a case study involving the evaluation of information security in a medium-sized company under the protection of ISO/IEC 27002:2013. The study revealed a picture full of nonconformities that allowed to raise hypotheses for future studies."
7118;en_US;"graph are very useful and it helps solving problem. A relatively new that has been studied is alliances in graph. In this paper, it is studied the defensive alliances, which can be used as a mathematical model in web communities, social media, chain food, etc. It was found result in wheel graph and complementary prisms of complete graph."
7119;en_US;"In this work, the behavior of the BER (Bit Error Rate) as a function of the SNR (Signal Noise Ratio) for MIMO (Multiple Input Multiple Output) system is analysed considering different spatial diversity schemes: Alamouti coding and maximum ratio combining (MRC). Furthermore, it is analysed in this article the operation of a MIMO communication system combining the two spatial diversity schemes. Through simulation, it is shown that the MRC technique provides lower error rates than the Alamouti coding. Furthermore, by combining the Alamouti code with the MRC method, it is possible to improve the BER of the system."
7122;en_US;"Word embedding has made possible to work with semantics in any application that work with a text document. Through algorithm that implement this technique, such as Word2Vec, it is possible to discover the similarity between word, paragraph and even whole document. However, generating word embedding still has a high computational cost. Some researches have been proposed parallel algorithm in recent years to deal with this problem, but gains in performance have ranged from 2 to 20 times compared to the original implementations. Manycore architectures have been able to scale algorithm in a more performative way. Since the accuracy of the word embeddings gener-ation depends on a large amount of data (Big Data), it is necessary that new scalable parallel algorithm are developed to deal with this large amount of data (billions of word). Scalable parallel algorithm development is one the most complex and difficult tasks so, in this work, we focus on exploiting parallelism in text representation with application. We work with Word2Vec for text representation."
7123;en_US;"The present work proposes the parallelization of BERT, an algorithm that combines boosting with bagging of extremely randomized trees to make automatic classification of textual dataset. Using high dimensionality sets can make the construction of classifier an onerous task. Parallelism combined with graphics cards can overcome this challenge, since they offer a high processing power, the execution time can decrease considerably."
7124;en_US;"Currently, one of the best application has been in identifying trans-formations on Earth surface, which is changing at an unprecedented rate. Hence, great efforts have been made to create solutions to identify these changes by processing large volumes of data (Big Data) continuously generated by several source (streaming). The goal of this paper is to explore the parallel architectures to proposes a new distributed solution for the collect, storing, in-dexing and processing of time serie of remote sensing image."
7125;en_US;"<p>This paper is based on a Natural Language Processing tool called Doc2Vec, for the semantic representation of textual document. The database of interest is composed of 44 (forty-four) undergraduate course final paper. Text mining technique were used to process the digital archives of the monograph and generate the text. Each document is represented by word vectors and the model performs term inferences for semantic analysis. As a result, the similarity of the document is in the form of a weighted graph, closeness between each element of the data sample.</p>"
7126;en_US;"<p>The analysis of Big Data has become so important with the progressive increase of the information stored in digital media. Extracting more value from diversified and unstructured data is really challenging. With the help of predictive model, it is possible to find new pattern and trends that could be innovation bases. Predictive model need to have a relevant reliability rate to aid us in decision-making process. In this context, this article discusses the influence of confounding variables on predictive model and proposes technique for identifying and minimizing their effect. Through a database with information collected in a hospital, it was possible to construct a predictive model, to identify possible confounding variables, to apply a technique to minimize its influences and to evaluate the accuracy of the model through machine learning technique. The result was an efficient prediction model.</p>"
7127;en_US;"<p>The next-generation wireless network (5G network) predict an expantion in the connected device number and network interface with higher transmission capacity, and consequently an exponential increase in the amount of traffic. In this context, solutions that do not overload the wireless communication infrastructure are needed to improve efficiency. This paper presents a cache’s proposal based on interest and interaction between device in network with D2D communication, which seeks to settle some of these problem. The proposal is based on cache approaches’ and solutions case studies aimed at improving the network’s use through the efficient use of its resource. It was verified that the proposal presents improvement of 25% when compared to another cache’s approach. From these result we can conclude that the use of this information can be beneficial for 5G network strategies.</p>"
7128;en_US;"<p>Electric vehicles are rising in popularity because of the politicians, automakers, and citizens’s interests. The same event happens with the number of mobile network (mobile or wi-fi). With the growing of user each day, many researcher are concerned that the infrastructure can become insufficient, leading them to believe in opportunistic network protocol as a solution. About the growing of electric cars, these protocol can impact in their autonomy. With that in mind, we propose a model of electric vehicles to analyze the effect of these protocol on the autonomy of the vehicle.</p>"
7129;en_US;"<p>Accessing unauthorized device on a network is an security issue on Internet of Things. The unique identifiers of the device used to authenticate them can be easily cloned, thus requiring another form of authentication. By monitoring the electromagnetic spectrum by means of a software defined radio it is possible to capture data transmitted by various wireless communication device. These data allow us to extract unique characteristics of a device, since an electric circuit that generates the electromagnetic signal does not behave perfectly like another. These characteristics can then be used to create a unique signature, thus enabling device differentiation. There are several IoT technologies on the market and it is expected that the implementation of an authentication technique will be technology independent. For the validation of the technique are collected signals of nRF24L01+ technology device, extracting characteristics of the magnitude of the signal. These characteristics are used in a classifier, which gives an accuracy of 94.7% in device differentiation.</p>"
7130;en_US;"<p>This work proposes a flight path optimization model for drones that serve as a communication gateway or data mule for IoT (Internet of Things) sensor scattered in an Intelligent Campus. This drone has limited power autonomy (battery), and in many cases can not fly over the course required to serve all allocated sensor. Therefore, the paper proposes, using Linear Program-ming, a model that ensures the maximum of sensor are satisfied considering the autonomy found in the drone.</p>"
7131;en_US;"<p>This work aims to evaluate the implementation of the photovoltaic solar energy system by shared generation in ten residences in the state of Goiás, from a economic-financial point of view. For the economic-financial analysis, the optimistic and pessimistic scenarios were economic indicators of the net present value, profitability index, internal rate of return and payback (simple and discounted), in addition to comparing with a case study reference. The result showed that the system is feasible, can be accepted in the two scenarios evaluated, it is superior to the reference case study and can attract participant with potential investors.</p>"
7132;en_US;"<p>A candidate technology to be used in the new generation of mobile communication, the 5G, is the F-OFDM (Filtered-Orthogonal Frequency Division Multiplexing) modulation, which basically consists of the application of filters in the OFDM modulation subbands. technique such as windowing allow the design of FIR (Finite Impulse Response) filters with variable performance depending on the chosen window, but which generally provides greater efficiency in the transmission and reception of data signals when compared to the OFDM modulation. In this article different types of windows are analyzed for the FIR filter design to be used in F-OFDM. In addition, this article proposes the use of pulse shaping technique to design the FIR filter prototype in order to increase its performance. In order to evaluate the proposal of the article, simulation of image transmission using F-OFDM modulation are carried out in comparison to OFDM modulation in terms of BER (Bit Error Rate). The result obtained in the simulation indicate that the performance of F-OFDM is generally higher than that obtained with OFDM modulation, but variable according to the filter design. In simulation, reduced BER values were obtained using the proposed filter: an application of the pulse shaping technique to the FIR filter prototype combined to the appropriate choice of the window to be used in the filter. The result indicate the relevance of the F-OFDM modulation filter design to make F-OFDM a modulation candidate to be used in new data communications architectures, including 5G.</p>"
7134;en_US;"<p>This article reports the use of metaheuristic technique for the resolution of the so-called Teacher-Classroom Timetabling Problem, one of subcategories of the Educational Timetabling Problem. The three metaheuristic technique employed are: In Vitro Fertilization Genetic Algorithm, Tabu Search and Greedy Ramdomized Adaptive Search Procedure. The experimentation was carried out with one real instance of the problem coming from a Brazilian school dedicated to elementary education and, in addition, with instances from widely known dataset. It turns out that the method are able to produce solutions suitable for practical use in their context, being that method In Vitro has overcome the others for the established optimization goal.</p>"
7135;en_US;"<p>The problem of longest paths in graph, began to be discussed in 1966 from a question raised by Gallai, which questions whether any connected graph has at least one vertex that appears in all the longest paths. In this work, we studied the longest paths in chordal graph, weighted graph, trees and complementary prisms graph and we obtained theoretical result and some factorial time algorithm, trying to understand the problem and the behavior of the longest paths in some types of graph.</p>"
7137;en_US;"<p>The aging population in the world has grown considerably, and the forecast for the year 2050 is around 22% of the worlds population. People over 65 years of age tend to face some health-related problem such as falls, respiratory, cardiovascular, and other disease. In this context, solutions that offer improvements in the quality of life are relevant. This project aims to build a health monitoring system for the elderly, in a way that is economically feasible and technologically possible. The system includes monitoring heart rate, body temperature and detection of falls. For family members or caregivers, a mobile application is offered to monitor data and receive alerts on monitoring situations.</p>"
7138;en_US;"<p>Identifying activity, establishing precedence, deadlines, and those responsible are initial tasks for good planning of software development. For this, there are important tool to help managers, such as the application of Critical Path Method (CPM) method and the development and monitoring of the Program Evaluation and Review Technique (PERT) network diagram. In the combination of these method we have the PERT-CPM, which, in this work, was applied on a case study about the production of a Web and mobile educational game using agile method. As a result, with PERT-CPM it was possible to identify experiences and lessons for other project.</p>"
7139;en_US;"<p>The reality in the organizational context is perceived by its complexity and manage it has been a challenge to your leaders. The dynamic inherent to the organization difficulties the adoption of the Knowledge Management (KM) practices, because the instability, uncertainties and turbulences imply in constants changes of the business. The objective of this study is to define evaluation parameters that can contribute to the maturity specification model of KM, in way to assure the relational and conceptual precepts inherent to organizational system. This is a narrative review that culminated with a discover of multidimensional nature parameters to evaluation of the maturity level of KM in complex scenarios.</p>"
7140;en_US;"<p>This article provides the characterization of textual data with traces of racism in Portuguese obtained from Twitter. It discusses racism in ethical and legal terms for conceptual identification. It explains Sentiment Analysis and some approaches and possible levels of analysis. At the end, the facts perceived during the data collection process are discussed.</p>"
7141;en_US;"<p>The present work aims to extract associations in data of criminal oc-currences in the city of Goiânia, identifying the neighborhoods where there is a greater concentration of crime, considering the spatial and temporal distribution, as well as the socioeconomic profile of the place of occurrence. The developed process uses all phases of knowledge discovery-KDD (Knowledge Discovery in Databases), including the selection of attributes, cleaning, standardization, pre-processing and data transformation. The data set used in this study refers to the record of criminal occurrence provided by the Information Analysis Management of the Public Security Secretariat of the State of Goiás. The result obtained through the use of association rule gathers important information about criminal occurrence, such as the identification of the most frequent crime in a specific place, in a time period, with a specific victim profile. The result are relevant to help decision making and also to inform and alert the population about the places with the most criminal occurrence at certain times in the municipality of Goiânia.</p>"
7142;en_US;"<p>This article aims to use Multiagent system, through the GAMA platform, to simulate an electric power distribution network and its regular and irregular consumers. To identify the irregularities is proposed a computing analyzing agent that, from the simulated data, suggests the possible irregular consumers. Through the simulator and the analyzing agent, it is possible to do complementary studies about the efficiency and effectiveness of the method used to detect non-technical losses (PNT).</p>"
7144;en_US;"<p>This research intends to evaluate the level of learning achieved with the application of methodology based on the discipline of Business Process Management (BPM). The study was developed through an exploratory analysis of a set of company, located in the State of Goiás, that underwent a process of intervention at the level of consulting or training to improve business process. In order to do so, an evaluation tool was structured based on factors considered critical for success in the implementation of business process in the corporate scope. The result allowed to reveal an acceptance framework favorable to the assimilation of the applied methodology, but with a strong tendency of unsatisfactory in terms of support and accommodation of the planned practices and actions.</p>"
7145;en_US;"<p>This work consists of displaying the study, analysis and survey of requirement of administrative relations, interconnections with the production of information and system operation in the Support Hospital of Brasília. And subsequent construction of an ERP capable of reformulating the communication process and optimizing the administrative activity, current reason of disorders and impediment in the agility of tasks. The process of gathering requirement was performed, through ethnography, technique used in Software Engineering for this purpose. The artifacts found and built: responsibilities of the sectors, diagrams and description of use cases, class diagrams, demonstrate how efficient the technique is and able to uncover problem and operations not perceptible to the requirement analyst only with quick technique such as interview.</p>"
7146;en_US;"<p>In the face of constant changes and cyber threats, information and information assets become a fundamental and extremely valuable asset for many company, determining their competitiveness. In order to ensure that the information is not with unauthorized persons, nor corrupted or even inaccessible, it is necessary to invest in confidentiality, integrity, and availability, which are the pillars of information security. In this sense, this paper approaches this theme through a case study involving the evaluation of information security in a medium-sized company under the protection of ISO/IEC 27002:2013. The study revealed a picture full of nonconformities that allowed to raise hypotheses for future studies.</p>"
7147;en_US;"<p>graph are very useful and it helps solving problem. A relatively new that has been studied is alliances in graph. In this paper, it is studied the defensive alliances, which can be used as a mathematical model in web communities, social media, chain food, etc. It was found result in wheel graph and complementary prisms of complete graph.</p>"
7148;en_US;"<p>In this work, the behavior of the BER (Bit Error Rate) as a function of the SNR (Signal Noise Ratio) for MIMO (Multiple Input Multiple Output) system is analysed considering different spatial diversity schemes: Alamouti coding and maximum ratio combining (MRC). Furthermore, it is analysed in this article the operation of a MIMO communication system combining the two spatial diversity schemes. Through simulation, it is shown that the MRC technique provides lower error rates than the Alamouti coding. Furthermore, by combining the Alamouti code with the MRC method, it is possible to improve the BER of the system.</p>"
7151;en_US;"<p>Word embedding has made possible to work with semantics in any application that work with a text document. Through algorithm that implement this technique, such as Word2Vec, it is possible to discover the similarity between word, paragraph and even whole document. However, generating word embedding still has a high computational cost. Some researches have been proposed parallel algorithm in recent years to deal with this problem, but gains in performance have ranged from 2 to 20 times compared to the original implementations. Manycore architectures have been able to scale algorithm in a more performative way. Since the accuracy of the word embeddings gener-ation depends on a large amount of data (Big Data), it is necessary that new scalable parallel algorithm are developed to deal with this large amount of data (billions of word). Scalable parallel algorithm development is one the most complex and difficult tasks so, in this work, we focus on exploiting parallelism in text representation with application. We work with Word2Vec for text representation.</p>"
7152;en_US;"<p>The present work proposes the parallelization of BERT, an algorithm that combines boosting with bagging of extremely randomized trees to make automatic classification of textual dataset. Using high dimensionality sets can make the construction of classifier an onerous task. Parallelism combined with graphics cards can overcome this challenge, since they offer a high processing power, the execution time can decrease considerably.</p>"
7153;en_US;"<p>Currently, one of the best application has been in identifying trans-formations on Earth surface, which is changing at an unprecedented rate. Hence, great efforts have been made to create solutions to identify these changes by processing large volumes of data (Big Data) continuously generated by several source (streaming). The goal of this paper is to explore the parallel architectures to proposes a new distributed solution for the collect, storing, in-dexing and processing of time serie of remote sensing image.</p>"
7154;en_US;"<p>Message from the XIII Women in Information Technology Coordination.</p>
<p>&nbsp;</p>"
7157;en_US;"<p>The problem of Protein Structure Prediction (PSP) is known to be computationally expensive, which calls for the application of high performance technique. In this project, parallel PSP algorithm found in the literature are being accelerated and ported to different parallel platforms, producing a set of algorithm that it is diverse in terms of the parallel architectures and parallel programming model used. The algorithm are intended to help other research project and they have also been made publicly available so as to support the development of more elaborate prediction algorithm. We have thus far produced a set of 16 algorithm (mixing CUDA, OpenMP, MPI and/or complexity reduction optimizations); during its development, two algorithm that promote high performance were proposed, and they have been written in an article that was accepted in the International Conference on Computational Science (ICCS).</p>
<p>&nbsp;</p>"
7161;en_US;"<p>A path partition P of a digraph D is a collection of directed paths such that every vertex belongs to precisely one path. Given a positive integer k, the k-norm of a path partition P of D is defined as P P ∈P min{|Pi |, k}. A path partition of a minimum k-norm is called k-optimal and its k-norm is denoted by πk(D). A stable set of a digraph D is a subset of pairwise non-adjacent vertices of V (D). Given a positive integer k, we denote by αk(D) the largest set of vertices of D that can be decomposed into k disjoint stable sets of D. In 1981, Linial conjectured that πk(D) ≤ αk(D) for every digraph. We say that a digraph D is arc-spine if V (D) can be partitioned into two sets X and Y where X is traceable and Y contains at most one arc in A(D). In this paper we show the validity of Linial’s Conjecture for arc-spine digraph.</p>"
7197;en_US;"<p>Access to public information is essential for the sake of transparency on governmental actions. Budgetary transparency is a key factor to better mo- nitor public expenditure and this kind of information improves the knowledge and participation of the Brazilian population [Beluzo and Craveiro 2014]. In Brazil, laws have been defined that require the publication of public expendi- ture in transparency portals, allowing the emergence of civil application that facilitate the access to government’s budget data. This study addresses the diffi- culties identified by using a transparency portal to build a data warehouse, such as: the manipulation of open data, the lack of metadata and the semantic loss of the Entity-Relationship model in the data schema.</p>
<p>&nbsp;</p>"
7198;en_US;"<p>Since the Industrial Revolution, the planet has been suffering drastically with the population neglect, especially with regard to the environment. Reflecting on the fierce dispute that the society has been blocking with the growth of the amount of garbage, we identified the problematic of the incorrect disposal and waste of the organic residues. In view of this we intend to develop a web platform and a smart bin that can establish a communication between who owns the organic waste, a compost or biogas plant and who wants to buy the fertilizer. To achieve this general goal, we will organize the methodological strategies of this research in the following specific steps: first develop the web platform and then develop the recycle bin establishing communication between them. As justification, we realize the importance of developing this work for the management of organic waste and for the technology to be used in favor of the collective. In conclusive terms, this research aims to generate a web platform and a user-friendly intelligent bin capable of managing the waste of organic waste and contributing to technological and environmental advancement.</p>
<p>&nbsp;</p>"
7199;en_US;"<p>The Entity-Relationship Model (ERM) is very important for the development of a database project. system that have a good planning, obeying the rule of the model, tend to respond to user requests more efficiently and quickly. Most Database Management system (DBMS) has a specific tool for creating the relational model of tables graphically. Thereby, the designer needs to adapt the ERM in the relational model. Observing this situation, the ConceptER tool is proposed here, which helps designers to construct, in drag and drop, the diagram and automatically maps it to SQL scripts, independent of the chosen DBMS.</p>
<p>&nbsp;</p>"
7201;en_US;"<p>This paper presents a system developed to analyze genomes data which is part of metagenomes sequencing. As a result, some tool were developed to identify the species of metagenomics sequences, for helping the assembly process and to analyze the taxonomy of the assembled sequences in order to identify the similarity between microorganisms genomes in metagenome.</p>"
7203;en_US;"<p>With the advances on science, a powerful computational infrastructure is desirable to increase the performance of experiment. The same holds true for research on the Computer Vision field, which deals with large amounts of data and also requires intensive computation. Nevertheless, the administration of a computational infrastructure involves many tasks, such as system configuration, preventive maintenance and storage management, which becomes very challenging for many research groups. With that in mind, this work proposes an infrastructure model to assist researcher with focus on Computer Vision. We conducted a serie of tests to evaluate the performance of our model and the processing power of our infrastructure.</p>"
7204;en_US;"<p>Uncertain time serie analysis has recently become an important research topic, particularly when searching for feature of natural phenomena using similarity functions. Natural phenomena are often modeled as time serie, such as in weather forecast, in which temperature variation is monitored through space and time. In such a context, different model for weather forecast produce variations on predictions that can be interpreted as predictions uncertainty. One important problem is to represent the variations presented in predictions along space and time. In order to address a solution to this problem, this paper defines a new type of serie, here named uncertain spatio-temporal serie, and proposes a computational strategy to manage uncertainty in probabilistic database. Using this new serie some analytical query can be performed, leading to the discovery of interesting observation pattern.</p>"
7206;en_US;"<p>In this paper, we propose a novel architecture to allow the implementation of a cyber environment composed of different High Performance Computing (HPC) infrastructures (i.e., cluster, grids and clouds). To access this cyber environment, scientific researcher do not have to become computer experts. In particular, we assume that scientific researcher provide a description of the problem as an input to the cyber environment and then get their result without being responsible for managing the computational resource. We provide a prototype of the architecture and introduce an evaluation which studies a real workload of scientific application executions. The result show the advantages of the proposed architecture. Besides, we highlight this work provides guidelines for developing cyber environments focused on e-Science.</p>"
7207;en_US;"<p>Meteorology handle large volumes of semi-structured data collected from various source. Thus, it is crucial that the meteorologists use computational tool to assist in the management of these dataset. This work presents an approach to aid them to organize and evaluate meteorological data based on concepts of Semantic Web and data provenance. The article present a semantic tool and a well-founded ontology developed from UFO foundational ontology to support experiment that manipulate large amounts of curated data.</p>"
7208;en_US;"<p>This paper presents the computational implementation of a data distributed fusion and consolidation model in support of health management. It is intended that this aggregation model work as a support and source of information to health care researcher aiming to planning health actions, especially in municipal instances. For this purpose, is implemented a process of obtaining and automated data preparation. We present the process of defining this model of obtaining the information, including the type of support, the process of obtaining the production registers, the connection model to social network and academic production. From the model presented here were generated 91 e-books that are available in open access.</p>"
7210;en_US;"<p>The knowledge (implicit-explicit), when modelled and made available on the Web, becomes essential for the generation of new knowledge. This work proposes a tacit knowledge formalization method to add semantics and expressiveness in formal ontology to support the generation of scientific knowledge.</p>"
7211;en_US;"<p>This paper presents an application ontology that describes the data of the research done by researcher from UFRJ Macaé in Lake Batata, an aquatic ecosystem that suffered environmental impacts. The ontology is the base for the creat ion of a data repository in RDF, which will enable the development of Web application to support research about this lake.</p>"
7212;en_US;"<p>Biological collections are the primary source of knowledge regarding biodiversity. In Brazil, such information have been historically gathered and maintained by research institutions in a traditional way. To register geographic information associated with biological data is essential for the curatorial work for later sharing. For legacy data, they need to align solutions with the new technological time of geospatial world. This work, under development, presents an architectural proposal for a system to improve the process of georeferencing legacy data of INPAs biological collections through an infrastructure of a gazetteer in a Web environment.</p>"
7213;en_US;"<p>Historically tandem repeats has been considered as nonfunctional DNA (junk), largely due to the fact there is no correlation between the content and the complexity of an organism. Different work have shown that these repeats occur in coding and promoter regions is not random: genes containing tandem repeats are enriched for specific functional classes. This study aimed to develop a pipeline for identification and storage tandem repeats.</p>"
7215;en_US;"<p>This article presents guidelines for the development of accessible educational game interface for children diagnosed with dyslexia. For the definitions of these guidelines, it was based on Child-Computer Interaction studies, game elements and studies on pedagogical approaches with dyslexic children. The motivation of this work is due to the fact that Dyslexia is a relevant subject to be approached in the most diverse area of knowledge, since few game and application are available to stimulate the teaching-learning process of this public.</p>
<p>&nbsp;</p>"
7216;en_US;"<p>Considering the social importance of the Federal Institutes and the attractive potential of the game, as well as their use in the school environment, this paper presents the development of a platform for the dissemination and preparation for the classification exam of the Instituto Federal Catarinense (IFC). After the data survey, carried out by means of a questionnaire, applied by the student of the IFC - Campus Avançado Sombrio, it was possible to perceive that they consider interesting a preparatory tool for the examination. The platform was developed as a game and will be used on an arcade machine, installed in elementary school where student can have access to it.</p>
<p>&nbsp;</p>"
7217;en_US;"<p>The program class is present in many curricula, and for many it is a discipline of great challenges, because of the level of abstraction that it requires. This article presents a new proposal of teaching of matrices, exploring the use of a didactic sequence, in the construction of mobile application, using the App Inventor 2 tool with a student in the technical education. The result of the experiment showed that the student had an excellent perception about the programming logic and demonstrated ease in learning math.</p>
<p>&nbsp;</p>"
7219;en_US;"This paper presents a system developed to analyze genomes data which is part of metagenomes sequencing. As a result, some tool were developed to identify the species of metagenomics sequences, for helping the assembly process and to analyze the taxonomy of the assembled sequences in order to identify the similarity between microorganisms genomes in metagenome."
7221;en_US;"With the advances on science, a powerful computational infrastructure is desirable to increase the performance of experiment. The same holds true for research on the Computer Vision field, which deals with large amounts of data and also requires intensive computation. Nevertheless, the administration of a computational infrastructure involves many tasks, such as system configuration, preventive maintenance and storage management, which becomes very challenging for many research groups. With that in mind, this work proposes an infrastructure model to assist researcher with focus on Computer Vision. We conducted a serie of tests to evaluate the performance of our model and the processing power of our infrastructure."
7222;en_US;"Uncertain time serie analysis has recently become an important research topic, particularly when searching for feature of natural phenomena using similarity functions. Natural phenomena are often modeled as time serie, such as in weather forecast, in which temperature variation is monitored through space and time. In such a context, different model for weather forecast produce variations on predictions that can be interpreted as predictions uncertainty. One important problem is to represent the variations presented in predictions along space and time. In order to address a solution to this problem, this paper defines a new type of serie, here named uncertain spatio-temporal serie, and proposes a computational strategy to manage uncertainty in probabilistic database. Using this new serie some analytical query can be performed, leading to the discovery of interesting observation pattern."
7224;en_US;"In this paper, we propose a novel architecture to allow the implementation of a cyber environment composed of different High Performance Computing (HPC) infrastructures (i.e., cluster, grids and clouds). To access this cyber environment, scientific researcher do not have to become computer experts. In particular, we assume that scientific researcher provide a description of the problem as an input to the cyber environment and then get their result without being responsible for managing the computational resource. We provide a prototype of the architecture and introduce an evaluation which studies a real workload of scientific application executions. The result show the advantages of the proposed architecture. Besides, we highlight this work provides guidelines for developing cyber environments focused on e-Science."
7225;en_US;"Meteorology handle large volumes of semi-structured data collected from various source. Thus, it is crucial that the meteorologists use computational tool to assist in the management of these dataset. This work presents an approach to aid them to organize and evaluate meteorological data based on concepts of Semantic Web and data provenance. The article present a semantic tool and a well-founded ontology developed from UFO foundational ontology to support experiment that manipulate large amounts of curated data."
7226;en_US;"This paper presents the computational implementation of a data distributed fusion and consolidation model in support of health management. It is intended that this aggregation model work as a support and source of information to health care researcher aiming to planning health actions, especially in municipal instances. For this purpose, is implemented a process of obtaining and automated data preparation. We present the process of defining this model of obtaining the information, including the type of support, the process of obtaining the production registers, the connection model to social network and academic production. From the model presented here were generated 91 e-books that are available in open access."
7228;en_US;"The knowledge (implicit-explicit), when modelled and made available on the Web, becomes essential for the generation of new knowledge. This work proposes a tacit knowledge formalization method to add semantics and expressiveness in formal ontology to support the generation of scientific knowledge."
7229;en_US;"This paper presents an application ontology that describes the data of the research done by researcher from UFRJ Macaé in Lake Batata, an aquatic ecosystem that suffered environmental impacts. The ontology is the base for the creat ion of a data repository in RDF, which will enable the development of Web application to support research about this lake."
7230;en_US;"Biological collections are the primary source of knowledge regarding biodiversity. In Brazil, such information have been historically gathered and maintained by research institutions in a traditional way. To register geographic information associated with biological data is essential for the curatorial work for later sharing. For legacy data, they need to align solutions with the new technological time of geospatial world. This work, under development, presents an architectural proposal for a system to improve the process of georeferencing legacy data of INPAs biological collections through an infrastructure of a gazetteer in a Web environment."
7231;en_US;"Historically tandem repeats has been considered as nonfunctional DNA (junk), largely due to the fact there is no correlation between the content and the complexity of an organism. Different work have shown that these repeats occur in coding and promoter regions is not random: genes containing tandem repeats are enriched for specific functional classes. This study aimed to develop a pipeline for identification and storage tandem repeats."
7267;en_US;"In Wireless Sensor Network (RSSF) monitoring application, sensor node depend on limited power source. Studies indicate that the main source of energy consumption in sensor node is related to data transmission. This paper presents an approach to data reduction based on the analysis of the dispersion of the values ​​detected by the sensor, in order to avoid sending detections whose values ​​are little dispersed. The experiment performed with the Castalia simulator showed that the proposed approach achieved a reduction greater than 96%, maintaining a low level of errors in the final destination data reconstruction."
7268;en_US;"Mobile location data is an important source for understanding user profiles, helping provider deliver better service. With this kind of data, it is possible to identify the relevant points of a user, and even classify these points as places of home or work. With this knowledge, mobile service provider can increase customer engagement and retention. However, identifying and classifying points of interest (PoI) is not a trivial task, and most existing work assumes that data should be collected at a high frequency, making the process difficult and expensive. In this paper, we propose approaches to identify and classify PoIs based on sparse data, that is, they were collected at long time interval. The result, when compared with literature solutions, show improvements of at least 13% in the accuracy for the identification of PoIs, and 10% and 4% in the classification of home and work points, respectively."
7269;en_US;"Advances in bioengineering and nanotechnology have led to the emergence of nanometer sized device, eg. synthetic nanomachine, nano-antennas and nano-injectors, capable of detecting and acting on their environment. However, while necessary, it is a major challenge to provide communication between them. Conventional electromagnetic communication is not necessarily an option for nanoredes due to the medium and its scale. Thus, researcher have been exploring molecular communication. In particular, this paper investigates the potential of the Inositol Triphosphate (IP3) molecule for data communication between nanodevice. Compared with calcium molecule performance, result for metrics such as gain and channel communication capability are promising and contribute to a detailed understanding of how to manage data transmission in an extracellular environment. Our result contribute to the design of nanoredes inside the neural cell tissue."
7272;en_US;"Known network as WiFi (IEEE 802.11 standard) are widely used in application ranging from simple home environments to complex control system network. However, the extensions incorporated into the standard to provide Quality of Service (QoS) are still unable to guarantee time constraints for real-time (RT) communications requirement. This paper presents an experimental validation of the RT-WiFi protocol that was recently proposed and analyzed through simulation. The experimental result demonstrate the feasibility of implementing the RT-WiFi protocol and improving the QoS level of communications through a comparative analysis with the EDCA mechanism, which is a mechanism incorporated in the IEEE 802.11 standard to provide different levels of transmission priority of different types of traffic"
7275;en_US;"Location-based service allow monitoring of specific people or area. By tracking your location, you can help rescue lost or injured people in natural environments. However, wireless network in dense vegetation area, in this case, the Atlantic Forest, imply challenges related to mobility and connectivity. This work compares the performance in terms of range, signal strength, loss rate and delay in links implemented using LoRa, IEEE 802.11g and ZigBee technologies in the Serra dos Órgãos National Park. Comparing these metrics allows us to distinguish the limitations of each technology that may influence the spread of alerts. The result show that LoRas maximum range is 3 times longer than IEEE 802.11g and 6 times greater than ZigBee, with received signal strength lower than both technologies, averaging 21.67% and 26.15%, respectively."
7276;en_US;"Due to the keen interest in bitcoins and blockchain application, distributed application with Byzantine safety and fault tolerance requirement have received additional attention. algorithm such as Proof of Work (PoW) and Proof of Stake (PoS) have been developed to handle consistency by capturing aspects of open system. However, when scaling well with the considerable number of replicas, most of these PoW-based or PoS-based system do not perform as much as conventional approaches that deal with replica consistency. algorithm such as PBFT that are based on active replication can fit the blockchain, ensuring better replication consistency performance. Thus hybrid approaches like Tendermint or Hot Stuff were developed offering openess and performance. Although they achieve large numbers of replicas, these solutions rely on PoW or PoS algorithm, which makes the consensus among their replicas expensive. project like Hyperledger propose high-performance blockchains where traditional PBFT consensus is used without the need for PoW or PoS. However, PBFT algorithm, in consensus of their replicas, do not scale well due to quadratic costs (O (n 2)). Thus, in the literature, hierarchical structures have been proposed with the PBFT to deal with the increasing number of replicas. We, in this paper, propose a hierarchical architecture with a PBFT algorithm to deal with the highly adversarial model of the blockchain environment. Our solution has a linear cost consensus on the number of replicas."
7277;en_US;"Blockchain and Tangle are data structures used to create an immutable public record of data insured by a network of peer-to-peer participant who maintain a set of constantly growing data records known as ledgers. Blockchain and Tangle technologies are a decentralized solution that guarantees the exchange of large amounts of trusted message, among billions of connected IoT device, which are very valuable as they are valid and complete. This highly encrypted and secure peer-to-peer messaging mechanism is adopted in this project to manage the processing of IoT transactions and the coordination between the device that interact with the process. To maintain private transactions, secure and trustless, the distributed consensus algorithm are responsible for validating and choosing transactions and recording them in the global ledger. The result showed that the speed of the consensus algorithm can affect the creation in real time of reliable stories that track the events of the IoT network. After incorporating Complex Event Processing that allows selecting only those high level events, it is possible to get an improvement in many situations. The result is a Middleware system that provides a framework for the construction of large-scale computer application that use Complex Events Processing and different decentralized ledgers such as the blockchain of Ethereum or IOTA Tangle, for secure data storage."
7278;en_US;"In recent years, Named Data network (NDN) have been proposed as a promising paradigm for the Internet of the future because of their disruptive content-centric feature. In order to ensure content authenticity, NDN relies on the use of digital signature which, due to the complexity involved in the validation process, may result in additional processing overhead. As a result, NDN implementations are susceptible to a variety of attacks. This work proposes a security framework that aims to use blockchain technology attributes to enable verification of the integrity and authenticity of NDN content. result obtained from emulation showed that the proposed framework can detect data tampering attacks and prevent the misrepresentation of content by malicious provider."
7279;en_US;"The complexity of home network requires innovative strategies for network management and characterization of user demand. In this paper we use unsupervised machine learning technique in order to find out the traffic profile of user. In partnership with an ISP, we collect download and upload traffic from over 2,000 home routers. We use a tensor decomposition technique (PARAFAC) to extract relevant network usage factors and a clustering algorithm to group user with similar daily traffic pattern. To characterize user behavior over periods longer than one day, we use cluster information and a hidden Markov model."
7280;en_US;"Device-to-Device (D2D) communication is one of the mechanism for releasing 4G network via data offloading to other network. D2D/4G hybrid network have as a challenge the efficient multiplexing of communication interface, which can directly impact user Quality of Experience (QoE). This paper introduces QD4G, a Machine Learning platform to control when customers using the Dynamic Adaptive Streaming over HTTP (DASH) standard should employ a 4G network or a D2D network. The goal is to improve QoE by providing video streaming at higher resolution. Tests were performed with real device and the result showed that prediction allows to achieve up to 87% accuracy, with an increase in average video resolution between user via D2D of up to 150% while at the same time relieving 4G network data traffic. up to 80% in the scenarios evaluated."
7281;en_US;"The rise of big data application brought along a serie of difficult challenges regarding the allocation of hardware and software resource. Typically these application are known for being computationally expensive and having high heterogeneity on how they operate, making the task of estimating application execution time very challenging. It may be still possible to correlate feature extracted from the cloud environment and from the input dataset to the execution time. Such relationship may then be used to predict execution times. Based on such assumption, this work explores machine learning (ML) model to the task of predict execution time of Spark application. This work investigates four ML model as well as different feature, while also comparing their result against the current state-of-the-art. All model are evaluated in several scenarios and configurations, producing result that are significantly superior to the state-of-the-art in various cases."
7282;en_US;"Low Power and Lossy network (LLNs) is a common type of wireless network in IoT application. LLN communication pattern usually requires an efficient routing protocol. The IPv6 Routing Protocol for Low-Power and Lossy Network (RPL) is considered to be a possible standard routing protocol for LLNs. However, RPL was developed for static network and node mobility decreases RPL overall performance. These are the purposes of the Mobility Aware RPL (MARPL), presented in this paper. MARPL provides a mobility detection mechanism based on neighbor variability. Performance evaluation result on the Cooja Simulator confirm the effectiveness of MARPL regarding link disconnection prevention, packet delivery rate and fast mobile node topology reconnection with low overhead impact when compared to other protocol."
7283;en_US;"The Internet of Things is gaining the attention of the market, industry and the scientific community. The integration of WSNs with the Internet led the IETF to specify new protocol. One of the main ones is RPL, a routing protocol for network that have considerable packet loss. Among the routing metrics, ETX stands out, which contributes to the choice of reliable paths. However, the rapid depletion of battery power from the bottleneck node is still a problem. In this context, we present here a new metric based on the estimated power consumption of the network interface, which contributes not only to reliability, but also to load balancing and extending the network lifetime."
7284;en_US;"Visible Light Communication (VLC) presents several challenges such as interference and blockages created by obstacles. At the same time, many environments offer a rich infrastructure of light source that can be used to aid end-to-end communication. In this paper, D-VLC is a dynamic routing protocol. D-VLC reacts to communication interruptions by building alternative routes in the visible light network without prior knowledge of the topology or even the device that compose it. The new protocol was implemented and evaluated in a real environment using the OpenVLC embedded platform. The result show that, using D-VLC, the network was able to adapt to dynamic changes in communication, such as shadows and obstacles, with network usage overload of less than 10%."
7285;en_US;"In ad hoc wireless vehicle network, communication between vehicles occurs opportunistically due to the high mobility of the node. Developing routing protocol is challenging given the complexity of defining metrics for choosing the next hop. We introduced the concept of transmission opportunities by analyzing three real taxi movement databases. We discuss how routing protocol impact the proper use of transmission opportunity inventory. We have shown that transmission opportunities can be used as a metric for both routing protocol performance evaluation and resource calculation in vehicular network."
7287;en_US;"The vehicular network refers to a promising approach of having vehicles equipped with wireless communication device capable of communicating with other vehicles. Each vehicle is able to collect, process and disclose information about itself and its environment. Acquiring a large amount of sensing information and increasing traffic demand requires mechanism to decongest the cellular network. Thus, this work uses a measure of centrality to propose an offloading mechanism, in which certain vehicles will collect data from their neighbors and transmit it on the cellular uplink. The experiment were conducted in a real scenario and the result found showed a reduction of up to 8.79% in the number of accesses to the cellular network compared to another solution in the literature."
7288;en_US;"Expenses due to congestion problem in large urban centers amount to billions of dollars worldwide. This is due to time lost in traffic and fuel consumption caused mainly by traffic jams at peak times. Several work in the literature propose solutions to the traffic management problem using the processing, storage and communication capacity of vehicular network. Among the solutions in the literature, infrastructural approaches utilize the processing and storage power of infrastructure to detect traffic jams and suggest vehicle routes. This paper presents GRIFO that, unlike the infrastructural approaches in the literature, vehicles are responsible for checking congestion and calculating new routes when needed. Using only information about near-road conditions provided by the auxiliary storage infrastructure, each vehicle verifies the need for recalculation. The proposed work manages to distribute the flow of vehicles in the road network in order to reduce the average travel time compared to literature algorithm."
7289;en_US;"Elastic optical network make up a network infrastructure capable of supporting the high demand for data traffic from high-speed network. One of the problem that must be solved to ensure the proper functioning of the network is called Routing, Modulation Level and Spectrum Allocation (RMLSA). This paper aims to propose a new approach to this problem through the use of an adaptive guard bandwidth provisioning algorithm, based on the level of network utilization, called GBUN. The performance of the proposed algorithm is compared with algorithm that use fixed guard band values ​​and the adaptive proposal AGBA. The result show that the proposed algorithm presents a better performance in terms of band block probability for the studied scenarios."
7290;en_US;"Elastic optical network allow splitting the optical spectrum into frequency slots that can be combined to create channels with defined bandwidth on demand. This flexibility provides greater spectral efficiency over traditional fixed grid optical network. Traffic aggregation strategies make it possible to achieve even greater efficiency in the use of network resource, reducing the amount of guard bands and the use of transmitters and receivers. This paper proposes a mechanism that, combined with existing resource allocation solutions, enhances the use of elastic network capabilities and traffic aggregation. The study shows that the adoption of the proposed mechanism also contributes to the reduction of bandwidth blocking rates and the gain of energy efficiency."
7291;en_US;"Several recent work reduce energy consumption in data centers but consider one or two of the three highest consumption dimensions, i.e., servers, cooling system, and network infrastructure. However, algorithm that optimize only one or two of those dimensions may hide significant energy losses in the other dimensions. Moreover, energy-saving strategies may increase service response times and violate service level agreements. This paper presents an extensive study of the relations between the three dimensions of higher-energy consumption in a data center and their impact on parameters of quality of service. The paper also proposes an algorithm for allocating virtual machine that exploit varying load levels in the data center to save energy more aggressively or to minimize violations of service level agreements and presents a new simulator for studying energy efficiency of data centers that allows the evaluation of several scheduling algorithm under different workloads, cooling strategies, and network optimizations. The experimental result are from more than 500 simulation with three traces of real workloads with up to 696 thousand virtual machine running over a period of up to 34 days."
7292;en_US;"Fifth generation (5G) cellular network will be the key element of a society that is becoming increasingly interconnected and digitalized. application adopted in many social and industrial sectors will require from 5G network higher standards of availability and reliability. These requirement are leading operators to plan the deployment of protection schemes in the backhaul layer. In this context, our aim is to employ simulation to assess in a technical and economic way different backhaul protection schemes based on passive optical network (PON). The result indicate that the use of protection can increase the viability of 5G network based on a PON backhaul supporting a hybrid fronthaul with fiber and copper."
7293;en_US;"This paper introduces T-Incident, a robust, low-cost architecture for detecting and enriching road events based on heterogeneous data fusion. A spatiotemporal model for merging incident, non-incident and social media data has been developed. In addition, this latter data source was filtered using natural language processing method for pattern detection capable of describing the event and its vicinity. A learning-based model was also developed to identify these pattern and detect the types of events. The methodology result showed the best parameters for the T-Incident approach, providing an accurate incident detection and description service above 90% for the F1 score, Recall and Precision metrics."
7294;en_US;"YouTube as a video platform currently has a ubiquitous presence in the dissemination of online content. As such, marketers and content creators are expected to make use of YouTube to spread products and ideas. In this article, we analyze the traffic of political video and video advertisements on YouTube during the 2018 elections. Our analysis is conducted through synthetic network personas designed to simulate human behavior. Over a period of approximately 40 days, we simulated voters from different states (via VPNs), gender (through account settings), and political alignment (through access to channels classified as left, center, and right). During the experiment, the different personas were susceptible to video advertisements that are paired with video accessed automatically. Based on the collected data, we present a study focusing on three aspects: (1) channel content popularity characteristics; (2) the difference in advertising exposure between different personas; (3) an analysis of parties that made most use of the platform."
7296;en_US;"WhatsApp is a mobile communication system that allows people to interact through groups. In this work, we analyze the dissemination of information within a group network that simulates the WhatsApp network. The built network considers two types of groups: organic groups, formed by friends and family, and artificial groups that are usually created with the purpose of being a mean of spreading certain subject or event, such as political campaigns. We analyzed the speed with which information is spread in this network considering the epidemiological model Susceptible-Infected (SI). We then deepen our analysis in order to identify parameters that cause this scattering to be partially controlled in order to make it difficult to propagate fake news in these network. Our result quantify the viralization ability of content in WhatsApp and identify aspects that could limit such ability to prevent the platform from being abused in election periods."
7298;en_US;"Network neutrality advocates that no traffic should ever be discriminated, either in terms of source, destination and,or content. Although several solutions for detecting traffic differentiation (TD) have been proposed, there is a lack of effective solutions for locating the source of TD. In this work, we propose a solution for detecting and locating TD that takes advantage of routing properties of Internet routing, in particular AS peering. The proposed strategy explores differences and similarities of the possible routes between measurement points. The assumptions regarding Internet routing were validated through an experiment executed on PlanetLab. We also evaluated with simulation the accuracy of our proposals."
7299;en_US;"Path changes caused by events such as traffic engineering, changing traffic exchange partnerships, or link failures impact multiple paths on the Internet. Topological monitoring platforms perform periodic measurements using traceroute for a large number of destinations. This approach, however, is inadequate to precisely identify the extent of the impact of routing events. For example, a link failure can be restored before all routes are measured. In this paper we present measurement strategies that minimize the cost of probing to identify paths impacted by a routing event. Our result show that it is possible to identify the set of paths impacted by an event efficiently. Our result further indicate that when integrated into a state-of-the-art pathway tracking system, our strategies more than double the number of changes detected."
7300;en_US;"Bulk Data Transfer (BDT) and its generalization, Multiple Bulk Data Transfer (MBDT), are critical service for business operations in geo-distributed inter-center data network. In these network, BDT or MBDT application perform synchronization, resynchronization, data replication, virtual machine migration, and big data aggregation, among other tasks, requiring large amounts of bandwidth and efficient traffic engineering solutions. Elastic optical network (EON) enable on-demand resource provisioning and allocation through Spectrum Routing and Allocation (RSA). This paper proposes and compares application-aware dynamic RSA solutions employing Smallest Deadline First (SDF), Larger Data Amount (LDA), Smallest Data Amount (SDA), and Smallest Remaining Time (SRT) scheduling technique."
7301;en_US;"Advances in optical data transmission technology have enabled the rapid growth of the internet and demanding bandwidth service. The emergence of Orthogonal Frequency Division Multiplexing (OFDM) based network has opened the possibility of increasing the spectral efficiency of a network by solving the routing and spectrum allocation (RSA) problem. In this work, two RSA heuristics were implemented that consider different available modulation formats (RMSA). simulation were made for several network using heuristics under incremental traffic conditions. The result showed that the load-balanced allocation heuristic (BMLM) tended to have a lower blocking rate in the early periods, when only one modulation format was available, but presented a higher long-term blockage rate relative to the heuristic. Shortest Path Allocation (SPMLM). When more modulation formats were available, BMLM performed worse in most cases, but achieved better result on some network."
7302;en_US;"The introduction of space division multiplexing in optical network brings new challenges for network protection since the lightpath can span high capacity and transmit data at different rates. In addition, these network suffer from the fragmentation of the spectrum that hinders contiguity and continuity constraints and therefore increases the block. To address these problem, in this paper, we propose the protection algorithm for elastic network with spatial division multiplexing through multipath routing and shared backup paths."
7303;en_US;"Energy consumption in core network is currently impacted by Bulk Data Transfer (BDT) application among the major Internet Data Centers (CDs). This is because these application consume most of the available resource and do so for long periods of time. Due to the increase in network traffic that occurs every year, one of the key challenges for cloud service provider is energy efficiency. To serve the growing demand, the Elastic Optical network (EON) paradigm has been proposed with the objective of meeting requests with greater flexibility, making better use of the frequency spectrum. This paper proposes the Energy Efficient Aware-BDT in EON (EEABE) solution, an energy efficient aware Routing and Spectrum Allocation (RSA) algorithm for performing inter-CD BDT (ICD), which is capable of scaling BDT requests and implementing the sleep mode technique to reduce the power consumption of the switching elements in the optical network."
7304;en_US;"Containers have been recently adopted as support for fast provisioning of distributed system. They can be used to implement microservice, dataflow processing, edge computing, and other complex system. However, due to the settings heterogeneity of requests and dimensionality of the hosting DCs, container scheduling is an NP-Hard problem. An efficient path to ease the scheduler complexity is to use the of high-performance parallel processing. In this context, we present present EMULAG: a GPU-accelerated multi-criteria scheduler. The schedulers objective function represents the provider perspective, aiming at data center (DC) consolidation. We present an experimental analysis revealing our solution is scalable and presents higher result than those foundin the literature, but with lower processing time."
7305;en_US;"The Apache Hadoop framework, which is used to process and store large amounts of data, uses the Checkpoint and Recovery technique to assist with failed recoveries of your distributed file system. However, efficient adaptations for time between Hadoop checkpoints depend on accurate system observations. The purpose of this paper is to estimate the cost of performing checkpoints and the average time between system failures from a history of observations. Factors are observed and analyzed for different variations of framework configuration and benchmark used."
7306;en_US;"Computational mists act in concert with traditional clouds to deliver service more efficiently. Mists replicate service and data in structures closer to user in order to increase the efficiency of service offered. However, such replication brings problem related to, for example, management service and identity storage. In fact, this type of service was proposed as a cloud-centric service. Thus, identity replication is not a trivial problem, as current identity replication technique either generate indiscriminate replication or little reduce their recovery latency. In this study, we investigated the relationship between number of replicas and distance of their user in identity distribution system with probabilistic replication. Simulation result show that, when compared to other distribution system, the probability distribution reduces by 25% the number of hops needed to recover identity and by 30% the number of replicas across the network."
7307;en_US;"The current network infrastructure needs to support the rapidly increasing data traffic. Sophisticated planning approaches must be adopted by the operators so the high number of application can be managed efficiently. In this work, a resource provisioning model for hierarchically distributed data centers is proposed using Integer Linear Programming (ILP). The objective is to increase the efficiency in the use of computational resource and decrease the overhead in network links. result show that the model is able to efficiently accommodate 20% more application when compared to the First-Fit approach."
7308;en_US;"The term offloading indicates the action of changing the processing location of a computational activity. The purpose of using offloading is to reduce the processing time of application, reduce the power consumption of the device and eventually enable the execution of tasks that would not be possible on device with reduced resource. This paper presents an offloading framework, called MLOOF, for smartphone and IoT device. The offloading process is done from the device to nearby servers (cloudlet), which enables the reduction of latency and increase in network throughput when compared to the offloading to servers in the cloud. The system was evaluated experimentally and the result show that the strategy of offloading in three levels achieves the goals of reducing processing time (up to 74%) and energy consumption (more than 90%)."
7309;en_US;"Fog Computing environments provide low latency access to computational resource in the edge of the network for IoT device. In the context of IoT in Smart city, user device with high mobility, such as wearables and vehicles, bring new challenges to the Fog. In this scenario recent related work have presented the advantages of a proactive migration approach, based on user mobility prediction. Otherwise, choosing the wrong node to place the user application due an inaccurate mobility prediction can not ensure an environment which serves the application requirement. This work presents an analysis of the proactive migration approach in the Fog Computing scenario and how much an inaccurate mobility prediction can hinder these advantages. simulation of a Smart City scenario show that incorporating user mobility prediction can decrease the number of migrations between the node, however, choosing the wrong destination can increase the latency in almost 30%."
7310;en_US;"Location-Based Social network (LBSN) data contains spatial, temporal, and social feature of user activity, providing valuable information that is currently available on large-scale and low-cost fashion via traditional data collection method. In this way, LBSN data enables to predict user mobility based on spatial, temporal, and social feature, which can be used in several area, such as device-to-device (D2D) communication, caching, and others. In addition, a Temporal Markov Chain (TMC) is a stochastic model used to model randomly changing system, such as mobility prediction based on the spatiotemporal factor such as location and day of the week. In this paper, we introduce the Temporal Markov Model with User Similarity (TEMMUS) mobility prediction model. TEMMUS considers a TMC of variable order based on the day of the week (weekday or weekend) and the user similarity to predict the user future location. The result highlight a higher accuracy of TEMMUS compared to three state-of-the-art Markov Model predictors."
7311;en_US;"Considering the increasing number of vehicles in city, application able to inform the traffic situation on the roads become more widely used. These application are intended to suggest routes, considering congestion and accidents, identified through participatory sensing. However, there are other issues encountered along a route that directly affect the user, such as crime in a particular region. Regions affected by a high crime rate may evolve during the day, depending on the type of crime and the density of people in a particular region. Therefore, this work aims to propose a service capable of identifying area with high criminal incidence, taking into consideration the evolution of the scenario, and suggesting safe routes that avoid these regions. The proposed solution allows for a safer route without compromising the time of the journey. Moreover, the result found allow us to verify the ability to avoid dangerous regions, making a drivers route safer."
7313;en_US;"Cloud computing provider offer multiple service classes to deal with workload heterogeneity. Classes are distinguished by their expected Quality of Service (QoS), which is defined in terms of Service Level Objectives (SLO). A priority-based scheduling policy is commonly used to ensure that requests submitted to the different service classes achieve the desired QoS. However, the QoS delivered during resource contention periods may be unfair to certain user. In this paper, we present a SLO-driven scheduling policy which takes the SLOs and current QoS delivered for each request into account when making decisions. We used simulation experiment fed with traces from a production system to compare the SLO-driven policy with a priority-based one. In general, the SLO-driven policy delivered a better service than the priority-based one."
7314;en_US;"Leading cloud computing provider, such as Amazon, Google, and Microsoft, use proprietary technologies to deliver their service. user have a desire to use multiple provider to increase their service availability, reduce costs, not rely on a single provider, among other reasons. Authorization Policy Federations (APFs) allow the definition of a single access control policy that can be applied across multiple heterogeneous provider. To do this, these policies, described in Disjunctive Normal Form (DNF) and semantics defined by an ontology, must be mapped to the local context of each user and cloud. This paper discusses the syntactic and semantic mapping process of policies and the Semantic Equivalence Level (LSE) metric used to measure their effectiveness."
7315;en_US;"Bag-of-Tasks (BoT) application are parallel application composed of independent (i.e., embarrassingly parallel) tasks, which do not communicate with each other, may depend upon one or more input files, and may be executed in any order. BoT application are very frequent in several scientific area, and it is the ideal application class for execution on large distributed computing system composed of hundreds to many thousands of computational resource. This paper focuses on the scalability of BoT application running on large heterogeneous distributed computing system organized as a master-slave platform. The result demonstrate that heterogeneous master-slave platforms can achieve higher scalability than homogeneous platforms for the execution of BoT application, when the computational power of individual node in the homogeneous platform is fixed. However, when individual node of the homogeneous platform can scale-up, experiment show that master-slave platforms can achieve near linear speedups."
7316;en_US;"Cloud computing seeks to mitigate the cloud limitation on high latency by providing flexible service to end user on the edge of the network. Both cloud and mist computing have strengths and weaknesses that impact performance and monetary cost. The proximity of the mist node to the edge of the network allows for adopting limited capacity computer to contain infrastructure and operational costs. Taking into account variables such as latency, workload, and computing power, it becomes complex to define under which circumstances it is most advantageous to use the cloud layer or the mist. Previous research has investigated when to use each layer but with very limited conclusions. This paper proposes a Stochastic Petri Net (SPN) model to model such a scenario considering the cloud and mist with varying number of node and varying workloads. We also present a case study with real values ​​and a distributed word processing benchmark application. The result indicate that there are cases where few cloud node can be more efficient than many mist node and vice versa. Therefore, the present work can help administrators of computational infrastructures to adapt their architectures finding the trade-off between cost and performance."
7317;en_US;"Since its inception, the Internet has been undergoing several transformations, one of which in particular has been calling attention to the Internet of Things (IoT), which is nothing more than various objects connected to the Internet and providing service to user, wearable, means of transportation among others. The idea is to increasingly connect the physical to the digital world. To ensure the safety of these device, and the user themselves, security mechanism must meet IoT characteristics. With this assumption, this paper presents a security proposal for Blockchain-based IoT, a model that seeks decentralization as a safety measure. To achieve this goal the proposal uses the same concept of Blockchain applied in cryptocurrencies, but with a consensus mechanism based on trust between the node. The application of the prototype in a test scenario made it possible to demonstrate that the proposed model is capable of obtaining consistent result for the given domain and application."
7318;en_US;"Biometric authentication supports different application and has gained a key role in wearable network by overcoming limitations on the human-machine interface of their device. Authentication method often rely on unique events, such as iris or face recognition, requiring validation of the user identity whenever they need access to the system. However, with the recent inclusion of biosensor in wearable device, some signals are constantly being collected, allowing for continuous authentication. However, existing method of continuous authentication via ECG and EMG are costly, complex or inconvenient for the user. Thus, to overcome these problem, this paper proposes the BEAT system, which uses photoplethysmogram (PPG) biosignals to estimate volumetric changes in blood flow. In addition, the BEAT system transmits signals collected by the skin (i.e. galvanic coupling communication), with epithelial tissue being a safe secondary channel against radiofrequency based attacks. The result of experimental evaluations demonstrate the viability and efficiency of the system."
7319;en_US;"The Internet of Things has a large number of device distributed around the world, and the low security standard of some of these device has been exploited by malicious agent to compose botnets. The impact of these botnets can be reduced by knowledgeable network operators by blocking access to Command and Control servers and creating defenses against new attack and spread mechanism. In this article, we extend existing tool in a framework for CeC server detection and malware classification into similar groups. We use static and dynamic analyzes in combination with heuristics for CeC address indication, and graph theory for binary similarity grouping. In our result, the clustering algorithm can concentrate binaries into a few groups, directing network operators efforts, while the proposed analysis and heuristics broaden the identification of CeCs by mitigating countermeasures implemented by malware developers."
7320;en_US;"The Internet of Things (IoT) is an ecosystem that combines wireless sensor network, cloud computing, analytical data, interactive technologies as well as smart device. Promoting security over this dynamic and heterogeneous environment with predefined and static mechanism can result in improper decisions, resulting in the need for adaptive security solutions. With this in mind, the objectives of this paper are to: (i) systematize and present the concepts of adaptive security for IoT, including their relationship with studies in context awareness; (ii) perform a systematic literature review seeking to identify the state of the art; and (iii) develop a critical analysis of the identified work, in an effort to list research opportunities."
7321;en_US;"The increase in mobile traffic consumption by user grows every year. Demanding resource for mobile device application such as processing power and storage capacity has led the architecture of mobile network to redesign into a centralized structure, C-RANs. The centralized nature of C-RAN makes it possible to manage resource more efficiently through virtualization technique and opens the horizon for ubiquitous computing to process IoT paradigm data. On the other hand, providing computational resource close to base stations, as suggested by the Mobile Edge Computing architecture, allows delay-sensitive application to be more user-friendly. In this paper, a mixed integer linear programming problem is formulated for the positioning of caches as virtual network functions and the location of content retrieval by user. The problem is to minimize the cost of recovery for user, as well as minimize the deployment of virtual functions."
7322;en_US;"RFC 7665 proposes a reference architecture for Service Function Chaining (SFC) that splits all SFC functionality into a set of specialized elements. However, this approach relies on the underlying network infrastructure and requires communication between Service Functions (SF) and SFC elements. In this work, we propose Cadeia-Aberta: an architecture in which SFC elements are implemented transparently inside SFs kernel using Extended Berkeley Packet Filters (eBPF). A proof-of-concept prototype demonstrates that this approach allows direct communication between SFs and reduces communication overhead."
7323;en_US;"The NFV-MANO architecture, widely adopted by Network Function Virtualization (NFV) solutions, includes the NFVO (NFV Orchestrator) element to support Service Function Chaining (SFC) orchestration. This paper proposes a strategy for orchestrating Multi-SFCs: SFCs distributed over multiple clouds, possibly across multiple domains, orchestrated by NFVOs from multiple NFV platforms. Existing solutions are monolithic as they are restricted to SFCs composed of Virtual Network Functions (VNFs) from a single cloud/domain/orchestrator. The proposed strategy establishes tunnels by instantiating VNFs at specific Multi-SFC points, allowing instantiation and secure communication of resource across multiple domains. Several management tasks including configuring NFV infrastructures are transparent to the operator. Experimental result evaluate the solution by comparing the proposed approach in terms of performance and resource consumption."
7324;en_US;"Future wireless communication infrastructures, starting from 5G, will operate their radio access network (RANs) based on virtualized functions distributed over a crosshaul, i.e., a transport solution integrating fronthaul and backhaul. Optimizing the resource allocation and positioning of the virtual network functions of a virtualized RAN (vRAN) is crucial to improve performance. In this paper, we propose a new optimization model to deal with VRAN functions allocation and positioning that seeks to maximize the level of centralization. Our model explores several representative functional splits, including the fully distributed remote unit (UK), while taking into account the limit imposed by the communication paths between the crosshaul and the core network. We compare our model with a state-of-the-art solution and show how our approach improves the centralization level in most of the scenarios, even considering the limit imposed by the core infrastructure. Our model also provides higher number of feasible solutions in most of the cases. Additionally, we investigate the positioning of the central unit (CU) and show that its placement with the core infrastructure is rarely the best choice."
7325;en_US;"Distributed Denial of Service (DDoS) attacks continues to be a major issue in todays Internet. Over the last few years, we have observed a dramatic escalation in the number, scale, and diversity of these attacks. Among the various types, spoofed TCP SYN Flood is one of the most common forms of volumetric DDoS attacks. Several work explored the flexible management control provided by the new network paradigm called Defined Networking Software (SDN) to produce a flexible and powerful defense system. Among them, data plane based solutions combined with recent flexibility of programmable switches aims to leverage hardware speed and defend against Spoofed Flooding attacks. Usually, they implement anti-spoofing mechanism that rely on performing client authentication on the data plane using technique such as TCP Proxy, TCP Reset, and Safe Reset. However, these mechanism have several limitations. First, due to the required interaction to authenticate the client, they penalize all clients connection time even without an ongoing attack. Second, they use a limited version of TCP cookies to detect a valid client ACK or RST, and finally, they are vulnerable to a buffer saturation attack due to limited data plan resource that stores the whitelist of authenticated user. In this work, we propose the use of sketch-based solutions to improve the data plane Safe Reset anti-spoofing defense mechanism. We implemented our solution in P4, a high-level language for programmable data planes, and evaluate our solution against a data plan. Safe Reset technique on an emulated environment using Mininet."
7326;en_US;"Vehicular mobility traces are dataset of vehicles location in a region with high spatiotemporal precision. Access to this sensitive information can threaten the safety and privacy of drivers, such as analyzing this data makes it possible to discover other contextual and latent information, such as user daily home routes or workplaces address. In this way, many obfuscation and anonymization technique have been proposed to mitigate the problem of user location privacy. In this work, we analyze an anonymization technique called mix-zone, where selected urban regions promote the simultaneous anonymization of vehicles by changing their pseudonym. We show how information about drivers behavior in a city, such as their road preferences, can be used to re-identify their trajectories. We present a simple and efficient re-identification technique that uses only two geo-referenced points as input data. We validate our technique with a real dataset of taxi cabs, being able to reidentify up to 95% of anonymised trajectories."
7327;en_US;"DDoS attacks are prevalent. To mitigate their impact, detection should preferably occur closest to the attack origin, at the network edge, e.g., at home routers. However, these device typically have limited resource and the use of approaches that resort on packet inspection do not bode well with such device. We propose an extremely lightweight approach for DDoS detection that employs solely network interface byte counts. To detect attacks with such limited amount of information, our key insight consists in training classifier making use of real workload data from nearly one thousand home-user augmented with attacks generated in a controlled environment. We show that our classifier are very efficient in detecting attacks with different vectors."
7328;en_US;"Exploring pattern of human behavior is a central and guiding theme in the development of new application and technological solutions. However, few studies investigate how user habits can improve the performance of Information Centered Network architectures. This paper presents an analysis of behavioral profiles of music user and how different profiles influence the performance of cache override policies. result from an experimental study using ndnSIM with real traces of multiple user show that user habits are key factors in choosing an optimized cache replacement policy. Investigations also reveal that the distribution of popularity of songs follows an approximation of Benfords Law, and it is possible to differentiate the profile of user according to the behavior of the Benford curve of the accessed songs."
7329;en_US;"Live video streams have already broken the boundary of the global scale and now face a new challenge: delivering uniform high quality of experience (QoE) to all their customers. To address this issue, several approaches use historical performance-related information to infer the quality of experience (QoE) of their future sessions. This allows the resource needed for each type of client to be better estimated even before the session starts. However, the success of such schemes depends on an accurate QoE prediction: Previous studies use performance metrics such as interrupt rate and average bitrate and achieve 70% prediction accuracy. In the present work we present a new approach, which correlates the customer QoE with its bitrate adaptation flow. We have shown that this set of metrics provides a forecast accuracy of 81%. We also presented a case study for customer allocation using the predictor and found a potential for increasing overall QoE compared to standard allocation."
7330;en_US;"Nominated Data network (NDN) have been proposed to address the current challenges facing traditional IP network. Promising NDN applied to wireless and mobile environments suffers from packet flooding and overhead. This work proposes a routing strategy for Mobile Named Data Ad Hoc network that aims to reduce packet flooding. The flow of packets of interest and data updates each node level of uncertainty about content retrieval. In addition, node also consider the signal strength received by the interface at the time of interest entry as a routing criterion. The assessment took place in an unmanned aerial vehicle network environment and the simulation result show gains in reducing the broadcast storm while maintaining a high satisfaction rate of interest."
7331;en_US;"Future generation cellular network are expected to provide broadband access to a continuously growing number of mobile user. The densification of cellular network is necessary to increase their capacity and improve spectral efficiency, however, in these system, ICI still represents a real challenge that limits system performance, especially for user located at the edge of the cell. This paper briefly review the ICIC technique in the LTE-A downlink of mobile cellular network as an approach to alleviate the impact of interference and improve performance. The simulation result show the advantages and limitations of the eICIC and FeICIC technique compared to the model without interference control."
7332;en_US;"The IEEE 802.11ah is one of the most recent wireless protocol that has emerged, aiming to improve Internet of Things (IoT) communication device. Among the 802.11ah related work that evaluate the Restricted Access Window (RAW) and others medium access control mechanism, only a few consider Quality of Service (QoS) and inherent traffic heterogeneity in IoT. Nevertheless, the purpose of this work is to compare two RAW scenarios, which consider two types of device with different traffic pattern and QoS requirement. The result suggest that the increase of medium containment within RAW slots in dense network may be a limiting factor for providing QoS."
7333;en_US;"The use of directive antennas in frequency ranges above 10 ~ GHz is mandatory due to the high attenuation and other propagation phenomena that occur in these bands. As a result, initial user access to such cellular network is slow as the base station and user are required to beamform before they can communicate. An alternative to make this process faster is by using user positioning information, but so far no work has considered the impact of geolocation errors on this process. In this paper, two new mechanism aware of geolocation errors that explore a larger angular space to find better performing beam combinations are proposed."
7334;en_US;"With the increasing popularization of computer network-based technologies, security has become a daily concern, and intrusion detection system (IDS) play an essential role in the supervision of computer network. An employed approach to combat network intrusions is the development of intrusion detection system via machine learning technique. The intrusion detection performance of these system depends highly on the quality of the IDS dataset used in their design and the decision making for the most suitable machine learning algorithm becomes a difficult task. The proposed paper focuses on evaluate and accurate the model of intrusion detection system of different machine learning algorithm on two resampling technique using the new CICIDS2017 dataset where Decision Trees, MLPs, and Random Forests on Stratified 10-Fold gives high stability in result with Precision, Recall, and F1-Scores of 98% and 99% with low execution times."
7335;en_US;"Machine learning has been used in cybersecurity to address the limitations of pattern identification technique in network traffic. The existence of numerous algorithm in the literature makes the choice of which one is most suitable for the intrusion detection, not be a trivial task. In this paper is performed a comparative analysis of 6 supervised machine learning algorithm evaluating the impact of the aggregation of the IP flows in the predictions, training time and test. The experiment showed that the aggregation method improves the classification and reduces the processing time of the model. In the analysis performed, the Decision Tree obtained the best balance in the result."
7336;en_US;"Assessing the quality of experience of residential user is of great interest to ISPs. However, obtaining perceived QoE is costly, making it difficult to use supervised classifier. This paper proposes a method based on unsupervised machine learning that detects statistical pattern in time serie from the detection of change points and the spatiotemporal correlation of QoS measurement result. We exemplify the application of the method to a set of actual data, showing that the model result reflect a user QoE metric obtained from technical calls made to the call center. Finally, we evaluated the accuracy of the online execution of the method."
7337;en_US;"Phishing is an attack that uses social engineering and other technique to steal victims personal or financial information. Brazil leads the phishing attacked user statistics and over 77% of these attacks are carried out via URLs. Despite the existence of bases and technique for detecting malicious URLs, they are not effective when it comes to URLs targeted at Brazilian user, which have different characteristics. This paper presents an effective method for detecting Brazilian malicious URLs based on machine learning. More than 110 characteristics (lexicons, network, reputation and others) and different classifier were used to evaluate the effectiveness of the proposed method. The evaluation was performed with real data extracted from the fraud catalog of the Brazilian academic network and other source. result show high accuracy and accuracy rates above 96%."
7338;en_US;"The growth in data volume has revolutionized business and science while demanding increasing capacity from computing resource. High performance computing platforms (HPC), traditionally employed in massively parallel numerical simulation, offer computational power that can be harnessed in big data analysis. However, the convergence of Big Data and HPC must be examined in several ways; In particular, network infrastructure needs to adjust to very different application demands. The software-defined network (SDN) model can favor this convergence, thanks to its global view of the network and its programmability. In this context, we present an SDN platform capable of convergently meeting Big Data and HPC application requirement. The platform applies routing mechanism best suited to each traffic profile, thus reducing application execution time. We simulated the viability of our platform by reducing the execution time of real MPI application in specific scenarios by up to 11% and Hadoop by up to 6%."
7339;en_US;"Data center network, which need to dynamically service a large number of flows with different service requirement, require load balancing mechanism. However, traditional load balancing approaches do not allow full utilization of network resource in a simple, programmable and scalable manner. In this context, this paper proposes RDNA Balance that explores elephant stream isolation balancing and source routing, supported by the core network, and edge sorting operations using existing feature in the OpenFlow protocol. The result show that this approach is capable of providing simple, scalable, and programmable load balancing."
7340;en_US;"Controller placement problem seek to spatially position the controllers of a software-defined network (SDN) and choose the links that will serve them. These problem are NP-Hard. In this work, we propose a new formulation focused on long distance network based on minimizing the financial costs of network maintenance. Our modeling still limits latency within the network and avoids controller overloading. The decision version of our formulation as NP-Complete has been proven. An exact algorithm for offline network structuring and a set of distributed heuristics for runtime topology adaptation were created. The heuristic result reach about 5% over the optimal cost within the simulated test cases. Therefore, the proposed solution can lead to financial savings for maintaining long distance SDN network."
7341;en_US;"Software-defined network (SDN) and the emergence of programmable data planes allow greater flexibility for network operation. These technologies are capable of allowing network administrators to reconfigure data and control planes. The ability to reconfigure and program the network on demand offers a number of benefits, in particular enabling it to improve network security mechanism by using programming capability. However, in addition to promoting a greater degree of flexibility, data plane programmability raises concerns about errors that can create inconsistencies in the most basic function of the network, data forwarding, thereby disrupting previously defined policies. In this paper we present a framework for reliably installing functions in programmable data planes, ensuring that installing such functions preserves the basic forwarding properties. To this end, we employ program composition technique to merge modular functions into a single aggregate data plane, ensuring that the resulting program is correct after the merge. To show the correctness of our method, we present a case study with a firewall and a monitoring module."
7342;en_US;"Managing mobility is an important and recurring challenge of urban centers, mainly due to the intensification of population grouping in large city. In this sense, one of the consequences of this impasse is the disproportionate growth in the number of vehicles in relation to urban infrastructure, responsible for the emergence or intensification of traffic jams. The objective of this paper is to propose a fully distributed algorithm capable of reducing these impacts through the reorganization of vehicular flow. Thus, the vehicles, in a collaborative way, are responsible for classifying and sharing information about the displacements made for decision making in a distributed environment. The result of the simulation indicate that the solution presented can reduce the travel time, the time in congestion, and increase the average speed achieved with low impact on the number of message transmitted, in order to allow a good performance of the proposed system."
7343;en_US;"Traffic jams in major urban centers are increasing each year and hampering peoples mobility. The timing setting of the traffic lights is an important factor to consider. Using vehicular network, this work presents an adaptive semaphore control algorithm reformulated from an improvement of the best solution found in the literature so far, the Intelligent Traffic Light Controlling (ITLC). The contributions of this paper focus on how vehicle platoons are formed and updated. Through simulation in a synthetic environment and in a realistic environment in the city of Bologna, Italy, it was found that the reformulated algorithm presented superior result in terms of vehicle flow at traffic lights, besides reducing the average vehicle delay, the average emission of CO2 and signaling overhead when compared to ITLC."
7344;en_US;"The Advanced Traffic Management System (ATMS) is increasingly used by urban mobility managers to improve vehicular traffic management. Many ATMS employ centralized solutions because of the difficulty of selecting the most relevant vehicles in highly dynamic network to detect congestion and suggest alternative routes. Moreover, such solutions are not always scalable. On the other hand, the distributed solution needs to segment the entire scenario before selecting vehicles. In addition, such a solution selfishly suggests alternative routes that can lead to secondary congestion. Based on these gaps, a distributed urban mobility management system based on the vehicular social network (VSNs) paradigm called MAESTRO was proposed. This paradigm arose from the integration of wireless communication device and social network in the vehicular environment. Thus two different approaches can be explored in VSNs: Social Network Analysis (SNA) and Social Network Concepts (SNC). Both approaches were applied in the MAESTRO system. Simulation result showed that the use of ANS and CNS in the vehicular environment has great potential to increase system scalability and also improve efficiency in urban mobility management."
7345;en_US;"Vehicular Ad-hoc network (VANETs) are technologies that allow drivers and passengers to use network service in vehicles. The heterogeneity of VANETs, ​​which can use different wireless technologies, represents a challenge for the development of communication protocol. In this context, the Software Defined Vehicular Network (SDVN) paradigm emerges as a promising alternative that allows the creation of flexible and adaptable protocol. Therefore, this paper presents a geocast dissemination protocol that uses environment and vehicle information to intelligently disseminate message. The result obtained through simulation show that the protocol presents a more efficient behavior than the opponents, both in environments that do not consider constructions (buildings, houses, etc.) or in environments that constructions are considered (realistic)."
7346;en_US;"<p>In Wireless Sensor Network (RSSF) monitoring application, sensor node depend on limited power source. Studies indicate that the main source of energy consumption in sensor node is related to data transmission. This paper presents an approach to data reduction based on the analysis of the dispersion of the values ​​detected by the sensor, in order to avoid sending detections whose values ​​are little dispersed. The experiment performed with the Castalia simulator showed that the proposed approach achieved a reduction greater than 96%, maintaining a low level of errors in the final destination data reconstruction.</p>"
7347;en_US;"<p>Mobile location data is an important source for understanding user profiles, helping provider deliver better service. With this kind of data, it is possible to identify the relevant points of a user, and even classify these points as places of home or work. With this knowledge, mobile service provider can increase customer engagement and retention. However, identifying and classifying points of interest (PoI) is not a trivial task, and most existing work assumes that data should be collected at a high frequency, making the process difficult and expensive. In this paper, we propose approaches to identify and classify PoIs based on sparse data, that is, they were collected at long time interval. The result, when compared with literature solutions, show improvements of at least 13% in the accuracy for the identification of PoIs, and 10% and 4% in the classification of home and work points, respectively.</p>"
7348;en_US;"<p>Advances in bioengineering and nanotechnology have led to the emergence of nanometer sized device, eg. synthetic nanomachine, nano-antennas and nano-injectors, capable of detecting and acting on their environment. However, while necessary, it is a major challenge to provide communication between them. Conventional electromagnetic communication is not necessarily an option for nanoredes due to the medium and its scale. Thus, researcher have been exploring molecular communication. In particular, this paper investigates the potential of the Inositol Triphosphate (IP3) molecule for data communication between nanodevice. Compared with calcium molecule performance, result for metrics such as gain and channel communication capability are promising and contribute to a detailed understanding of how to manage data transmission in an extracellular environment. Our result contribute to the design of nanoredes inside the neural cell tissue.</p>"
7351;en_US;"<p>Known network as WiFi (IEEE 802.11 standard) are widely used in application ranging from simple home environments to complex control system network. However, the extensions incorporated into the standard to provide Quality of Service (QoS) are still unable to guarantee time constraints for real-time (RT) communications requirement. This paper presents an experimental validation of the RT-WiFi protocol that was recently proposed and analyzed through simulation. The experimental result demonstrate the feasibility of implementing the RT-WiFi protocol and improving the QoS level of communications through a comparative analysis with the EDCA mechanism, which is a mechanism incorporated in the IEEE 802.11 standard to provide different levels of transmission priority of different types of traffic</p>"
7354;en_US;"<p>Location-based service allow monitoring of specific people or area. By tracking your location, you can help rescue lost or injured people in natural environments. However, wireless network in dense vegetation area, in this case, the Atlantic Forest, imply challenges related to mobility and connectivity. This work compares the performance in terms of range, signal strength, loss rate and delay in links implemented using LoRa, IEEE 802.11g and ZigBee technologies in the Serra dos Órgãos National Park. Comparing these metrics allows us to distinguish the limitations of each technology that may influence the spread of alerts. The result show that LoRas maximum range is 3 times longer than IEEE 802.11g and 6 times greater than ZigBee, with received signal strength lower than both technologies, averaging 21.67% and 26.15%, respectively.</p>"
7355;en_US;"<p>Due to the keen interest in bitcoins and blockchain application, distributed application with Byzantine safety and fault tolerance requirement have received additional attention. algorithm such as Proof of Work (PoW) and Proof of Stake (PoS) have been developed to handle consistency by capturing aspects of open system. However, when scaling well with the considerable number of replicas, most of these PoW-based or PoS-based system do not perform as much as conventional approaches that deal with replica consistency. algorithm such as PBFT that are based on active replication can fit the blockchain, ensuring better replication consistency performance. Thus hybrid approaches like Tendermint or Hot Stuff were developed offering openess and performance. Although they achieve large numbers of replicas, these solutions rely on PoW or PoS algorithm, which makes the consensus among their replicas expensive. project like Hyperledger propose high-performance blockchains where traditional PBFT consensus is used without the need for PoW or PoS. However, PBFT algorithm, in consensus of their replicas, do not scale well due to quadratic costs (O (n 2)). Thus, in the literature, hierarchical structures have been proposed with the PBFT to deal with the increasing number of replicas. We, in this paper, propose a hierarchical architecture with a PBFT algorithm to deal with the highly adversarial model of the blockchain environment. Our solution has a linear cost consensus on the number of replicas.</p>"
7356;en_US;"<p>Blockchain and Tangle are data structures used to create an immutable public record of data insured by a network of peer-to-peer participant who maintain a set of constantly growing data records known as ledgers. Blockchain and Tangle technologies are a decentralized solution that guarantees the exchange of large amounts of trusted message, among billions of connected IoT device, which are very valuable as they are valid and complete. This highly encrypted and secure peer-to-peer messaging mechanism is adopted in this project to manage the processing of IoT transactions and the coordination between the device that interact with the process. To maintain private transactions, secure and trustless, the distributed consensus algorithm are responsible for validating and choosing transactions and recording them in the global ledger. The result showed that the speed of the consensus algorithm can affect the creation in real time of reliable stories that track the events of the IoT network. After incorporating Complex Event Processing that allows selecting only those high level events, it is possible to get an improvement in many situations. The result is a Middleware system that provides a framework for the construction of large-scale computer application that use Complex Events Processing and different decentralized ledgers such as the blockchain of Ethereum or IOTA Tangle, for secure data storage.</p>"
7357;en_US;"<p>In recent years, Named Data network (NDN) have been proposed as a promising paradigm for the Internet of the future because of their disruptive content-centric feature. In order to ensure content authenticity, NDN relies on the use of digital signature which, due to the complexity involved in the validation process, may result in additional processing overhead. As a result, NDN implementations are susceptible to a variety of attacks. This work proposes a security framework that aims to use blockchain technology attributes to enable verification of the integrity and authenticity of NDN content. result obtained from emulation showed that the proposed framework can detect data tampering attacks and prevent the misrepresentation of content by malicious provider.</p>"
7358;en_US;"<p>The complexity of home network requires innovative strategies for network management and characterization of user demand. In this paper we use unsupervised machine learning technique in order to find out the traffic profile of user. In partnership with an ISP, we collect download and upload traffic from over 2,000 home routers. We use a tensor decomposition technique (PARAFAC) to extract relevant network usage factors and a clustering algorithm to group user with similar daily traffic pattern. To characterize user behavior over periods longer than one day, we use cluster information and a hidden Markov model.</p>"
7359;en_US;"<p>Device-to-Device (D2D) communication is one of the mechanism for releasing 4G network via data offloading to other network. D2D/4G hybrid network have as a challenge the efficient multiplexing of communication interface, which can directly impact user Quality of Experience (QoE). This paper introduces QD4G, a Machine Learning platform to control when customers using the Dynamic Adaptive Streaming over HTTP (DASH) standard should employ a 4G network or a D2D network. The goal is to improve QoE by providing video streaming at higher resolution. Tests were performed with real device and the result showed that prediction allows to achieve up to 87% accuracy, with an increase in average video resolution between user via D2D of up to 150% while at the same time relieving 4G network data traffic. up to 80% in the scenarios evaluated.</p>"
7360;en_US;"<p>The rise of big data application brought along a serie of difficult challenges regarding the allocation of hardware and software resource. Typically these application are known for being computationally expensive and having high heterogeneity on how they operate, making the task of estimating application execution time very challenging. It may be still possible to correlate feature extracted from the cloud environment and from the input dataset to the execution time. Such relationship may then be used to predict execution times. Based on such assumption, this work explores machine learning (ML) model to the task of predict execution time of Spark application. This work investigates four ML model as well as different feature, while also comparing their result against the current state-of-the-art. All model are evaluated in several scenarios and configurations, producing result that are significantly superior to the state-of-the-art in various cases.</p>"
7361;en_US;"<p>Low Power and Lossy network (LLNs) is a common type of wireless network in IoT application. LLN communication pattern usually requires an efficient routing protocol. The IPv6 Routing Protocol for Low-Power and Lossy Network (RPL) is considered to be a possible standard routing protocol for LLNs. However, RPL was developed for static network and node mobility decreases RPL overall performance. These are the purposes of the Mobility Aware RPL (MARPL), presented in this paper. MARPL provides a mobility detection mechanism based on neighbor variability. Performance evaluation result on the Cooja Simulator confirm the effectiveness of MARPL regarding link disconnection prevention, packet delivery rate and fast mobile node topology reconnection with low overhead impact when compared to other protocol.</p>"
7362;en_US;"<p>The Internet of Things is gaining the attention of the market, industry and the scientific community. The integration of WSNs with the Internet led the IETF to specify new protocol. One of the main ones is RPL, a routing protocol for network that have considerable packet loss. Among the routing metrics, ETX stands out, which contributes to the choice of reliable paths. However, the rapid depletion of battery power from the bottleneck node is still a problem. In this context, we present here a new metric based on the estimated power consumption of the network interface, which contributes not only to reliability, but also to load balancing and extending the network lifetime.</p>"
7363;en_US;"<p>Visible Light Communication (VLC) presents several challenges such as interference and blockages created by obstacles. At the same time, many environments offer a rich infrastructure of light source that can be used to aid end-to-end communication. In this paper, D-VLC is a dynamic routing protocol. D-VLC reacts to communication interruptions by building alternative routes in the visible light network without prior knowledge of the topology or even the device that compose it. The new protocol was implemented and evaluated in a real environment using the OpenVLC embedded platform. The result show that, using D-VLC, the network was able to adapt to dynamic changes in communication, such as shadows and obstacles, with network usage overload of less than 10%.</p>"
7364;en_US;"<p>In ad hoc wireless vehicle network, communication between vehicles occurs opportunistically due to the high mobility of the node. Developing routing protocol is challenging given the complexity of defining metrics for choosing the next hop. We introduced the concept of transmission opportunities by analyzing three real taxi movement databases. We discuss how routing protocol impact the proper use of transmission opportunity inventory. We have shown that transmission opportunities can be used as a metric for both routing protocol performance evaluation and resource calculation in vehicular network.</p>"
7366;en_US;"<p>The vehicular network refers to a promising approach of having vehicles equipped with wireless communication device capable of communicating with other vehicles. Each vehicle is able to collect, process and disclose information about itself and its environment. Acquiring a large amount of sensing information and increasing traffic demand requires mechanism to decongest the cellular network. Thus, this work uses a measure of centrality to propose an offloading mechanism, in which certain vehicles will collect data from their neighbors and transmit it on the cellular uplink. The experiment were conducted in a real scenario and the result found showed a reduction of up to 8.79% in the number of accesses to the cellular network compared to another solution in the literature.</p>"
7367;en_US;"<p>Expenses due to congestion problem in large urban centers amount to billions of dollars worldwide. This is due to time lost in traffic and fuel consumption caused mainly by traffic jams at peak times. Several work in the literature propose solutions to the traffic management problem using the processing, storage and communication capacity of vehicular network. Among the solutions in the literature, infrastructural approaches utilize the processing and storage power of infrastructure to detect traffic jams and suggest vehicle routes. This paper presents GRIFO that, unlike the infrastructural approaches in the literature, vehicles are responsible for checking congestion and calculating new routes when needed. Using only information about near-road conditions provided by the auxiliary storage infrastructure, each vehicle verifies the need for recalculation. The proposed work manages to distribute the flow of vehicles in the road network in order to reduce the average travel time compared to literature algorithm.</p>"
7368;en_US;"<p>Elastic optical network make up a network infrastructure capable of supporting the high demand for data traffic from high-speed network. One of the problem that must be solved to ensure the proper functioning of the network is called Routing, Modulation Level and Spectrum Allocation (RMLSA). This paper aims to propose a new approach to this problem through the use of an adaptive guard bandwidth provisioning algorithm, based on the level of network utilization, called GBUN. The performance of the proposed algorithm is compared with algorithm that use fixed guard band values ​​and the adaptive proposal AGBA. The result show that the proposed algorithm presents a better performance in terms of band block probability for the studied scenarios.</p>"
7369;en_US;"<p>Elastic optical network allow splitting the optical spectrum into frequency slots that can be combined to create channels with defined bandwidth on demand. This flexibility provides greater spectral efficiency over traditional fixed grid optical network. Traffic aggregation strategies make it possible to achieve even greater efficiency in the use of network resource, reducing the amount of guard bands and the use of transmitters and receivers. This paper proposes a mechanism that, combined with existing resource allocation solutions, enhances the use of elastic network capabilities and traffic aggregation. The study shows that the adoption of the proposed mechanism also contributes to the reduction of bandwidth blocking rates and the gain of energy efficiency.</p>"
7370;en_US;"<p>Several recent work reduce energy consumption in data centers but consider one or two of the three highest consumption dimensions, i.e., servers, cooling system, and network infrastructure. However, algorithm that optimize only one or two of those dimensions may hide significant energy losses in the other dimensions. Moreover, energy-saving strategies may increase service response times and violate service level agreements. This paper presents an extensive study of the relations between the three dimensions of higher-energy consumption in a data center and their impact on parameters of quality of service. The paper also proposes an algorithm for allocating virtual machine that exploit varying load levels in the data center to save energy more aggressively or to minimize violations of service level agreements and presents a new simulator for studying energy efficiency of data centers that allows the evaluation of several scheduling algorithm under different workloads, cooling strategies, and network optimizations. The experimental result are from more than 500 simulation with three traces of real workloads with up to 696 thousand virtual machine running over a period of up to 34 days.</p>"
7371;en_US;"<p>Fifth generation (5G) cellular network will be the key element of a society that is becoming increasingly interconnected and digitalized. application adopted in many social and industrial sectors will require from 5G network higher standards of availability and reliability. These requirement are leading operators to plan the deployment of protection schemes in the backhaul layer. In this context, our aim is to employ simulation to assess in a technical and economic way different backhaul protection schemes based on passive optical network (PON). The result indicate that the use of protection can increase the viability of 5G network based on a PON backhaul supporting a hybrid fronthaul with fiber and copper.</p>"
7372;en_US;"<p>This paper introduces T-Incident, a robust, low-cost architecture for detecting and enriching road events based on heterogeneous data fusion. A spatiotemporal model for merging incident, non-incident and social media data has been developed. In addition, this latter data source was filtered using natural language processing method for pattern detection capable of describing the event and its vicinity. A learning-based model was also developed to identify these pattern and detect the types of events. The methodology result showed the best parameters for the T-Incident approach, providing an accurate incident detection and description service above 90% for the F1 score, Recall and Precision metrics.</p>"
7373;en_US;"<p>YouTube as a video platform currently has a ubiquitous presence in the dissemination of online content. As such, marketers and content creators are expected to make use of YouTube to spread products and ideas. In this article, we analyze the traffic of political video and video advertisements on YouTube during the 2018 elections. Our analysis is conducted through synthetic network personas designed to simulate human behavior. Over a period of approximately 40 days, we simulated voters from different states (via VPNs), gender (through account settings), and political alignment (through access to channels classified as left, center, and right). During the experiment, the different personas were susceptible to video advertisements that are paired with video accessed automatically. Based on the collected data, we present a study focusing on three aspects: (1) channel content popularity characteristics; (2) the difference in advertising exposure between different personas; (3) an analysis of parties that made most use of the platform.</p>"
7375;en_US;"<p>WhatsApp is a mobile communication system that allows people to interact through groups. In this work, we analyze the dissemination of information within a group network that simulates the WhatsApp network. The built network considers two types of groups: organic groups, formed by friends and family, and artificial groups that are usually created with the purpose of being a mean of spreading certain subject or event, such as political campaigns. We analyzed the speed with which information is spread in this network considering the epidemiological model Susceptible-Infected (SI). We then deepen our analysis in order to identify parameters that cause this scattering to be partially controlled in order to make it difficult to propagate fake news in these network. Our result quantify the viralization ability of content in WhatsApp and identify aspects that could limit such ability to prevent the platform from being abused in election periods.</p>"
7377;en_US;"<p>Network neutrality advocates that no traffic should ever be discriminated, either in terms of source, destination and,or content. Although several solutions for detecting traffic differentiation (TD) have been proposed, there is a lack of effective solutions for locating the source of TD. In this work, we propose a solution for detecting and locating TD that takes advantage of routing properties of Internet routing, in particular AS peering. The proposed strategy explores differences and similarities of the possible routes between measurement points. The assumptions regarding Internet routing were validated through an experiment executed on PlanetLab. We also evaluated with simulation the accuracy of our proposals.</p>"
7378;en_US;"<p>Path changes caused by events such as traffic engineering, changing traffic exchange partnerships, or link failures impact multiple paths on the Internet. Topological monitoring platforms perform periodic measurements using traceroute for a large number of destinations. This approach, however, is inadequate to precisely identify the extent of the impact of routing events. For example, a link failure can be restored before all routes are measured. In this paper we present measurement strategies that minimize the cost of probing to identify paths impacted by a routing event. Our result show that it is possible to identify the set of paths impacted by an event efficiently. Our result further indicate that when integrated into a state-of-the-art pathway tracking system, our strategies more than double the number of changes detected.</p>"
7379;en_US;"<p>Bulk Data Transfer (BDT) and its generalization, Multiple Bulk Data Transfer (MBDT), are critical service for business operations in geo-distributed inter-center data network. In these network, BDT or MBDT application perform synchronization, resynchronization, data replication, virtual machine migration, and big data aggregation, among other tasks, requiring large amounts of bandwidth and efficient traffic engineering solutions. Elastic optical network (EON) enable on-demand resource provisioning and allocation through Spectrum Routing and Allocation (RSA). This paper proposes and compares application-aware dynamic RSA solutions employing Smallest Deadline First (SDF), Larger Data Amount (LDA), Smallest Data Amount (SDA), and Smallest Remaining Time (SRT) scheduling technique.</p>"
7380;en_US;"<p>Advances in optical data transmission technology have enabled the rapid growth of the internet and demanding bandwidth service. The emergence of Orthogonal Frequency Division Multiplexing (OFDM) based network has opened the possibility of increasing the spectral efficiency of a network by solving the routing and spectrum allocation (RSA) problem. In this work, two RSA heuristics were implemented that consider different available modulation formats (RMSA). simulation were made for several network using heuristics under incremental traffic conditions. The result showed that the load-balanced allocation heuristic (BMLM) tended to have a lower blocking rate in the early periods, when only one modulation format was available, but presented a higher long-term blockage rate relative to the heuristic. Shortest Path Allocation (SPMLM). When more modulation formats were available, BMLM performed worse in most cases, but achieved better result on some network.</p>"
7381;en_US;"<p>The introduction of space division multiplexing in optical network brings new challenges for network protection since the lightpath can span high capacity and transmit data at different rates. In addition, these network suffer from the fragmentation of the spectrum that hinders contiguity and continuity constraints and therefore increases the block. To address these problem, in this paper, we propose the protection algorithm for elastic network with spatial division multiplexing through multipath routing and shared backup paths.</p>"
7382;en_US;"<p>Energy consumption in core network is currently impacted by Bulk Data Transfer (BDT) application among the major Internet Data Centers (CDs). This is because these application consume most of the available resource and do so for long periods of time. Due to the increase in network traffic that occurs every year, one of the key challenges for cloud service provider is energy efficiency. To serve the growing demand, the Elastic Optical network (EON) paradigm has been proposed with the objective of meeting requests with greater flexibility, making better use of the frequency spectrum. This paper proposes the Energy Efficient Aware-BDT in EON (EEABE) solution, an energy efficient aware Routing and Spectrum Allocation (RSA) algorithm for performing inter-CD BDT (ICD), which is capable of scaling BDT requests and implementing the sleep mode technique to reduce the power consumption of the switching elements in the optical network.</p>"
7383;en_US;"<p>Containers have been recently adopted as support for fast provisioning of distributed system. They can be used to implement microservice, dataflow processing, edge computing, and other complex system. However, due to the settings heterogeneity of requests and dimensionality of the hosting DCs, container scheduling is an NP-Hard problem. An efficient path to ease the scheduler complexity is to use the of high-performance parallel processing. In this context, we present present EMULAG: a GPU-accelerated multi-criteria scheduler. The schedulers objective function represents the provider perspective, aiming at data center (DC) consolidation. We present an experimental analysis revealing our solution is scalable and presents higher result than those foundin the literature, but with lower processing time.</p>"
7384;en_US;"<p>The Apache Hadoop framework, which is used to process and store large amounts of data, uses the Checkpoint and Recovery technique to assist with failed recoveries of your distributed file system. However, efficient adaptations for time between Hadoop checkpoints depend on accurate system observations. The purpose of this paper is to estimate the cost of performing checkpoints and the average time between system failures from a history of observations. Factors are observed and analyzed for different variations of framework configuration and benchmark used.</p>"
7385;en_US;"<p>Computational mists act in concert with traditional clouds to deliver service more efficiently. Mists replicate service and data in structures closer to user in order to increase the efficiency of service offered. However, such replication brings problem related to, for example, management service and identity storage. In fact, this type of service was proposed as a cloud-centric service. Thus, identity replication is not a trivial problem, as current identity replication technique either generate indiscriminate replication or little reduce their recovery latency. In this study, we investigated the relationship between number of replicas and distance of their user in identity distribution system with probabilistic replication. Simulation result show that, when compared to other distribution system, the probability distribution reduces by 25% the number of hops needed to recover identity and by 30% the number of replicas across the network.</p>"
7386;en_US;"<p>The current network infrastructure needs to support the rapidly increasing data traffic. Sophisticated planning approaches must be adopted by the operators so the high number of application can be managed efficiently. In this work, a resource provisioning model for hierarchically distributed data centers is proposed using Integer Linear Programming (ILP). The objective is to increase the efficiency in the use of computational resource and decrease the overhead in network links. result show that the model is able to efficiently accommodate 20% more application when compared to the First-Fit approach.</p>"
7387;en_US;"<p>The term offloading indicates the action of changing the processing location of a computational activity. The purpose of using offloading is to reduce the processing time of application, reduce the power consumption of the device and eventually enable the execution of tasks that would not be possible on device with reduced resource. This paper presents an offloading framework, called MLOOF, for smartphone and IoT device. The offloading process is done from the device to nearby servers (cloudlet), which enables the reduction of latency and increase in network throughput when compared to the offloading to servers in the cloud. The system was evaluated experimentally and the result show that the strategy of offloading in three levels achieves the goals of reducing processing time (up to 74%) and energy consumption (more than 90%).</p>"
7388;en_US;"<p>Fog Computing environments provide low latency access to computational resource in the edge of the network for IoT device. In the context of IoT in Smart city, user device with high mobility, such as wearables and vehicles, bring new challenges to the Fog. In this scenario recent related work have presented the advantages of a proactive migration approach, based on user mobility prediction. Otherwise, choosing the wrong node to place the user application due an inaccurate mobility prediction can not ensure an environment which serves the application requirement. This work presents an analysis of the proactive migration approach in the Fog Computing scenario and how much an inaccurate mobility prediction can hinder these advantages. simulation of a Smart City scenario show that incorporating user mobility prediction can decrease the number of migrations between the node, however, choosing the wrong destination can increase the latency in almost 30%.</p>"
7389;en_US;"<p>Location-Based Social network (LBSN) data contains spatial, temporal, and social feature of user activity, providing valuable information that is currently available on large-scale and low-cost fashion via traditional data collection method. In this way, LBSN data enables to predict user mobility based on spatial, temporal, and social feature, which can be used in several area, such as device-to-device (D2D) communication, caching, and others. In addition, a Temporal Markov Chain (TMC) is a stochastic model used to model randomly changing system, such as mobility prediction based on the spatiotemporal factor such as location and day of the week. In this paper, we introduce the Temporal Markov Model with User Similarity (TEMMUS) mobility prediction model. TEMMUS considers a TMC of variable order based on the day of the week (weekday or weekend) and the user similarity to predict the user future location. The result highlight a higher accuracy of TEMMUS compared to three state-of-the-art Markov Model predictors.</p>"
7390;en_US;"<p>Considering the increasing number of vehicles in city, application able to inform the traffic situation on the roads become more widely used. These application are intended to suggest routes, considering congestion and accidents, identified through participatory sensing. However, there are other issues encountered along a route that directly affect the user, such as crime in a particular region. Regions affected by a high crime rate may evolve during the day, depending on the type of crime and the density of people in a particular region. Therefore, this work aims to propose a service capable of identifying area with high criminal incidence, taking into consideration the evolution of the scenario, and suggesting safe routes that avoid these regions. The proposed solution allows for a safer route without compromising the time of the journey. Moreover, the result found allow us to verify the ability to avoid dangerous regions, making a drivers route safer.</p>"
7392;en_US;"<p>Cloud computing provider offer multiple service classes to deal with workload heterogeneity. Classes are distinguished by their expected Quality of Service (QoS), which is defined in terms of Service Level Objectives (SLO). A priority-based scheduling policy is commonly used to ensure that requests submitted to the different service classes achieve the desired QoS. However, the QoS delivered during resource contention periods may be unfair to certain user. In this paper, we present a SLO-driven scheduling policy which takes the SLOs and current QoS delivered for each request into account when making decisions. We used simulation experiment fed with traces from a production system to compare the SLO-driven policy with a priority-based one. In general, the SLO-driven policy delivered a better service than the priority-based one.</p>"
7393;en_US;"<p>Leading cloud computing provider, such as Amazon, Google, and Microsoft, use proprietary technologies to deliver their service. user have a desire to use multiple provider to increase their service availability, reduce costs, not rely on a single provider, among other reasons. Authorization Policy Federations (APFs) allow the definition of a single access control policy that can be applied across multiple heterogeneous provider. To do this, these policies, described in Disjunctive Normal Form (DNF) and semantics defined by an ontology, must be mapped to the local context of each user and cloud. This paper discusses the syntactic and semantic mapping process of policies and the Semantic Equivalence Level (LSE) metric used to measure their effectiveness.</p>"
7394;en_US;"<p>Bag-of-Tasks (BoT) application are parallel application composed of independent (i.e., embarrassingly parallel) tasks, which do not communicate with each other, may depend upon one or more input files, and may be executed in any order. BoT application are very frequent in several scientific area, and it is the ideal application class for execution on large distributed computing system composed of hundreds to many thousands of computational resource. This paper focuses on the scalability of BoT application running on large heterogeneous distributed computing system organized as a master-slave platform. The result demonstrate that heterogeneous master-slave platforms can achieve higher scalability than homogeneous platforms for the execution of BoT application, when the computational power of individual node in the homogeneous platform is fixed. However, when individual node of the homogeneous platform can scale-up, experiment show that master-slave platforms can achieve near linear speedups.</p>"
7395;en_US;"<p>Cloud computing seeks to mitigate the cloud limitation on high latency by providing flexible service to end user on the edge of the network. Both cloud and mist computing have strengths and weaknesses that impact performance and monetary cost. The proximity of the mist node to the edge of the network allows for adopting limited capacity computer to contain infrastructure and operational costs. Taking into account variables such as latency, workload, and computing power, it becomes complex to define under which circumstances it is most advantageous to use the cloud layer or the mist. Previous research has investigated when to use each layer but with very limited conclusions. This paper proposes a Stochastic Petri Net (SPN) model to model such a scenario considering the cloud and mist with varying number of node and varying workloads. We also present a case study with real values ​​and a distributed word processing benchmark application. The result indicate that there are cases where few cloud node can be more efficient than many mist node and vice versa. Therefore, the present work can help administrators of computational infrastructures to adapt their architectures finding the trade-off between cost and performance.</p>"
7396;en_US;"<p>Since its inception, the Internet has been undergoing several transformations, one of which in particular has been calling attention to the Internet of Things (IoT), which is nothing more than various objects connected to the Internet and providing service to user, wearable, means of transportation among others. The idea is to increasingly connect the physical to the digital world. To ensure the safety of these device, and the user themselves, security mechanism must meet IoT characteristics. With this assumption, this paper presents a security proposal for Blockchain-based IoT, a model that seeks decentralization as a safety measure. To achieve this goal the proposal uses the same concept of Blockchain applied in cryptocurrencies, but with a consensus mechanism based on trust between the node. The application of the prototype in a test scenario made it possible to demonstrate that the proposed model is capable of obtaining consistent result for the given domain and application.</p>"
7397;en_US;"<p>Biometric authentication supports different application and has gained a key role in wearable network by overcoming limitations on the human-machine interface of their device. Authentication method often rely on unique events, such as iris or face recognition, requiring validation of the user identity whenever they need access to the system. However, with the recent inclusion of biosensor in wearable device, some signals are constantly being collected, allowing for continuous authentication. However, existing method of continuous authentication via ECG and EMG are costly, complex or inconvenient for the user. Thus, to overcome these problem, this paper proposes the BEAT system, which uses photoplethysmogram (PPG) biosignals to estimate volumetric changes in blood flow. In addition, the BEAT system transmits signals collected by the skin (i.e. galvanic coupling communication), with epithelial tissue being a safe secondary channel against radiofrequency based attacks. The result of experimental evaluations demonstrate the viability and efficiency of the system.</p>"
7398;en_US;"<p>The Internet of Things has a large number of device distributed around the world, and the low security standard of some of these device has been exploited by malicious agent to compose botnets. The impact of these botnets can be reduced by knowledgeable network operators by blocking access to Command and Control servers and creating defenses against new attack and spread mechanism. In this article, we extend existing tool in a framework for CeC server detection and malware classification into similar groups. We use static and dynamic analyzes in combination with heuristics for CeC address indication, and graph theory for binary similarity grouping. In our result, the clustering algorithm can concentrate binaries into a few groups, directing network operators efforts, while the proposed analysis and heuristics broaden the identification of CeCs by mitigating countermeasures implemented by malware developers.</p>"
7427;en_US;"<p>This paper proposes an adequation of the Learning Management System (LMS) Openredu to support quantitative data analysis technique such as Educational Data Mining (EDM) and Learning Analytics (LA) based on a set of data requirement identified in previous studies. The contributions of this study are (1) the redesign of the platforms data architecture, which has the objective of making possible several application with the stored data, and being one of them the associated data visualization, was designed (2) a dashboard.</p>"
7428;en_US;"<p>Indoor location is essential because there is a growth of application that make use of this. Consequently, the need to locate user efficiently in these environments also arises. Therefore, this paper performs a systematic review of existing method of indoor location. With the definition and application of a research method, the review intends to determine how the current state of the art of this subject is.</p>"
7429;en_US;"<p>Evaluating the level of security in Android application, in an environment that there is a significant amount of data transferred in real time, is not an easy task, because the lack of ability to quickly run the security tests is immense. Therefore, performing the automation of safety tests is an extremely important activity since it is necessary to provide greater safety quality to both the final product and the customer. In this paper, the MobiSec tool is presented that performs the automation of software tests in the Androids operating system application through test plans.</p>"
7430;en_US;"<p>This paper presents the creation process of a mobile app for food delivery, named MyLunch, which aims to innovate the user interface (UI) quality in order to offer more information and better usability. As a result, UI makes the customer experience more enjoyable and promotes the people inclusion who do not have mobile technologies power.</p>"
7431;en_US;"<p>Fake news contains incorrect or imprecise information that are distributed for some purpose. The impacts resulted by the consumption of fake news can be large, affecting political, social, economic and personal aspects of the population live. Furthermore, there aren’t scalable and trusty definitive solutions to identifying fake news. The purpose of this work is to identify characteristics on websites that distribution fake news by analyzing different audit data and content that may be useful by classifier.</p>"
7432;en_US;"<p>Brazilian Law number 10.436, of April 24th, 2002, recognizes the Brazilian Sign Language (LIBRAS) as a legal way for communication and expression. However, the non-listening community, which makes use of this language, has difficulties to communicate with the listening community. In order to decrease such a difficulty, in this work is described an application of a convolutional neural network for the LIBRAS static symbols recognition. To validate the model, a database with about 2640 image was used, including symbols from 0 to 9 for training; and, 1360 symbols for testing. In addition to an extra set of 1000 symbols for validating more test cases. As a result, a recognition rate ranging from 82.5% to 98.57% for different symbols was obtained.</p>"
7433;en_US;"<p>The discovery and characterization of driving behavior profiles can be useful to support the optimization of process for insurance company or fleet managers. The evolution of ubiquitous computing and data analysis tech- niques have made such tasks possible. In this paper, we present a study on the analysis of driving behavior through clustering algorithm on a real-world dataset. We applied the k-Means++ and Spectral Clustering algorithm that came up with result that showed: the existence of less and more aggressive behavior profiles; potential to discover more profiles since preliminary quanti- tative evaluation indicated good quality in clustering with four profiles.</p>"
7434;en_US;"<p>Given the complex search tasks imposed to multimedia retrieval system, the similarity-based result often represent redundant item sets. Several real-world search tasks demand broad coverage of multiple implicit subtopic of a given query. Many work have proposed the use of clustering-based result diversification for addressing such problem. However, the definition of the number of cluster (subtopic) to be discovered is a long-lasting challenge. In order to attenuate such problem, this work proposes a novel diverse image retrieval approach as an unsupervised query-adaptive subtopic discovery based on intrinsic clustering quality optimization. Our experimental analysis have shown significant improvements, both in terms of relevance and diversity.</p>"
7435;en_US;"<p>This article introduces a proposal that enables end user, with no knowledge in software development, to create prototypes in institutional Virtual Environments of Social Participation. Then, the proposal aims to empower end-user in the practice of innovation in institutions.</p>"
7436;en_US;"<p>Brazil is a low schooling country which consumes in large scale: game, cell phones and television. In this context, promoting citizen awareness and participation has been a challenge. Research area study the potential of serious digital game for this purpose. Previous research has proposed the Play Your Process (PYP), a method of designing serious game based on ublic service process aimed at promoting citizens understanding of how these service work. One of the challenges of building game based on PYP is how to convey values through them. This dissertation aims to evolve the PYP proposing the use of technique of popular narratives to integrate values.</p>"
7437;en_US;"<p>The social perspective is increasingly presented in software development. As a consequence, influence emerges as a relevant factor in the interaction between developers using the same technological platform, the socalled software ecosystem (SECO). Influence can be considered as the power that something or someone can have over something or a person and can be a determining factor for the success or failure of a SECO. This work aims to present a Master research proposal for a theory to explain how influence, as a power, manifests among developers in SECO. We intend to build the theory based on empirical evidence from our studies in GitHub SECO, in light of the theoretical framework underpinned by French and Ravens power taxonomy.</p>"
7438;en_US;"<p>Process mining aims to automatically discover, analyze and improve business process. Trace clustering is a task commonly used to reduce the inherent complexity of process by identifying pattern. This research focuses on the application of experts knowledge in process mining through interactive clustering, referred to herein as interactive trace clustering. The aim is to improve trace clustering by reducing potential losses arising from arbitrary assumptions on the similarity between the datapoints, what is commonly required in unsupervised scenarios. Initial experiment considered partitioning clustering and three representation schemes for traces. Preliminary result show potential to improve the trace clustering quality by inserting experts knowledge.</p>"
7439;en_US;"<p>Dynamically Adaptive system (DAS) support adaptations to deal with changes in the user requirement and the environments constraints at runtime. A DAS can have high dynamicity of its configurations at runtime, so a major challenge is to perform quality assurance activity. In the literature, approaches that perform runtime testing mostly uses the DAS operational context to generate test plans, then missing other relevant runtime data (e.g., violation of behavioral properties) in the process. Therefore, this master thesis proposes an approach that monitors behavioral properties and use its result to improve the selection and execution of tests at runtime. Thus, the main contribution is the identification of failures in the adaptation mechanism during the DAS execution.</p>"
7440;en_US;"<p>Joining actors and artifacts through a common technological platform has been the strategy used by large software company, creating software ecosystem (SECO). This approach also encompasses the field of digital game. Focusing on the Brazilian scenario, this work aims to develop a business model for digital game independent studios, using the concepts from SECO research and practice. To do so, it is necessary to explore the Brazilian scenario, mapping its characteristics and later creating a specialized business model. Design Science Research (DSR) is used to support our research.</p>"
7441;en_US;"<p>This paper reports a PhD work about accountability and Information system (IS). We highlight the need for a research agenda where complex system must value three accountability fundamentals as a way to improve sustainability in system: engagement, management of activity and compliance. In order to do so, we propose to extend the meaning of accountability and elaborate a framework for evaluating accountability in IS.</p>"
7442;en_US;"<p>Brazilian National Health System has been treated as a priority in discussions of political agendas and still lives with precariousness. Solutions to related problem in most cases suggest the implementation of Health Information system. The question is such implementation, or any other underlying activity, should not be limited strictly to a technical perspective. The aim of this work is to investigate the emergent complexity of relationships in digital ecosystem, using the Brazilian Public Health Digital Ecosystem as a scenario in order to contribute with a sociotechnical view on the theme.</p>"
7443;en_US;"<p>Recent studies in social innovation ecosystem research area claim for new technological solutions for providing support to social innovation actors in order to foster collaboration, cocreation, and knowledge and competencies sharing inside these environments. Such support aims at improving the development of social innovation project, the dissemination and generation of more effective social innovations, and the use of existing knowledge. This PhD research proposes an approach for exploring digital ecosystem concepts to build a solution to support a Social Innovation Digital Ecosystem where social innovation actors interact and collaborate through the support provided by a common technological platform.</p>"
7444;en_US;"The interest in system-of-system (SoS) has been increasing as this approach allows the development of system with capabilities that are possible only through a set of constituent system working together. However, these types of system run under high uncertainty, since constituent system are independent and their behavior over time is unknown. Thus, a SoS must be able to readapt itself in the face of situations that cause failures. To this end, this PhD work proposes a fault avoidance and fault tolerance architecture for dealing with misbehavior of constituent system in SoS."
7445;en_US;"<p>This study aimed to analyze the dynamics of professionals in software teams from a model called Adaptive Competencies. For this, we adopt teams as Complex Adaptive system (CAS). From a qualitative approach, involving semi-structured and quantitative observations, and interviews, including multivariate analyzes, it was possible to construct the components that make up the model, their relationships and the types of agent that make up the SAC. The result advance towards the improvement of policies and practices of project management and teams in Information system (IS).</p>"
7446;en_US;"<p>Machine learning has been widely used in the detection of socialbots in Online Social network. This paper presents the use of an algorithm committee to improve the accuracy of socialbots identification. The committee combines the knowledge obtained by machine learning algorithm and human heuristic knowledge obtained through interviews and formalized in fuzzy rule. result show that these approaches are complementary, since their use in a single committee presents accuracy above 93%, better than each of the algorithm independently.</p>"
7447;en_US;"<p>This work presents a case study on the implementation of the ManGve Framework in a public organization located in Recife, Pernambuco. The purpose of this project is to make explicit the effectiveness of ManGve in an initially problematic and poorly organized environment, reporting through its practical methodology all the steps taken during the implementation process of Agile ICT Governance. All the procedures performed during a period of about two months will be reported, selecting the main problem encountered and analyzing all deliveries of values acquired by the organization in its management and use of ICT assets.</p>"
7448;en_US;"<p>This paper presents an agile process that aims to allow the management and development of software for software development company. The qualitative and quantitative work methodology was based on a descriptive case study on a process of management and development of agile software. Taking into account these concepts, the proposal of the Scrum Iteration Driven Development (SIDD) is to be an agile process capable of directing development and management activity, as well as taking into account the company context. To disseminate the result of the work, an interactive presentation area of the SIDD process was developed with information related to the software development and management process.</p>"
7449;en_US;"<p>The Food and Nutrition Units (UAN) produce and distribute meals to people in establishments such as universities, hospitals and social centers. The UANs management is performed by a nutritionist and includes tasks such as selecting menus, staff management, food preparation and efficient use of ingredients. These tasks require an effort that could be reduced by using an Information System. The purpose of this paper is to present the development of the Integrated System of Management of Food and Nutrition Units (SIGUAN) that aims to assist the nutritionist in the elaboration and prescription of menus and in the management of an UAN. The SIGUAN was evaluated through the execution of a controlled experiment in terms of usability, utility and productivity compared to the traditional approach employed in the university restaurant of EAJ-UFRN. The result of the evaluation showed that SIGUAN achieved its objectives.</p>"
7450;en_US;"<p>This article addresses the dissemination of public data as a mechanism that strengthens democracy. Its availability should occur in a clear way, allowing a greater engagement of society in its reuse in social control project. The development of creative technological solutions can provide a better manipulation of such data, as the proposed application.</p>"
7451;en_US;"<p>We propose Colabore! platform whose objective is to offer means for identification and collaboration between specialists to find out the solution of a problem. After reporting a new problem and the fields of knowledge needed, the platform will suggest a group of professionals qualified to solve it.</p>"
7452;en_US;"<p>This article aims to describe the development of an application, an API and a WEB application that refers to the mapping of the primary health care network, using data from the Family Health Program (FHP). From there, the application was built using the NET Core, IONIC and Angular framework. Key elements for the platform were available: priority groups of primary care, such as status, description and geolocation. The platform aimed to facilitate the management made by health professionals, in addition to synchronization and integrality with external application.</p>"
7453;en_US;"<p>EduSearch allows user to search and view the scientific articles of journals classified in the Qualis Education of the 2013-2016 quadrennium, also displaying their international classification indexes and their strata.</p>"
7455;en_US;"<p>This article presents a tool for automating security analysis in mobile application aimed at the android operating system. Automating the tool Androguard, Androbus and Androwarn we developed the MobiSec that is based on a test plan for execution.</p>"
7456;en_US;"<p>Medicaments adverse effects result from different factors. Pharmacovigilance is the health area responsible for the collection, detection, assessment, monitoring, and prevention of medicaments side effects, and also they audit medicaments production by pharmaceutics. We present PharmaSpy, an IS which aims to support ANVISA on its auditing process at Brazil, decreasing risks for patient.</p>"
7457;en_US;"<p>This article presents a tool for decision making based on the union of the Project Management Guide (PMBOK) and the Scrum methodology, called Project Social Network (PSN). Focusing on adapting them to the reality of small and medium-sized enterprises (SMEs). We propose through PSN, a way to manage and develop software, following a simple model and adaptable to the reality of SMEs.</p>"
7458;en_US;"<p>Human milk banks form an extensive and complex network that provides essential service to the country that ensures that newborns and mothers can fully enjoy the benefits of breast milk. These centers serve millions of people annually using thousands of liters of human milk. Thus, in this work we aim to create a breast milk distribution management system, using artificial intelligence to predict shortages, the use of geographic information to help locate human milk centers and provide essential information about motherhood and breastfeeding.</p>"
7459;en_US;"<p>Due to the difficulties faced by undergraduate student, the Via Universitária is a platform seeking to make their day to day lives easier, offering 4 core service: Rooms for rental, classes schedule, events available nearby and carpool rides.</p>"
7460;en_US;"<p>Context. The low quality education indices in Brazil demonstrate the damages arising from a sector formed by complex administrative layers and low transparency. Objetive. Through an application whose lovely name is also your mascot, the Duca, facilitate cooperation and social control of the population, as well as direct actions by the control organization, justice and executive. Method. Beyond to the agile construction of the application, an evaluative case study was conducted with a state public school, in which teachers, student and parents suggested corrections and improvements. result. The application, as a participatory collaboration tool, promotes the engagement of the school community, changing the life of this community with innovative aspects, among which the possibilities of visualization the oficial menu school lunch and of application of dynamic surveys. Conclusion. Bringing civil society closer together with governing, the application raise the public governance at the economic, social and academic levels on the perspective of planning more efficient and effective.</p>"
7461;en_US;"<p>Fish consumption is increasing, especially with extractive fisheries. However, many consumers find it difficult to identify fish due to a wide variety of species. In this context, this work aims to develop an application to assist fishermen and the general population in the identification of the fish species of the São Francisco River. For this, Artificial Intelligence (AI) as machine learning technique are applied to create a classifier based on Convolutional Neural Network. The application contains innovative aspects, enabling an individual, with no prior knowledge, to use the application to: (I) recognize and describe the species, (II) inform the approximate size of the fish, (III) indicate nutritional information and (IV) recommend ways to cook the fish. This application introduces evidence of positive impacts in the social, academic and economic area of the Baixo São Francisco region.</p>"
7462;en_US;"<p>Galactus is a designed, integrating environment with the capacity to store all the digital collection of investigative bodies or departments that operate with the activity of Public Security Intelligence (PSI). The Prosecution Office of Sergipe has used this technological environment to prospect and discover essential information to the investigative process. Daily case studies have presented result that demonstrate the inherent need of the investigator to possess a unique modal of search.</p>"
